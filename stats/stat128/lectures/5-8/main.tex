\documentclass{report}

\input{~/dev/latex/template/preamble.tex}
\input{~/dev/latex/template/macros.tex}

\title{\Huge{}}
\author{\huge{Nathan Warner}}
\date{\huge{}}
\pagestyle{fancy}
\fancyhf{}
\lhead{Warner \thepage}
\rhead{}
% \lhead{\leftmark}
\cfoot{\thepage}
\setborder
% \usepackage[default]{sourcecodepro}
% \usepackage[T1]{fontenc}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

\begin{document}
    % \maketitle
        \begin{titlepage}
       \begin{center}
           \vspace*{1cm}
    
           \textbf{Chapters 5-8}
    
           \vspace{0.5cm}
           Stat 128: Elementary Statistics
            
                
           \vspace{1.5cm}
   
           A Document By: \\
           \textbf{Nathan Warner}
    
           \vfill
                
                
           \vspace{0.8cm}
         
           \includegraphics[width=0.4\textwidth]{../1-4/figures/2.png} \\
            July 03, 2023  \\
           Computer Science \\
           Joliet Junior College \\
           United States\\
           
                
       \end{center}
    \end{titlepage}
    \tableofcontents
    \pagebreak \bigbreak \noindent
    \section{Chapter 5}
    \bigbreak \noindent 
    \subsection{5.1: Probability Rules}
    \bigbreak \noindent 
    \textbf{\textit{\underline{Learning Objectives For This Section:}}}
    \begin{enumerate}
        \item \textbf{Understand Random Processes and the Law of Large Numbers}
        \item \textbf{Apply the Rules of Probabilities}
        \item \textbf{Compute and Interpret Probabilities Using the Empirical Method}
        \item \textbf{Compute and Interpret Probabilities Using the Classical Method}
        \item \textbf{Recognize and Interpret Subjective Probabilities}
    \end{enumerate}
    \bigbreak \noindent 
    \textbf{Vocab:}
    \begin{itemize}
        \item \textbf{Simulation:} is a technique used to recreate a random event.
        \item \textbf{Random Process:} represents scenarios where the outcome of any particular trial of an experiment is unknown, but the proportion (or relative frequency) a particular outcome is observed approaches roaches a specific value
        \item \textbf{Probability:} Is the measure of the likelihood of a random phenomenon or chance behavior occurring. It deals with experiments that yield random short-term results or outcomes yet reveal long-term predictability. The long-term proportion in which a certain outcome is observed is the probability of that outcome. 
        \item \textbf{Outcomes:} Short term results
        \item \textbf{The Law of Large Numbers:} As the number of repetitions of a probability experiment increases, the proportion with which a certain outcome is observed gets closer to the probability of the outcome.
        \item \textbf{an experiment} is any process with uncertain results that can be repeated.
        \item \textbf{The sample space, $S$,} of a probability experiment is the collection of all possible outcomes for that experiment.
        \item \textbf{An event} is any collection of outcomes from a probability experiment. An event consists of one or more outcomes. We denote events with one outcome, sometimes called simple events, as $e_{i}$. In general, events are denoted using capital letters such as $ E$.
        \item \textbf{A probability model} lists the possible outcomes of a probability experiment and each outcome's probability. A probability model must satisfy Rules 1 and 2 of the rules of probabilities.
        \item  \textbf{An unusual event} is an event that has a low probability of occurring.
        \item An experiment has \textbf{equally likely outcomes} when each outcome has the same probability of occurring. 
        \item A \textbf{subjective probability} is a probability that is determined based on personal judgment.
    \end{itemize}

    \pagebreak \bigbreak \noindent
    \textbf{Formulas:}
    \begin{itemize}
        \item Computing probability with the empirical method
        \begin{align*}
            P(E) = \text{Relative frequency of E} = \frac{Frequency\ of\ E}{number\ of\ trials\ of\ experiment}
        .\end{align*}
        \item Computing Probability With The Classical Method
            \begin{itemize}
                \item If an experiment has n equally likely outcomes and if the number of ways that an event E can occur is m, then the probability of E,P(E), is
            \end{itemize}
            \begin{align*}
                P(E) = \frac{\text{number of ways that $E$ can occur}}{\text{number of possible outcomes}} = \frac{m}{n}
            .\end{align*}
            \begin{itemize}
                \item So, if S is the sample space of this experiment, then
                    \begin{align*}
                        P(E) = \frac{N(E)}{N(E)}
                    .\end{align*}
            where N(E) is the number of outcomes in E, and N(S) is the number of outcomes in the sample space.
            \end{itemize}
    \end{itemize}


    \pagebreak \bigbreak \noindent
    \textbf{\textit{\underline{Objective 1: Understand Random Processes and the Law of Large Numbers:}}}
    \bigbreak \noindent 
    Refer to vocab above for definition on the law of large numbers.
    \bigbreak \noindent 
    \qs{}{Brad and Allison have three girls. Brad tells Allison that he would like one more child because they are due to have a boy. What do you think of​ Brad's logic? }
    \bigbreak \noindent 
    Brad is incorrect due to the nonexistent Law of Averages. The fact that Brad and Allison had three girls in a row does not matter. The likelihood the next child will be a boy is about 0.5.

    \bigbreak \noindent 
    \begin{mdframed}
        \textbf{Example: A probability experiment consists of rolling a single six-sided fair die. A fair die is one in which each possible outcome is equally likely. For example, rolling a two is just as likely as rolling a five.}
      \bigbreak \noindent 
      \textbf{a.)  Identify the outcomes of the probability experiment. }
      \bigbreak \noindent 
      \textbf{b.) Identify the sample space}
      \bigbreak \noindent 
      \textbf{c.) Define the event $E$=“roll an even number”.}
      \bigbreak \noindent 
      \textbf{A.)} The outcomes from rolling a single fair die are $e_1=\text{``rolling a one''}=\{1\}$, $e_2=\text{``rolling a two''}=\{2\}$, $e_3=\text{``rolling a three''}=\{3\}$, $e_4=\text{``rolling a four''}=\{4\}$, $e_5=\text{``rolling a five''}=\{5\}$, and $e_6=\text{``rolling a six''}=\{6\}$.
      \bigbreak \noindent 
      \textbf{B.)} The set of all possible outcomes forms the sample space, $S=\{1,2,3,4,5,6\}$. There are six outcomes in the sample space.
      \bigbreak \noindent 
      \textbf{C.)} The event E=“roll an even number"$=\{2,4,6\}$.
    \end{mdframed}

    \bigbreak \noindent 
    \qs{}{If a person rolls a 6 sided dice and then flips a coin, describe the sample space of possible outcomes.
        \bigbreak \noindent 
        \textbf{Solution:}
        \bigbreak \noindent 
        The sample space is $\{1H,1T,2H,2T,3H,3T,4H,4T,5H,5T,6H,6T\}$
    }

    \pagebreak \bigbreak \noindent
    \textbf{\textit{\underline{Apply the Rules of Probabilities:}}}
    \bigbreak \noindent 
    In the following probability rules, the notation $P(E)$ means “the probability that event E occurs.”
    \bigbreak \noindent 
    \textbf{Rules of Probability:}
    \begin{enumerate}
        \item The probability of any event E, $P(E)$, must be greater than or equal to 0 and less than or equal to 1. That is, $0 \leq P(E) \leq 1$.
        \item The sum of the probabilities of all outcomes must equal 1. That is, if the sample space $S = \{e_1, e_2, \dots, e_n\}$, then
            \begin{align*}
                P(e_1) + P(e_2) + \dots + P(e_n) = 1.
            .\end{align*}
    \end{enumerate}
    \bigbreak \noindent 
    \begin{mdframed}
      \textbf{Example: Probability Model:}
      \bigbreak \noindent 
      In a bag of peanut candies, the colors of the candies can be brown, yellow, red, blue, orange, or green. Suppose that a candy is randomly selected from a bag. The table shows each color and the probability of drawing that color. Verify that this is a probability model.
      \bigbreak \noindent 
      \begin{center}
          \begin{center}
              \begin{tabular}{|l|c|}
              \hline
              Color & Probability \\
              	\hline
               	 Brown  & 0.12  \\
              	\hline
              	 Yellow & 0.15 \\
              	 \hline 
              	 Red & 0.12 \\
              	 \hline
              	 Blue & 0.23 \\
              	 \hline
              	 Orange & 0.23 \\
              	 \hline
              	 Green & 0.15 \\
              	 \hline
              \end{tabular}
          \end{center}
      \end{center}
      \bigbreak \noindent 
      \textbf{Solution:}
      \bigbreak \noindent 
        Rule 1 is satisfied because all probabilities are between 0 and 1, inclusive.
          \bigbreak \noindent 
          Rule 2 is satisfied because $\sum P(E)= 1$
    \end{mdframed}

    \bigbreak \noindent 
    \textbf{Key Concepts Regarding Probabilities}
    \bigbreak \noindent 
    \begin{itemize}
        \item If an event is impossible, the probability of the event is 0.
        \item If an event is a certainty, the probability of the event is 1.
        \item The closer a probability is to 1, the more likely the event will occur.
        \item The closer a probability is to 0, the less likely the event will occur.
        \item For example, an event with probability 0.8 is more likely to occur than an event with probability 0.75.
        \item An event with probability 0.8 will occur about 80 times out of 100 repetitions of the experiment, whereas an event with probability 0.75 will occur about 75 times out of 100.
    \end{itemize}

    \pagebreak \bigbreak \noindent
    \qs{}{In a certain card​ game, the probability that a player is dealt a particular hand is 0.46 . Explain what this probability means. If you play this card game 100​ times, will you be dealt this hand exactly  ​ 46 times? Why or why​ not?
        \bigbreak \noindent 
        \textbf{Solution:}
        \bigbreak \noindent 
        The probability  0.46 means that approximately  46 out of every 100 dealt hands will be that particular hand.​ No, you will not be dealt this hand exactly 46 times since the probability refers to what is expected in the​ long-term, not​ short-term.
    }

    \bigbreak \noindent \bigbreak \noindent 
    \textbf{Unusual Event}
    \bigbreak \noindent 
    Typically, an event with a probability less than 0.05 (or 5\%) is considered unusual, but this cutoff point is not set in stone. The researcher and the context of the problem determine the probability that separates unusual events from not so unusual events.

    \bigbreak \noindent \bigbreak \noindent 
    \textbf{The three methods for determining the probability of an event:}
    \bigbreak \noindent 
    \begin{itemize}
        \item the Empirical Method
        \item the Classical Method
        \item the Subjective Method
    \end{itemize}

    \bigbreak \noindent 
    \textbf{Approximating Probabilities Using the Empirical Approach:}
    \bigbreak \noindent 
    The probability of an event E occurring is approximately the number of times event E is observed divided by the number of repetitions (or trials) of the experiment.
    \begin{align*}
        P(E) = \text{Relative frequency of E} = \frac{Frequency\ of\ E}{number\ of\ trials\ of\ experiment}
    .\end{align*}

    \bigbreak \noindent 
    \nt{When we find probabilities using the empirical approach, the result is approximate because different trials of the experiment lead to different outcomes and, therefore, different estimates of $P(E)$}

    \bigbreak \noindent 
    Surveys are probability experiments. Why? Each time a survey is conducted, a different random sample of individuals is selected. Therefore, the results of a survey are likely to be different each time the survey is conducted because different people are included.
    \pagebreak \bigbreak \noindent
    \textbf{\textit{\underline{Compute and Interpret Probabilities Using the Classical Method}}}
    \bigbreak \noindent 
    The empirical method gives an approximate probability of an event by conducting a probability experiment. The classical method of computing probabilities does not require that a probability experiment actually be performed. Rather, it relies on counting techniques.
    \bigbreak \noindent 
    The classical method of computing probabilities requires equally likely outcomes. An experiment has equally likely outcomes when each outcome has the same probability of occurring. For example, when a fair die is thrown once, each of the six outcomes in the sample space, {1,2,3,4,5,6}, has an equal chance of occurring
     Computing Probability With The Classical Method
     \bigbreak \noindent 
     If an experiment has n equally likely outcomes and if the number of ways that an event E can occur is m, then the probability of E,P(E), is
    \begin{align*}
        P(E) = \frac{\text{number of ways that $E$ can occur}}{\text{number of possible outcomes}} = \frac{m}{n}
    .\end{align*}
    \bigbreak \noindent 
         So, if S is the sample space of this experiment, then
            \begin{align*}
                P(E) = \frac{N(E)}{N(E)}
            .\end{align*}
    where N(E) is the number of outcomes in E, and N(S) is the number of outcomes in the sample space.

    \bigbreak \noindent \bigbreak \noindent 
    \textbf{Comparing Empirical Probabilities and Classical Probabilities}
    \bigbreak \noindent 
    We just saw that the classical probability of rolling a seven is 16≈0.167. Suppose a pit boss at a casino rolls a pair of dice 100 times and obtains 15 sevens. From this empirical evidence, we would assign the probability of rolling a seven as 15100=0.15. If the dice are fair, we would expect the relative frequency of sevens to get closer to 0.167 as the number of rolls of the dice increases. In other words, the empirical probability will get closer to the classical probability as the number of trials of the experiment increases due to the Law of Large Numbers. If the two probabilities do not get closer, we may suspect that the dice are not fair.
    \bigbreak \noindent 
    \nt{In simple random sampling, each individual has the same chance of being selected. Therefore, we can use the classical method to compute the probability of obtaining a specific sample.}

    \bigbreak \noindent \bigbreak \noindent 
    \textbf{\textit{\underline{Recognize and Interpret Subjective Probabilities}}}
    \bigbreak \noindent 
    If a sports reporter is asked what he thinks the chances are for the Boston Red Sox to play in this season's World Series, the reporter would likely process information about the Red Sox (pitching staff, leadoff hitter, and so on) and then make an educated guess of the likelihood. The reporter may respond that there is a 20\% chance the Red Sox will play in the World Series. This forecast is a probability, although it is not based on relative frequencies. We cannot, after all, repeat the experiment of playing a season under the same circumstances (same players, schedule, and so on) over and over. Nonetheless, the forecast of 20\%=0.20 does satisfy the criterion that a probability be between 0 and 1, inclusive. This forecast is known as a subjective probability.
    \bigbreak \noindent r
    Subjective probabilities are legitimate and are often the only method of assigning likelihood to an outcome. For instance, a financial reporter may ask an economist about the likelihood of the economy falling into recession next year. Again, we cannot conduct an experiment n times to find a relative frequency. The economist must use knowledge of the current conditions of the economy and make an educated guess about the likelihood of recession.

        \pagebreak \bigbreak \noindent
    \subsection{5.2: The Addition Rule and Complements}
    \bigbreak \noindent 
    \textbf{\textit{\underline{Learning Objectives For This Section:}}}
    \begin{enumerate}
      \item \textbf{Use the Addition Rule for Disjoint Events}
      \item \textbf{Use the General Addition Rule}
      \item \textbf{Compute the Probability of an Event Using the Complement Rule}
    \end{enumerate}
    \bigbreak \noindent 
    \textbf{Vocab:}
    \begin{itemize}
      \item \textbf{Disjoint:} Two vents are disjoint if they have no outcomes in common. 
      \item \textbf{Mutually Exclusive:} Another name for disjoint events.
        \item \textbf{Complement of $E$:} Let $S$ denote the sample space of a probability experiment and let $E$ denote an event. The complement of $E $, denoted $E^{C} $, is all outcomes in the sample space $S $ that are not outcomes in the event $E $.
    \end{itemize}
    \bigbreak \noindent 
    \textbf{Formulas:}
    \begin{itemize}
        \item Addition Rule for Disjoint Events:
            \begin{itemize}
                \item if $E $ and $F $ are disjoint (or mutually exclusive) events, then:
                    \begin{align*}
                        P(E\ or\ F) = P(E) + P(F)
                    .\end{align*}
            \end{itemize}
        \item Complement Rule:
            \begin{itemize}
                \item If E represents any event and EC represents the complement of E, then
            \end{itemize}
            \begin{align*}
                P(E^{C}) = 1-P(E)                
            .\end{align*}
    \end{itemize}

    \pagebreak \bigbreak \noindent
    \textbf{\textit{\underline{Use the Addition Rule for Disjoint Events}}}
    \thmcon{\textbf{\textit{\underline{Definition: Addition Rule for Disjoint Events}}}
    \bigbreak \noindent
    If $E $ and $F $ are disjoint (or mutually exclusive) events, then:
    \begin{align*}
        P(E\ or\ F) = P(E) + P(F)
    .\end{align*}
    } 
    \bigbreak \noindent 
    We often draw  pictures of events using \textbf{Venn Diagrams}. These pictures represent events as circles enclosed in a rectangle. The
    rectangle represents the sample space, and each circle represents an event. For example, suppose we randomly select a 
    chip from a bag where each chip in the bag is labeled 0,1,2,3,4,5,6,7,8,9. Let $E $ represent the event "Choose a number less than or equal to 2",
    and let $F $ represent the event "Choose a number greater than or equal to 8." These events are disjoint as shown in the figure.
    \bigbreak \noindent 
    \textit{Figure:}
    \begin{figure}[ht]
        \centering
        \incfig{figab}
        \label{fig:figab}
    \end{figure}
    \bigbreak \noindent 
    So you can see that these events are \textbf{Disjoint} because they \textbf{do not} share any outcomes.
    \bigbreak \noindent 
    We can then compute the probability of event $E$ using the classical approach
    \begin{align*}
        P(E) = \frac{N(E)}{N(S)} = \frac{3}{10} = 0.3
    .\end{align*}
    \bigbreak \noindent 
    Similarly,  if we wanted to know the probability of event $F$: 
    \begin{align*}
        P(F) = \frac{N(F)}{N(S)} = \frac{2}{10} = 0.2
    .\end{align*}
    \bigbreak \noindent 
    What if we wanted to know the probability of $E$ \textbf{or} $F $? ($P(E\ or\ F)$):
    \begin{align*}
        P(E\ or\ F) = \frac{N(E\ or\ F)}{N(S)} = \frac{5}{10} = 0.5 
    .\end{align*}
    \bigbreak \noindent 
    However, we can use the \textbf{Addition Rule}, which goes like:
    \begin{align*}
     P(E\ or\ F) = P(E) + P(F) = 0.3 + 0.2  \\
     = 0.5
    .\end{align*}

    \pagebreak \bigbreak \noindent
    \textbf{\textit{\underline{Compute the Probability of an Event Using the Complement Rule}}}
    \bigbreak \noindent 
    Suppose that the probability of an event $E $ is known and we would like to determine the probability that $E $ does not occur. This can be accomplished using the idea of complements.
    \bigbreak \noindent 
    Because $E$ and $E^{C}$ are mutually exclusive,
    \thmcon{\textbf{\textit{\underline{Definition:}}}
    \bigbreak \noindent
     \textbf{Complement Rule:}
    \begin{itemize}
        \item If $E$ represents any event and $E^{C} $ represents the complement of $E$, then
    \end{itemize}
    \begin{align*}
        P(E^{C}) = 1-P(E)                
    .\end{align*}

    }
    \bigbreak \noindent 
      \textbf{Example: Compliment Rule}
      \bigbreak \noindent 
      Suppose 31.6\% of American households own a dog. What is the probability that a randomly selected household \textbf{does} not own a dog?
      \begin{align*}
          P(E^{C}) = 1 - P(E) \\
          = 1- 0.36 \\
          =0.684
      .\end{align*}
    \bigbreak \noindent 
      \textbf{Example: Compliment Rule:}
      \bigbreak \noindent 
      Let:
      \begin{align*}
          S=\{9,10,11,12,13,14,15,16,17,18,19,20\} \\
          E=\{11,12,13,14,15,16,17,18,19\}
      .\end{align*}
      Assume each outcome is equally likely. List the outcomes in $E^{C} $ Find $P(E^{C})$
      \begin{align*}
          P(E) = \frac{9}{12} = \frac{3}{4} = 0.75 \\
          P(E^{C}) =1- 0.75 \\
          = 0.25
      .\end{align*}

    \pagebreak \bigbreak \noindent
    \subsection{ 5.3: Independence and the Multiplication Rule}
    \bigbreak \noindent 
    \textbf{\textit{\underline{Learning Objectives For This Section:}}}
    \begin{enumerate}
        \item \textbf{Identify Independent Events}
        \item \textbf{Compute At-least Probabilities}
        \item \textbf{Use the Multiplication Rule for Independent Events}
    \end{enumerate}
    \bigbreak \noindent 
    \textbf{Vocab:}
    \begin{itemize}
        \item \textbf{Two events being Independent: } Two events $E$ and $F$ are independent if the occurrence of event $E$ in a probability experiment does not affect the probability of event $F $.
        \item \textbf{Two events being Dependent:} Two events are dependent if the occurrence of event $E $ in a probability experiment affects the probability of event $F$.
    \end{itemize}
    \bigbreak \noindent 
    \textbf{Formulas:}
    \begin{itemize}
        \item If $E$ and $F$ are independent events, then
    \begin{align*}
         P(E \text{ and } F) = P(E) \cdot P(F) 
    .\end{align*}
    \bigbreak \noindent 
    \item If $E_1, E_2, E_3, \ldots, E_n$ are independent events, then
    \begin{align*}
         P(E_1 \text{ and } E_2 \text{ and } E_3 \text{ and } \ldots \text{ and } E_n) = P(E_1) \cdot P(E_2) \cdot \ldots \cdot P(E_n)
    .\end{align*}

        
    \end{itemize}
    \pagebreak \bigbreak \noindent
    \textbf{\textit{\underline{Identify Independent Events}}}
    \bigbreak \noindent 
    \textbf{Example A:} Suppose you draw a card from a standard 52-card deck of cards and then roll a die. The events "draw a heart" and "roll a number" are \textbf{independent} because the results of choosing a card do not impact the results of the die toss.
    \bigbreak \noindent 
    \textbf{Example B:} Suppose two 40-year old women who live in the United States are randomly selected. The events "woman 1 survived the year" and "women 2 survives the year" are \textbf{independent}
    \bigbreak \noindent 
    \textbf{Example C:} Suppose two 40-year old women live in the same apartment complex. The events "woman 1 survived the year" and "women 2 survives the year" are \textbf{dependent}
      
    \bigbreak \noindent 
    \nt{When we take small samples from large finite populations, we make the assumption of independence even though the events are technically dependent.
        \bigbreak \noindent 
        As a general rule of thumb, if the sample size $n $ is no more than 5\% of the population $N $ ($n \leq 0.05 N $), we assume independence.

    }

    \bigbreak \noindent 
    \qs{}{Determine whether the events E and F are independent or dependent. Justify your answer.
        \bigbreak \noindent 
        \begin{center}
            E: A person having an at-fault accident \\
            F: The same person being prone to road rage
        \end{center}
        \bigbreak \noindent 
        \textbf{Solution:}
        E and F are dependent because  being prone to road rage can affect the probability of a person having an at-fault accident
        \bigbreak \noindent 
        \begin{center}
            E: A randomly selected person coloring her hair black. \\
            F: A different randomly selected person coloring her hair blond.
        \end{center}
        \bigbreak \noindent 
        \textbf{Solution:}
        E cannot affect F and vice versa because the people were randomly​ selected, so the events are independent.
        \bigbreak \noindent 
        \begin{center}
            E: The rapid spread of a cocoa plant disease \\
            F: The price of chocolate
        \end{center}
        \bigbreak \noindent 
        \textbf{Solution:}
        \text{The rapid spread of a cocoa plant disease could affect the price of chocolate, so } $\mathrm{E}$ \text { and } $\mathrm{F}$ \text {are dependent.}

}
    \pagebreak \bigbreak \noindent
    \textbf{ Disjoint (or Mutually Exclusive) Events versus Independent Events}
    \bigbreak \noindent 
    Disjoint events and independent events are different concepts.
    \begin{itemize}
        \item Recall that two events are disjoint if they have no outcomes in common, that is, if knowing that one of the events occurs, we know that the other event did not occur.
        \item Independence means that one event occurring does not affect the probability of the other event occurring.
    \end{itemize}
    \bigbreak \noindent 
    Therefore, knowing that two events are disjoint means that the events are not independent.
    \bigbreak \noindent 
    Consider the experiment of rolling a single die. Let $E$ represent the event "roll an even number" and let $F$ represent the event "roll an odd number." We can see that $E$ and $F$ are disjoint (mutually exclusive) because they have no outcomes in common. In addition, $P(E)=\frac{1}{2}$ and $P(F)=\frac{1}{2}$. However, if we are told that the roll of the die is going to be an even number, then what is the probability of event $F$? Because the outcome will be even, the probability of event $F$ is now 0 (and the probability of event $E$ is now 1). So knowledge of event $E$ changes the likelihood of observing event $F$.

    \bigbreak \noindent \bigbreak \noindent 
    \textbf{\textit{\underline{Use the Multiplication Rule for Independent Events}}}
    \bigbreak \noindent 
    Suppose that you flip a fair coin twice. What is the probability that you obtain a head on both flips, that is, a head on the first flip and a head on the second flip? If $H$ represents the outcome "heads" and $T$ represents the outcome "tails," then the sample space of this experiment is
    \begin{align*}
        S={HH,HT,TH,TT}
    .\end{align*}
    \bigbreak \noindent 
    There is one outcome with both heads. Because each outcome is equally likely, we have
    \begin{align*}
        P(\text{heads on Flip 1 and heads on Flip 2})=\frac{N(\text{heads on Flip 1 and heads on Flip 2})}{N(S)} \\ =\frac{1}{4}
    .\end{align*}
    \bigbreak \noindent 
    We may have intuitively figured this out by recognizing $P(\text{head})=\frac{1}{2}$ for each flip. So it seems reasonable that
    \begin{align*}
        P(\text{heads on Flip 1 and heads on Flip 2})=P(\text{heads on Flip 1})\cdot P(\text{heads on Flip 2})\\ =\frac{1}{2}\cdot\frac{1}{2}\\ =\frac{1}{4}
    .\end{align*}
    \bigbreak \noindent 
    Because both approaches result in the same answer, we conjecture that $P(E \text{ and } F)=P(E)\cdot P(F)$, which is true.
    \pagebreak \bigbreak \noindent
    \thmcon{\textbf{\textit{\underline{Definition: Multiplication Rule for Independent Events}}}
    \bigbreak \noindent
    If $E$ and $F$ are independent events, then
    \begin{align*}
         P(E \text{ and } F) = P(E) \cdot P(F) 
    .\end{align*}
    \bigbreak \noindent 
    If $E_1, E_2, E_3, \ldots, E_n$ are independent events, then
    \begin{align*}
         P(E_1 \text{ and } E_2 \text{ and } E_3 \text{ and } \ldots \text{ and } E_n) = P(E_1) \cdot P(E_2) \cdot \ldots \cdot P(E_n)
    .\end{align*}
    }
    \bigbreak \noindent \bigbreak \noindent 
    \qs{}{Suppose that events $E$  $F$ are independent,  $P(E)=0.6$ and $P(F)=0.7$ What is the $P(E\ and\ F)$?
        \bigbreak \noindent 
        \begin{align*}
            P(E\ and\ F)  = P(E) \cdot P(F) = 0.6 \cdot 0.7 = 0.42
        .\end{align*}
    }

    \bigbreak \noindent \bigbreak \noindent 
    \textbf{\textit{\underline{Compute At-least Probabilities}}}
    \bigbreak \noindent 
    Usually, when computing probabilities involving the phrase at least, use the Complement Rule.
    \bigbreak \noindent 
    The phrase at least means “greater than or equal to.” For example, a person must be at least 17 years old to see an R-rated movie. This means that the person's age must be greater than or equal to 17 to watch the movie.
    \bigbreak \noindent \bigbreak \noindent 
    \qs{}{The probability that a randomly selected female aged 60 years will survive the year is 0.99186 according to the National Vital Statistics Report. What is the probability that at least one of 500 randomly selected 60-year-old females will die during the course of the year?
        \bigbreak \noindent 
        \textbf{Solution:}
        \bigbreak \noindent 
        The phrase at least means “greater than or equal to,” so we want to know the probability that 1 or 2 or 3 or ⋯ or 500 60-year-old females will die during the year. These events are mutually exclusive, so
        \begin{align*}
            P(1 \text{ or } 2 \text{ or } 3 \text{ or } \dots \text{ or } 500 \text{ die}) &= P(1 \text{ dies}) + P(2 \text{ dies}) + P(3 \text{ dies}) + \dots + P(500 \text{ dies})
        .\end{align*}
        Computing these probabilities would be very time-consuming. However, notice that the complement of “at least one dying” is “none die”, or all 500 survive. Use the Complement Rule to compute the probability.
        \bigbreak \noindent 
        So:
        \begin{align*}
            P(\text{at least one dies}) = 1- P(\text{None dies}) \\
            = 1 - (0.99186)^{500} \\
            = 0.9832
        .\end{align*}



    }































\end{document}
