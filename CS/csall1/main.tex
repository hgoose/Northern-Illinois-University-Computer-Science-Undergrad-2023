\documentclass{report}

\input{~/dev/latex/template/preamble.tex}
\input{~/dev/latex/template/macros.tex}

\title{\Huge{}}
\author{\huge{Nathan Warner}}
\date{\huge{}}
\fancyhf{}
\rhead{}
\fancyhead[R]{\itshape Warner} % Left header: Section name
\fancyhead[L]{\itshape\leftmark}  % Right header: Page number
\cfoot{\thepage}
\renewcommand{\headrulewidth}{0pt} % Optional: Removes the header line
%\pagestyle{fancy}
%\fancyhf{}
%\lhead{Warner \thepage}
%\rhead{}
% \lhead{\leftmark}
%\cfoot{\thepage}
%\setborder
% \usepackage[default]{sourcecodepro}
% \usepackage[T1]{fontenc}

% Change the title
\hypersetup{
    pdftitle={CS Complete}
}

\begin{document}
    % \maketitle
        \begin{titlepage}
       \begin{center}
           \vspace*{1cm}
    
           \textbf{Comprehensive CS}
    
           \vspace{0.5cm}
            
                
           \vspace{1.5cm}
    
           \textbf{Nathan Warner}
    
           \vfill
                
                
           \vspace{0.8cm}
         
           \includegraphics[width=0.4\textwidth]{~/niu/seal.png}
                
           Computer Science \\
           Northern Illinois University\\
           United States\\
           
                
       \end{center}
    \end{titlepage}
    \tableofcontents
    \pagebreak 
    \unsect{Theory of Computation}
    \bigbreak \noindent 
    \subsection{Natural Languages, Formal languages: Definitions and theorems}
    \begin{itemize}
        \item \textbf{G\"odel's incompleteness theorem}: 
        G\"odel's Incompleteness Theorems are two fundamental results in mathematical logic that state: 
        \begin{itemize}
            \item  Proved that for some axiomatic
                systems that there is no algorithm
                that will generate all true
                statements from those axioms.
            \item No such system can prove its own consistency.
        \end{itemize}
        This was the first indication that there are inherent limts on algorithms
        \item \textbf{Turing}: Alan Turing later provided formalism to the concepts of an “algorithm” and “computation”, he Invented definition for an abstract machine called the “universal algorithm machine”, he Provided means to formally (i.e., with mathematical rigor) explore the boundaries of what algorithms could, and could not, accomplish. Turing’s model for a universal abstract machine was the basis for the first computer – in fact, Turing was involved in the construction of the first computer.
        \item \textbf{Natural languages}: We communicate via a \textit{natural language}, Although we don’t often think about it, our language is
            guided by rules; spelling, grammar, punctuation
        \item \textbf{Formal language}:
            Formal languages, which are not intended for human-to-
            human communication, are similar to natural languages in
            that they too have rules that define “correct” words and
            statements, but they are also different than natural languages
            in two key ways;
            \begin{itemize}
                \item The rules that define a formal language are strictly enforced. There is no tolerance for misspellings, bad grammar, etc.
                \item For the purpose of determining if a word or statement is
                    acceptable in a formal language, meaning is ignored. Determining
                    if something is (or is not) part of a language is determined by the
                    language’s defining rules which do not attach meaning (i.e., no
                    definitions of words like in natural languages)
            \end{itemize}
            In short, formal languages is a game of symbols, not meaning
        \item \textbf{Formal Languge terminology}:
            \begin{itemize}
                \item \textbf{Symbol}: it is an abstract entity that is not formally defined – like a point or a line in geometry – but think of it as a single character like a letter, numerical digit, punctuation mark, or emoticon
                \item \textbf{String (or Word)}: A finite sequence (i.e., order matters) of zero or more symbols
                \item \textbf{Length}: The length of a string $w$ is denoted by $length(w)$ or $\abs{w}$ and is the number of symbols composing the string. Because strings, by definition, are finite then a string’s lengths is always defined (sometimes zero).
                \item \textbf{Prefix, suffix}: Any number of leading/trailing symbols of the string.
                \item \textbf{Concatenation}: The concatenation of two strings $w$ and $x$ is formed by writing the first string $w$ then the second string $x$
                    \bigbreak \noindent 
                    \textbf{Note:} For any string $w$, $\Lambda w = w\Lambda = w$  
                \item \textbf{Alphabet}: A finite set of symbols, typically denoted by the
                    Greek capital letter sigma $\Sigma$, for example
                    \begin{align*}
                        \Sigma = \{a,b,c\} \quad \Sigma = \{0,1\} \quad \Sigma = \varnothing \quad \text{(special case)}
                    .\end{align*}
            \end{itemize}
        \item \textbf{The empty string}:  A string with zero symbols is called the empty string
            and is denoted by the capital Greek letter lambda $\Lambda$, or sometimes
            lower case Greek letter epsilon $\epsilon$, where $\Lambda$ and $\epsilon$ are \textbf{not} symbols
            \bigbreak \noindent 
            Thus,
            \begin{align*}
                \abs{\Lambda} = 0
            .\end{align*}
        \item \textbf{Formal language definition}: A formal language is a et of strings from some \textbf{one} alphabet. Given an alphabet we generally define a formal language over that alphabet by
            specifying rules that either;
            \begin{enumerate}
                \item Tell us how to test a candidate word, or
                \item Tell us how to construct all words.
            \end{enumerate}
            For example, Given $\Sigma_{1}= \{x\} $, we can define languages
            \begin{align*}
                L_{1} &= \text{ any non empty string } = \{x, xx, xxx,...\} \\
                L_{2} &= \{X^{n}:\ x = 2k+1,\ k\in \mathbb{Z} \} = \{x,xxx,xxxxx,xxxxxxx,...\} \
                L_{3} &= \{x,xxxxxxxx\}
            .\end{align*}
        \item \textbf{The empty language}: The empty language $L = \varnothing$ is typically  denoted with the capital  greek letter phi $\Phi$. Thus, $L = \varnothing = \Phi $
        \item \textbf{Notes on formal languages}:
            \begin{itemize}
                \item All languages are defined over some alphabet; cannot define a language without an alphabet.
                \item Some languages are finite, some languages are infinite (remember, alphabets are always finite).
                \item Some languages include the empty string \(\Lambda\), some do not.
                \item Some languages are defined by rules, some are simply written completely (e.g., \(\Sigma_1 = \{x\}\), \(L_3 = \{x, \text{xxxxxxxxxx}\}\)).
                \item No matter what the alphabet \(\Sigma\) (even \(\Sigma = \emptyset\)), you can always define at least two languages; \(L_1 = \{\Lambda\}\) and \(L_2 = \emptyset\).
            \end{itemize}
        \item \textbf{Closure of an alphabet (closure of $\Sigma$) (Kleene closure)}:
            The language defined by the set of all strings (including the empty string $\Lambda$) over a fixed alphabet $\Sigma$.
            \begin{itemize}
                \item \textbf{Examples:}
                    \begin{align*}
                        \Sigma &= \{a\} & \Sigma^* &= \{\Lambda, a, aa, aaa, aaaa, \dots\} \\
                        \Sigma &= \{0, 1\} & \Sigma^* &= \{\Lambda, 0, 1, 00, 01, 10, 11, 000, \dots\} \\
                        \Sigma &= \emptyset & \Sigma^* &= \{\Lambda\}
                    \end{align*}
                    \bigbreak \noindent 
                    \textbf{Note:} If $\Sigma = \emptyset$ then $\Sigma^*$ is finite and $\Sigma^* = \{\Lambda\}$, otherwise $\Sigma^*$ is infinite.
            \end{itemize}
        \item \textbf{Positive closure}: $\Sigma^{+} = \Sigma^{*} - \{\Lambda\}$, you just take the empty string out of the kleene closure 
        \item \textbf{Recall: Power set}: The power set of any set $S$, written $\mathcal{P}(S)$ is the set of all subsets of $S$, including the empty set and the set $S$ itself.
            \bigbreak \noindent 
            In other words, given a set $S$, then its power set $\mathcal{P}(S)$ is a set of sets
            \begin{itemize}
                \item \textbf{Note:}
                    \begin{itemize}
                        \item If $S = \emptyset$, then then $\mathcal{P}(S) = \mathcal{P}(\emptyset) = \{\emptyset\} = \{\emptyset\}$ = a set with one element $=\emptyset$.
                        \item If $S$ is non-empty and finite with $n$ elements, then $\mathcal{P}(S)$ will be finite with $2^n$ elements.
                        \item If $S$ is infinite, then $\mathcal{P}(S)$ will be infinite.
                    \end{itemize}

                \item \textbf{Example:}

                    If $S = \{x, y, z\}$, then $\mathcal{P}(S)$ will have the following $2^3 = 8$ elements (each a set):
                    \[
                        \mathcal{P}(S) = \{\emptyset, \{x\}, \{y\}, \{z\}, \{x, y\}, \{x, z\}, \{y, z\}, \{x, y, z\}\}
                    \]
            \end{itemize}
        \item \textbf{Power set of the kleene closure $\mathcal{P}(\Sigma^{\star}) $}: Given some alphabet $\Sigma$ we can construct the set of all possible languages from $\Sigma$ as follows (assume non-empty $\Sigma$):
            \bigbreak \noindent 
            \fig{.6}{./figures/6.png}
        \item \textbf{From formal languages to computers}:
            \begin{itemize}
                \item Given an alphabet $\Sigma$ we can define many formal languages – the range of which is captured by $\mathcal{P}(\Sigma^*)$.

                \item We can define many formal languages verbally, but is there a way to define/express every language in any $\mathcal{P}(\Sigma^*)$ with some formal system or abstract machine?

                \item We search for a formal system or abstract machine with enough “power” to define any language in any $\mathcal{P}(\Sigma^*)$.

                \item \textbf{KEY POINT} \\
                    The abstract machines we discover along our search to cover $\mathcal{P}(\Sigma^*)$ turn out to be \textit{the theoretical basis for all computing}.

                \item In other words, by understanding the power (and limitations) of abstract machines that cover $\mathcal{P}(\Sigma^*)$, we are simultaneously discovering the same limits about all computing.
            \end{itemize}
    \end{itemize}

    \pagebreak 
    \subsection{Regular languages}
    \bigbreak \noindent 
    \textbf{Preface.} The first few subsubsections will be in the world of regular languages. In the context of computation theory, regular languages are a class of formal languages that can be recognized by finite automata. These languages are important because they are the simplest class of languages that can be described by a computational model. The characteristics of regular languages are as follows,
    \begin{itemize}
        \item \textbf{Finite Automata:} Regular languages can be recognized by deterministic or nondeterministic finite automata (DFA or NFA).
        \item \textbf{Regular Expressions:} Regular languages can be described using regular expressions.
        \item \textbf{Closure Properties:} Regular languages are closed under several operations, including:
            \begin{itemize}
                \item \textbf{Union:} The union of two regular languages is also regular.
                \item \textbf{Concatenation:} The concatenation of two regular languages is also regular.
                \item \textbf{Kleene Star:} The Kleene star operation, which involves repeating a regular language any number of times (including zero), results in a regular language.
                \item \textbf{Intersection and Difference:} Regular languages are also closed under intersection and difference.
            \end{itemize}
        \item \textbf{Decision Problems:} Certain decision problems are decidable for regular languages. For example, it is possible to determine whether a given string belongs to a regular language (membership problem), whether two regular languages are equivalent, or whether a regular language is empty.
    \end{itemize}
    \bigbreak \noindent 
    \subsubsection{Finite Automata}
    \begin{itemize}
        \item \textbf{Informal definition}: Described informally, a finite automaton (FA) is always associated with some alphabet $\Sigma$ and is an abstract machine which has 
            \begin{enumerate}
                \item A non-empty finite number of states, exactly one of which is designated as the “start state” and some number (possibly zero) of which are designated as “accepting states”.
                \item A transition table that shows how to move from one state to another based on symbols in the alphabet $\Sigma$
            \end{enumerate}
        \item \textbf{A simple example of a FA}:
            \bigbreak \noindent 
            \fig{.5}{./figures/23.png}
            \begin{itemize}
                \item Defined over alphabet $\Sigma = \{0, 1\}$.
                \item States are circles; transitions are directed edges (i.e., arrows) between states.
                \item Has exactly three states; \textbf{A}, \textbf{B}, and \textbf{C}.
                \item Every FA must have exactly one start state. In this example, the start state is \textbf{A} and denoted as the only state that has an edge coming to it from no other state.
                \item There is only one accepting state, \textbf{C}, and it is denoted by its \textit{double circle}. (We could have more than one but in this case we only have one)
                \item \textbf{Very important:}
                    \begin{itemize}
                        \item Each symbol in the alphabet has exactly one associated edge leaving every state.
                        \item In other words, every state must have exactly one edge leaving it for each symbol in the alphabet.
                    \end{itemize}
            \end{itemize}
        \item \textbf{How to use an FA}: The purpose of a FA is to define a language over its alphabet $\Sigma$. The FA provides the means by which to test a candidate string from $\Sigma$ and determine whether or not the string is in the language. It does this by “writing” the candidate string on an fictitious input tape and proceeding as follows:
        \begin{enumerate}
            \item Set the FA to the start state.
            \item If end-of-string then halt.
            \item Read next symbol on tape.
            \item Update the state according to the current state and the last symbol read.
            \item Goto step 2.
        \end{enumerate}
        When the process halts check which state the FA is in. If it is in any accepting state, then the string is in the language defined by the FA, otherwise the string is not in the language
    \item \textbf{Using the previous FA}: Let’s now try to use our FA to test whether or not the string 1001 is in the language
        \bigbreak \noindent 
        We start by writing the string on an input tape, placing the read head at the beginning of the tape, and placing the FA in its initial state, $A$
        \bigbreak \noindent 
        \fig{.8}{./figures/24.png}
        \bigbreak \noindent 
        Since the tape head is not at the end of the tape we
        \begin{enumerate}
            \item Read the next symbol from the tape.
            \item Follow the edge from the state we are currently in that corresponds to the symbol we just read to transition to the next state.
            \item Move the tape head
        \end{enumerate}
        \bigbreak \noindent 
        \fig{.8}{./figures/25.png}
        \bigbreak \noindent 
        In this case, we started in state $A$, read symbol 1, and followed the edge labeled 1 from $A$ which brought us back to $A$
        \bigbreak \noindent 
        We proceed in this way, read, change state, move tape head until we reach the end of the tape
        \bigbreak \noindent 
        Once the tape head reaches the end of the tape we simply look to see whether or not the FA ended in an accepting state.
        \bigbreak \noindent 
        In this case it ended in state $C$, which is an accepting state, which means that string 1001 is in the language.
        \bigbreak \noindent 
        \fig{.8}{./figures/26.png}
        \bigbreak \noindent 
        We deduce that the language has only strings with two consecutive zeroes somewhere.
        \pagebreak \bigbreak \noindent
    \item \textbf{FA Example Two: The set of all strings that do not contain a one ($\Sigma = \{0,1\})$}:
        \bigbreak \noindent 
        \fig{.5}{./figures/27.png}
        \bigbreak \noindent 
        This one is pretty simple. If we have a zero, stay in the accepting state, if we see a one, toss it to the other non-accepting state, its not coming back.
    \item \textbf{FA Example Three: The set of all strings that end in one ($\Sigma = \{0,1\})$}:
        \bigbreak \noindent 
        \fig{.5}{./figures/28.png}
    \item \textbf{FA Example Four: The set of all strings with an odd number of zeros ($\Sigma = \{0,1\})$}:
        \bigbreak \noindent 
        \fig{.5}{./figures/29.png}
    \item \textbf{FA Example Five: The set of all strings where the second to last symbol is one ($\Sigma = \{0,1\})$}:
        \bigbreak \noindent 
        \fig{.5}{./figures/30.png}
    \item \textbf{States are "memory"}: Consider the four FA we just created, in each instance the solution required us to design an FA that remembered at least part of what it had already read from the input tape. The type of memory that an FA has is very different than the RAM we find in
        contemporary computers, but the FA does have memory. Each time the FA enters a different state it is, in effect, redefining the memory of the
        entire FA. The FA can only be in a finite number of states, and that number can be arbitrarily
        large, but (as we will see) that difference in memory has a profound limiting effect in
        what FAs can compute.
        \bigbreak \noindent 
    \item \textbf{Limits of a FA}:
        \bigbreak \noindent 
        \textbf{Limited Memory:}
        \begin{itemize}
            \item \textbf{Finite State:} A finite automaton has a finite number of states. This means it can only "remember" a limited amount of information about the input it has processed. Once a finite automaton transitions to a new state, it forgets all previous information except for the current state.
            \item \textbf{No Stack or Tape:} Unlike more powerful models such as pushdown automata (which have a stack) or Turing machines (which have an infinite tape), finite automata cannot use any form of auxiliary memory to keep track of an unbounded number of items or to perform operations that require more complex memory management.
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Inability to Count Unboundedly:}
        \begin{itemize}
            \item \textbf{No Arbitrary Counting}: Finite automata cannot count occurrences of symbols beyond the number of states they have. For example, a DFA with $n$ states can only count up to $n-1$ occurrences of a symbol reliably. Thus, they cannot recognize languages that require matching counts of different symbols if those counts are unbounded, such as $\{a^n b^n \mid n \geq 1\}$, where the number of 'a's must match the number of 'b's.
        \end{itemize}
    \item \textbf{FA Formal Definition}:
     We formally denote a \textit{finite automaton} by a 5-tuple $(Q, \Sigma, q_0, T, \delta)$, where
    \begin{itemize}
        \item $Q$ is a finite set of \textit{states}.
        \item $\Sigma$ is an alphabet of \textit{input symbols}.
        \item $q_0 \in Q$, is the \textit{start state}.
        \item $T \subseteq Q$, is the set of \textit{accepting states}.
        \item $\delta$ is the \textit{transition function} that maps a state in $Q$ and a symbol in $\Sigma$ to some state in $Q$. In mathematical notation, we say that $\delta: Q \times \Sigma \rightarrow Q$.
            With:
            \begin{itemize}
                \item $Q \times \Sigma$: The Cartesian product of the set of states $Q$ and the alphabet $\Sigma$. This represents all possible pairs of a state and an input symbol.
                \item $\rightarrow Q$: Indicates that the transition function maps each pair $(q, \sigma)$ (where $q \in Q$ and $\sigma \in \Sigma$) to a single state in $Q$.
            \end{itemize}
    \end{itemize}
    \item \textbf{Formally Specifying Our First FA}:
        \bigbreak \noindent 
        \fig{.5}{./figures/23.png}
        \bigbreak \noindent 
        Recall our first FA that accepts any string with two consecutive zeros somewhere.
        \bigbreak \noindent 
        We drew it as a Finite State diagram, but to formally define this FA we must specify each of the elements from the 5-tuple $(Q, \Sigma, q_0, T, \delta)$.
        \begin{itemize}
            \item $Q$ is a finite set of \textit{states}: \hspace{0.2cm} $Q = \{A, B, C\}$
            \item $\Sigma$ is an alphabet of \textit{input symbols}: \hspace{0.2cm} $\Sigma = \{0, 1\}$
            \item $q_0 \in Q$, is the \textit{start state}: \hspace{0.2cm} $q_0 = A$
            \item $T \subseteq Q$, is the set of \textit{accepting states}: \hspace{0.2cm} $T = \{C\}$
            \item $\delta$ is the \textit{transition function} $\delta: Q \times \Sigma \rightarrow Q$
        \end{itemize}
        \[
            \begin{array}{c|cc}
                \delta & \text{0} & \text{1} \\
                \hline
                A & B & C \\
                B & C & A \\
                C & C & C \\
            \end{array}
        \]
    \item \textbf{Unary}: consisting of or involving a single component or element.
    \item \textbf{Unary language}: One where the alphabet has only one symbol.
    \item \textbf{Binary}: Relating to, composed of, or involving two things.
    \item \textbf{Ternary}: Composed of three parts.
    \item \textbf{Dead state (trap state)}: This is a state that once entered, can never be left.
    \item \textbf{Deterministic finite automaton (DFA)}: The FA's we have looked at thus far have been DFA's. A DFA is a finite automaton where, for each state and each input symbol, there is exactly one transition to a new state. This means that given a current state and an input symbol, the next state is uniquely determined. In the future we will look at nondeterministic finite automaton (NFA). An NFA is a finite automaton where, for each state and input symbol, there can be multiple possible transitions to different states. Additionally, an NFA can have transitions that do not consume any input symbol ($\epsilon$-transitions).
    








    \end{itemize}

    \pagebreak 
    \subsubsection{Finite Automata: More examples}
    \begin{itemize}
        \item \textbf{$\Sigma = \{0,1\}$, all strings that start with 00}
        \item \textbf{$\Sigma = \{0,1\}$, all strings that end with 00}
            \bigbreak \noindent 
            \fig{.5}{./figures/31.png}
            \bigbreak \noindent 
            With:
            \begin{itemize}
                \item $Q = \{A,B,C\}$
                \item $\Sigma = \{0,1\}$
                \item $q_{0} = A$
                \item $T = C$
                \item $\delta:\ Q \times \Sigma \to  Q$ defined by                \begin{array}{c|cc}
                    $\delta$ & 0 & 1 \\
                    \hline
                    A & B & A\\
                    B & C & A\\
                    C & C & A
                \end{array}

            \end{itemize}
                
    \end{itemize}

    \pagebreak 
    \subsubsection{Regular expressions}
    \begin{itemize}
        \item \textbf{RE}: A RE corresponds to a set of strings; that is, a RE describes a language
        \item \textbf{RE three operations}:
            \begin{enumerate}
                \item Union (+)
                \item concatenation (xy)
                \item star (zero or more copies)
            \end{enumerate}
        \item \textbf{RE special symbols}
            \begin{align*}
                + \quad * \quad (\ \ )
            .\end{align*}
        \item \textbf{Grouping}: The parenthesis are used for grouping, 
        \item \textbf{Union}: the plus sign means \textbf{union}. Thus, writing
            \begin{align*}
                0 + 1
            .\end{align*}
            Means zero or one, we refer to + as "or"
        \item \textbf{Concatenation}: We concatenate simply by writing one expression after the other, with no spaces
            \begin{align*}
                (0+1)0
            .\end{align*}
            Is the pair of strings 00 and 10
        \item \textbf{Empty string}: We can also use the empty string $\epsilon$
            \begin{align*}
                (0 + 1)(0 + \epsilon)
            .\end{align*}
            corresponds to 00, 0, 10, and 1
        \item \textbf{Zero or more copies (star)}: Using the start indicates zero or more copies, thus
            \begin{align*}
                a*
            .\end{align*}
            corresponds to any string of a's: $\{\epsilon, a,aa,aaa,...\} $
        \item \textbf{More on union}:
            If you form an RE by the or of two REs, call them $R$ and $S$, then the resulting language is the union of the languages of $R$ and $S$.
            \bigbreak \noindent 
            Suppose $R = (0+1) = \{0, 1\}$, and $S=\{01(0+1)\}  = \{ 010,011\}$, then $R+S = (0+1) + (01(0+1))  = \{0,1,010, 011\}$
        \item \textbf{More on concatenation}: If you form an RE by the or of two REs, call them $R$ and $S$, then the resulting language consists of all strings that can be formed by taking one string from the language of $R$ and one string from the language of $S$ and concatenating them.
            \bigbreak \noindent 
            Suppose $R = (0+1) = \{0, 1\}$, and $S=\{01(0+1)\}  = \{ 010,011\}$, then $RS = (0+1)01(0+1) = \{0010,0011,1010,1011\}$
        \item \textbf{More on star}: If you for man RE by taking the star of an RE $R$, then the resulting language consists of all strings that can be formed by taking any number of strings from the language of $R$ (they need not be the same and they need not be different), and concatenating them.
            \bigbreak \noindent 
            Suppose $R = 01(0+1) = \{010, 011\}$, then $R^{*} = 01(0+1)* \{010, 010010, ..., 011,011011,... 010011, ...\} $
    \item \textbf{Precedence of the operations}
        \begin{enumerate}
            \item Star (*)
            \item Concatenation
            \item Union (+)
        \end{enumerate}
        \item \textbf{Recursive definition of the kleene star (closure) ($L^{*}$)}:
            \begin{enumerate}
                \item $\epsilon \in L^{*} $
                \item If $x \in L^{*}$ and $y\in L$, then $xy \in L^{*}$
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{Base case:} The first rule provides a starting point by ensuring that the empty string \( \epsilon \) is in \( L^* \).
            \bigbreak \noindent 
            \textbf{Recursive step:} The second rule allows you to take any string \( x \) already in \( L^* \) and concatenate it with a string \( y \in L \) to produce a new string \( xy \in L^* \).
            \bigbreak \noindent 
            After using the second rule once to generate a new string \( xy \in L^* \), you can apply the rule again by concatenating this new string with another string from \( L \). This recursive process can continue indefinitely, generating all possible strings that can be formed by concatenating zero or more strings from \( L \).

        \item \textbf{Kleene's theorem}:
            There is an FA for a language if and only if there is an RE for the language
        \item \textbf{Regular expressions order of operations}: From highest to lowest precedence
            \begin{enumerate}
                \item Parenthesis  
                \item Kleene star
                \item Concatenation
                \item Union (+ or \|)
            \end{enumerate}
    \item \textbf{Properties of regular expressions}:
        \bigbreak \noindent 
        \textbf{Note:} Intersection is a operation not defined for regular expressions
        \bigbreak \noindent 
        \textbf{Union}
        \begin{itemize}
            \item \textbf{Commutative}:
                \[
                    R_1 \cup R_2 = R_2 \cup R_1
                \]

            \item \textbf{Associative}:
                \[
                    (R_1 \cup R_2) \cup R_3 = R_1 \cup (R_2 \cup R_3)
                \]

            \item \textbf{Identity Element}:
                \[
                    R_1 \cup \emptyset = R_1
                \]

            \item \textbf{Idempotent}:
                \[
                    R_1 \cup R_1 = R_1
                \]
        \end{itemize}
        \textbf{2. Concatenation (\(\cdot\))}
        \begin{itemize}
            \item \textbf{Non-commutative}:
                \[
                    R_1 \cdot R_2 \neq R_2 \cdot R_1
                \]

            \item \textbf{Associative}:
                \[
                    (R_1 \cdot R_2) \cdot R_3 = R_1 \cdot (R_2 \cdot R_3)
                \]

            \item \textbf{Identity Element}:
                \[
                    R_1 \cdot \epsilon = \epsilon \cdot R_1 = R_1
                \]

            \item \textbf{Concatenation with \(\emptyset\)}:
                \[
                    R_1 \cdot \emptyset = \emptyset \cdot R_1 = \emptyset
                \]
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Kleene Star (\(*\))}
        \begin{itemize}
            \item \textbf{Kleene Star of \(\epsilon\)}:
                \[
                    \epsilon^* = \{\epsilon\}
                \]

            \item \textbf{Kleene Star of \(\emptyset\)}:
                \[
                    \emptyset^* = \{\epsilon\}
                \]

            \item \textbf{Idempotent}:
                \[
                    (R^*)^* = R^*
                \]
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Distributive Properties}
        \begin{itemize}
            \item \textbf{Union over Concatenation}:
                \[
                    R_1 \cdot (R_2 \cup R_3) = (R_1 \cdot R_2) \cup (R_1 \cdot R_3)
                \]

            \item \textbf{Concatenation over Union}:
                \[
                    (R_1 \cup R_2) \cdot R_3 = (R_1 \cdot R_3) \cup (R_2 \cdot R_3)
                \]
        \end{itemize}
    \item \textbf{Language of a RE notation}: $L(RE)$ is the language defined by the regular expression $RE$, If we have an RE $R$, then the language $L(R)$ is the language defined by the RE $R$
    \item \textbf{When a regular expression is the empty set $\varnothing$}: When a regular expression (RE) represents the empty set it means that the RE matches no strings at all, not even the empty string.
        \bigbreak \noindent 
        The language is then
        \begin{align*}
            L(\varnothing) = \Phi        
        .\end{align*}
        Where $\Phi$ denotes the empty language
    \item \textbf{One or more occurences $RR^{*}$}: We denote this by plus instead of star, ie $RR^{*} = R^{+}$, but you also must redefine union as $\mid$ instead of $+$
    \item \textbf{Simplifying regular expressions (Some can also be found above in properties)}:
        \begin{itemize}
            \item \textbf{Concatenation of stars}: $(R^{*})^{*}  = R^{*}$
            \item \textbf{Concatenation of Repeated Expressions}: $R^{*}R^{*} = R^{*} $
            \item \textbf{Idempotence of Union}: $R\midR = R$
            \item \textbf{Empty Set in Union and Concatenation:} $R \mid \varnothing  = R$, $R\varnothing = \varnothing $
            \item \textbf{Empty string in concatenation}: $\epsilon R = R\epsilon = R $
            \item \textbf{Union with the kleene star}: $R^{*}\mid R = R^{*}$
            \item \textbf{Distributive Property:} $R_{1}(R_{2} \mid R_{3}) = R_{1}R_{2} \mid R_{1}R_{3} $
            \item \textbf{Absorption:} $R\mid (RR^{*})  = RR^{*} = R^{+}$
        \end{itemize}

    \end{itemize}

    \pagebreak 
    \subsubsection{nondeterministic Finite automata (NFA)}
    \begin{itemize}
        \item \textbf{NFA definition}:
            \begin{itemize}
                \item If an automaton gets to a state where there is more than one possible transition corresponding to the symbol read from the tape, the automaton may  choose any of those paths. (nondeterminism) We say it \textbf{branches}
                \item if an automaton gets to a state where there is no transition for the symbol read from the tape, then that path of the automaton halts and rejects the string. We say it \textbf{dies}
                \item the automaton accepts the input string if and only if there exists a choice of transitions that ends in an accept state.
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Example}: Consider this nondeterministic FA (NFA) over $\Sigma = \{0, 1\}$
            \bigbreak \noindent 
            \fig{.5}{./figures/32.png}
        \item \textbf{DFA or NFA?}:
            Consider the language $L$ over $\Sigma = \{a, b\}$ which is defined by
            \begin{align*}
                L = (a^{*}) + (ab)^{*}
            .\end{align*}
            \bigbreak \noindent 
            \fig{.5}{./figures/33.png}
        \item \textbf{NFA Formal definition}: We define an NFA $M(Q, \Sigma, q_{0}, T, \delta) $
            \begin{itemize}
                \item $Q$ is a finite set of states
                \item $\Sigma$ is an alphabet of input symbols
                \item $q_0 \in Q$ is the start state
                \item $T \subseteq Q$ is the set of accepting states
                \item $\delta$ is the transition function $\delta: Q \times \Sigma \to P(Q)$
            \end{itemize}
        \item \textbf{Transition function, DFA vs NFA}:
            \bigbreak \noindent 
            \fig{.5}{./figures/34.png}
        \item \textbf{NFA with $\epsilon$-transitions}: $\epsilon$-transitions allow the automaton to change state without
            consuming an input symbol
            \bigbreak \noindent 
            Changing states without consuming input symbols can go on arbitrarily long as there are $\epsilon$-transitions to traverse.
        \item \textbf{DFA or NFA with $\epsilon$-moves?}: Consider the language L over $\Sigma = \{a, b\}$ which is
            \begin{align*}
                L = (b^{*}a) + (a^{*}b)
            .\end{align*}
            \bigbreak \noindent 
            \fig{.5}{./figures/35.png}
        \item \textbf{NFA with $\epsilon$-transitions formal definition}: Everything is the same except for the transition function, we now have
            \begin{align*}
                \delta:\ Q \times (\Sigma \cup \{\epsilon\}) \to \mathcal{P}(Q)
            .\end{align*}
            \pagebreak \bigbreak \noindent 
        \item \textbf{$\delta$ – DFA, NFA, and NFA with $\epsilon$-moves}:
            \bigbreak \noindent 
            \fig{.35}{./figures/36.png}
        \item \textbf{DFA, NFA, or NFA with $\epsilon$ moves, who can define the most languages?}: We begin by noting, by definition, every DFA is an NFA. This means that any language you can define with a DFA can also be defined by an NFA. Thus,
            \begin{align*}
                \text{Languages defined by DFA} \subseteq \text{ Languages defined by NFA}
            .\end{align*}
            Also, by definition, every DFA is an NFA with $\epsilon$-moves, an NFA is an NFA with $\epsilon$ moves, even if it doesnt have any. Thus,
            \begin{align*}
                \text{Languages defined by DFA} \subseteq \text{ Languages defined by NFA with $\epsilon$-moves}
            .\end{align*}
            \bigbreak \noindent 
            But, by definition, every NFA is an NFA with $\epsilon$-moves. Thus,
            \begin{align*}
                \text{Languages defined by NFA} \subseteq \text{ Languages defined by NFA with $\epsilon$-moves}
            .\end{align*}
            \bigbreak \noindent 
            This tells us that
            \begin{itemize}
                
                \item NFAs are at least as powerful in defining languages as DFAs
                \item NFAs with $\epsilon$-moves are at least as powerful in defining languages as DFAs and NFAs.
            \end{itemize}
            \bigbreak \noindent 
            It turns out that these three are \textbf{equally} as powerful. We assert
            \begin{align*}
                &\text{Languages defined by DFA's} \\
                &=\text{Languages defined by NFA's} \\
                &=\text{Languages defined by NFA's with $\epsilon$-moves} \\
            .\end{align*}
            We prove this by showing an algorithm that converts any NFA with $\epsilon$-moves (or any NFA) to a DFA that accepts the exact same language
            \bigbreak \noindent 
            This means that there does not exist a language that can be defined by an NFA with $\epsilon$-moves (or NFA) that cannot also be defined by a DFA.
        \item \textbf{$\epsilon$-closure}: Before we can look at the algorithm we must first define the $\epsilon$-closure of a set of states 
            \bigbreak \noindent 
            Given:
            \begin{itemize}
                \item an NFA with $\epsilon$-moves $M(Q, \Sigma, q_{0}, T, \delta) $
                \item Some set of states $S \subseteq Q$
            \end{itemize}
            \bigbreak \noindent 
            \text{We define the } \varepsilon\text{-closure}(S) \text{ as the set of states that are reachable from the set of states } S \text{ using only zero or more } \varepsilon\text{-moves in } \delta.
            \bigbreak \noindent 
            \text{Note: it is always the case that } S \subseteq \varepsilon\text{-closure}(S)
        \item \textbf{Algorithm: Converting NFA with $\epsilon$-moves to DFA}: The algorithm constructs a new DFA $M^{\prime}(Q^{\prime}, \Sigma, q_{0}^{\prime}, T^{\prime}, \delta^{\prime}) $ From an NFA with $\epsilon$-moves $M(Q, \Sigma, q_{0}, T, \delta) $. $\Sigma$ will remain the same
            \bigbreak \noindent 
            Things to note about the conversion:
            \begin{itemize}
                \item Same alphabet $\Sigma $
                \item Lose column $\epsilon$
                \item Lose all nondeterminism
                \item Lose all empty sets
                \item Cell values change from sets of states to states
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Example}:
            \textbf{Consider the following NFA with $\varepsilon$-moves M(Q, $\Sigma$, $q_0$, T, $\delta$) over $\Sigma = \{0, 1\}$ and its associated transition table $\delta$: Q $\times$ ($\Sigma \cup \{\varepsilon\}$) $\rightarrow$ P(Q)}
            \bigbreak \noindent 
            \[
                \begin{array}{|c|c|c|c|}
                    \hline
                     & 0 & 1 & \varepsilon \\
                    \hline
                    X & \{Y\} & \{Y\} & \emptyset \\
                    \hline
                    Y & \{X, Z\} & \{Z\} & \{Z\} \\
                    \hline
                    Z & \emptyset & \{Y\} & \emptyset \\
                    \hline
                \end{array}
            \]
            \bigbreak \noindent 
            Start by computing the $\epsilon$-closure of the start state in $\delta$.
            \bigbreak \noindent 
            \fig{.4}{./figures/37.png}
            \bigbreak \noindent 
            There is a subtle - but very important - point to be made here …
            \bigbreak \noindent 
            we cannot simply take the $\epsilon$-closure (a set) and use it to create a row in $\delta^{\prime}$ (which needs to be a state). What we do is create a label for the new state in $\delta^{\prime}$ that represents the set of states from $\delta$ and then add that new state to $\delta^{\prime}$
            \bigbreak \noindent 
            In this instance we represented the set of states $\{X\}$ by a single state whose label is $X^{\prime}$
            \bigbreak \noindent 
            We continue by filling the columns of the start state for each symbol $\Sigma = \{0, 1\}$
            \bigbreak \noindent 
            Processing $\delta'$ state $X'$ which represents the set of states $\{X\}$ in $M$:
            \begin{itemize}
                \item Processing input symbol 0 (process each state in $\{X\}$ using $\delta$):
                    \begin{itemize}
                        \item Process $X$
                            \[
                                \delta(X, 0) = \{Y\}
                            \]
                            \[
                                \varepsilon\text{-closure}(\{Y\}) = \{Y, Z\}
                            \]
                    \end{itemize}
            \end{itemize}
    Since there are no more states in $\{X\}$ to process, we have finished processing the symbol 0 and have produced the set of states $\{Y, Z\}$.
    \bigbreak \noindent 
    We create a new state with label $Y'Z'$ (or $Z'Y'$, order does not matter) for $\delta'$ that represents $\{Y, Z\}$ in $M$ and define:
    \[
    \delta'(X', 0) = Y'Z'
    \]
    We note that $Y'Z'$ is a new state in $\delta'$ and so we create a new row for it in $\delta'$.
    \bigbreak \noindent 
    We continue this until we reach 
    \bigbreak \noindent 
    \fig{.8}{./figures/38.png}
    \bigbreak \noindent 
    Processing $\delta'$ state $Y'Z'$ which represents the set of states $\{Y, Z\}$ in $M$:
    \begin{itemize}
        \item Processing 0:
            \begin{itemize}
                \item Process $Y$
                    \[
                        \delta(Y, 0) = \{X, Z\}, \quad \varepsilon\text{-closure}(\{X, Z\}) = \{X, Z\}
                    \]
                \item Process $Z$
                    \[
                        \delta(Z, 0) = \emptyset, \quad \varepsilon\text{-closure}(\emptyset) = \emptyset
                    \]
            \end{itemize}
    \end{itemize}
    Here is our first instance of processing a state and symbol where the state in $\delta'$ represents multiple states in NFA $M$. When this happens, the set of states in NFA $M$ is computed by \textit{taking the union of the $\varepsilon$-closures}: $\{X, Z\} \cup \emptyset = \{X, Z\}$.
    \bigbreak \noindent 
    This produces a new label $X'Z'$ which we use to define:
    \[
        \delta'(X'Y', 0) = X'Z'
    \]
    and since $X'Z'$ is a new state, we add it to $\delta'$.
    \bigbreak \noindent 
    We continue this until we reach 
    \bigbreak \noindent 
    \fig{.8}{./figures/39.png}
    \bigbreak \noindent 
    A state in $M^{\prime}$ is an accepting state iff at least one of the states that it represents in $M$ is an accepting state … in this case $T^{\prime}= \{Y^{\prime}Z^{\prime}\}$.
    \bigbreak \noindent 
    We can now draw the new DFA 
    \bigbreak \noindent 
    \fig{.7}{./figures/40.png}
    \bigbreak \noindent 
    \textbf{Note:} If the closure or union of closures is the empty set, we do this
    \bigbreak \noindent 
    \fig{.7}{./figures/41.png}
    \bigbreak \noindent 
    This "emtpy" is a state and represents a garbage state, what goes does not leave.
\item \textbf{Kleene's theorem revisited}: The following are equivalent for a language $L$
    \begin{enumerate}
        \item There is a DFA for $L$
        \item There is an NFA for $L$
        \item There is an RE for $L$
    \end{enumerate}
    \item \textbf{Union of two DFA's (cartesian product construction)}:
        The process of finding the union of two deterministic finite automata (DFAs) involves creating a new DFA that accepts the union of the languages accepted by the original DFAs. This is done using a product construction (also called the Cartesian product construction), where you combine the states of both DFAs in a systematic way to ensure the resulting DFA accepts strings from either of the original DFAs.
        \bigbreak \noindent 
        Let’s say we have two DFAs:
        \[
            D_1 = (Q_1, \Sigma, \delta_1, q_1^{\text{start}}, F_1)
        \]
        that recognizes language \( L_1 \).
        \[
            D_2 = (Q_2, \Sigma, \delta_2, q_2^{\text{start}}, F_2)
        \]
        that recognizes language \( L_2 \).
        \bigbreak \noindent 
        \textbf{Create a New DFA State Set}:
        \bigbreak \noindent 
        \begin{itemize}
            \item The states of the new DFA are pairs of states, one from each of the original DFAs. The new state set will be the Cartesian product \(Q_1 \times Q_2\), meaning every possible combination of a state from \(D_1\) and a state from \(D_2\).
            \item If \(D_1\) has \(n\) states and \(D_2\) has \(m\) states, the new DFA will have \(n \times m\) states.
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Define the New Start State}:
        \begin{itemize}
            \item The new start state is \((q_1^{\text{start}}, q_2^{\text{start}})\), where \(q_1^{\text{start}}\) is the start state of \(D_1\) and \(q_2^{\text{start}}\) is the start state of \(D_2\).
        \end{itemize}
        \textbf{Define the New Transition Function:}
        \begin{itemize}
            \item The transition function \(\delta\) for the new DFA operates by taking an input symbol and applying the transition functions of both original DFAs in parallel.
            \item For each input symbol \(a \in \Sigma\), the new DFA transitions from state \((q_1, q_2)\) to state \((\delta_1(q_1, a), \delta_2(q_2, a))\).
            \item In other words, if \(q_1\) moves to \(q_1'\) on input \(a\) in \(D_1\), and \(q_2\) moves to \(q_2'\) on input \(a\) in \(D_2\), the new DFA will move from \((q_1, q_2)\) to \((q_1', q_2')\).
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Define the New Set of Accepting (Final) States}:
        The new DFA will accept a string if either of the original DFAs would accept it. Therefore, the set of final states \( F \) in the new DFA is defined as:
        \[
            F = \{ (q_1, q_2) \mid q_1 \in F_1 \ \text{or} \ q_2 \in F_2 \}
        \]
        This means that if either \( q_1 \) is a final state in \( D_1 \), or \( q_2 \) is a final state in \( D_2 \), the pair \( (q_1, q_2) \) is a final state in the new DFA.
        \bigbreak \noindent 
        \textbf{Note:} It is possible in the new DFA (constructed as the union of two DFAs) to have states that are unreachable—meaning there are states in the DFA that cannot be reached from the start state. This typically happens because, in the product construction, we generate all possible pairs of states from the two original DFAs, but not all of these pairs are necessarily reachable.
        \bigbreak \noindent 
        The union of two finite automata (FAs) is useful for constructing a new automaton that recognizes any string accepted by either of the two original automata. This has several practical applications in theoretical computer science and programming:
    \item \textbf{Finding the intersection of two DFA's}: The process is basically the same as finding the union, but it differs in how we define the accepting states in the new machine, the accepting states will be
        \begin{align*}
            T = \{(q_{1},q_{2}):\ q_{1} \in T_{1} \text{ and } q_{2} \in T_{2}\}
        .\end{align*}
        \bigbreak \noindent 
        \textbf{Note:} The intersection of two DFAs is useful in various practical applications where you need to accept only the strings that satisfy the conditions or rules of both automata
    \item \textbf{Concatenation of two DFA's}: The process is simple
        \bigbreak \noindent 
        For two machines $M_{1}(Q_{1}, \Sigma, q_{0_{1}}, T_{1}, \delta_{1})$, and $M_{2}(Q_{2}, \Sigma, q_{0_{2}}, T_{2}, \delta_{2})$ 
        \begin{enumerate}
            \item Connect the final states of the first machine to the start state of the second machine (With $\epsilon$-transitions)
            \item Clear $T_{1}$, There are no more final states in the first machine
            \item Convert $\epsilon$-NFA to DFA
        \end{enumerate}
        \textbf{Note:} The concatenation of two DFAs has practical uses in many scenarios where the language of interest is the concatenation of two sublanguages. Concatenating two DFAs allows you to recognize strings that can be divided into two parts, where the first part is recognized by one DFA and the second part is recognized by the other.
    \item \textbf{Finding the union of two NFA's}:
        taking the union of two nondeterministic finite automata (NFAs) involves constructing a new NFA that accepts any string that is accepted by either of the original NFAs. This process can be done by creating a new NFA that combines the two original NFAs. 
        \bigbreak \noindent 
        Given $M_{1}(Q_{1}, \Sigma, q_{0_{1}}, T_{1}, \delta_{1}) $, and $M_{2}(Q_{2}, \Sigma, q_{0_{2}}, T_{2}, \delta_{2}) $
        \bigbreak \noindent 
        \begin{enumerate}
            \item \textbf{New start state}: Start by defining a new start state $q^{\prime}_{0}$, this state will have $\epsilon$ transitions to the start states of both machines.
            \item \textbf{Define $Q^{\prime}$, the new set of states}: The new set of states will be the set of all states in $M_1$, and it will include all the states in $M_2$, along with the new start state. Thus,
                \begin{align*}
                    Q^{\prime} = Q_{1} \cup Q_{2} \cup \{q^{\prime}_{0}\}
                .\end{align*}
            \item \textbf{Define the transition function}: The transition function $\delta^{\prime}$ of the new NFA will include:
                \begin{itemize}
                    \item All the transitions of $M_{1}$ and $M_{2}$
                    \item Two $\epsilon$ transitions from the new start state to the start states of the two original machines $q_{0_{1}}$ and $q_{0_{2}}$. Thus,
                        \begin{align*}
                            \delta^{\prime}(q_{0}^{\prime}, \epsilon) = \{q_{0_{1}}, q_{0_{2}}\}
                        .\end{align*}
                \end{itemize}
            \item \textbf{Define the set of accepting states}: The set of accepting states will be
                \begin{align*}
                    T^{\prime} = T_{1} \cup T_{2}
                .\end{align*}
        \end{enumerate}
        \pagebreak \bigbreak \noindent 
        \textbf{Example:}
        \begin{figure}[ht]
            \centering
            \incfig{machine10}
            \label{fig:machine10}
        \end{figure}
        \bigbreak \noindent 
        $M_1 \cup M_2$ is then
        \begin{figure}[ht]
            \centering
            \incfig{machine11}
            \label{fig:machine11}
        \end{figure}
        \pagebreak \bigbreak \noindent 
    \item \textbf{Finding the intersection of two NFA's}: 
        For NFAs, intersection is more complex because NFAs are nondeterministic and don’t handle intersection naturally. Typically, you convert the NFAs to DFAs and then apply the DFA product construction
    \item \textbf{Concatenation of two NFA's}: The process is the same as with two DFA's (see above), but you don't need to convert to a DFA at the end.
    \item \textbf{Convert DFA into RE}: To convert a DFA (Deterministic Finite Automaton) into a Regular Expression (RE), you can use the state elimination method or generalized transition automaton method. This process works by gradually reducing the DFA's states and transitions until only a regular expression representing the entire language remains.
        \bigbreak \noindent 
        Given a DFA $M(Q, \Sigma, \delta, q_{0}, F)$, the goal is to find a regular expression that represents the language recognized by this DFA.
        \bigbreak \noindent 
        \textbf{Process:}
        \begin{enumerate}
            \item \textbf{Add a new Start and accept state}:
                \begin{itemize}
                    \item Add a new start state \( q_s \) with an \(\epsilon\)-transition (empty string) to the original start state \( q_0 \). 
                        \bigbreak \noindent 
                        \textbf{Note:} Once you add the new start state \( q_s \) with an \(\epsilon\)-transition to the original start state \( q_0 \), \( q_0 \) is no longer considered the start state. Instead, \( q_0 \) becomes just another intermediate state in the automaton. The new start state is \( q_s \), and it immediately transitions to \( q_0 \) without consuming any input (via the \(\epsilon\)-transition).
                    \item Add a new accept state \( q_f \) and add \(\epsilon\)-transitions from each of the original accept states to this new accept state \( q_f \).
                        \bigbreak \noindent 
                        \textbf{Note:} Similarly, when you add the new accept state \( q_f \) and connect it via \(\epsilon\)-transitions from the original final states in \( F \), the original final states are no longer considered final states in the sense of marking the end of a string's acceptance. Now, the new final state \( q_f \) serves as the sole final state, and the automaton reaches \( q_f \) via \(\epsilon\)-transitions from the original final states.
                \end{itemize}
                These new states simplify the process because now there's exactly one start state and one accept state.
            \item \textbf{Eliminate States One by One}:
                \begin{itemize}
                    \item The idea is to progressively eliminate states from the DFA while updating the transitions between the remaining states with regular expressions.
                    \item Every time you eliminate a state $r$, you need to update the regular expressions on the transitions between the remaining states to account for the paths that go through $r$.
                \end{itemize}
                For any three states \( p \), \( r \), and \( q \), if there is a path from \( p \) to \( q \) that goes through \( r \), the new transition after eliminating \( r \) will include the regular expression:
                \[
                    R(p \rightarrow q) = R(p \rightarrow q) + R(p \rightarrow r) R(r \rightarrow r)^* R(r \rightarrow q)
                \]
                \pagebreak \bigbreak \noindent 
                Where:
                \begin{itemize}
                    \item \( R(p \rightarrow q) \) is the regular expression for the direct transition from \( p \) to \( q \).
                    \item \( R(p \rightarrow r) \) is the regular expression for the transition from \( p \) to \( r \).
                    \item \( R(r \rightarrow r) \) is the regular expression for the loop on state \( r \).
                    \item \( R(r \rightarrow q) \) is the regular expression for the transition from \( r \) to \( q \).
                    \item \( + \) represents union, and \( * \) represents the Kleene star (zero or more repetitions).
                \end{itemize}
                \bigbreak \noindent 
                After updating the transitions, remove the state \( r \).
                \bigbreak \noindent 
            \item \textbf{Repeat the Elimination Until Only Two States Remain}:
                Continue eliminating states and updating the transitions until only two states remain: the start state \( q_s \) and the new accept state \( q_f \).
                \bigbreak \noindent 
                At this point, the regular expression on the transition from \( q_s \) to \( q_f \) represents the language of the DFA.
        \end{enumerate}
        \bigbreak \noindent 
        \textbf{Example}: For the alphabet $\Sigma = \{0,1\}$, let's take the machine that accepts the strings with any number of ones, but the total number of zero's must be odd, and convert it to a RE.
        \begin{figure}[ht]
            \centering
            \incfig{machine1}
            \label{fig:machine1}
        \end{figure}
        \bigbreak \noindent 
        Let's start by making the new start and end states
        \pagebreak \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{machine4}
            \label{fig:machine4}
        \end{figure}
        \bigbreak \noindent 
        Now we start eliminating states, note that it does not matter in which order we eliminate the states, but for this example we will begin by eliminating state $A$. To get from the start state $q_{0}$ to state $B$, we need to pass through $A$, to get from $A$ to $B$, we can have any number of $1's$ followed by a zero which takes us to be. Thus, the transition from $q_{0}$ to $B$ is the regular expression $1^{*}0$
        \bigbreak \noindent 
        We also have to consider the original transition from $B$ to $A$, and then back to $B$, for this we have the RE $01^{*}0$. Thus the machine becomes
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{machine9}
            \label{fig:machine9}
        \end{figure}
        \bigbreak \noindent 
        To eliminate $B$, we need to consider the transitions through $B$ ie from $q_{0}$ to $q_{f}$. We know to get from $q_{0}$ to $B$ we have the RE $1^{*}0$, then from $B$ to $q_{f}$ we have $(1 + 01^{*}0)^{*} $. Thus, the transition for $q_{0}$ to $q_{f}$ is $1^{*}0(1 + 1^{*}01^{*}0)^{*} $. And the final machine with only one regular expression is 
        \begin{figure}[ht]
            \centering
            \incfig{machine8}
            \label{fig:machine8}
        \end{figure}
        \pagebreak 
    \item \textbf{Convert RE to NFA}: Before we begin, recall order of operations (From highest to lowest )
        \begin{enumerate}
            \item Parenthesis  
            \item Kleene star
            \item Concatenation
            \item Union (+ or \|)
        \end{enumerate}
        Let's consider the regular expression $aa(a+b)^{*}bb$
        \begin{enumerate}
            \item We start by defining simple NFA's for each symbol ($a$ and $b$)
        \end{enumerate}
        \begin{figure}[ht]
            \centering
            \incfig{machine12}
            \label{fig:machine12}
        \end{figure}
        \bigbreak \noindent 
        Then, by precedence, we design an NFA for inside the parenthesis, and then for the kleene star of the parenthesis. To make the NFA for $a + b$, we follow the rules for the union of two NFAs
        \bigbreak \noindent 
    \begin{figure}[ht]
        \centering
        \incfig{machine13}
        \label{fig:machine13}
    \end{figure}
    \bigbreak \noindent 
    In order to take the kleen star of this machine, we need to allow for zero or more repetitions. Thus,
    \bigbreak \noindent 
\begin{figure}[ht]
    \centering
    \incfig{machine14}
    \label{fig:machine14}
\end{figure}
\bigbreak \noindent 
Now we create two more NFA's, one for $aa$, and one for $bb$
\bigbreak \noindent 
\begin{figure}[ht]
    \centering
    \incfig{machine15}
    \label{fig:machine15}
\end{figure}
\pagebreak \bigbreak \noindent 
Now, we combine them all using the logic of concatenation. The final product is then
\bigbreak \noindent 
\begin{figure}[ht]
    \centering
    \incfig{machine17}
    \label{fig:machine17}
\end{figure}
\bigbreak \noindent 
Notice we added the extra epsilon transition (pink), this is to bypass the kleene star if the choice of zero occurences is executed.



    \pagebreak 
    \item \textbf{Properties of union, intersect, and concatenation for two FA's}: the properties of union, intersection, and concatenation for finite automata (FAs) are directly tied to the properties of regular languages.
        \bigbreak \noindent 
        \textbf{Union of two FA}
        \begin{itemize}
            \item \textbf{Closure}: The class of regular languages (those recognized by FA) is closed under union. This means the union of two regular languages is also regular, and there exists an FA that recognizes the union of the languages.
            \item \textbf{Commutative:} Union is commutative for FA, meaning the order of combining automata does not matter.
            \item \textbf{Associative:} Union is associative, so it doesn't matter how automata are grouped when performing multiple unions.
            \item \textbf{Distributive over Intersection} Union distributes over intersection for regular languages, just as with sets.
        \end{itemize}
        \textbf{Intersection of two FA}
        \begin{itemize}
            \item \textbf{Closure:} The class of regular languages is also closed under intersection, meaning there is always an FA (typically constructed as a DFA) that recognizes the intersection of two regular languages.
            \item \textbf{Commutative:} Intersection is commutative, meaning the order of combining automata doesn't matter.
            \item \textbf{Associative:} Intersection is associative, so the grouping doesn't matter.
            \item \textbf{Distributive over Union:} Intersection distributes over union for regular languages, just as with sets.
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Concatenation}
        \begin{itemize}
            \item \textbf{Closure:} Regular languages are closed under concatenation.
            \item \textbf{Associativity:} Concatenation is associative. This means that the way in which you group the automata when performing concatenation doesn't matter. 
            \item \textbf{Identity Element:} The identity element for concatenation is the language that contains only the empty string,
                \begin{align*}
                    L(A)  \cdot \{\epsilon\} = L(A)
                .\end{align*}
            \item \textbf{Distributivity Over Union:} Concatenation distributes over union. This means:
                \begin{align*}
                    L(A) \cdot (L(B) \cup (L(C)) = L(A) \cdot L(B)) \cup (L(A) \cdot L(C))
                .\end{align*}
            \item \textbf{Concatenation with the Empty Set:} Concatenating any language with the empty set results in the empty set. This is because there are no strings to concatenate if one of the languages is empty:
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Not commutative}






    \end{itemize}


    \pagebreak 
    \unsect{DSA}
    \bigbreak \noindent 
    \subsection{C++ Stuff}
    \bigbreak \noindent 
    \subsubsection{Type declarations: Definitions and theorems}
    \begin{itemize}
        \item \textbf{Discern any type}: Some rules,
            \begin{enumerate}
                \item Start with the variable name, we read from inside to out
                \item const, \%, *, and basic types go on the left
                \item const refers to what is immediately on the left (except for \texttt{const int*}), but the standard form of this is actually \texttt{int const*}. Thus, the exception to this is const is at the very left, then it refers to what is immediately right.
                \item arrays and functions go on the right, function args are type declaration sub-problems
            \end{enumerate}
            The Algorithm:
            \begin{itemize}
                \item Start with the variable name, or the implied name position 
                \item Read right until end or )
                \item Read left until end or (
                \item If something still left to read, move out one level of parenthesis and go to 2, else done.
            \end{itemize}
            \bigbreak \noindent 
            Thus, using parenthesis allows us to change direction, this will come in handy.
            \bigbreak \noindent 
            \textbf{Examples}:
            \begin{itemize}
                \item  $a$ is an int $\implies$ \texttt{int a}
                \item $a$ is a pointer to an int $\implies$ \texttt{int * a}
                \item $a$ is a pointer to a constant int $\implies$ \texttt{int const * a} (also \texttt{const int * a})
                \item $a$ is a constant pointer to an int $\implies$ \texttt{int * const a}
                \item $a$ is a constant pointer to a constant int $\implies$ \texttt{int const * const a} (also \texttt{const int * const a})
                \item $a$ is an array of 5 ints $\implies$ \texttt{int a[5]}
                \item $a$ is an array of 5 pointers to constant ints $\implies$ \texttt{int const * a[5]}
                \item $a$ is a pointer to an array of 5 constant ints $\implies$ \texttt{int const (* a)[5]}
            \end{itemize}
        \item \textbf{Multi dimensional arrays (matrices)}: Think of multi-dimensional arrays as arrays of arrays. More indicative of what’s happening internally. \texttt{float dat [3][4];} can be read as: "dat is an array of 3 arrays of 4 floats" (Using the algorithm from above).
            \bigbreak \noindent 
            \textbf{Examples}:
            \begin{itemize}
                \item \texttt{arg1} is a reference to an array of 25 constant pointers to arrays of 8 strings. $\implies$ \texttt{string (* const (\& arg1)[25])[8]}
                    \bigbreak \noindent 
                    \textbf{Note:} Notice how we use parenthesis to change direction
            \end{itemize}
        \item \textbf{Function Pointers}: Pointers point to bytes, which can be interpreted different ways. Pointers can point to bytes that can be interpreted as code, i.e. a function pointer.
            \bigbreak \noindent 
            \textbf{Examples}: 
            \begin{itemize}
                \item $f$ is a pointer to a function which takes an int and returns void. $\implies$ \texttt{void (* f) (int)}
            \end{itemize}
    \end{itemize}

   \pagebreak 
   \subsubsection{G++}
   \begin{itemize}
       \item \textbf{Compliation and linking}:
           Compilers turn source code into executable code.
           \begin{itemize}
               \item \textbf{Source code $\to$ object code (Compilation)}: Object code is almost executable. It contains pieces that it provides to other objects, and holes to be filled in. It is a slow process
               \item \textbf{Object code $\to$ executable (Linking)}: Connects pieces of object files together. This is a fast process
           \end{itemize}
           \bigbreak \noindent 
           \textbf{Note:}  Many “compilers” do both compiling and linking. Most programs are built in two stages:
           \begin{enumerate}
               \item Compile all the source code files
                \item Link the object code file into an executable
           \end{enumerate}
           This is the most efficient way to compile large projects.  Changing a single source code file requires a small number of compilations (slow), followed by linking (fast).
        \item \textbf{Standard unix c compiler}: The standard is GNU gcc
        \item \textbf{Standard unix cpp compiler}: The standard is GNU g++
        \item {g++ Options}: With no options, g++ will go from source to an executable named a.out
            \begin{itemize}
                \item \textbf{-o}: The -o option gives the name of the output file
                \item \textbf{-c}: The -c option makes the compiler stop after the compilation stage. No linking is done. The name of the object code file is the same as the source with the extension replaced with .o
                \item \textbf{-W[\textit{warning}]}: Tell the complier to look for a specific warning
                \item \textbf{-Wall (Warning all)}: There are many -W\textit{warning} options, which warn of various conditions. -Wall warns about all of them. The compiler keeps going through warnings
                    \bigbreak \noindent 
                    \textbf{Note:} A compiler warning is usually a bug waiting to happen. Do all you can to get rid of all warnings.
                \item \textbf{-Werror}: The -Werror option turns all warnings into errors. The compiler aborts on an error.
                \item \textbf{-g}: The -g option turns on debugging, and leaves much extra information in an object file. Executable is much larger, possibly slower.
                \item \textbf{-0}: The -O option turns on optimization. There are several different levels of optimization, e.g. -O0, -O1, -O2, -O3. 
                    \bigbreak \noindent 
                    \textbf{Note:} Optimization may break your code, and -O and -g don’t always work well together
                \item \textbf{-I[\textit{directory}]}: The -I option specifies an additional directory to search for include files. No space between -I and directory
                    \bigbreak \noindent 
                    Thus, 
                    \begin{cppcode}
                    #include "./dir/headerfile" // Without -I
                    #include "headerfile" // With -I : g++ -I./dir ...
                    \end{cppcode}
                \item \textbf{-L[\textit{directory}]}: The -L option specifies an additional directory to search for libraries. No space between -L and directory.
                    \bigbreak \noindent 
                    \textbf{Note:} This option is meant for linking only. It has no effect in compilation.
                \item \textbf{-l[\textit{libraryname}]}: The -l option specifies a library for linking. No space between -l and library name. The library name is related to the libray file name, but it is not identical. Library names start with “lib” and end with “.so.*” or “.a”. These are removed. For example
                    \begin{itemize}
                        \item The math library /lib/x86_64-linux/gnu/libm.so.6 is linked as -lm
                        \item The X11 graphics library /usr/lib/x86_64-linux-gnu/libX11.so is linked as -lX11
                    \end{itemize}
                    \bigbreak \noindent 
                    \textbf{Note:} This option is for linking only. It has no effect in compilation.  Libraries are the last things listed in a linking command.
                    \bigbreak \noindent 
                    If you're linking against a library that is located in a non-standard directory (a directory that is not automatically searched by the linker, such as ./libs), then you need to tell the linker where to find that library using the -L option. Thus, -L tells the compiler  where to look, -l specifies which one to grab.

            \end{itemize}
   \end{itemize}
    
    \pagebreak 
    \subsubsection{Makefiles}

    \pagebreak 
    \unsect{Databases}
    \bigbreak \noindent 
    \subsection{Introduction to databases (db concepts)}
    \bigbreak \noindent 
    \subsubsection{Definitions and theorems}
    \begin{itemize}
        \item \textbf{What is a database?}: A database is a collection of stored operational data used by the application systems of some particular enterprise, better yet a collection of related data.
        \item \textbf{What is an enterprise?}: a generic term for any reasonably large-scale commercial, scientific, technical, or other application. Such as
            \begin{itemize}
                \item Manufacturing
                \item Financial
                \item Medical
                \item University
                \item Government
            \end{itemize}
        \item \textbf{Operational data}: Data maintained about the operation of an enterprise, such as
            \begin{itemize}
                \item Products
                \item Accounts
                \item Patients
                \item Students
                \item Plans
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Note:} Notice that this DOES NOT include input/output data
        \item \textbf{Database Management System (DBMS)}: A Database Management System (DBMS) is a collection of programs that enables users to create and maintain a database. Ie a general-purpose software system that facilitates
            \begin{itemize}
                \item Definition of databases
                \item Construction of databases
                \item Manipulation of data within a database
                \item Sharing of data between users/applications
            \end{itemize}
        \item \textbf{Defining a database}: For the data being stored in the database, defining the database specifies
            \begin{itemize}
                \item The data types
                \item The structures
                \item The constraints
            \end{itemize}
        \item \textbf{Constructing a Database}: Constructing a database is the process of storing the data itself on some storage device
            \bigbreak \noindent 
            \textbf{Note:} The storage device is controlled by the DBMS
        \item \textbf{Manipulating a Database}
            \begin{itemize}
                \item retrieve specific information in a query
                \item update the database to include changes
                \item generate reports from the data
            \end{itemize}
            \bigbreak \noindent 
            Most likely already defined by whatever dbms you choose
        \item \textbf{Sharing a Database}: Sharing a database Allows multiple users and programs to access the database at the same time, any conflicts between applications are handled by the DBMS
        \item \textbf{Other Important Functions of a Database}: Other important functions provided by a DBMS include
            \begin{itemize}
                \item Protection, system protection, security protection
                \item Maintenence, allows updates to be performed easily
            \end{itemize}
        \item \textbf{Simplified Database System Environment}:
            \bigbreak \noindent 
            \fig{.5}{./figures/1.png}
        \item \textbf{Main characteristics of a database system are:}
            \begin{itemize}
                \item Self-describing nature of a database system
                \item Insulation between programs and data, and data abstraction
                \item Support for multiple views of the data
                \item Sharing of data and multi-user transaction processing
            \end{itemize}
        \item \textbf{Other Capabilities of DBMS Systems}: Support for at least one data model through which the user can view the data, There is at least one abstract model of data that allows the user to see the “information” in the database, Relational, hierarchical, network, inverted list, or object-oriented
            \bigbreak \noindent 
            Support for at least one data model through which the user can view the data
            \begin{itemize}
                \item efficient file access which allows us to “find the boss of Susie Jones”
                \item allows us to “navigate” within the data
                \item allows us to combine values in 2 or more databases to obtain “information”
            \end{itemize}
            \bigbreak \noindent 
            Support for high-level languages that allow the user to define the structure of the data, access that data, and manipulate it
            \begin{itemize}
                \item Data Definition Language (DDL)
                \item Data Manipulation Language (DML)
                \item Data Control Language (DCL)
                \item query language access data
                \item operations such as add, delete, and replace
            \end{itemize}
        \item \textbf{Transaction Management}: Transaction management is a feature that provides correct, concurrent access to the database, possibly by many users at the same time, ability to simultaneously manage large numbers of \textit{transactions}
        \item \textbf{Access Control}: Access control is the ability to limit access to data by unauthorized users along with the capability to check the validity of the data. This is to protect against loss when database crashes and prevent unauthorized access to portions of the data
        \item \textbf{Resiliency}: Resiliency is the ability to recover from system failures without losing data, Ideally, should be able to recover from any type of failure, such as 
            \begin{itemize}
                \item sabotage
                \item acts of God
                \item hardware failure
                \item software failure
                \item etc.
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Note}: Obviously, some of these would require more than just software - offsite backups, etc
        \item \textbf{Use of Conceptual Modeling}:
            \bigbreak \noindent 
            \fig{.5}{./figures/2.png}
        \item \textbf{Leveled Architecture of a DBMS}:
            \bigbreak \noindent 
            \fig{.5}{./figures/3.png}
        \item \textbf{External level}: a view or sub-schema, a portion of the logical database, may be in a higher level language
        \item \textbf{Logical Level}: abstraction of the real world as it pertains to the users of the database. DBMS provides a data definition language (DDL) to describe the logical schema in terms of a specific data model such as relational, hierarchical, network, inverted list, etc.
        \item \textbf{Physical Level}: The collection of files and indices, the collection of files and indices, this is the actual data
        \item \textbf{Instance}: An instance of the database is the actual contents of the data, it could be 
            \begin{itemize}
                \item the extension of the database
                \item current state of the database
                \item a snapshot of the data at a given point in time
            \end{itemize}
        \item \textbf{Schema}: The schema of a database is the data about what the data represents. Such as,
            \begin{itemize}
                \item plan of the database
                \item logical plan
                \item physical plan
                \item the intention of the database
            \end{itemize}
        \item \textbf{Schema vs Instance}:
            \bigbreak \noindent 
            \fig{.5}{./figures/4.png}
        \item \textbf{Data Independence}: Data Independence is a property of an appropriately designed database system,  it has to do with the mapping of logical level to physical level, and logical to external
            \begin{itemize}
                \item \textbf{Physical data independence}:  Physical schema can be changed without modifying logical schema
                \item \textbf{Logical data independence}: logical schema can be changed without having to modify any of the external views
            \end{itemize}
        \item \textbf{DCL (Control), DDL (Definition), DML (Manipulation)}: may be completely separate (example is IMS), may be intermixed (DB2), or may be a host language, for example an  application program in which DML commands are embedded such as COBOL or PL/I
        \item \textbf{DBMS Components}:
            \bigbreak \noindent 
            \fig{.5}{./figures/5.png}
        \item \textbf{Overall DBMS Usage Scenario}: Database Administrator (DBA) define the conceptual, logical, and physical levels using DDL.  DBMS software stores instances of these in schemas.  User defines views (External Schema) in DDL. User accesses database using DML
        \item \textbf{Advantages of a Database}:
            \begin{itemize}
                \item Controlled redundancy
                \item Reduced inconsistency in the data
                \item Shared access to data
                \item Standards enforced
                \item Security restrictions maintained
                \item Integrity maintained more easily
                \item Provides capability for backup and recovery
                \item Permitting inferences and actions using rules
            \end{itemize}
        \item \textbf{Disadvantages of a Database}:
            \begin{itemize}
                \item Increased complexity needed to implement concurrency control
                \item Increased complexity needed for centralized access control
                \item Security needed to allow the sharing of data
                \item Necessary redundancies can cause complexity when updating
            \end{itemize}
        \item \textbf{Data vs Information}:
            \begin{itemize}
                \item \textbf{Data}: Data refers to raw, unprocessed facts, figures, and details. It represents basic elements that have not been interpreted or given any meaning.
                \item \textbf{Information}: Information is processed, organized, or structured data that is meaningful and useful. It is data that has been interpreted or analyzed to provide context, relevance, and purpose.
            \end{itemize}
    \end{itemize}

    \pagebreak 
    \subsection{Conceptual Modeling and ER Diagrams}
    \bigbreak \noindent 
    \subsubsection{Definitions and theorems}
    \begin{itemize}
        \item \textbf{Data Models}: A means of describing the structure of data, we typically have A set of operations that manipulate the data (for data models that are implemented)
        \item \textbf{Types of data models}:
            \begin{itemize}
                \item Conceptual data model
                \item  Logical data models - relational, network, hierarchical, inverted list, or object-oriented
            \end{itemize}
        \item \textbf{Conceptual Data Model}:
            \begin{itemize}
                \item Shows the structure of the data including how things are related
                \item Communication tool
                \item Independent of commercial DBMSes
                \item Relatively easy to learn and use
                \item Helps show the semantics or meaning of the data
                \item Graphical representation
                \item Entity-Relationship Model is very common
            \end{itemize}
        \item \textbf{Logical Data Models - Relational}: Data is stored in relations (tables). These tables have one value per cell. Based upon a mathematical model.
        \item \textbf{Logical Data Models - Network}: Data is stored in records (vertices) and associations between them (edges), Based upon a model called CODASYL
        \item \textbf{Logical Data Models - Hierarchical}: Data is stored in a tree structure with parent/child relationships
        \item \textbf{Logical Data Models - Inverted List}: Tabular representation of the data using indices to access the tables, Almost relational, but it allows for non-atomic data values \footnote{ "Non-atomic data values" refer to data structures or values that are composed of multiple components, as opposed to atomic data values, which are indivisible and represent a single value.}, which are not allowed in relations
        \item \textbf{Logical Data Models - Object Oriented}: Data stored as objects which contain
            \begin{itemize}
                \item Identifier
                \item Name
                \item Lifetime
                \item Structure
            \end{itemize}
        \item \textbf{Entity-Relationship Model}: Meant to be simple and easy to read. Should be able to convey the design both to database designers and unsophisticated users
        \item \textbf{Entities}: Principle objects about which information is kept - These are the *things* we store data about. If you look at the ER Diagram like a spoken language, the entities are nouns - Person, place, thing, event. When drawn on the ER diagram, entities are shown as rectangles with the name of the entity inside.
            \bigbreak \noindent 
            \fig{.5}{./figures/7.png}
        \item \textbf{Relationships}:  Relationships connect one or more entities together to show an association. A relationship \textit{cannot} exist without at least one associated entity.  Graphically represented as a diamond with the name of the relationship inside, or just beside it
            \bigbreak \noindent 
            \fig{.7}{./figures/8.png}
        \item \textbf{Attributes}: Characteristics of entities \textbf{OR} of relationships, Represent some small piece of associated data, Represented by either a rounded rectangle or an oval.
            \bigbreak \noindent 
            \fig{.5}{./figures/9.png}
        \item \textbf{Attributes on Entities}: When an attribute is attached to an entity, it is expected to have a value for every instance of that entity, unless it is
            allowed to be null. For instance, in the diagram above, Name was an attribute of Person. Every person
            that we store data about will have a value for Name.
        \item \textbf{Attributes on Relationships}: When an attribute is attached to a relationship, it is only expected to have a value when the entities involved in the
            relationship come together in the appropriate way.
            In the diagram from before, the Amount attribute is attached to the donates relationship, which connects the
            Person and Charity entities. Amount will have one value for each time a Person donates to a Charity, denoting how
            much that person donated to the charity. It will not necessarily have a value for a given person, or a given charity.
            This can be referred to as the \textbf{intersection data}.
        \item \textbf{Types of attributes}:
            \fig{.5}{./figures/10.png}
        \item \textbf{Degree of a Relationship}: The degree of a relationship is defined as how many entities it associates. If one entity is associated more than once
            (such as with a recursive relationship), then the degree counts each time it is referenced.
            \bigbreak \noindent 
            \fig{.5}{./figures/11.png}
            \bigbreak \noindent 
            \textbf{Note:} There is no limit to how many entities there can be in a relationship. After binary, and ternary, we start to call the relationships $n$-ary, where $n$ is the degree
        \item \textbf{Connectivity of a Relationship}:
            \begin{itemize}
                \item A constraint of the mapping of associated entities
                \item Written as (minimum, maximum).
                \item Minimum is usually zero or one.
                \item Maximum is a number (commonly one) or can be a letter denoting many.
                \item The actual number is called the cardinality.
            \end{itemize}
            \bigbreak \noindent 
            \fig{.5}{./figures/12.png}
            \bigbreak \noindent 
            Together (from the image) both sides make up the connectivity, to refer to a single side, we use the term "cardinality", ie the cardinality of a person is (1,1). If we hold Address constant (We know a specific address and are therefore refering to that), how many persons may live at that address, in this case (1,1)
        \item \textbf{Attributes on Relationships (revisited)}: Must be on a many-to-many relationship. (1-many and 1-to-1 relationships should have the attribute on one of
the entities involved.  Someone needs to know all of the associated entities to access the attribute.
        \item \textbf{Reading Cardinalities}: For binary relationships:
            \begin{itemize}
                \item For each Thing that smurfs, there are a minimum of $c$, and a maximum of $d$ Objects.
                \item For each Object that smurfs/is smurfed, there is a minimum of $a$ and a maximum of $b$ Things
            \end{itemize}
            \bigbreak \noindent 
            \fig{.5}{./figures/13.png}
        \item \textbf{Weak Entities}: Sometimes you may run into an entity that depends upon another entity for its existence. The weak entity is a tool you can use to represent this.:w
            \bigbreak \noindent 
            Weak entities are written like normal entities, except that they have a double rectangle outline. The relationship
that connects the weak entity to the strong entity it depends upon will be written with a double diamond. This
does not mean that the relationship is weak. It is just to indicate upon which entity the weak entity depends.
\bigbreak \noindent 
\fig{.5}{./figures/14.png}
        \item \textbf{Recursive Relationships}: It is possible for an entity to have a relationship with itself. This is called a recursive relationship. It makes more sense if you think of entities as collections of objects of their appropriate type
        \item \textbf{Recursive Relationships - Many-To-Many}: A many-to-many recursive relationship means that the objects are arranged in a network structure, Notice that the minimum is 0 on both sides. This is important.
            \bigbreak \noindent 
            \fig{.5}{./figures/15.png}
        \item \textbf{Recursive Relationships - One-To-Many}: A one-to-many recursive relationship means that the objects are arranged in a tree structure, Notice that the minimum is still 0 on both sides. This is important.
            \bigbreak \noindent 
            \fig{.4}{./figures/16.png}
        \item \textbf{Entity or Attribute?}: 
            Sometimes it isn’t clear whether something should be an entity or an attribute of some other entity. Usually the
decision will come down to how complicated it is to store the data, and how important it is. If it ends up being used
in multiple places, it might be a clue that you should use an entity
        \item \textbf{Inheritance}: Two types of inheritance available
            \begin{itemize}
                \item ”is a” inheritance. This shows that the subtype IS a member of the supertype.
                \item ”is part of ” inheritance. This shows that the supertype contains, or is made up of members of the subtypes.
            \end{itemize}
            \bigbreak \noindent 
            All attributes of the supertype entity are inherited by the subtype entities. The identifier of the subtypes will be the same as the supertype
            \bigbreak \noindent 
        \item \textbf{IS A Inheritance}:  This type of inheritance happens when you have a supertype and one or more subtypes that are members
            of the supertype. Denoted by an upside-down triangle, with the supertype on top, and the subtypes coming out the bottom.
            \bigbreak \noindent 
            \fig{.5}{./figures/17.png}
        \item \textbf{Defining IS-A inheritance}: There are two things you need to choose when using IS-A inheritance:
            \begin{itemize}
                \item \textbf{Generalization (no) vs. specialization (yes)}: can the supertype occur without being a member of the specified subtypes?
                \item \textbf{Overlapped (yes) vs. disjoint subtypes (no)}: is it possible for a single occurrence of the supertype to be a member of more than one subtype?
            \end{itemize}
            \bigbreak \noindent 
            They are mutually exclusive so you need to pick one of each, ie. GO, GD, SO, SD
        \item \textbf{IS-A inheritance - Generalization}:  Supertype is the union of all of the subtypes, This means that an instance of the supertype CANNOT EXIST without belonging to at least one subtype.
        \item \textbf{IS-A inheritance - Specialization}: The subtype entities specialize the supertype, This means that an instance of the supertype CAN exist without being related to any of the subtypes
        \item \textbf{IS-A inheritance - Overlapping Subtypes}: It is possible for an instance of the supertype to be related to more than one of the subtypes
        \item \textbf{IS-A inheritance - Disjoint Subtypes}: the subtype entities are mutually exclusive, it is not possible for an instance of the supertype to be related to more than one subtype.
        \item \textbf{IS-PART-OF Inheritance}: ”Is part of ” inheritance indicates that the
supertype is constructed from instances of the
subtypes. It is shown on an ER diagram as a circle,
with the supertype on the top, and subtypes on
the bottom.
\bigbreak \noindent 
\fig{.5}{./figures/18.png}
    \item \textbf{Warning about IS-PART-OF}:  The IS PART OF inheritance operator does have its uses, but it is not very commonly used, If you see something involving a certain number of things being present, there are several possibilities
        \begin{itemize}
            \item Sometimes a number is specified that isn’t actually important for what we are modeling. This won’t even be represented on an ER Diagram. This is the case when changing the number wouldn’t have any effect on the necessary structure of a database.
            \item If you need a certain number of items for a relationship to hold, you should explore using the connectivity of the relationship to express that.
            \item Finally, this IS PART OF inheritance might be useful. It is almost never necessary, however.
        \end{itemize}
    \item \textbf{Are you actually representing what you want to?}: Let’s say you’re running a business selling used cars. A simple ER diagram for the sales might look like the following:
        \bigbreak \noindent 
        \fig{.4}{./figures/19.png}
        \bigbreak \noindent 
        The resulting database would have one entry for each time a specific person buys a specific car. If the same person
buys the same car more than once (obviously selling it to someone else at some point), this model would no longer
be appropriate.
\bigbreak \noindent 
Adding a new entity to the relationship for the date/time of the purchase can fix this problem.
\bigbreak \noindent 
\fig{.5}{./figures/20.png}
\bigbreak \noindent 
Notice that the connectivities can change when you add new entities to the relationship.
\item \textbf{Weak Entities - Introduction}: So far, all of the entities we have used have been things that stand on their own. There are some situations where
we are modeling an object for which we certainly need to store data, but the items exist only in the context of some
other entity. Many of these examples can occur
\bigbreak \noindent 
One example of a time that an entity depends on another would be the idea of a city. Within a state, we can
generally be assured that cities will have unique names. If we were working only at that level, the City could be an
entity as we saw above. A good identifier for it would be the name of the city, so we would see the following:
\bigbreak \noindent 
\fig{.5}{./figures/21.png}
\bigbreak \noindent 
In some situations, this would be valid. The Name attribute can serve, in those circumstances, as an appropriate
identifier.
\bigbreak \noindent 
To indicate this sort of dependency, we can make the dependent entity a “weak” entity. This is drawn with a
double-edged rectangle, shown below.
\bigbreak \noindent 
\fig{.4}{./figures/22.png}
\bigbreak \noindent 
Notice that the City entity is now drawn as a weak entity, with a double border. The relationship between the weak
entity and the strong entity is also drawn with a double border. The relationship is not weak, per se, but it is used to
indicate which strong entity the weak entity depends upon.






    \end{itemize}
\end{document}

