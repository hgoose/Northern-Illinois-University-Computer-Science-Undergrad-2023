\documentclass{report}

\input{~/dev/latex/template/preamble.tex}
\input{~/dev/latex/template/macros.tex}

\title{\Huge{}}
\author{\huge{Nathan Warner}}
\date{\huge{}}
\fancyhf{}
\rhead{}
\fancyhead[R]{\itshape Warner} % Left header: Section name
\fancyhead[L]{\itshape\leftmark}  % Right header: Page number
\cfoot{\thepage}
\renewcommand{\headrulewidth}{0pt} % Optional: Removes the header line
%\pagestyle{fancy}
%\fancyhf{}
%\lhead{Warner \thepage}
%\rhead{}
% \lhead{\leftmark}
%\cfoot{\thepage}
%\setborder
% \usepackage[default]{sourcecodepro}
% \usepackage[T1]{fontenc}

% Change the title
\hypersetup{
    pdftitle={CS Complete}
}

\begin{document}
    % \maketitle
        \begin{titlepage}
       \begin{center}
           \vspace*{1cm}
    
           \textbf{Comprehensive CS}
    
           \vspace{0.5cm}
            
                
           \vspace{1.5cm}
    
           \textbf{Nathan Warner}
    
           \vfill
                
                
           \vspace{0.8cm}
         
           \includegraphics[width=0.4\textwidth]{~/niu/seal.png}
                
           Computer Science \\
           Northern Illinois University\\
           United States\\
           
                
       \end{center}
    \end{titlepage}
    \tableofcontents
    \pagebreak 
    \unsect{Theory of Computation}
    \bigbreak \noindent 
    \subsection{Natural Languages, Formal languages: Definitions and theorems}
    \begin{itemize}
        \item \textbf{G\"odel's incompleteness theorem}: 
        G\"odel's Incompleteness Theorems are two fundamental results in mathematical logic that state: 
        \begin{itemize}
            \item  Proved that for some axiomatic
                systems that there is no algorithm
                that will generate all true
                statements from those axioms.
            \item No such system can prove its own consistency.
        \end{itemize}
        This was the first indication that there are inherent limts on algorithms
        \item \textbf{Turing}: Alan Turing later provided formalism to the concepts of an “algorithm” and “computation”, he Invented definition for an abstract machine called the “universal algorithm machine”, he Provided means to formally (i.e., with mathematical rigor) explore the boundaries of what algorithms could, and could not, accomplish. Turing’s model for a universal abstract machine was the basis for the first computer – in fact, Turing was involved in the construction of the first computer.
        \item \textbf{Natural languages}: We communicate via a \textit{natural language}, Although we don’t often think about it, our language is
            guided by rules; spelling, grammar, punctuation
        \item \textbf{Formal language}:
            Formal languages, which are not intended for human-to-
            human communication, are similar to natural languages in
            that they too have rules that define “correct” words and
            statements, but they are also different than natural languages
            in two key ways;
            \begin{itemize}
                \item The rules that define a formal language are strictly enforced. There is no tolerance for misspellings, bad grammar, etc.
                \item For the purpose of determining if a word or statement is
                    acceptable in a formal language, meaning is ignored. Determining
                    if something is (or is not) part of a language is determined by the
                    language’s defining rules which do not attach meaning (i.e., no
                    definitions of words like in natural languages)
            \end{itemize}
            In short, formal languages is a game of symbols, not meaning
        \item \textbf{Formal Languge terminology}:
            \begin{itemize}
                \item \textbf{Symbol}: it is an abstract entity that is not formally defined – like a point or a line in geometry – but think of it as a single character like a letter, numerical digit, punctuation mark, or emoticon
                \item \textbf{String (or Word)}: A finite sequence (i.e., order matters) of zero or more symbols
                \item \textbf{Length}: The length of a string $w$ is denoted by $length(w)$ or $\abs{w}$ and is the number of symbols composing the string. Because strings, by definition, are finite then a string’s lengths is always defined (sometimes zero).
                \item \textbf{Prefix, suffix}: Any number of leading/trailing symbols of the string.
                \item \textbf{Concatenation}: The concatenation of two strings $w$ and $x$ is formed by writing the first string $w$ then the second string $x$
                    \bigbreak \noindent 
                    \textbf{Note:} For any string $w$, $\Lambda w = w\Lambda = w$  
                \item \textbf{Alphabet}: A finite set of symbols, typically denoted by the
                    Greek capital letter sigma $\Sigma$, for example
                    \begin{align*}
                        \Sigma = \{a,b,c\} \quad \Sigma = \{0,1\} \quad \Sigma = \varnothing \quad \text{(special case)}
                    .\end{align*}
            \end{itemize}
        \item \textbf{The empty string}:  A string with zero symbols is called the empty string
            and is denoted by the capital Greek letter lambda $\Lambda$, or sometimes
            lower case Greek letter epsilon $\epsilon$, where $\Lambda$ and $\epsilon$ are \textbf{not} symbols
            \bigbreak \noindent 
            Thus,
            \begin{align*}
                \abs{\Lambda} = 0
            .\end{align*}
        \item \textbf{Formal language definition}: A formal language is a et of strings from some \textbf{one} alphabet. Given an alphabet we generally define a formal language over that alphabet by
            specifying rules that either;
            \begin{enumerate}
                \item Tell us how to test a candidate word, or
                \item Tell us how to construct all words.
            \end{enumerate}
            For example, Given $\Sigma_{1}= \{x\} $, we can define languages
            \begin{align*}
                L_{1} &= \text{ any non empty string } = \{x, xx, xxx,...\} \\
                L_{2} &= \{X^{n}:\ x = 2k+1,\ k\in \mathbb{Z} \} = \{x,xxx,xxxxx,xxxxxxx,...\} \
                L_{3} &= \{x,xxxxxxxx\}
            .\end{align*}
        \item \textbf{The empty language}: The empty language $L = \varnothing$ is typically  denoted with the capital  greek letter phi $\Phi$. Thus, $L = \varnothing = \Phi $
        \item \textbf{Notes on formal languages}:
            \begin{itemize}
                \item All languages are defined over some alphabet; cannot define a language without an alphabet.
                \item Some languages are finite, some languages are infinite (remember, alphabets are always finite).
                \item Some languages include the empty string \(\Lambda\), some do not.
                \item Some languages are defined by rules, some are simply written completely (e.g., \(\Sigma_1 = \{x\}\), \(L_3 = \{x, \text{xxxxxxxxxx}\}\)).
                \item No matter what the alphabet \(\Sigma\) (even \(\Sigma = \emptyset\)), you can always define at least two languages; \(L_1 = \{\Lambda\}\) and \(L_2 = \emptyset\).
            \end{itemize}
        \item \textbf{Closure of an alphabet (closure of $\Sigma$) (Kleene closure)}:
            The language defined by the set of all strings (including the empty string $\Lambda$) over a fixed alphabet $\Sigma$.
            \begin{itemize}
                \item \textbf{Examples:}
                    \begin{align*}
                        \Sigma &= \{a\} & \Sigma^* &= \{\Lambda, a, aa, aaa, aaaa, \dots\} \\
                        \Sigma &= \{0, 1\} & \Sigma^* &= \{\Lambda, 0, 1, 00, 01, 10, 11, 000, \dots\} \\
                        \Sigma &= \emptyset & \Sigma^* &= \{\Lambda\}
                    \end{align*}
                    \bigbreak \noindent 
                    \textbf{Note:} If $\Sigma = \emptyset$ then $\Sigma^*$ is finite and $\Sigma^* = \{\Lambda\}$, otherwise $\Sigma^*$ is infinite.
            \end{itemize}
        \item \textbf{Positive closure}: $\Sigma^{+} = \Sigma^{*} - \{\Lambda\}$, you just take the empty string out of the kleene closure 
        \item \textbf{Recall: Power set}: The power set of any set $S$, written $\mathcal{P}(S)$ is the set of all subsets of $S$, including the empty set and the set $S$ itself.
            \bigbreak \noindent 
            In other words, given a set $S$, then its power set $\mathcal{P}(S)$ is a set of sets
            \begin{itemize}
                \item \textbf{Note:}
                    \begin{itemize}
                        \item If $S = \emptyset$, then then $\mathcal{P}(S) = \mathcal{P}(\emptyset) = \{\emptyset\} = \{\emptyset\}$ = a set with one element $=\emptyset$.
                        \item If $S$ is non-empty and finite with $n$ elements, then $\mathcal{P}(S)$ will be finite with $2^n$ elements.
                        \item If $S$ is infinite, then $\mathcal{P}(S)$ will be infinite.
                    \end{itemize}

                \item \textbf{Example:}

                    If $S = \{x, y, z\}$, then $\mathcal{P}(S)$ will have the following $2^3 = 8$ elements (each a set):
                    \[
                        \mathcal{P}(S) = \{\emptyset, \{x\}, \{y\}, \{z\}, \{x, y\}, \{x, z\}, \{y, z\}, \{x, y, z\}\}
                    \]
            \end{itemize}
        \item \textbf{Power set of the kleene closure $\mathcal{P}(\Sigma^{\star}) $}: Given some alphabet $\Sigma$ we can construct the set of all possible languages from $\Sigma$ as follows (assume non-empty $\Sigma$):
            \bigbreak \noindent 
            \fig{.6}{./figures/6.png}
        \item \textbf{From formal languages to computers}:
            \begin{itemize}
                \item Given an alphabet $\Sigma$ we can define many formal languages – the range of which is captured by $\mathcal{P}(\Sigma^*)$.

                \item We can define many formal languages verbally, but is there a way to define/express every language in any $\mathcal{P}(\Sigma^*)$ with some formal system or abstract machine?

                \item We search for a formal system or abstract machine with enough “power” to define any language in any $\mathcal{P}(\Sigma^*)$.

                \item \textbf{KEY POINT} \\
                    The abstract machines we discover along our search to cover $\mathcal{P}(\Sigma^*)$ turn out to be \textit{the theoretical basis for all computing}.

                \item In other words, by understanding the power (and limitations) of abstract machines that cover $\mathcal{P}(\Sigma^*)$, we are simultaneously discovering the same limits about all computing.
            \end{itemize}
    \end{itemize}

    \pagebreak 
    \subsection{Regular languages}
    \bigbreak \noindent 
    \textbf{Preface.} The first few subsubsections will be in the world of regular languages. In the context of computation theory, regular languages are a class of formal languages that can be recognized by finite automata. These languages are important because they are the simplest class of languages that can be described by a computational model. The characteristics of regular languages are as follows,
    \begin{itemize}
        \item \textbf{Finite Automata:} Regular languages can be recognized by deterministic or nondeterministic finite automata (DFA or NFA).
        \item \textbf{Regular Expressions:} Regular languages can be described using regular expressions.
        \item \textbf{Closure Properties:} Regular languages are closed under several operations, including:
            \begin{itemize}
                \item \textbf{Union:} The union of two regular languages is also regular.
                \item \textbf{Concatenation:} The concatenation of two regular languages is also regular.
                \item \textbf{Kleene Star:} The Kleene star operation, which involves repeating a regular language any number of times (including zero), results in a regular language.
                \item \textbf{Intersection and Difference:} Regular languages are also closed under intersection and difference.
            \end{itemize}
        \item \textbf{Decision Problems:} Certain decision problems are decidable for regular languages. For example, it is possible to determine whether a given string belongs to a regular language (membership problem), whether two regular languages are equivalent, or whether a regular language is empty.
    \end{itemize}
    \bigbreak \noindent 
    \subsubsection{Finite Automata}
    \begin{itemize}
        \item \textbf{Informal definition}: Described informally, a finite automaton (FA) is always associated with some alphabet $\Sigma$ and is an abstract machine which has 
            \begin{enumerate}
                \item A non-empty finite number of states, exactly one of which is designated as the “start state” and some number (possibly zero) of which are designated as “accepting states”.
                \item A transition table that shows how to move from one state to another based on symbols in the alphabet $\Sigma$
            \end{enumerate}
        \item \textbf{A simple example of a FA}:
            \bigbreak \noindent 
            \fig{.5}{./figures/23.png}
            \begin{itemize}
                \item Defined over alphabet $\Sigma = \{0, 1\}$.
                \item States are circles; transitions are directed edges (i.e., arrows) between states.
                \item Has exactly three states; \textbf{A}, \textbf{B}, and \textbf{C}.
                \item Every FA must have exactly one start state. In this example, the start state is \textbf{A} and denoted as the only state that has an edge coming to it from no other state.
                \item There is only one accepting state, \textbf{C}, and it is denoted by its \textit{double circle}. (We could have more than one but in this case we only have one)
                \item \textbf{Very important:}
                    \begin{itemize}
                        \item Each symbol in the alphabet has exactly one associated edge leaving every state.
                        \item In other words, every state must have exactly one edge leaving it for each symbol in the alphabet.
                    \end{itemize}
            \end{itemize}
        \item \textbf{How to use an FA}: The purpose of a FA is to define a language over its alphabet $\Sigma$. The FA provides the means by which to test a candidate string from $\Sigma$ and determine whether or not the string is in the language. It does this by “writing” the candidate string on an fictitious input tape and proceeding as follows:
        \begin{enumerate}
            \item Set the FA to the start state.
            \item If end-of-string then halt.
            \item Read next symbol on tape.
            \item Update the state according to the current state and the last symbol read.
            \item Goto step 2.
        \end{enumerate}
        When the process halts check which state the FA is in. If it is in any accepting state, then the string is in the language defined by the FA, otherwise the string is not in the language
    \item \textbf{Using the previous FA}: Let’s now try to use our FA to test whether or not the string 1001 is in the language
        \bigbreak \noindent 
        We start by writing the string on an input tape, placing the read head at the beginning of the tape, and placing the FA in its initial state, $A$
        \bigbreak \noindent 
        \fig{.8}{./figures/24.png}
        \bigbreak \noindent 
        Since the tape head is not at the end of the tape we
        \begin{enumerate}
            \item Read the next symbol from the tape.
            \item Follow the edge from the state we are currently in that corresponds to the symbol we just read to transition to the next state.
            \item Move the tape head
        \end{enumerate}
        \bigbreak \noindent 
        \fig{.8}{./figures/25.png}
        \bigbreak \noindent 
        In this case, we started in state $A$, read symbol 1, and followed the edge labeled 1 from $A$ which brought us back to $A$
        \bigbreak \noindent 
        We proceed in this way, read, change state, move tape head until we reach the end of the tape
        \bigbreak \noindent 
        Once the tape head reaches the end of the tape we simply look to see whether or not the FA ended in an accepting state.
        \bigbreak \noindent 
        In this case it ended in state $C$, which is an accepting state, which means that string 1001 is in the language.
        \bigbreak \noindent 
        \fig{.8}{./figures/26.png}
        \bigbreak \noindent 
        We deduce that the language has only strings with two consecutive zeroes somewhere.
        \pagebreak \bigbreak \noindent
    \item \textbf{FA Example Two: The set of all strings that do not contain a one ($\Sigma = \{0,1\})$}:
        \bigbreak \noindent 
        \fig{.5}{./figures/27.png}
        \bigbreak \noindent 
        This one is pretty simple. If we have a zero, stay in the accepting state, if we see a one, toss it to the other non-accepting state, its not coming back.
    \item \textbf{FA Example Three: The set of all strings that end in one ($\Sigma = \{0,1\})$}:
        \bigbreak \noindent 
        \fig{.5}{./figures/28.png}
    \item \textbf{FA Example Four: The set of all strings with an odd number of zeros ($\Sigma = \{0,1\})$}:
        \bigbreak \noindent 
        \fig{.5}{./figures/29.png}
    \item \textbf{FA Example Five: The set of all strings where the second to last symbol is one ($\Sigma = \{0,1\})$}:
        \bigbreak \noindent 
        \fig{.5}{./figures/30.png}
    \item \textbf{States are "memory"}: Consider the four FA we just created, in each instance the solution required us to design an FA that remembered at least part of what it had already read from the input tape. The type of memory that an FA has is very different than the RAM we find in
        contemporary computers, but the FA does have memory. Each time the FA enters a different state it is, in effect, redefining the memory of the
        entire FA. The FA can only be in a finite number of states, and that number can be arbitrarily
        large, but (as we will see) that difference in memory has a profound limiting effect in
        what FAs can compute.
        \bigbreak \noindent 
    \item \textbf{Limits of a FA}:
        \bigbreak \noindent 
        \textbf{Limited Memory:}
        \begin{itemize}
            \item \textbf{Finite State:} A finite automaton has a finite number of states. This means it can only "remember" a limited amount of information about the input it has processed. Once a finite automaton transitions to a new state, it forgets all previous information except for the current state.
            \item \textbf{No Stack or Tape:} Unlike more powerful models such as pushdown automata (which have a stack) or Turing machines (which have an infinite tape), finite automata cannot use any form of auxiliary memory to keep track of an unbounded number of items or to perform operations that require more complex memory management.
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Inability to Count Unboundedly:}
        \begin{itemize}
            \item \textbf{No Arbitrary Counting}: Finite automata cannot count occurrences of symbols beyond the number of states they have. For example, a DFA with $n$ states can only count up to $n-1$ occurrences of a symbol reliably. Thus, they cannot recognize languages that require matching counts of different symbols if those counts are unbounded, such as $\{a^n b^n \mid n \geq 1\}$, where the number of 'a's must match the number of 'b's.
        \end{itemize}
    \item \textbf{FA Formal Definition}:
     We formally denote a \textit{finite automaton} by a 5-tuple $(Q, \Sigma, q_0, T, \delta)$, where
    \begin{itemize}
        \item $Q$ is a finite set of \textit{states}.
        \item $\Sigma$ is an alphabet of \textit{input symbols}.
        \item $q_0 \in Q$, is the \textit{start state}.
        \item $T \subseteq Q$, is the set of \textit{accepting states}.
        \item $\delta$ is the \textit{transition function} that maps a state in $Q$ and a symbol in $\Sigma$ to some state in $Q$. In mathematical notation, we say that $\delta: Q \times \Sigma \rightarrow Q$.
            With:
            \begin{itemize}
                \item $Q \times \Sigma$: The Cartesian product of the set of states $Q$ and the alphabet $\Sigma$. This represents all possible pairs of a state and an input symbol.
                \item $\rightarrow Q$: Indicates that the transition function maps each pair $(q, \sigma)$ (where $q \in Q$ and $\sigma \in \Sigma$) to a single state in $Q$.
            \end{itemize}
    \end{itemize}
    \item \textbf{Formally Specifying Our First FA}:
        \bigbreak \noindent 
        \fig{.5}{./figures/23.png}
        \bigbreak \noindent 
        Recall our first FA that accepts any string with two consecutive zeros somewhere.
        \bigbreak \noindent 
        We drew it as a Finite State diagram, but to formally define this FA we must specify each of the elements from the 5-tuple $(Q, \Sigma, q_0, T, \delta)$.
        \begin{itemize}
            \item $Q$ is a finite set of \textit{states}: \hspace{0.2cm} $Q = \{A, B, C\}$
            \item $\Sigma$ is an alphabet of \textit{input symbols}: \hspace{0.2cm} $\Sigma = \{0, 1\}$
            \item $q_0 \in Q$, is the \textit{start state}: \hspace{0.2cm} $q_0 = A$
            \item $T \subseteq Q$, is the set of \textit{accepting states}: \hspace{0.2cm} $T = \{C\}$
            \item $\delta$ is the \textit{transition function} $\delta: Q \times \Sigma \rightarrow Q$
        \end{itemize}
        \[
            \begin{array}{c|cc}
                \delta & \text{0} & \text{1} \\
                \hline
                A & B & C \\
                B & C & A \\
                C & C & C \\
            \end{array}
        \]
    \item \textbf{Unary}: consisting of or involving a single component or element.
    \item \textbf{Unary language}: One where the alphabet has only one symbol.
    \item \textbf{Binary}: Relating to, composed of, or involving two things.
    \item \textbf{Ternary}: Composed of three parts.
    \item \textbf{Dead state (trap state)}: This is a state that once entered, can never be left.
    \item \textbf{Deterministic finite automaton (DFA)}: The FA's we have looked at thus far have been DFA's. A DFA is a finite automaton where, for each state and each input symbol, there is exactly one transition to a new state. This means that given a current state and an input symbol, the next state is uniquely determined. In the future we will look at nondeterministic finite automaton (NFA). An NFA is a finite automaton where, for each state and input symbol, there can be multiple possible transitions to different states. Additionally, an NFA can have transitions that do not consume any input symbol ($\epsilon$-transitions).
    








    \end{itemize}

    \pagebreak 
    \subsubsection{Finite Automata: More examples}
    \begin{itemize}
        \item \textbf{$\Sigma = \{0,1\}$, all strings that start with 00}
        \item \textbf{$\Sigma = \{0,1\}$, all strings that end with 00}
            \bigbreak \noindent 
            \fig{.5}{./figures/31.png}
            \bigbreak \noindent 
            With:
            \begin{itemize}
                \item $Q = \{A,B,C\}$
                \item $\Sigma = \{0,1\}$
                \item $q_{0} = A$
                \item $T = C$
                \item $\delta:\ Q \times \Sigma \to  Q$ defined by                \begin{array}{c|cc}
                    $\delta$ & 0 & 1 \\
                    \hline
                    A & B & A\\
                    B & C & A\\
                    C & C & A
                \end{array}

            \end{itemize}
                
    \end{itemize}


    \pagebreak 
    \subsubsection{nondeterministic Finite automata (NFA)}
    \begin{itemize}
        \item \textbf{NFA definition}:
            \begin{itemize}
                \item If an automaton gets to a state where there is more than one possible transition corresponding to the symbol read from the tape, the automaton may  choose any of those paths. (nondeterminism) We say it \textbf{branches}
                \item if an automaton gets to a state where there is no transition for the symbol read from the tape, then that path of the automaton halts and rejects the string. We say it \textbf{dies}
                \item the automaton accepts the input string if and only if there exists a choice of transitions that ends in an accept state.
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Example}: Consider this nondeterministic FA (NFA) over $\Sigma = \{0, 1\}$
            \bigbreak \noindent 
            \fig{.5}{./figures/32.png}
        \item \textbf{DFA or NFA?}:
            Consider the language $L$ over $\Sigma = \{a, b\}$ which is defined by
            \begin{align*}
                L = (a^{*}) + (ab)^{*}
            .\end{align*}
            \bigbreak \noindent 
            \fig{.5}{./figures/33.png}
        \item \textbf{NFA Formal definition}: We define an NFA $M(Q, \Sigma, q_{0}, T, \delta) $
            \begin{itemize}
                \item $Q$ is a finite set of states
                \item $\Sigma$ is an alphabet of input symbols
                \item $q_0 \in Q$ is the start state
                \item $T \subseteq Q$ is the set of accepting states
                \item $\delta$ is the transition function $\delta: Q \times \Sigma \to P(Q)$
            \end{itemize}
        \item \textbf{Transition function, DFA vs NFA}:
            \bigbreak \noindent 
            \fig{.5}{./figures/34.png}
        \item \textbf{NFA with $\epsilon$-transitions}: $\epsilon$-transitions allow the automaton to change state without
            consuming an input symbol
            \bigbreak \noindent 
            Changing states without consuming input symbols can go on arbitrarily long as there are $\epsilon$-transitions to traverse.
        \item \textbf{DFA or NFA with $\epsilon$-moves?}: Consider the language L over $\Sigma = \{a, b\}$ which is
            \begin{align*}
                L = (b^{*}a) + (a^{*}b)
            .\end{align*}
            \bigbreak \noindent 
            \fig{.5}{./figures/35.png}
        \item \textbf{NFA with $\epsilon$-transitions formal definition}: Everything is the same except for the transition function, we now have
            \begin{align*}
                \delta:\ Q \times (\Sigma \cup \{\epsilon\}) \to \mathcal{P}(Q)
            .\end{align*}
            \pagebreak \bigbreak \noindent 
        \item \textbf{$\delta$ – DFA, NFA, and NFA with $\epsilon$-moves}:
            \bigbreak \noindent 
            \fig{.35}{./figures/36.png}
        \item \textbf{DFA, NFA, or NFA with $\epsilon$ moves, who can define the most languages?}: We begin by noting, by definition, every DFA is an NFA. This means that any language you can define with a DFA can also be defined by an NFA. Thus,
            \begin{align*}
                \text{Languages defined by DFA} \subseteq \text{ Languages defined by NFA}
            .\end{align*}
            Also, by definition, every DFA is an NFA with $\epsilon$-moves, an NFA is an NFA with $\epsilon$ moves, even if it doesnt have any. Thus,
            \begin{align*}
                \text{Languages defined by DFA} \subseteq \text{ Languages defined by NFA with $\epsilon$-moves}
            .\end{align*}
            \bigbreak \noindent 
            But, by definition, every NFA is an NFA with $\epsilon$-moves. Thus,
            \begin{align*}
                \text{Languages defined by NFA} \subseteq \text{ Languages defined by NFA with $\epsilon$-moves}
            .\end{align*}
            \bigbreak \noindent 
            This tells us that
            \begin{itemize}
                
                \item NFAs are at least as powerful in defining languages as DFAs
                \item NFAs with $\epsilon$-moves are at least as powerful in defining languages as DFAs and NFAs.
            \end{itemize}
            \bigbreak \noindent 
            It turns out that these three are \textbf{equally} as powerful. We assert
            \begin{align*}
                &\text{Languages defined by DFA's} \\
                &=\text{Languages defined by NFA's} \\
                &=\text{Languages defined by NFA's with $\epsilon$-moves}
            .\end{align*}
            We prove this by showing an algorithm that converts any NFA with $\epsilon$-moves (or any NFA) to a DFA that accepts the exact same language
            \bigbreak \noindent 
            This means that there does not exist a language that can be defined by an NFA with $\epsilon$-moves (or NFA) that cannot also be defined by a DFA.
        \item \textbf{$\epsilon$-closure}: Before we can look at the algorithm we must first define the $\epsilon$-closure of a set of states 
            \bigbreak \noindent 
            Given:
            \begin{itemize}
                \item an NFA with $\epsilon$-moves $M(Q, \Sigma, q_{0}, T, \delta) $
                \item Some set of states $S \subseteq Q$
            \end{itemize}
            \bigbreak \noindent 
            \text{We define the } \varepsilon\text{-closure}(S) \text{ as the set of states that are reachable from the set of states } S \text{ using only zero or more } \varepsilon\text{-moves in } \delta.
            \bigbreak \noindent 
            \text{Note: it is always the case that } S \subseteq \varepsilon\text{-closure}(S)
            \bigbreak \noindent 
            The formal definition is
            \begin{align*}
                \epsilon-\text{closure}(q) = \{q\} \cup \{p:\ q \xrightarrow{\epsilon} p\}
            .\end{align*}
        \item \textbf{$\epsilon$-closure alternate notation}. 
            \begin{align*}
                \epsilon\text{-closure}(\{A\}) = \epsilon(\{A\}) = E(\{A\})
            .\end{align*}
        \item \textbf{$\epsilon$-closure of the empty set $\varnothing$}: The epsilon closure of the empty set is $\epsilon(\varnothing)  = \varnothing$
        \item \textbf{Algorithm: Converting NFA with $\epsilon$-moves to DFA}: The algorithm constructs a new DFA $M^{\prime}(Q^{\prime}, \Sigma, q_{0}^{\prime}, T^{\prime}, \delta^{\prime}) $ From an NFA with $\epsilon$-moves $M(Q, \Sigma, q_{0}, T, \delta) $. $\Sigma$ will remain the same
            \bigbreak \noindent 
            Things to note about the conversion:
            \begin{itemize}
                \item Same alphabet $\Sigma $
                \item Lose column $\epsilon$
                \item Lose all nondeterminism
                \item Lose all empty sets
                \item Cell values change from sets of states to states
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Example}:
            \textbf{Consider the following NFA with $\varepsilon$-moves M(Q, $\Sigma$, $q_0$, T, $\delta$) over $\Sigma = \{0, 1\}$ and its associated transition table $\delta$: Q $\times$ ($\Sigma \cup \{\varepsilon\}$) $\rightarrow$ P(Q)}
            \bigbreak \noindent 
            \[
                \begin{array}{|c|c|c|c|}
                    \hline
                     & 0 & 1 & \varepsilon \\
                    \hline
                    X & \{Y\} & \{Y\} & \emptyset \\
                    \hline
                    Y & \{X, Z\} & \{Z\} & \{Z\} \\
                    \hline
                    Z & \emptyset & \{Y\} & \emptyset \\
                    \hline
                \end{array}
            \]
            \bigbreak \noindent 
            Start by computing the $\epsilon$-closure of the start state in $\delta$.
            \bigbreak \noindent 
            \fig{.4}{./figures/37.png}
            \bigbreak \noindent 
            There is a subtle - but very important - point to be made here …
            \bigbreak \noindent 
            we cannot simply take the $\epsilon$-closure (a set) and use it to create a row in $\delta^{\prime}$ (which needs to be a state). What we do is create a label for the new state in $\delta^{\prime}$ that represents the set of states from $\delta$ and then add that new state to $\delta^{\prime}$
            \bigbreak \noindent 
            In this instance we represented the set of states $\{X\}$ by a single state whose label is $X^{\prime}$
            \bigbreak \noindent 
            We continue by filling the columns of the start state for each symbol $\Sigma = \{0, 1\}$
            \bigbreak \noindent 
            Processing $\delta'$ state $X'$ which represents the set of states $\{X\}$ in $M$:
            \begin{itemize}
                \item Processing input symbol 0 (process each state in $\{X\}$ using $\delta$):
                    \begin{itemize}
                        \item Process $X$
                            \[
                                \delta(X, 0) = \{Y\}
                            \]
                            \[
                                \varepsilon\text{-closure}(\{Y\}) = \{Y, Z\}
                            \]
                    \end{itemize}
            \end{itemize}
    Since there are no more states in $\{X\}$ to process, we have finished processing the symbol 0 and have produced the set of states $\{Y, Z\}$.
    \bigbreak \noindent 
    We create a new state with label $Y'Z'$ (or $Z'Y'$, order does not matter) for $\delta'$ that represents $\{Y, Z\}$ in $M$ and define:
    \[
    \delta'(X', 0) = Y'Z'
    \]
    We note that $Y'Z'$ is a new state in $\delta'$ and so we create a new row for it in $\delta'$.
    \bigbreak \noindent 
    We continue this until we reach 
    \bigbreak \noindent 
    \fig{.8}{./figures/38.png}
    \bigbreak \noindent 
    Processing $\delta'$ state $Y'Z'$ which represents the set of states $\{Y, Z\}$ in $M$:
    \begin{itemize}
        \item Processing 0:
            \begin{itemize}
                \item Process $Y$
                    \[
                        \delta(Y, 0) = \{X, Z\}, \quad \varepsilon\text{-closure}(\{X, Z\}) = \{X, Z\}
                    \]
                \item Process $Z$
                    \[
                        \delta(Z, 0) = \emptyset, \quad \varepsilon\text{-closure}(\emptyset) = \emptyset
                    \]
            \end{itemize}
    \end{itemize}
    Here is our first instance of processing a state and symbol where the state in $\delta'$ represents multiple states in NFA $M$. When this happens, the set of states in NFA $M$ is computed by \textit{taking the union of the $\varepsilon$-closures}: $\{X, Z\} \cup \emptyset = \{X, Z\}$.
    \bigbreak \noindent 
    This produces a new label $X'Z'$ which we use to define:
    \[
        \delta'(X'Y', 0) = X'Z'
    \]
    and since $X'Z'$ is a new state, we add it to $\delta'$.
    \bigbreak \noindent 
    We continue this until we reach 
    \bigbreak \noindent 
    \fig{.8}{./figures/39.png}
    \bigbreak \noindent 
    A state in $M^{\prime}$ is an accepting state iff at least one of the states that it represents in $M$ is an accepting state … in this case $T^{\prime}= \{Y^{\prime}Z^{\prime}\}$.
    \bigbreak \noindent 
    We can now draw the new DFA 
    \bigbreak \noindent 
    \fig{.7}{./figures/40.png}
    \bigbreak \noindent 
    \textbf{Note:} If the closure or union of closures is the empty set, we do this
    \bigbreak \noindent 
    \fig{.7}{./figures/41.png}
    \bigbreak \noindent 
    This "emtpy" is a state and represents a garbage state, what goes does not leave.
\item \textbf{Kleene's theorem revisited}: The following are equivalent for a language $L$
    \begin{enumerate}
        \item There is a DFA for $L$
        \item There is an NFA for $L$
        \item There is an RE for $L$
    \end{enumerate}
    \item \textbf{Union of two DFA's (cartesian product construction)}:
        The process of finding the union of two deterministic finite automata (DFAs) involves creating a new DFA that accepts the union of the languages accepted by the original DFAs. This is done using a product construction (also called the Cartesian product construction), where you combine the states of both DFAs in a systematic way to ensure the resulting DFA accepts strings from either of the original DFAs.
        \bigbreak \noindent 
        Let’s say we have two DFAs:
        \[
            D_1 = (Q_1, \Sigma, \delta_1, q_1^{\text{start}}, F_1)
        \]
        that recognizes language \( L_1 \).
        \[
            D_2 = (Q_2, \Sigma, \delta_2, q_2^{\text{start}}, F_2)
        \]
        that recognizes language \( L_2 \).
        \bigbreak \noindent 
        \textbf{Create a New DFA State Set}:
        \bigbreak \noindent 
        \begin{itemize}
            \item The states of the new DFA are pairs of states, one from each of the original DFAs. The new state set will be the Cartesian product \(Q_1 \times Q_2\), meaning every possible combination of a state from \(D_1\) and a state from \(D_2\).
            \item If \(D_1\) has \(n\) states and \(D_2\) has \(m\) states, the new DFA will have \(n \times m\) states.
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Define the New Start State}:
        \begin{itemize}
            \item The new start state is \((q_1^{\text{start}}, q_2^{\text{start}})\), where \(q_1^{\text{start}}\) is the start state of \(D_1\) and \(q_2^{\text{start}}\) is the start state of \(D_2\).
        \end{itemize}
        \textbf{Define the New Transition Function:}
        \begin{itemize}
            \item The transition function \(\delta\) for the new DFA operates by taking an input symbol and applying the transition functions of both original DFAs in parallel.
            \item For each input symbol \(a \in \Sigma\), the new DFA transitions from state \((q_1, q_2)\) to state \((\delta_1(q_1, a), \delta_2(q_2, a))\).
            \item In other words, if \(q_1\) moves to \(q_1'\) on input \(a\) in \(D_1\), and \(q_2\) moves to \(q_2'\) on input \(a\) in \(D_2\), the new DFA will move from \((q_1, q_2)\) to \((q_1', q_2')\).
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Define the New Set of Accepting (Final) States}:
        The new DFA will accept a string if either of the original DFAs would accept it. Therefore, the set of final states \( F \) in the new DFA is defined as:
        \[
            F = \{ (q_1, q_2) \mid q_1 \in F_1 \ \text{or} \ q_2 \in F_2 \}
        \]
        This means that if either \( q_1 \) is a final state in \( D_1 \), or \( q_2 \) is a final state in \( D_2 \), the pair \( (q_1, q_2) \) is a final state in the new DFA.
        \bigbreak \noindent 
        \textbf{Note:} It is possible in the new DFA (constructed as the union of two DFAs) to have states that are unreachable—meaning there are states in the DFA that cannot be reached from the start state. This typically happens because, in the product construction, we generate all possible pairs of states from the two original DFAs, but not all of these pairs are necessarily reachable.
        \bigbreak \noindent 
        The union of two finite automata (FAs) is useful for constructing a new automaton that recognizes any string accepted by either of the two original automata. This has several practical applications in theoretical computer science and programming:
    \item \textbf{Finding the intersection of two DFA's}: The process is basically the same as finding the union, but it differs in how we define the accepting states in the new machine, the accepting states will be
        \begin{align*}
            T = \{(q_{1},q_{2}):\ q_{1} \in T_{1} \text{ and } q_{2} \in T_{2}\}
        .\end{align*}
        \bigbreak \noindent 
        \textbf{Note:} The intersection of two DFAs is useful in various practical applications where you need to accept only the strings that satisfy the conditions or rules of both automata
    \item \textbf{Concatenation of two DFA's}: The process is simple
        \bigbreak \noindent 
        For two machines $M_{1}(Q_{1}, \Sigma, q_{0_{1}}, T_{1}, \delta_{1})$, and $M_{2}(Q_{2}, \Sigma, q_{0_{2}}, T_{2}, \delta_{2})$ 
        \begin{enumerate}
            \item Connect the final states of the first machine to the start state of the second machine (With $\epsilon$-transitions)
            \item Clear $T_{1}$, There are no more final states in the first machine
            \item Convert $\epsilon$-NFA to DFA
        \end{enumerate}
        \textbf{Note:} The concatenation of two DFAs has practical uses in many scenarios where the language of interest is the concatenation of two sublanguages. Concatenating two DFAs allows you to recognize strings that can be divided into two parts, where the first part is recognized by one DFA and the second part is recognized by the other.
    \item \textbf{Finding the union of two NFA's}:
        taking the union of two nondeterministic finite automata (NFAs) involves constructing a new NFA that accepts any string that is accepted by either of the original NFAs. This process can be done by creating a new NFA that combines the two original NFAs. 
        \bigbreak \noindent 
        Given $M_{1}(Q_{1}, \Sigma, q_{0_{1}}, T_{1}, \delta_{1}) $, and $M_{2}(Q_{2}, \Sigma, q_{0_{2}}, T_{2}, \delta_{2}) $
        \bigbreak \noindent 
        \begin{enumerate}
            \item \textbf{New start state}: Start by defining a new start state $q^{\prime}_{0}$, this state will have $\epsilon$ transitions to the start states of both machines.
            \item \textbf{Define $Q^{\prime}$, the new set of states}: The new set of states will be the set of all states in $M_1$, and it will include all the states in $M_2$, along with the new start state. Thus,
                \begin{align*}
                    Q^{\prime} = Q_{1} \cup Q_{2} \cup \{q^{\prime}_{0}\}
                .\end{align*}
            \item \textbf{Define the transition function}: The transition function $\delta^{\prime}$ of the new NFA will include:
                \begin{itemize}
                    \item All the transitions of $M_{1}$ and $M_{2}$
                    \item Two $\epsilon$ transitions from the new start state to the start states of the two original machines $q_{0_{1}}$ and $q_{0_{2}}$. Thus,
                        \begin{align*}
                            \delta^{\prime}(q_{0}^{\prime}, \epsilon) = \{q_{0_{1}}, q_{0_{2}}\}
                        .\end{align*}
                \end{itemize}
            \item \textbf{Define the set of accepting states}: The set of accepting states will be
                \begin{align*}
                    T^{\prime} = T_{1} \cup T_{2}
                .\end{align*}
        \end{enumerate}
        \pagebreak \bigbreak \noindent 
        \textbf{Example:}
        \begin{figure}[ht]
            \centering
            \incfig{machine10}
            \label{fig:machine10}
        \end{figure}
        \bigbreak \noindent 
        $M_1 \cup M_2$ is then
        \begin{figure}[ht]
            \centering
            \incfig{machine11}
            \label{fig:machine11}
        \end{figure}
        \pagebreak \bigbreak \noindent 
    \item \textbf{Finding the intersection of two NFA's}: 
        For NFAs, intersection is more complex because NFAs are nondeterministic and don’t handle intersection naturally. Typically, you convert the NFAs to DFAs and then apply the DFA product construction
    \item \textbf{Concatenation of two NFA's}: The process is the same as with two DFA's (see above), but you don't need to convert to a DFA at the end.
    % \item \textbf{Convert DFA into RE}: To convert a DFA (Deterministic Finite Automaton) into a Regular Expression (RE), you can use the state elimination method or generalized transition automaton method. This process works by gradually reducing the DFA's states and transitions until only a regular expression representing the entire language remains.
    %     \bigbreak \noindent 
    %     Given a DFA $M(Q, \Sigma, \delta, q_{0}, F)$, the goal is to find a regular expression that represents the language recognized by this DFA.
    %     \bigbreak \noindent 
    %     \textbf{Process:}
    %     \begin{enumerate}
    %         \item \textbf{Add a new Start and accept state}:
    %             \begin{itemize}
    %                 \item Add a new start state \( q_s \) with an \(\epsilon\)-transition (empty string) to the original start state \( q_0 \). 
    %                     \bigbreak \noindent 
    %                     \textbf{Note:} Once you add the new start state \( q_s \) with an \(\epsilon\)-transition to the original start state \( q_0 \), \( q_0 \) is no longer considered the start state. Instead, \( q_0 \) becomes just another intermediate state in the automaton. The new start state is \( q_s \), and it immediately transitions to \( q_0 \) without consuming any input (via the \(\epsilon\)-transition).
    %                 \item Add a new accept state \( q_f \) and add \(\epsilon\)-transitions from each of the original accept states to this new accept state \( q_f \).
    %                     \bigbreak \noindent 
    %                     \textbf{Note:} Similarly, when you add the new accept state \( q_f \) and connect it via \(\epsilon\)-transitions from the original final states in \( F \), the original final states are no longer considered final states in the sense of marking the end of a string's acceptance. Now, the new final state \( q_f \) serves as the sole final state, and the automaton reaches \( q_f \) via \(\epsilon\)-transitions from the original final states.
    %             \end{itemize}
    %             These new states simplify the process because now there's exactly one start state and one accept state.
    %         \item \textbf{Eliminate States One by One}:
    %             \begin{itemize}
    %                 \item The idea is to progressively eliminate states from the DFA while updating the transitions between the remaining states with regular expressions.
    %                 \item Every time you eliminate a state $r$, you need to update the regular expressions on the transitions between the remaining states to account for the paths that go through $r$.
    %             \end{itemize}
    %             For any three states \( p \), \( r \), and \( q \), if there is a path from \( p \) to \( q \) that goes through \( r \), the new transition after eliminating \( r \) will include the regular expression:
    %             \[
    %                 R(p \rightarrow q) = R(p \rightarrow q) + R(p \rightarrow r) R(r \rightarrow r)^* R(r \rightarrow q)
    %             \]
    %             \pagebreak \bigbreak \noindent 
    %             Where:
    %             \begin{itemize}
    %                 \item \( R(p \rightarrow q) \) is the regular expression for the direct transition from \( p \) to \( q \).
    %                 \item \( R(p \rightarrow r) \) is the regular expression for the transition from \( p \) to \( r \).
    %                 \item \( R(r \rightarrow r) \) is the regular expression for the loop on state \( r \).
    %                 \item \( R(r \rightarrow q) \) is the regular expression for the transition from \( r \) to \( q \).
    %                 \item \( + \) represents union, and \( * \) represents the Kleene star (zero or more repetitions).
    %             \end{itemize}
    %             \bigbreak \noindent 
    %             After updating the transitions, remove the state \( r \).
    %             \bigbreak \noindent 
    %         \item \textbf{Repeat the Elimination Until Only Two States Remain}:
    %             Continue eliminating states and updating the transitions until only two states remain: the start state \( q_s \) and the new accept state \( q_f \).
    %             \bigbreak \noindent 
    %             At this point, the regular expression on the transition from \( q_s \) to \( q_f \) represents the language of the DFA.
    %     \end{enumerate}
    %     \bigbreak \noindent 
    %     \textbf{Example}: For the alphabet $\Sigma = \{0,1\}$, let's take the machine that accepts the strings with any number of ones, but the total number of zero's must be odd, and convert it to a RE.
    %     \begin{figure}[ht]
    %         \centering
    %         \incfig{machine1}
    %         \label{fig:machine1}
    %     \end{figure}
    %     \bigbreak \noindent 
    %     Let's start by making the new start and end states
    %     \pagebreak \bigbreak \noindent 
    %     \begin{figure}[ht]
    %         \centering
    %         \incfig{machine4}
    %         \label{fig:machine4}
    %     \end{figure}
    %     \bigbreak \noindent 
    %     Now we start eliminating states, note that it does not matter in which order we eliminate the states, but for this example we will begin by eliminating state $A$. To get from the start state $q_{0}$ to state $B$, we need to pass through $A$, to get from $A$ to $B$, we can have any number of $1's$ followed by a zero which takes us to be. Thus, the transition from $q_{0}$ to $B$ is the regular expression $1^{*}0$
    %     \bigbreak \noindent 
    %     We also have to consider the original transition from $B$ to $A$, and then back to $B$, for this we have the RE $01^{*}0$. Thus the machine becomes
    %     \bigbreak \noindent 
    %     \begin{figure}[ht]
    %         \centering
    %         \incfig{machine9}
    %         \label{fig:machine9}
    %     \end{figure}
    %     \bigbreak \noindent 
    %     To eliminate $B$, we need to consider the transitions through $B$ ie from $q_{0}$ to $q_{f}$. We know to get from $q_{0}$ to $B$ we have the RE $1^{*}0$, then from $B$ to $q_{f}$ we have $(1 + 01^{*}0)^{*} $. Thus, the transition for $q_{0}$ to $q_{f}$ is $1^{*}0(1 + 1^{*}01^{*}0)^{*} $. And the final machine with only one regular expression is 
    %     \begin{figure}[ht]
    %         \centering
    %         \incfig{machine8}
    %         \label{fig:machine8}
    %     \end{figure}
    %     \pagebreak 
%     \item \textbf{Convert RE to NFA}: Before we begin, recall order of operations (From highest to lowest )
%         \begin{enumerate}
%             \item Parenthesis  
%             \item Kleene star
%             \item Concatenation
%             \item Union (+ or \|)
%         \end{enumerate}
%         Let's consider the regular expression $aa(a+b)^{*}bb$
%         \begin{enumerate}
%             \item We start by defining simple NFA's for each symbol ($a$ and $b$)
%         \end{enumerate}
%         \begin{figure}[ht]
%             \centering
%             \incfig{machine12}
%             \label{fig:machine12}
%         \end{figure}
%         \bigbreak \noindent 
%         Then, by precedence, we design an NFA for inside the parenthesis, and then for the kleene star of the parenthesis. To make the NFA for $a + b$, we follow the rules for the union of two NFAs
%         \bigbreak \noindent 
%     \begin{figure}[ht]
%         \centering
%         \incfig{machine13}
%         \label{fig:machine13}
%     \end{figure}
%     \bigbreak \noindent 
%     In order to take the kleen star of this machine, we need to allow for zero or more repetitions. Thus,
%     \bigbreak \noindent 
% \begin{figure}[ht]
%     \centering
%     \incfig{machine14}
%     \label{fig:machine14}
% \end{figure}
% \bigbreak \noindent 
% Now we create two more NFA's, one for $aa$, and one for $bb$
% \bigbreak \noindent 
% \begin{figure}[ht]
%     \centering
%     \incfig{machine15}
%     \label{fig:machine15}
% \end{figure}
% \pagebreak \bigbreak \noindent 
% Now, we combine them all using the logic of concatenation. The final product is then
% \bigbreak \noindent 
% \begin{figure}[ht]
%     \centering
%     \incfig{machine17}
%     \label{fig:machine17}
% \end{figure}
% \bigbreak \noindent 
% Notice we added the extra epsilon transition (pink), this is to bypass the kleene star if the choice of zero occurences is executed.
%


    \pagebreak 
    \item \textbf{Properties of union, intersect, and concatenation for two FA's}: the properties of union, intersection, and concatenation for finite automata (FAs) are directly tied to the properties of regular languages.
        \bigbreak \noindent 
        \textbf{Union of two FA}
        \begin{itemize}
            \item \textbf{Closure}: The class of regular languages (those recognized by FA) is closed under union. This means the union of two regular languages is also regular, and there exists an FA that recognizes the union of the languages.
            \item \textbf{Commutative:} Union is commutative for FA, meaning the order of combining automata does not matter.
            \item \textbf{Associative:} Union is associative, so it doesn't matter how automata are grouped when performing multiple unions.
            \item \textbf{Distributive over Intersection} Union distributes over intersection for regular languages, just as with sets.
        \end{itemize}
        \textbf{Intersection of two FA}
        \begin{itemize}
            \item \textbf{Closure:} The class of regular languages is also closed under intersection, meaning there is always an FA (typically constructed as a DFA) that recognizes the intersection of two regular languages.
            \item \textbf{Commutative:} Intersection is commutative, meaning the order of combining automata doesn't matter.
            \item \textbf{Associative:} Intersection is associative, so the grouping doesn't matter.
            \item \textbf{Distributive over Union:} Intersection distributes over union for regular languages, just as with sets.
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Concatenation}
        \begin{itemize}
            \item \textbf{Closure:} Regular languages are closed under concatenation.
            \item \textbf{Associativity:} Concatenation is associative. This means that the way in which you group the automata when performing concatenation doesn't matter. 
            \item \textbf{Identity Element:} The identity element for concatenation is the language that contains only the empty string,
                \begin{align*}
                    L(A)  \cdot \{\epsilon\} = L(A)
                .\end{align*}
            \item \textbf{Distributivity Over Union:} Concatenation distributes over union. This means:
                \begin{align*}
                    L(A) \cdot (L(B) \cup (L(C)) = L(A) \cdot L(B)) \cup (L(A) \cdot L(C))
                .\end{align*}
            \item \textbf{Concatenation with the Empty Set:} Concatenating any language with the empty set results in the empty set. This is because there are no strings to concatenate if one of the languages is empty:
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Not commutative}






    \end{itemize}

        \pagebreak 
    \subsubsection{Regular expressions}
    \begin{itemize}
        \item \textbf{RE}: A RE corresponds to a set of strings; that is, a RE describes a language
        \item \textbf{RE three operations}:
            \begin{enumerate}
                \item Union (+)
                \item concatenation (xy)
                \item star (zero or more copies)
            \end{enumerate}
        \item \textbf{RE special symbols}
            \begin{align*}
                + \quad * \quad (\ \ )
            .\end{align*}
        \item \textbf{Grouping}: The parenthesis are used for grouping, 
        \item \textbf{Union}: the plus sign means \textbf{union}. Thus, writing
            \begin{align*}
                0 + 1
            .\end{align*}
            Means zero or one, we refer to + as "or"
        \item \textbf{Concatenation}: We concatenate simply by writing one expression after the other, with no spaces
            \begin{align*}
                (0+1)0
            .\end{align*}
            Is the pair of strings 00 and 10
        \item \textbf{Empty string}: We can also use the empty string $\epsilon$
            \begin{align*}
                (0 + 1)(0 + \epsilon)
            .\end{align*}
            corresponds to 00, 0, 10, and 1
        \item \textbf{Zero or more copies (star)}: Using the start indicates zero or more copies, thus
            \begin{align*}
                a*
            .\end{align*}
            corresponds to any string of a's: $\{\epsilon, a,aa,aaa,...\} $
        \item \textbf{More on union}:
            If you form an RE by the or of two REs, call them $R$ and $S$, then the resulting language is the union of the languages of $R$ and $S$.
            \bigbreak \noindent 
            Suppose $R = (0+1) = \{0, 1\}$, and $S=\{01(0+1)\}  = \{ 010,011\}$, then $R+S = (0+1) + (01(0+1))  = \{0,1,010, 011\}$
        \item \textbf{More on concatenation}: If you form an RE by the or of two REs, call them $R$ and $S$, then the resulting language consists of all strings that can be formed by taking one string from the language of $R$ and one string from the language of $S$ and concatenating them.
            \bigbreak \noindent 
            Suppose $R = (0+1) = \{0, 1\}$, and $S=\{01(0+1)\}  = \{ 010,011\}$, then $RS = (0+1)01(0+1) = \{0010,0011,1010,1011\}$
        \item \textbf{More on star}: If you for man RE by taking the star of an RE $R$, then the resulting language consists of all strings that can be formed by taking any number of strings from the language of $R$ (they need not be the same and they need not be different), and concatenating them.
            \bigbreak \noindent 
            Suppose $R = 01(0+1) = \{010, 011\}$, then $R^{*} = 01(0+1)* \{010, 010010, ..., 011,011011,... 010011, ...\} $
    \item \textbf{Precedence of the operations}
        \begin{enumerate}
            \item Star (*)
            \item Concatenation
            \item Union (+)
        \end{enumerate}
        \item \textbf{Recursive definition of the kleene star (closure) ($L^{*}$)}:
            \begin{enumerate}
                \item $\epsilon \in L^{*} $
                \item If $x \in L^{*}$ and $y\in L$, then $xy \in L^{*}$
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{Base case:} The first rule provides a starting point by ensuring that the empty string \( \epsilon \) is in \( L^* \).
            \bigbreak \noindent 
            \textbf{Recursive step:} The second rule allows you to take any string \( x \) already in \( L^* \) and concatenate it with a string \( y \in L \) to produce a new string \( xy \in L^* \).
            \bigbreak \noindent 
            After using the second rule once to generate a new string \( xy \in L^* \), you can apply the rule again by concatenating this new string with another string from \( L \). This recursive process can continue indefinitely, generating all possible strings that can be formed by concatenating zero or more strings from \( L \).
        \item \textbf{Recursive definition of the kleene star (other)}
            \begin{enumerate}
                \item $L^{0} = \{\epsilon\}$ $\quad$ (Start with the empty string, always in the closure)
                \item $L^{i}=LL^{i-1}$ for $i>0$ $\quad$ (Start recursively building strings)
                \item $L^{*} = \bigcup_{i=0}^{\infty} L^{i}$ $\quad$ (the whole thing)
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{Note:} We also define the positive closure of \( L \), denoted \( L^+ \), as \( L^* - \{\epsilon\} \) or
            \[
                L^+ = \bigcup_{i=1}^{\infty} L^i.
            \]
        \item \textbf{Closure of the empty language}: $\Phi^{*} = \{\epsilon\} $
        \item \textbf{Regular expression for the empty language}: $\Phi  = \varnothing$  is the regular expression for the empty language (empty set)
        \item \textbf{More on language composition operators}:
            The language composition operators were defined over any language and, in turn, generate new languages. As such, composition operators take any one or two languages from $P(\Sigma^{*})$ and can produce any language in $P(\Sigma^{*})$.
            \begin{align*}
                \in \quad \epsilon
            .\end{align*}
        \item \textbf{Regular languages (regular sets), regular expression limits}: Although regular expressions are based on language composition operators, their recursive definition (i.e., only regular expressions, therefore only languages defined by regular expressions) limits the languages that they can define.
            \bigbreak \noindent 
            \textbf{Note:} Regular expressions cannot produce all languages in $P(\Sigma^{*})$.
            \bigbreak \noindent 
            In fact, the set of languages that regular expressions can define have a special name – they are called regular languages (or sometimes regular sets).

        \item \textbf{Kleene's theorem}:
            There is an FA for a language if and only if there is an RE for the language
        \item \textbf{Regular expressions order of operations}: From highest to lowest precedence
            \begin{enumerate}
                \item Parenthesis  
                \item Kleene star
                \item Concatenation
                \item Union (+ or \|)
            \end{enumerate}
    \item \textbf{Properties of regular expressions}:
        \bigbreak \noindent 
        \textbf{Note:} Intersection is a operation not defined for regular expressions
        \bigbreak \noindent 
        \textbf{Union}
        \begin{itemize}
            \item \textbf{Commutative}:
                \[
                    R_1 \cup R_2 = R_2 \cup R_1
                \]

            \item \textbf{Associative}:
                \[
                    (R_1 \cup R_2) \cup R_3 = R_1 \cup (R_2 \cup R_3)
                \]

            \item \textbf{Identity Element}:
                \[
                    R_1 \cup \emptyset = R_1
                \]

            \item \textbf{Idempotent}:
                \[
                    R_1 \cup R_1 = R_1
                \]
        \end{itemize}
        \textbf{2. Concatenation (\(\cdot\))}
        \begin{itemize}
            \item \textbf{Non-commutative}:
                \[
                    R_1 \cdot R_2 \neq R_2 \cdot R_1
                \]

            \item \textbf{Associative}:
                \[
                    (R_1 \cdot R_2) \cdot R_3 = R_1 \cdot (R_2 \cdot R_3)
                \]

            \item \textbf{Identity Element}:
                \[
                    R_1 \cdot \epsilon = \epsilon \cdot R_1 = R_1
                \]

            \item \textbf{Concatenation with \(\emptyset\)}:
                \[
                    R_1 \cdot \emptyset = \emptyset \cdot R_1 = \emptyset
                \]
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Kleene Star (\(*\))}
        \begin{itemize}
            \item \textbf{Kleene Star of \(\epsilon\)}:
                \[
                    \epsilon^* = \{\epsilon\}
                \]

            \item \textbf{Kleene Star of \(\emptyset\)}:
                \[
                    \emptyset^* = \{\epsilon\}
                \]

            \item \textbf{Idempotent}:
                \[
                    (R^*)^* = R^*
                \]
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Distributive Properties}
        \begin{itemize}
            \item \textbf{Union over Concatenation}:
                \[
                    R_1 \cdot (R_2 \cup R_3) = (R_1 \cdot R_2) \cup (R_1 \cdot R_3)
                \]

            \item \textbf{Concatenation over Union}:
                \[
                    (R_1 \cup R_2) \cdot R_3 = (R_1 \cdot R_3) \cup (R_2 \cdot R_3)
                \]
        \end{itemize}
    \item \textbf{Language of a RE notation}: $L(RE)$ is the language defined by the regular expression $RE$, If we have an RE $R$, then the language $L(R)$ is the language defined by the RE $R$
    \item \textbf{When a regular expression is the empty set $\varnothing$}: When a regular expression (RE) represents the empty set it means that the RE matches no strings at all, not even the empty string.
        \bigbreak \noindent 
        The language is then
        \begin{align*}
            L(\varnothing) = \Phi        
        .\end{align*}
        Where $\Phi$ denotes the empty language
    \item \textbf{One or more occurences $RR^{*}$}: We denote this by plus instead of star, ie $RR^{*} = R^{+}$, but you also must redefine union as $\mid$ instead of $+$
    \item \textbf{Simplifying regular expressions (Some can also be found above in properties)}:
        \begin{itemize}
            \item \textbf{Concatenation of stars}: $(R^{*})^{*}  = R^{*}$
            \item \textbf{Concatenation of Repeated Expressions}: $R^{*}R^{*} = R^{*} $
            \item \textbf{Idempotence of Union}: $R\mid R = R$
            \item \textbf{Empty Set in Union and Concatenation:} $R \mid \varnothing  = R$, $R\varnothing = \varnothing $
            \item \textbf{Empty string in concatenation}: $\epsilon R = R\epsilon = R $
            \item \textbf{Union with the kleene star}: $R^{*}\mid R = R^{*}$
            \item \textbf{Distributive Property:} $R_{1}(R_{2} \mid R_{3}) = R_{1}R_{2} \mid R_{1}R_{3} $
            \item \textbf{Absorption:} $R\mid (RR^{*})  = RR^{*} = R^{+}$
        \end{itemize}
    \item \textbf{The RE operators with the empty language $\Phi$}:
        \begin{enumerate}
            \item $\varnothing r  = r\varnothing = \varnothing\varnothing = \varnothing$ for any regular expression $r$
            \item $r + \varnothing = \varnothing + r = r $
            \item $\varnothing + \varnothing = \varnothing $
            \item $\varnothing^{*} = \{\epsilon\} $
        \end{enumerate}
        These cases can also be represented with language notation
        \begin{enumerate}
            \item $\Phi L  = L\Phi = \Phi\Phi = \Phi$\ $\forall L$
            \item $L + \Phi = \Phi + L = L $
            \item $\Phi + \Phi = \Phi $
            \item $\Phi^{*} = \{\epsilon\} $
        \end{enumerate}
    \item \textbf{Convert RE to NFA-$\epsilon$}: The conversion algorithm starts by defining an NFA with $\epsilon$-moves for each of the three base cases from the recursive definition of a regular expressions over an alphabet $\Sigma$
        \begin{enumerate}
            \item $\varnothing$ is a regular expression and denotes the empty set (i.e., the empty language $\Phi$)
            \item $\epsilon$ is a regular expression and denotes the set $\{\epsilon\}$
            \item For each symbol $x \in \Sigma$, $x$ is a regular expression and denotes the set $\{x\} $.
        \end{enumerate}
        \bigbreak \noindent 
        Conditions on the NFAs with $\epsilon$-moves for This Algorithm
        \begin{enumerate}
            \item  There must be exactly one accepting state.
            \item No transitions (not even $\epsilon$-moves) may leave the one accepting state.
        \end{enumerate}
        \bigbreak \noindent 
        \textbf{Note:} If faced with an NFA with $\epsilon$-moves that has more than one accepting state and/or accepting states with transitions leaving it then simply modify the NFA with $\epsilon$-moves by
        \begin{enumerate}
            \item Adding a new accepting state.
            \item Add an $\epsilon$-move from each of the original accepting states to the newly added accepting state.
            \item Convert all of the original accepting states to non-accepting states.
        \end{enumerate}
        \bigbreak \noindent 
        The three base cases have the following nfa that satisfy the above criteria
        \bigbreak \noindent 
\begin{figure}[ht]
    \centering
    \incfig{crit2}
    \label{fig:crit2}
\end{figure}
\bigbreak \noindent 
We use those NFAs as the basic building blocks to iteratively build more complex NFA’s with $\epsilon$-moves (all the while honoring the accepting state conditions for this algorithm) as we apply the recursive part of the regular expression definition. Recall:
\bigbreak \noindent 
If $r$ and $s$ are regular expressions denoting the sets $R$ and $S$, respectively, then
\begin{enumerate}
    \item $r+s$ is a regular expression denoting the set $R + S$, (i.e,. union of languages),
    \item $rs$ is a regular expression denoting the set $RS$ (i.e., concatenating languages), and
\item $r*$ is a regular expression denoting the set $R^{*}$ (i.e., Kleene closure of a language).
\end{enumerate}
\bigbreak \noindent 
Once we define an NFA with $\epsilon$-moves for each of the base cases (which we have done) then when we address each recursive part of the definition (e.g., union above)
\begin{enumerate}
    \item We may assume that there already exists NFAs with $\epsilon$-moves for each of the regular expressions $r$ and $s$ (and that each also satisfies the acceptance state conditions of this algorithm) and 
    \item Then our job is to use those NFAs with $\epsilon$-moves to create a new NFA with $\epsilon$-moves that accepts $r+s$ and that also satisfies the acceptance state conditions of this algorithm.
\end{enumerate}
\bigbreak \noindent 
\textbf{The algorithm:}
\begin{itemize}
    \item \textbf{Handling union:} We start by assuming there already exists NFAs with $\epsilon$-moves $M_{1}$ and $M_{2}$ that accept regular expressions $r$ and $s$, respectively, and that both $M_{1}$ and $M_{2}$ satisfy the acceptance state conditions (i.e., one accepting state, no exit) of this algorithm.
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{crit3}
            \label{fig:crit3}
        \end{figure}
        \bigbreak \noindent 
        \textbf{Note:} The details of the machine arn't important here, all we know is the machine has a start, does whatever else it needs to (repesented by the elipsis), and then accepts strings represented by $r$ in the top machine and $s$ in the bottom
        \bigbreak \noindent 
        We then use these machines $M_{1}$ and $M_{2}$ to create a new machine $M$ that accepts $r+s$
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{crit4}
            \label{fig:crit4}
        \end{figure}
        \bigbreak \noindent 
        So what did we do here
        \begin{enumerate}
            \item Create new start state and add $\epsilon$-moves to the original start states
            \item Create new accepting state and add emoves from all the original accepting states.
            \item Change the original accepting states to non-accepting states.
        \end{enumerate}
    \item \textbf{Handle Concatenation}: We again start by assuming there already exists NFAs with $\epsilon$-moves $M_{1}$ and $M_{2}$ that accept regular expressions $r$ and $s$, respectively, and that both $M_{1}$ and $M_{2}$ satisfy the acceptance state conditions (i.e., one accepting state, no exit) of this algorithm.
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{crit5}
            \label{fig:crit5}
        \end{figure}
        \bigbreak \noindent 
        We use $M_{1}$ and $M_{2}$ to construct new NFA with $\epsilon$-move $M$ that accepts $rs$.
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{crit6}
            \label{fig:crit6}
        \end{figure}
        \bigbreak \noindent 
        \begin{enumerate}
            \item Add an $\epsilon$-move from $M_{1}$’s accepting state to $M_{2}$’s start state.
            \item Change $M_{1}$’s accepting state to a nonaccepting state.
        \end{enumerate}
        \pagebreak 
    \item \textbf{Handle Kleene closure}: We again start by assuming there already exists an NFA with $\epsilon$-moves $M_{1}$ that accepts regular expressions $r$ and that satisfies the acceptance state conditions (i.e., one accepting state, no exit) of this algorithm.
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{crit7}
            \label{fig:crit7}
        \end{figure}
\end{itemize}
\bigbreak \noindent 
We use $M_{1}$ to construct new NFA with $\epsilon$-move $M$ that accepts $r^{*}$
\begin{figure}[ht]
    \centering
    \incfig{crit9}
    \label{fig:crit9}
\end{figure}
\bigbreak \noindent 
\begin{enumerate}
    \item Create new start and accepting states.
    \item Add $\epsilon$-move from new start to $M_{1}$ start, $M_{1}$ accepting to new accepting, and new start to new accepting.
    \item Add $\epsilon$-move from $M_{1}$ accepting to $M_{1}$ start. 
    \item Change $M_{1}$'s accepting state to a non accepting state.
\end{enumerate}

\item \textbf{RE to NFA conversion: Special cases}: Recall the special case with regular expressions, the empty language $\Phi$ – and how it behaved with the three regular expression operators;
    \begin{enumerate}
        \item $\Phi L  = L\Phi = \Phi\Phi = \Phi$\ $\forall L$
        \item $L + \Phi = \Phi + L = L $
        \item $\Phi + \Phi = \Phi $
        \item $\Phi^{*} = \{\epsilon\} $
    \end{enumerate}
    \bigbreak \noindent 
    \pagebreak \bigbreak \noindent 
    We can now check these operations using the algorithm with $\Phi $. First, we define the base case NFA's
    \bigbreak \noindent 
    \begin{figure}[ht]
        \centering
        \incfig{base}
        \label{fig:base}
    \end{figure}
    \bigbreak \noindent 
    \begin{enumerate}
        \item Confirming $L+\Phi = \Phi+L= L$ and $\Phi+\Phi = \Phi$:
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{base2}
                \label{fig:base2}
            \end{figure}
            \pagebreak 
        \item Confirming $\Phi L = L\Phi = \Phi\Phi = \Phi$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{base6}
                \label{fig:base6}
            \end{figure}
        \item Confirming $\Phi^{*} = \{\epsilon\}$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{base7}
                \label{fig:base7}
            \end{figure}
    \end{enumerate}

    \item \textbf{Convert NFA-$\epsilon$ to RE}:
        If necessary, first modify the NFA with $\epsilon$-moves to satisfy these two conditions (i.e., conditions of this algorithm, not requirements of all NFA’s with $\epsilon$-moves);
        \begin{enumerate}[label=\alph*)]
            \item No transition may enter the start state – not even a loop. 
            \item  If there exists even one accepting state, then there can be only one accepting state and no transition may leave that accepting state.
        \end{enumerate}
        \bigbreak \noindent 
        \textbf{Note:} If there was no accepting state then do not create one, stop the algorithm, and output the regular expression $\varnothing$ to denote the empty language $\Phi$.
        \bigbreak \noindent 
        Then we start the algorithm. We need to convert the label on each transition to a regular expression until there is only two states, a start state and an accepting state, and all transitions between these two states are regular expressions. The final regular expression will be the union of all transitions.
        \begin{enumerate}
            \item  While there are more “middle” states (i.e., states that are neither the start state or accepting state)
                \begin{enumerate}[label=(\roman*)]
                    \item Select one of the remaining middle states.
                    \item Bypass the middle state creating new transitions as necessary annotating each new transition with a regular expression.
                    \item Remove the bypassed middle state.
                \end{enumerate}
            \item If there are any transitions between the start and accepting state, then the regular expression that accepts the same language as the original FA is the the union (i.e., “+”) of the regular expressions of all the transitions. 
                \bigbreak \noindent 
                If there are no transitions between the start and accepting state, then output the regular expression $\varnothing$ to denote the empty language $\Phi$.
        \end{enumerate}
        \bigbreak \noindent 
        Recall the following from the definition of regular expressions;
        \begin{enumerate}[label=(\roman*)]
            \item \relax [base case]: $L$ is a regular expression and denotes the set $\{L\}$
            \item  \relax [base case]: For each symbol $x\in\Sigma$, $x$ is a regular expression and denotes the set $\{x\}$
            \item  \relax [recursive case]: $r+s$ is a regular expression denoting the set $R + S$, (i.e,. union of languages).                       
        \end{enumerate}
        \bigbreak \noindent 
        We use those to covert every $\epsilon$ to a $\Lambda$, every symbol $x\in\Sigma$ to a regular expression of the same symbol, and every case comma-separated transition label to a regular expression with “+”.
        \bigbreak \noindent 
        After ensuring the FA abides by the start and end state conditions, and we convert every transition to the simple regular expressions, we begin eliminating states.
        \bigbreak \noindent 
        \textbf{Some notes:}
        \begin{enumerate}[label=(\alph*)]
            \item Regarding the middle states (states that are neither the start nor accepting state), it doesn't matter in which order we choose to eliminate them.
            \item For each state we are eliminating, we count the number of incoming and outgoing transitions (loops don't add to the count but we still need to take care of them with the regular expressions), there will be a new regular expression transition for all combinations of outgoing and incoming transitions. Ie pick a state to eliminate, then
                \begin{align*}
                    \text{New RE transitions} = N(\text{outgoing}) \times N(\text{incoming}) 
                .\end{align*}
                Not including the loops
        \end{enumerate}
        \pagebreak \bigbreak \noindent 
        \textbf{Example:} Consider the NFA-$\epsilon$
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{re1}
            \label{fig:re1}
        \end{figure}
        \bigbreak \noindent 
        Before we begin eliminating states, we see that this FA does not obey the two constraints described above. So, we create a new accepting state such that there is only one accepting state. Each old accepting state has $\epsilon$ transitions to this new accepting state. This FA has no incoming transitions to the start state so nothing to fix there.
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{re2}
            \label{fig:re2}
        \end{figure}
        \bigbreak \noindent 
        Now, we start eliminating states one at a time. We recall that it does not matter the order in which we eliminate them.
        \bigbreak \noindent 
        We start by eliminating state $X$. There is one incoming transition and one outgoing transition. Thus, there is $1\times 1 = 1$ new transition. To get from the start state, through $X$, to the accepting state, the regular expression is $aa^{*}\Lambda = aa^{*}$. Thus,
        \bigbreak \noindent 
\begin{figure}[ht]
    \centering
    \incfig{re3}
    \label{fig:re3}
\end{figure}
\bigbreak \noindent 
Next, we choose to eliminate state $Z$. We have one incoming and two outgoing transitionss. Thus, we have $1\times 2  = 2$ new regular expression transitions. To get from $Y$ through $Z$ to the accepting state, the RE is $b\epsilon =  b$. To go from $Y$ through $Z$ back to $Y$, we have $ba$. Thus
\bigbreak \noindent 
\begin{figure}[ht]
    \centering
    \incfig{re4}
    \label{fig:re4}
\end{figure}
\bigbreak \noindent 
Finally, we eliminate $Y$. To get from the start state, through $Y$, to the accepting state, the regular expression is $a(ba)^{*}b$. Thus, 
\bigbreak \noindent 
\begin{figure}[ht]
    \centering
    \incfig{re5}
    \label{fig:re5}
\end{figure}
\bigbreak \noindent 
The final regular expression is then 
\begin{align*}
    aa^{*} + \epsilon + a(ba)^{*}b
.\end{align*}
\blacksquare










    \end{itemize}

    \pagebreak 
    \subsubsection{Properties of regular languages}
    \begin{itemize}
        \item \textbf{Recall: Regular language}: Recall that we call a language a regular language if, and only if, the language is accepted by some regular expression. 
        \item \textbf{Recall: Recursive definition of regular expressions}: Recall also our recursive definition of regular expressions over some alphabet $\Sigma $
            \bigbreak \noindent 
            Let $\Sigma$ be an alphabet. The regular expressions over $\Sigma$ and the sets (i.e., languages) that they denote are defined recursively as follows:
            \bigbreak \noindent 
            \textbf{Base cases:}
            \begin{enumerate}
                \item $\varnothing$ is a regular expression and denotes the empty set (i.e., the empty language $\Phi$).
                \item $L$ is a regular expression and denotes the set $\{L\}$.
                \item For each symbol $x\in \Sigma$, $x$ is a regular expression and denotes the set $\{x\}$.
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{Recursion:} If $r$ and $s$ are regular expressions denoting the sets $R$ and $S$, respectively, then
            \begin{enumerate}
                \item $r+s$ is a regular expression denoting the set $R + S$, (i.e,. union of languages),
                \item $rs$ is a regular expression denoting the set $RS$ (i.e., concatenating languages), and
                \item $r^{*}$ is a regular expression denoting the set $R^{*}$ (i.e., Kleene closure of a language).
            \end{enumerate}
        \item \textbf{Relationship between regular languages and the set of all possible languages $\mathcal{P}(\Sigma^{*})$}:
            We know that the set of regular languages must be a subset of $\mathcal{P}(\Sigma^{*})$ (it may be equal to $\mathcal{P}(\Sigma^{*})$), and so, we can start by creating that subset.
            \bigbreak \noindent 
            We can then start noting the languages that we know are regular based on the base cases from the definition of regular expressions and for some given alphabet, say $\Sigma = \{a, b\}$.
            \bigbreak \noindent 
            The recursion from the definition tells us that we can take any language, or pair of languages, from the already existing set of regular languages, and use it/them to create a new language this is also a regular language. And the recursion may be applied over and over (i.e., without limit), always taking only regular languages that have been previously created (original base case languages or languages subsequently derived), to create new languages. (i.e., the set of regular languages is infinite).
            \bigbreak \noindent 
        \item \textbf{Closure of regular languages and their operations}: Expanding on the item above, formally, we say that the set of regular languages is \textbf{closed} under the language composition operations union, concatentation, and Kleene star
        \item \textbf{Closure of complement and intersection}: In addition to the three operations that come from the definition of regular expressions (i.e., union, concatenation, and Kleene star), the set of regular languages is also closed under;
            \begin{itemize}
                \item Complement
                \item Intersection
            \end{itemize}
        \item \textbf{Complement of a Language}: Recall that every language is a set of strings – empty, finite, or infinite – that is always a subset of $\Sigma^{*}$
            \bigbreak \noindent 
            That is,
            \begin{itemize}
                \item For any alphabet $\Sigma$ we get $\Sigma^{*} $
                \item We define some language $L$ over that alphabet $\Sigma$
                \item Then $L$ is a subset of $\Sigma^{*}$; $L \subseteq \Sigma^{*}$
            \end{itemize}
            \bigbreak \noindent 
            We define a new language, the complement of $L$, denoted $L^{\prime}$ as the set of strings that are not in the language $L$ (i.e., $L^{\prime} = \Sigma^{*}  - L$).
        \item \textbf{Proof: Regular languages are closed under complement}: We assert that if you take the complement of a regular language, the resulting language is then regular
            \bigbreak \noindent 
            \textbf{Proof:}
            \begin{enumerate}
                \item A regular language is one that is accepted by some regular expression.
               \item By Kleene’s Theorem we know that any regular expression can be converted to a NFA with $\epsilon$-moves that accepts the same language, and vice versa.
                \item  We can convert any NFA with $\epsilon$-moves to a DFA that accepts the same language and every DFA is, by definition, an NFA with $\epsilon$-moves. 
            \end{enumerate}
            So $L$ is a regular language iff it is accepted by some DFA...
            \bigbreak \noindent 
            Consider some DFA $M(Q, \Sigma, q_{0}, T, \delta)$ that accepts regular language $L$.
            \bigbreak \noindent 
            We construct a new DFA $M^{\prime}(Q, \Sigma, q_{0}, T^{\prime}, \delta)$ from M by defining $T^{\prime} = Q - T$, that is, every accepting state in $M$ becomes a non- accepting state in $M^{\prime}$, and vice versa.
            \bigbreak \noindent 
            Since $M^{\prime}$ accepts $L^{\prime}$ and $M^{\prime}$ is a DFA, then $L^{\prime}$ is a regular language.
            \bigbreak \noindent 
            Since M was chosen arbitrarily, the complement of any regular language is also a regular language
            \bigbreak \noindent 
            \blacksquare
            \bigbreak \noindent 
            \textbf{Note:} Note: The proof must be based on DFA’s ... would not have worked for non-deterministic FA’s.
        \item \textbf{Intersection of Languages}:
            Given any two languages, $L_{1}$ and $L_{2}$, over some alphabet $\Sigma$ we can create a new language $L$ that is the intersection of the two sets $L_{1}$ and $L_{2}$.
            \bigbreak \noindent 
            That is, 
            \begin{align*}
                L = L_{1} \cap L_{2} = \{x:\ x \in L_{1} \land x\in L_{2} \}
            .\end{align*}
        % \item \textbf{Proof: Regular languages are closed under intersection}: This means that when you take the intersection of any two regular languages the language you produce is always regular. 
        \item \textbf{Proof: Regular languages are closed under intersection}: This means that when you take the intersection of any two regular languages, the resulting language is always regular.
            \bigbreak \noindent 
            Assume you have two regular languages \(L_1\) and \(L_2\).
            \bigbreak \noindent 
            We define a new language \(L\), which is the intersection of \(L_1\) and \(L_2\), namely
            \[
                L = \{x \mid x \in L_1 \land x \in L_2\},
            \]
            \begin{center}
                where ``\(\land\)'' means "logical and."
            \end{center}
            \bigbreak \noindent 
            Demorgan's law:
            \begin{align*}
                (a \land b) = \sim(\sim a \lor \sim b)
            .\end{align*}
            \bigbreak \noindent 
            To prove that \(L = L_1 \cap L_2\) is regular, we use the fact that regular languages are closed under complement and union. This leads us to apply De Morgan's Law:
            \[
                L_1 \cap L_2 = \sim (\sim L_1 \cup \sim L_2).
            \]
            \bigbreak \noindent 
            Here, \(\sim L_1\) and \(\sim L_2\) represent the complements of \(L_1\) and \(L_2\), respectively. Since \(L_1\) and \(L_2\) are regular, their complements \(\sim L_1\) and \(\sim L_2\) are also regular (because regular languages are closed under complement).
            \bigbreak \noindent 
            Next, since regular languages are closed under union, the language \(\sim L_1 \cup \sim L_2\) is also regular.
            \bigbreak \noindent 
            Finally, the complement of \(\sim L_1 \cup \sim L_2\), i.e., \((\sim L_1 \cup \sim L_2)'\), is also regular because regular languages are closed under complement. But \((\sim L_1 \cup \sim L_2)'\) is precisely \(L_1 \cap L_2\).
            \bigbreak \noindent 
            Thus, \(L = L_1 \cap L_2\) is regular, as required.
            \[
                L_1 \cap L_2 = \sim (\sim L_1 \cup \sim L_2) = \{x \mid x \in L_1 \land x \in L_2\}.
            \]
            \bigbreak \noindent 
            \(\blacksquare\)
        \item {Addings to regular expression recursive}: Thus, we add complement and intersection to recursive cases when building regular languages defined in $\mathcal{P}(\Sigma^{*})$
            \bigbreak \noindent 
            \textbf{Recursion:} If $r$ and $s$ are regular expressions denoting the sets $R$ and $S$, respectively, then
            \begin{enumerate}
                \item $r+s$ is a regular expression denoting the set $R + S$, (i.e,. union of languages),
                \item $rs$ is a regular expression denoting the set $RS$ (i.e., concatenating languages), and
                \item $r^{*}$ is a regular expression denoting the set $R^{*}$ (i.e., Kleene closure of a language).
            \end{enumerate}
            \bigbreak \noindent 
            or by taking the complement or intersection of one or two previously created regular languages.


            % \bigbreak \noindent 
            % Assume you have two regular languages \(L_1\) and \(L_2\).
            % \bigbreak \noindent 
            % We define a new language \(L\) that is the intersection of \(L_1\) and \(L_2\), namely \(L = \{x \mid x \in L_1 \land x \in L_2\}\),
            % \begin{center}
            %     where ``\(\land\)'' means ``logical and''.
            % \end{center}
            % \bigbreak \noindent 
            % By DeMorgan's Law (logic) we know that \((a \land b) \equiv (\sim a \lor \sim b)\),
            % \begin{center}
            %     where ``\(\sim\)'' means ``logical negation, or not'' and ``\(\lor\)'' means ``logical or''.
            % \end{center}
            % \bigbreak \noindent 
            % We can use DeMorgan's Law to re-write \(L\) as follows:
            % \[
            %     L = \{x \mid x \in L_1 \land x \in L_2\} = \sim \{x \mid x \notin L_1 \lor x \notin L_2\} = \sim(L_1' \cup L_2')'
            % \]
            % \bigbreak \noindent 
            % Since \(L_1\) and \(L_2\) are regular languages, then we know that their complements \(L_1'\) and \(L_2'\) are also regular languages.
            % \bigbreak \noindent 
            % Since \(L_1'\) and \(L_2'\) are regular languages, then we know that their union \(L_1' \cup L_2'\) is also a regular language.
            % \bigbreak \noindent 
            % Since \(L_1' \cup L_2'\) is a regular language, then we know its complement \((L_1' \cup L_2')' = L\) is also a regular language.
            % \bigbreak \noindent 
            % Since \(L_1\) and \(L_2\) were two arbitrarily chosen regular languages, then the intersection of any two regular languages is also a regular language.
            % \bigbreak \noindent 
            % It then follows from $L = \{x \mid x \in L_1 \land x \in L_2\} = \sim \{x \mid x \notin L_1 \lor x \notin L_2\} = \sim(L_1' \cup L_2')'$
            % \begin{align*}
            %     \sim(L^{\prime}_{1} \cup L^{\prime}_{2})     &= L_{1} \cap L_{2}
            % .\end{align*}
            %
            % \blacksquare
    \end{itemize}




    \pagebreak 
    \unsect{DSA}
    \bigbreak \noindent 
    \subsection{C++ Stuff}
    \bigbreak \noindent 
    \subsubsection{Type declarations: Definitions and theorems}
    \begin{itemize}
        \item \textbf{Discern any type}: Some rules,
            \begin{enumerate}
                \item Start with the variable name, we read from inside to out
                \item const, \%, *, and basic types go on the left
                \item const refers to what is immediately on the left (except for \texttt{const int*}), but the standard form of this is actually \texttt{int const*}. Thus, the exception to this is const is at the very left, then it refers to what is immediately right.
                \item arrays and functions go on the right, function args are type declaration sub-problems
            \end{enumerate}
            The Algorithm:
            \begin{itemize}
                \item Start with the variable name, or the implied name position 
                \item Read right until end or )
                \item Read left until end or (
                \item If something still left to read, move out one level of parenthesis and go to 2, else done.
            \end{itemize}
            \bigbreak \noindent 
            Thus, using parenthesis allows us to change direction, this will come in handy.
            \bigbreak \noindent 
            \textbf{Examples}:
            \begin{itemize}
                \item  $a$ is an int $\implies$ \texttt{int a}
                \item $a$ is a pointer to an int $\implies$ \texttt{int * a}
                \item $a$ is a pointer to a constant int $\implies$ \texttt{int const * a} (also \texttt{const int * a})
                \item $a$ is a constant pointer to an int $\implies$ \texttt{int * const a}
                \item $a$ is a constant pointer to a constant int $\implies$ \texttt{int const * const a} (also \texttt{const int * const a})
                \item $a$ is an array of 5 ints $\implies$ \texttt{int a[5]}
                \item $a$ is an array of 5 pointers to constant ints $\implies$ \texttt{int const * a[5]}
                \item $a$ is a pointer to an array of 5 constant ints $\implies$ \texttt{int const (* a)[5]}
            \end{itemize}
        \item \textbf{Multi dimensional arrays (matrices)}: Think of multi-dimensional arrays as arrays of arrays. More indicative of what’s happening internally. \texttt{float dat [3][4];} can be read as: "dat is an array of 3 arrays of 4 floats" (Using the algorithm from above).
            \bigbreak \noindent 
            \textbf{Examples}:
            \begin{itemize}
                \item \texttt{arg1} is a reference to an array of 25 constant pointers to arrays of 8 strings. $\implies$ \texttt{string (* const (\& arg1)[25])[8]}
                    \bigbreak \noindent 
                    \textbf{Note:} Notice how we use parenthesis to change direction
            \end{itemize}
        \item \textbf{Function Pointers}: Pointers point to bytes, which can be interpreted different ways. Pointers can point to bytes that can be interpreted as code, i.e. a function pointer.
            \bigbreak \noindent 
            \textbf{Examples}: 
            \begin{itemize}
                \item $f$ is a pointer to a function which takes an int and returns void. $\implies$ \texttt{void (* f) (int)}
            \end{itemize}
    \end{itemize}

   \pagebreak 
   \subsubsection{G++}
   \begin{itemize}
       \item \textbf{Compliation and linking}:
           Compilers turn source code into executable code.
           \begin{itemize}
               \item \textbf{Source code $\to$ object code (Compilation)}: Object code is almost executable. It contains pieces that it provides to other objects, and holes to be filled in. It is a slow process
               \item \textbf{Object code $\to$ executable (Linking)}: Connects pieces of object files together. This is a fast process
           \end{itemize}
           \bigbreak \noindent 
           \textbf{Note:}  Many “compilers” do both compiling and linking. Most programs are built in two stages:
           \begin{enumerate}
               \item Compile all the source code files
                \item Link the object code file into an executable
           \end{enumerate}
           This is the most efficient way to compile large projects.  Changing a single source code file requires a small number of compilations (slow), followed by linking (fast).
        \item \textbf{Standard unix c compiler}: The standard is GNU gcc
        \item \textbf{Standard unix cpp compiler}: The standard is GNU g++
        \item {g++ Options}: With no options, g++ will go from source to an executable named a.out
            \begin{itemize}
                \item \textbf{-o}: The -o option gives the name of the output file
                \item \textbf{-c}: The -c option makes the compiler stop after the compilation stage. No linking is done. The name of the object code file is the same as the source with the extension replaced with .o
                \item \textbf{-W[\textit{warning}]}: Tell the complier to look for a specific warning
                \item \textbf{-Wall (Warning all)}: There are many -W\textit{warning} options, which warn of various conditions. -Wall warns about all of them. The compiler keeps going through warnings
                    \bigbreak \noindent 
                    \textbf{Note:} A compiler warning is usually a bug waiting to happen. Do all you can to get rid of all warnings.
                \item \textbf{-Werror}: The -Werror option turns all warnings into errors. The compiler aborts on an error.
                \item \textbf{-g}: The -g option turns on debugging, and leaves much extra information in an object file. Executable is much larger, possibly slower.
                \item \textbf{-0}: The -O option turns on optimization. There are several different levels of optimization, e.g. -O0, -O1, -O2, -O3. 
                    \bigbreak \noindent 
                    \textbf{Note:} Optimization may break your code, and -O and -g don’t always work well together
                \item \textbf{-I[\textit{directory}]}: The -I option specifies an additional directory to search for include files. No space between -I and directory
                    \bigbreak \noindent 
                    Thus, 
                    \begin{cppcode}
                    #include "./dir/headerfile" // Without -I
                    #include "headerfile" // With -I : g++ -I./dir ...
                    \end{cppcode}
                \item \textbf{-L[\textit{directory}]}: The -L option specifies an additional directory to search for libraries. No space between -L and directory.
                    \bigbreak \noindent 
                    \textbf{Note:} This option is meant for linking only. It has no effect in compilation.
                \item \textbf{-l[\textit{libraryname}]}: The -l option specifies a library for linking. No space between -l and library name. The library name is related to the libray file name, but it is not identical. Library names start with “lib” and end with “.so.*” or “.a”. These are removed. For example
                    \begin{itemize}
                        \item The math library /lib/x86\_64-linux/gnu/libm.so.6 is linked as -lm
                        \item The X11 graphics library /usr/lib/x86\_64-linux-gnu/libX11.so is linked as -lX11
                    \end{itemize}
                    \bigbreak \noindent 
                    \textbf{Note:} This option is for linking only. It has no effect in compilation.  Libraries are the last things listed in a linking command.
                    \bigbreak \noindent 
                    If you're linking against a library that is located in a non-standard directory (a directory that is not automatically searched by the linker, such as ./libs), then you need to tell the linker where to find that library using the -L option. Thus, -L tells the compiler  where to look, -l specifies which one to grab.

            \end{itemize}
   \end{itemize}
    
   \pagebreak 
   \subsubsection{STL Vectors}
   \bigbreak \noindent 
   \paragraph{Implementation}
   \bigbreak \noindent 
   A vector models a dynamic array. Thus, a vector is an abstraction that manages its elements with a dynamic C-style arra
   \bigbreak \noindent 
   A vector copies its elements into its internal dynamic array. The elements always have a certain order. Thus, a vector is a kind of ordered collection. A vector provides random access. Thus, you can access every element directly in constant time, provided that you know its position. The iterators are random-access iterators, so you can use any algorithm of the STL.

   \bigbreak \noindent 
   \paragraph{Performance in operations on the end}
   \bigbreak \noindent 
   Vectors provide good performance if you append or delete elements at the end. If you insert or
   delete in the middle or at the beginning, performance gets worse. This is because every element
   behind has to be moved to another position. In fact, the assignment operator would be called for
   every following element.

   \bigbreak \noindent 
   \paragraph{Size and capacity}
   \bigbreak \noindent 
   Part of the way in which vectors give good performance is by allocating more memory than they
   need to contain all their elements. To use vectors effectively and correctly, you should understand
   how size and capacity cooperate in a vector.
   \bigbreak \noindent 
   Vectors provide the usual size operations size(), empty(), and max\_size(). An additional “size” operation is the capacity() function, which returns the number of
   elements a vector could contain in its actual memory. If you exceed the capacity(), the vector has
   to reallocate its internal memory.
   \bigbreak \noindent 
   The capacity of a vector is important for two reasons:
   \begin{enumerate}
       \item Reallocation invalidates all references, pointers, and iterators for elements of the vector
       \item Reallocation takes time.
   \end{enumerate}
   Thus, if a program manages pointers, references, or iterators into a vector, or if speed is a goal, it is
   important to take the capacity into account
   \bigbreak \noindent 
   To avoid reallocation, you can use reserve() to ensure a certain capacity before you really need
it. In this way, you can ensure that references remain valid as long as the capacity is not exceeded:
\bigbreak \noindent 
Another way to avoid reallocation is to initialize a vector with enough elements by passing additional
arguments to the constructor. For example, if you pass a numeric value as parameter, it is taken as
the starting size of the vector:
\bigbreak \noindent 
\begin{cppcode}
    std::vector<T> v(5);
\end{cppcode}
\bigbreak \noindent 
\textbf{Note:} If the only reason for initialization is to reserve memory, you should use reserve()
\bigbreak \noindent 
Unlike for strings, it is not possible to call reserve() for vectors to shrink the capacity. Calling reserve() with an argument that is less than the current capacity is a no-op
\bigbreak \noindent 
Because the capacity of vectors never shrinks, it is guaranteed that references, pointers, and
iterators remain valid even when elements are deleted, provided that they refer to a position before
the manipulated elements. However, insertions invalidate all references, pointers, and iterators when
the capacity gets exceeded

\bigbreak \noindent 
\paragraph{Constructors}
\bigbreak \noindent 
\begin{itemize}
    \item \texttt{vector<Elem> c} \\
          Default constructor; creates an empty vector without any elements.
          
    \item \texttt{vector<Elem> c(c2)} \\
          Copy constructor; creates a new vector as a copy of \texttt{c2} (all elements are copied).
          
    \item \texttt{vector<Elem> c = c2} \\
          Copy constructor; creates a new vector as a copy of \texttt{c2} (all elements are copied).
          
    \item \texttt{vector<Elem> c(rv)} \\
          Move constructor; creates a new vector, taking the contents of the rvalue \texttt{rv} (since C++11).
          
    \item \texttt{vector<Elem> c = rv} \\
          Move constructor; creates a new vector, taking the contents of the rvalue \texttt{rv} (since C++11).
          
    \item \texttt{vector<Elem> c(n)} \\
          Creates a vector with \texttt{n} elements created by the default constructor.
          
    \item \texttt{vector<Elem> c(n, elem)} \\
          Creates a vector initialized with \texttt{n} copies of element \texttt{elem}.
          
    \item \texttt{vector<Elem> c(beg, end)} \\
          Creates a vector initialized with the elements of the range [\texttt{beg}, \texttt{end}].
          
    \item \texttt{vector<Elem> c\{initlist\}} \\
          Creates a vector initialized with the elements of the initializer list \texttt{initlist} (since C++11).
          
    \item \texttt{vector<Elem> c = \{initlist\}} \\
        Creates a vector initialized with the elements of the initializer list \texttt{initlist} (since C++11).

    \item \texttt{c.~vector()} \\
        Destroys all elements and frees the memory.
\end{itemize}

\paragraph{Note about at()}
\bigbreak \noindent 
Out of all the element access operators and methods: [], at(), front(), back(), only at() performs range checking. If the index is out of range, at() throws an out\_of\_range
\bigbreak \noindent 
All other functions do not check. A range error results in
undefined behavior. Calling operator [ ], front(), and back() for an empty container always
results in undefined behavior:

\bigbreak \noindent 
\paragraph{Iterator methods}
\bigbreak \noindent 
We have
\begin{itemize}
    \item begin()
    \item end()
    \item rbegin()
    \item cbegin()
    \item cend()
    \item crbegin()
    \item crend()
\end{itemize}






    \pagebreak 
    \subsubsection{STL Deque}
    \bigbreak \noindent 
    \paragraph{Implementation}
    \bigbreak \noindent 
    A deque (pronounced “deck”) is very similar to a vector. It manages its elements with a dynamic
    array, provides random access, and has almost the same interface as a vector. The difference is
    that with a deque, the dynamic array is open at both ends. Thus, a deque is fast for insertions and
    deletions at both the end and the beginning
    \bigbreak \noindent 
    To provide this ability, the deque is typically implemented as a bunch of individual blocks, with the
    first block growing in one direction and the last block growing in the opposite direction

    \paragraph{Abilities, performance, uses}
    \bigbreak \noindent 
    The abilities of deques differ from those of vectors as follows:
    \begin{itemize}
        \item Inserting and removing elements is fast at both the beginning and the end (for vectors, it is fast only at the end). These operations are done in amortized constant time.
        \item The internal structure has one more indirection to access the elements, so with deques, element access and iterator movement are usually a bit slower.
        \item Iterators must be smart pointers of a special type rather than ordinary pointers because they must jump between different blocks.
        \item In systems that have size limitations for blocks of memory (for example, some PC systems), a deque might contain more elements because it uses more than one block of memory. Thus, max\_size() might be larger for deques.
        \item Deques provide no support to control the capacity and the moment of reallocation. In particular, any insertion or deletion of elements other than at the beginning or end invalidates all pointers, references, and iterators that refer to elements of the deque. However, reallocation may perform better than for vectors because according to their typical internal structure, deques don’t have to copy all elements on reallocation.
        \item Blocks of memory might get freed when they are no longer used, so the memory size of a deque might shrink (however, whether and how this happens is implementation specific).
    \end{itemize}

    \bigbreak \noindent 
    \paragraph{When to use deques}
    \begin{itemize}
        \item You insert and remove elements at both ends (this is the classic case for a queue).
        \item You don’t refer to elements of the container.
        \item It is important that the container frees memory when it is no longer used (however, the standard does not guarantee that this happens).
    \end{itemize}

    \bigbreak \noindent 
    \paragraph{Constructors}
    \begin{itemize}
    \item \texttt{deque<Elem> c} \\
        Default constructor; creates an empty deque without any elements.
    \item \texttt{deque<Elem> c(c2)} \\
        Copy constructor; creates a new deque as a copy of \texttt{c2} (all elements are copied).
    \item \texttt{deque<Elem> c = c2} \\
        Copy assignment operator; creates a new deque as a copy of \texttt{c2} (all elements are copied).
    \item \texttt{deque<Elem> c(rv)} \\
        Move constructor; creates a new deque, taking the contents of the rvalue \texttt{rv} (since C++11).
    \item \texttt{deque<Elem> c = rv} \\
        Move assignment operator; creates a new deque, taking the contents of the rvalue \texttt{rv} (since C++11).
    \item \texttt{deque<Elem> c(n)} \\
        Creates a deque with \texttt{n} elements created by the default constructor.
    \item \texttt{deque<Elem> c(n, elem)} \\
        Creates a deque initialized with \texttt{n} copies of element \texttt{elem}.
    \item \texttt{deque<Elem> c(beg, end)} \\
        Creates a deque initialized with the elements of the range \texttt{[beg, end]}.
    \item \texttt{deque<Elem> c \{inilist\}} \\
        Creates a deque initialized with the elements of initializer list \texttt{inilist} (since C++11).
    \item \texttt{deque<Elem> c = \{inilist\}} \\
        Creates a deque initialized with the elements of initializer list \texttt{inilist} (since C++11).
    \item \texttt{c.\textasciitilde deque()} \\
        Destroys all elements and frees the memory.
\end{itemize}
\bigbreak \noindent 
Deque operations differ from vector operations in only two ways:
\begin{enumerate}
    \item Deques do not provide the functions for capacity (capacity() and reserve()).
    \item Deques do provide direct functions to insert and to delete the first element (push\_front() and pop\_front()).
\end{enumerate}




   \pagebreak 
   \subsubsection{STL Lists}
   \bigbreak \noindent 
   \paragraph{Implementation}
   \bigbreak \noindent 
   Manages its elements as a doubly linked list. As usual, the C++ standard library does not specify the kind of the implementation, but it follows from the list’s name, constraints, and specifications.
   \bigbreak \noindent 
   \paragraph{Abilities}
   \bigbreak \noindent 
   The internal structure of a list is totally different from that of an array, a vector, or a deque. The list
object itself provides two pointers, the so-called anchors, which refer to the first and last elements.
Each element has pointers to the previous and next elements (or back to the anchor). To insert a new
element, you just manipulate the corresponding pointers
\bigbreak \noindent 
Thus, a list differs in several major ways from arrays, vectors, and deques:
\begin{itemize}
    \item A list does not provide random access. For example, to access the fifth element, you must navigate the first four elements, following the chain of links. Thus, accessing an arbitrary element using a list is slow. However, you can navigate through the list from both end. So accessing both the first and the last elements is fast.
    \item Inserting and removing elements is fast at each position (provided you are there), and not only at one or both ends. You can always insert and delete an element in constant time, because no other elements have to be moved. Internally, only some pointer values are manipulated.
    \item Inserting and deleting elements does not invalidate pointers, references, and iterators to other elements.
    \item A list supports exception handling in such a way that almost every operation succeeds or is a no-op. Thus, you can’t get into an intermediate state in which only half of the operation is complete.
\end{itemize}

\bigbreak \noindent 
\paragraph{Differencs in the methods}
\bigbreak \noindent 
The member functions provided for lists reflect these differences from arrays, vectors, and deques as follows:
\begin{itemize}
    \item Lists provide front(), push\_front(), and pop\_front(), as well as back(), push\_back(), and pop\_back().
    \item Lists provide neither a subscript operator nor at(), because no random access is provided.
\item Lists don’t provide operations for capacity or reallocation, because neither is needed. Each element has its own memory that stays valid until the element is deleted.
\item Lists provide many special member functions for moving and removing elements. These member functions are faster versions of general algorithms that have the same names. They are faster because they only redirect pointers rather than copy and move the values.
\end{itemize}

\bigbreak \noindent 
\paragraph{Constructors}
\bigbreak \noindent 
\begin{itemize}
    \item \texttt{list<Elem> c} \\
        Default constructor; creates an empty list without any elements.
    \item \texttt{list<Elem> c(c2)} \\
        Copy constructor; creates a new list as a copy of \texttt{c2} (all elements are copied).
    \item \texttt{list<Elem> c = c2} \\
        Copy assignment operator; creates a new list as a copy of \texttt{c2} (all elements are copied).
    \item \texttt{list<Elem> c(rv)} \\
        Move constructor; creates a new list, taking the contents of the rvalue \texttt{rv} (since C++11).
    \item \texttt{list<Elem> c = rv} \\
        Move assignment operator; creates a new list, taking the contents of the rvalue \texttt{rv} (since C++11).
    \item \texttt{list<Elem> c(n)} \\
        Creates a list with \texttt{n} elements created by the default constructor.
    \item \texttt{list<Elem> c(n, elem)} \\
        Creates a list initialized with \texttt{n} copies of element \texttt{elem}.
    \item \texttt{list<Elem> c(beg, end)} \\
        Creates a list initialized with the elements of the range \texttt{[beg, end]}.
    \item \texttt{list<Elem> c\{inilist\}} \\
        Creates a list initialized with the elements of initializer list \texttt{inilist} (since C++11).
    \item \texttt{list<Elem> c = \{inilist\}} \\
        Creates a list initialized with the elements of initializer list \texttt{inilist} (since C++11).
    \item \texttt{c.\~list()} \\
        Destroys all elements and frees the memory.
\end{itemize}

\bigbreak \noindent 
\paragraph{Element access}
\bigbreak \noindent 
With lists, we only have front and back methods. However, these methods do not check for existence. Calling these methods on empty containers results in undefined behavior
\bigbreak \noindent 
Thus, the caller must ensure that the container contains at least one element

\bigbreak \noindent 
\paragraph{Iterator functions}
\bigbreak \noindent 
To access all elements of a list, you must use iterators. Lists provide the usual iterator functions. However, because a list has no random access, these iterators are only bidirectional.
Thus, you can’t call algorithms that require random-access iterators. All algorithms that manipulate
the order of elements a lot, especially sorting algorithms, are in this category. However, for sorting
the elements, lists provide the special member function sort()

\bigbreak \noindent 
\paragraph{Splice Functions and Functions to Change the Order of Elements}
\bigbreak \noindent 
Linked lists have the advantage that you can remove and insert elements at any position in constant
time. If you move elements from one container to another, this advantage doubles in that you need
only redirect some internal pointers
\bigbreak \noindent 
To support this ability, lists provide not only remove() but also additional modifying member
functions to change the order of and relink elements and ranges.




   \pagebreak 
   \subsubsection{STL Forward lists}
   \bigbreak \noindent 
   \paragraph{Implementation}
   \bigbreak \noindent 
   \bigbreak \noindent 
   A forward list (an instance of the container class forward\_list<>), which was introduced with C++11, manages its elements as a singly linked list
   \bigbreak \noindent 
   Conceptionally, a forward list is a list (object of class list<>) restricted such that it is not able to iterate backward. It provides no functionality that is not also provided by lists. As benefits, it uses less memory and provides slightly better runtime behavior. The standard states: “It is intended that forward\_list have zero space or time overhead relative to a hand-written C-style singly linked list. Features that would conflict with that goal have been omitted.

   \bigbreak \noindent 
   \paragraph{Abilities, limitations}
   \bigbreak \noindent \bigbreak \noindent 
   Forward lists have the following limitations compared to lists:
   \begin{itemize}
       \item A forward list provides only forward iterators, not bidirectional iterators. As a consequence, no reverse iterator support is provided, which means that types, such as reverse\_iterator, and member functions, such as rbegin(), rend(), crbegin(), and crend(), are not provided.
       \item A forward list does not provide a size() member function. This is a consequence of omitting features that create time or space overhead relative to a handwritten singly linked list.
       \item The anchor of a forward list has no pointer to the last element. For this reason, a forward list does not provide the special member functions to deal with the last element, back(), push\_back(), and pop\_back().
       \item For all member functions that modify forward lists in a way that elements are inserted or deleted at a specific position, special versions for forward lists are provided. The reason is that you have to pass the position of the element before the first element that gets manipulated, because there you have to assign a new successor element. Because you can’t navigate backwards (at least not in constant time), for all these member functions you have to pass the position of the preceding element. Because of this difference, these member functions have a \_after suffix in their name. For example, instead of insert(), insert\_after() is provided, which inserts new elements after the element passed as first argument; that is, it appends an element at that position.
       \item For this reason, forward lists provide before\_begin() and cbefore\_begin(), which yield the position of a virtual element before the first element (technically speaking, the anchor of the linked list), which can be used to let built-in algorithms ending with _after exchange even the first element.
   \end{itemize}

   \bigbreak \noindent 
   \paragraph{No size()?}
   \bigbreak \noindent \bigbreak \noindent 
   The decision not to provide size() might be especially surprising because size() is one of the operations required for all STL containers. Here, you can see the consequences of the design goal to have “zero space or time overhead relative to a hand-written Cstyle singly linked list.” The alternative would have been either to compute the size each time size() is called, which would have linear complexity, or to provide an additional field in the forward\_list object for the size, which is updated with each and every operation that changes the number of elements. As the design paper for the forward list, “It’s a cost that all users would have to pay for, whether they need this feature or not.” So, if you need the size, either track it outside the forward\_list or use a list instead.
   \bigbreak \noindent 
   If you have to compute the number of elements, you can use distance()
   \bigbreak \noindent 
   \begin{cppcode}
   #include <forward_list>
   #include <iterator>

   std::forward_list<int> l;
   std::cout << "Size: " << std::distance(l.begin(), l.end()) << std::endl;
   \end{cppcode}

   \bigbreak \noindent 
   \paragraph{Similarities to list}
   \bigbreak \noindent \bigbreak \noindent 
   \begin{itemize}
       \item A forward list does not provide random access. For example, to access the fifth element, you
       \item must navigate the first four elements, following the chain of links. Thus, using a forward list to access an arbitrary element is slow.
       \item Inserting and removing elements is fast at each position, if you are there. You can always insert and delete an element in constant time, because no other elements have to be moved. Internally, only some pointer values are manipulated.
       \item Inserting and deleting elements does not invalidate iterators, references, and pointers to other elements.
       \item A forward list supports exception handling in such a way that almost every operation succeeds or is a no-op. Thus, you can’t get into an intermediate state in which only half of the operation is complete.
       \item Forward lists provide many special member functions for moving and removing elements. These member functions are faster versions of general algorithms, because they only redirect pointers rather than copy and move the values. However, when element positions are involved, you have to pass the preceding position, and the member function has the suffix \_after in its name.
   \end{itemize}

   \bigbreak \noindent 
   \paragraph{Constructors}
   \bigbreak \noindent 
   \bigbreak \noindent 
   \begin{itemize}
    \item \texttt{forward\_list<Elem> c} \\
    Default constructor; creates an empty forward list without any elements.
    
    \item \texttt{forward\_list<Elem> c(c2)} \\
    Copy constructor; creates a new forward list as a copy of \texttt{c2} (all elements are copied).
    
    \item \texttt{forward\_list<Elem> c = c2} \\
    Copy assignment operator; creates a new forward list as a copy of \texttt{c2} (all elements are copied).
    
    \item \texttt{forward\_list<Elem> c(rv)} \\
    Move constructor; creates a new forward list, taking the contents of the rvalue \texttt{rv} (since C++11).
    
    \item \texttt{forward\_list<Elem> c = rv} \\
    Move assignment operator; creates a new forward list, taking the contents of the rvalue \texttt{rv} (since C++11).
    
    \item \texttt{forward\_list<Elem> c(n)} \\
    Creates a forward list with \texttt{n} elements created by the default constructor.
    
    \item \texttt{forward\_list<Elem> c(n, elem)} \\
    Creates a forward list initialized with \texttt{n} copies of element \texttt{elem}.
    
    \item \texttt{forward\_list<Elem> c(beg, end)} \\
    Creates a forward list initialized with the elements of the range \texttt{[beg, end]}.
    
    \item \texttt{forward\_list<Elem> c\{inilist\}} \\
    Creates a forward list initialized with the elements of initializer list \texttt{inilist} (since C++11).
    
    \item \texttt{forward\_list<Elem> c = \{inilist\}} \\
    Creates a forward list initialized with the elements of initializer list \texttt{inilist} (since C++11).
    
    \item \texttt{c.\~forward\_list()} \\
    Destroys all elements and frees the memory.
\end{itemize}




   \pagebreak 
   \subsubsection{STL Sets and multisets}
   \bigbreak \noindent 
   \paragraph{Implementation}
   \bigbreak \noindent \bigbreak \noindent 
   Sets and multisets are implemented as height balanced binary search trees. (red-black trees)
   \bigbreak \noindent 
   Set and multiset containers sort their elements automatically according to a certain sorting criterion. The difference between the two types of containers is that multisets allow duplicates, whereas sets do not
   \bigbreak \noindent 
   The elements of a set or a multiset may have any type T that is comparable according to the sorting criterion. The optional second template argument defines the sorting criterion. If a special sorting criterion is not passed, the default criterion less is used. The function object less sorts the elements by comparing them with operator $<$
   \bigbreak \noindent 
   The optional third template parameter defines the memory model. The default memory model is the model allocator, which is provided by the C++ standard library.
   \bigbreak \noindent 
   \paragraph{Strict weak ordering}
   \bigbreak \noindent \bigbreak \noindent 
   The sorting criterion must define strict weak ordering, which is defined by the following four properties:
   \begin{enumerate}
       \item It has to be \textbf{antisymmetric}.
           \begin{itemize}
               \item This means that for operator \texttt{<}: If $x < y$ is true, then $y < x$ is false.
               \item This means that for a predicate \texttt{op()}: If \texttt{op(x, y)} is true, then \texttt{op(y, x)} is false.
           \end{itemize}

       \item It has to be \textbf{transitive}.
           \begin{itemize}
               \item This means that for operator \texttt{<}: If $x < y$ is true and $y < z$ is true, then $x < z$ is true.
               \item This means that for a predicate \texttt{op()}: If \texttt{op(x, y)} is true and \texttt{op(y, z)} is true, then \texttt{op(x, z)} is true.
           \end{itemize}

       \item It has to be \textbf{irreflexive}.
           \begin{itemize}
               \item This means that for operator \texttt{<}: $x < x$ is always false.
               \item This means that for a predicate \texttt{op()}: \texttt{op(x, x)} is always false.
           \end{itemize}

       \item It has to have \textbf{transitivity of equivalence}, which means roughly: If $a$ is equivalent to $b$ and $b$ is equivalent to $c$, then $a$ is equivalent to $c$.
           \begin{itemize}
               \item This means that for operator \texttt{<}: If !$(a < b)$ \&\& !$(b < a)$ is true and !$(b < c)$ \&\& !$(c < b)$ is true, then !$(a < c)$ \&\& !$(c < a)$ is true.
               \item This means that for a predicate \texttt{op()}: If \texttt{op(a, b)}, \texttt{op(b, a)}, \texttt{op(b, c)}, and \texttt{op(c, b)} all yield false, then \texttt{op(a, c)} and \texttt{op(c, a)} yield false.
           \end{itemize}
   \end{enumerate}
   \bigbreak \noindent 
   \textbf{Note}: Note that this means that you have to distinguish between less and equal. A criterion such as operator \texttt{<=} does not fulfill this requirement.
   \bigbreak \noindent 
   Based on these properties, the sorting criterion is also used to check equivalence. That is, two elements are considered to be duplicates if neither is less than the other (or if both \texttt{op(x, y)} and \texttt{op(y, x)} are false).
   \bigbreak \noindent 
   For multisets, the order of equivalent elements is random but stable. Thus, insertions and erasures preserve the relative ordering of equivalent elements (guaranteed since C++11).
   \bigbreak \noindent 
   \paragraph{Abilities}
   \bigbreak \noindent \bigbreak \noindent 
   Like all standardized associative container classes, sets and multisets are usually implemented as balanced binary trees
   \bigbreak \noindent 
   The major advantage of automatic sorting is that a binary tree performs well when elements with
a certain value are searched. In fact, search functions have logarithmic complexity. For example, to
search for an element in a set or a multiset of 1,000 elements, a tree search performed by a member
function needs, on average, one-fiftieth of the comparisons of a linear search

\bigbreak \noindent 
\paragraph{Changing elements directly, no direct element access}
\bigbreak \noindent 
Automatic sorting also imposes an important constraint on sets and multisets: You may
not change the value of an element directly
\bigbreak \noindent 
Therefore, to modify the value of an element, you must remove the element having the old value and
insert a new element that has the new value. The interface reflects this behavior:
\begin{itemize}
    \item Sets and multisets don’t provide operations for direct element access.
    \item Indirect access via iterators has the constraint that, from the iterator’s point of view, the element value is constant.
\end{itemize}

\bigbreak \noindent 
\paragraph{Constructors}
\bigbreak \noindent \bigbreak \noindent 
\begin{itemize}
    \item \texttt{set c} \\
    Default constructor; creates an empty set/multiset without any elements.
    
    \item \texttt{set c(op)} \\
    Creates an empty set/multiset that uses \texttt{op} as the sorting criterion.
    
    \item \texttt{set c(c2)} \\
    Copy constructor; creates a copy of another set/multiset of the same type (all elements are copied).
    
    \item \texttt{set c = c2} \\
    Copy assignment operator; creates a copy of another set/multiset of the same type (all elements are copied).
    
    \item \texttt{set c(rv)} \\
    Move constructor; creates a new set/multiset of the same type, taking the contents of the rvalue \texttt{rv} (since C++11).
    
    \item \texttt{set c = rv} \\
    Move assignment operator; creates a new set/multiset of the same type, taking the contents of the rvalue \texttt{rv} (since C++11).
    
    \item \texttt{set c(beg, end)} \\
    Creates a set/multiset initialized by the elements of the range \texttt{[beg, end]}.
    
    \item \texttt{set c(beg, end, op)} \\
    Creates a set/multiset with the sorting criterion \texttt{op} initialized by the elements of the range \texttt{[beg, end]}.
    
    \item \texttt{set c\{inilist\}} \\
    Creates a set/multiset initialized with the elements of initializer list \texttt{inilist} (since C++11).
    
    \item \texttt{set c = \{inilist\}} \\
    Creates a set/multiset initialized with the elements of initializer list \texttt{inilist} (since C++11).
    
    \item \texttt{c.\~set()} \\
    Destroys all elements and frees the memory.
\end{itemize}


\bigbreak \noindent 
\paragraph{Types}
\bigbreak \noindent \bigbreak \noindent 
\begin{itemize}
    \item \texttt{set<Elem>} \\
    A set that by default sorts with \texttt{less<>} (operator \texttt{<}).
    
    \item \texttt{set<Elem, Op>} \\
    A set that by default sorts with \texttt{Op}.
    
    \item \texttt{multiset<Elem>} \\
    A multiset that by default sorts with \texttt{less<>} (operator \texttt{<}).
    
    \item \texttt{multiset<Elem, Op>} \\
    A multiset that by default sorts with \texttt{Op}.
\end{itemize}






   \pagebreak 
   \subsubsection{STL Maps and multimaps}
   \bigbreak \noindent 
   Maps and multimaps are containers that manage key/value pairs as elements. These containers sort
   their elements automatically, according to a certain sorting criterion that is used for the key. The
   difference between the two is that multimaps allow duplicates, whereas maps do not
   \bigbreak \noindent 
   \paragraph{Implementation}
   \bigbreak \noindent \bigbreak \noindent 
   Maps and multimaps are implemented the same as sets and multisets, height balanced binary search trees (red-black trees).

   \bigbreak \noindent 
   \paragraph{Template parameters}
   \bigbreak \noindent \bigbreak \noindent 
   The first template parameter is the type of the element’s key, and the second template parameter is
the type of the element’s associated value. The elements of a map or a multimap may have any types
Key and T that meet the following two requirements:
\begin{enumerate}
    \item Both key and value must be copyable or movable.
    \item The key must be comparable with the sorting criterion.
\end{enumerate}
\bigbreak \noindent 
The optional third template parameter defines the sorting criterion. As for sets, this sorting criterion must define a “strict weak ordering” The elements are sorted according to their keys, so the value doesn’t matter for the order of the elements. The sorting criterion is also used to check for equivalence; that is, two elements are equal if neither key is less than the other.
\bigbreak \noindent 
If a special sorting criterion is not passed, the default criterion less<> is used. The function object
less<> sorts the elements by comparing them with operator <
\bigbreak \noindent 
\paragraph{Abilities}
\bigbreak \noindent \bigbreak \noindent 
Sets, multisets, maps, and multimaps
typically use the same internal data type. So, you could consider sets and multisets as special maps
and multimaps, respectively, for which the value and the key of the elements are the same objects.
Thus, maps and multimaps have all the abilities and operations of sets and multisets. Some minor
differences exist, however. First, their elements are key/value pairs. In addition, maps can be used
as associative arrays.
\bigbreak \noindent 
Maps and multimaps sort their elements automatically, according to the element’s keys, and so have
good performance when searching for elements that have a certain key. Searching for elements that
have a certain value promotes bad performance. Automatic sorting imposes an important constraint
on maps and multimaps: You may not change the key of an element directly, because doing so might
compromise the correct order. To modify the key of an element, you must remove the element that
has the old key and insert a new element that has the new key and the old value. As a consequence, from the iterator’s point of view, the element’s key is
constant. However, a direct modification of the value of the element is still possible, provided that
the type of the value is not constant.

\bigbreak \noindent 
\paragraph{Constructors and types}
\bigbreak \noindent \bigbreak \noindent 
\begin{itemize}
    \item \texttt{map c} \\
    Default constructor; creates an empty map/multimap without any elements.
    
    \item \texttt{map c(op)} \\
    Creates an empty map/multimap that uses \texttt{op} as the sorting criterion.
    
    \item \texttt{map c(c2)} \\
    Copy constructor; creates a copy of another map/multimap of the same type (all elements are copied).
    
    \item \texttt{map c = c2} \\
    Copy assignment operator; creates a copy of another map/multimap of the same type (all elements are copied).
    
    \item \texttt{map c(rv)} \\
    Move constructor; creates a new map/multimap of the same type, taking the contents of the rvalue \texttt{rv} (since C++11).
    
    \item \texttt{map c = rv} \\
    Move assignment operator; creates a new map/multimap of the same type, taking the contents of the rvalue \texttt{rv} (since C++11).
    
    \item \texttt{map c(beg, end)} \\
    Creates a map/multimap initialized by the elements of the range \texttt{[beg, end]}.
    
    \item \texttt{map c(beg, end, op)} \\
    Creates a map/multimap with the sorting criterion \texttt{op} initialized by the elements of the range \texttt{[beg, end]}.
    
    \item \texttt{map c\{inilist\}} \\
    Creates a map/multimap initialized with the elements of initializer list \texttt{inilist} (since C++11).
    
    \item \texttt{map c = \{inilist\}} \\
    Creates a map/multimap initialized with the elements of initializer list \texttt{inilist} (since C++11).
    
    \item \texttt{c.\~map()} \\
    Destroys all elements and frees the memory.
\end{itemize}
\textbf{Here, map may be one of the following types:}
\begin{itemize}
    \item \texttt{map<Key, Val>} \\
    A map that by default sorts keys with \texttt{less<>} (operator \texttt{<}).
    
    \item \texttt{map<Key, Val, Op>} \\
    A map that by default sorts keys with \texttt{Op}.
    
    \item \texttt{multimap<Key, Val>} \\
    A multimap that by default sorts keys with \texttt{less<>} (operator \texttt{<}).
    
    \item \texttt{multimap<Key, Val, Op>} \\
    A multimap that by default sorts keys with \texttt{Op}.
\end{itemize}

\bigbreak \noindent 
\paragraph{Using maps as associative arrays}
\bigbreak \noindent 
Associative containers don’t typically provide abilities for direct element access. Instead, you must
use iterators. For maps, as well as for unordered maps, however, there is an exception to this rule. Nonconstant maps provide a subscript operator for direct element access. In addition, since C++11, a corresponding member function at() is provided for constant and
nonconstant maps 
\bigbreak \noindent 
at() yields the value of the element with the passed key and throws an exception object of type
out\_of\_range if no such element is present
\bigbreak \noindent 
For operator [ ], the index also is the key that is used to identify the element. This means that
for operator [ ], the index may have any type rather than only an integral type. Such an interface is
the interface of a so-called associative array.
\bigbreak \noindent 
For operator [ ], the type of the index is not the only difference from ordinary arrays. In addition,
you can’t have a wrong index. If you use a key as the index for which no element yet exists, a new
element gets inserted into the map automatically. The value of the new element is initialized by the
default constructor of its type. Thus, to use this feature, you can’t use a value type that has no default
constructor. Note that the fundamental data types provide a default constructor that initializes their
values to zero





   \pagebreak 
   \subsubsection{STL Unordered containers}

   \pagebreak 
    \subsubsection{STL Containers: Implementations}
\begin{itemize}
    \item \textbf{std::vector}
    \begin{itemize}
        \item Implemented as a dynamically resizable array with contiguous memory.
    \end{itemize}

    \item \textbf{std::deque}
    \begin{itemize}
        \item Implemented as a sequence of dynamically allocated arrays (blocks) for efficient insertion/removal at both ends.
    \end{itemize}

    \item \textbf{std::list}
    \begin{itemize}
        \item Implemented as a doubly linked list, where each node contains pointers to the previous and next nodes.
    \end{itemize}

    \item \textbf{std::forward\_list}
    \begin{itemize}
        \item Implemented as a singly linked list, where each node contains a pointer to the next node.
    \end{itemize}

    \item \textbf{std::set} / \textbf{std::multiset}
    \begin{itemize}
        \item Implemented as a self-balancing binary search tree (typically Red-Black Tree).
    \end{itemize}

    \item \textbf{std::unordered\_set} / \textbf{std::unordered\_multiset}
    \begin{itemize}
        \item Implemented as a hash table with separate chaining or open addressing for collision resolution.
    \end{itemize}

    \item \textbf{std::map} / \textbf{std::multimap}
    \begin{itemize}
        \item Implemented as a self-balancing binary search tree (typically Red-Black Tree) for sorted key-value pairs.
    \end{itemize}

    \item \textbf{std::unordered\_map} / \textbf{std::unordered\_multimap}
    \begin{itemize}
        \item Implemented as a hash table with separate chaining or open addressing for key-value pairs.
    \end{itemize}
\end{itemize}


\pagebreak 
\subsubsection{STL Containers: Iterator Functions}
\begin{itemize}
    \item \textbf{Containers with all the iterator functions (begin(), end(), cbegin(), cend(), rbegin(), rend(), crbegin(), crend())}: 
        \begin{enumerate}
            \item Vector
            \item Deque
            \item List
            \item Set 
            \item Muliset
            \item Map
            \item Mulimap
            \item Unordered set
            \item unordered multiset
            \item unordered map
            \item unordered multimap
        \end{enumerate}
    \item \textbf{Containers with limited iterator support:}
        \begin{enumerate}
            \item \textbf{Forward\_list}: Only supports forward iterators (begin(), end(), cbegin(), cend()).
        \end{enumerate}
\end{itemize}


   \pagebreak 
   \subsubsection{STL containers: Main concepts, differences, uses}
   \begin{itemize}
       \item \textbf{Vectors}: 
           \begin{itemize}
               \item Dynamic array, automatic resizing. 
               \item We have access to capacity and reserve methods. 
               \item Fast at end operations. 
               \item Contiguous memory, random access. 
               \item at() method to index with error checking.
           \end{itemize}

        \item \textbf{Deque}: 
            \begin{itemize}
                \item Multiple blocks / Dynamic arrays to give access to both ends. 
                \item Fast at both ends. 
                \item Front and back operations. 
                \item Slower iterator access compared to vectors. 
                \item Iterators are smart pointers. 
                \item No capacity access
            \end{itemize}
        \item \textbf{List:}
            \begin{itemize}
                \item Doubly-linked list
                \item Insertion and removing is fast
                \item Access at any element thats not the first or last is slow.
                \item NO random access
                \item Member method to sort
                \item Splice
                \item Unique
                \item Merge
            \end{itemize}
        \item \textbf{Forward\_list}
            \begin{itemize}
                \item Singly linked list
                \item No size method
                \item No reverse iterators
                \item No pointer to last element, no back(), push\_back(), or pop\_back() methods
                \item For all member functions that modify forward lists in a way that elements are inserted or deleted at a specific position, special versions for forward lists are provided. The reason is that you have to pass the position of the element before the first element that gets manipulated, because there you have to assign a new successor element. Because you can’t navigate backwards (at least not in constant time), for all these member functions you have to pass the position of the preceding element. Because of this difference, these member functions have a after suffix in their name. For example, instead of insert(), insert\_after() is provided, which inserts new elements after the element passed as first argument; that is, it appends an element at that position.
                    \bigbreak \noindent 
                    For this reason, forward lists provide before\_begin() and cbefore\_begin(), which yield the position of a virtual element before the first element (technically speaking, the anchor of the linked list), which can be used to let built-in algorithms ending with after exchange even the first element
            \end{itemize}
        \item \textbf{Sets and multisets}
            \begin{itemize}
                \item Height balanced bst
                \item No duplicates in set, can have duplicates in multiset
                \item logarithmic searching
                \item logarithmic insertion and deletion
                \item Automatic sorting
                \item Can't change elements directly
                \item No direct element access
                \item Constant iterators
            \end{itemize}
   \end{itemize}
   

   \pagebreak 
   \subsubsection{STL Containers: Iterator invalidation}
   \begin{itemize}
       \item \textbf{Vectors:} 
           \begin{itemize}
               \item \textbf{Insertion:} All iterators are invalidated if a reallocation occurs; otherwise, only iterators at or after the point of insertion are invalidated.
               \item \textbf{Deletion:} Iterators at or after the point of deletion are invalidated.
           \end{itemize}
        \item \textbf{Deque}: 
            \begin{itemize}
                \item \textbf{Insertion/Deletion:} At beginning or end, no invalidation unless reallocation occurs. Inserting or deleting in the middle invalidates all iterators.
            \end{itemize}
        \item \textbf{List}:
            \begin{itemize}
                \item \textbf{Insertion:} No invalidation.
                \item \textbf{Deletion:} Only the iterator to the erased element is invalidated.
            \end{itemize}
        \item \textbf{Forward list}:
            \begin{itemize}
                \item \textbf{Insertion:} No invalidation.
                \item \textbf{Deletion:} Only the iterator to the erased element is invalidated.
            \end{itemize}
        \item \textbf{Set/multiset}:
            \begin{itemize}
                \item \textbf{Insertion:} No invalidation.
                \item \textbf{Deletion:} Only the iterator to the erased element is invalidated.
            \end{itemize}
        \item \textbf{unordered set/unordered multiset}:
            \begin{itemize}
                \item \textbf{Insertion:} No invalidation unless rehashing occurs.
                \item \textbf{Deletion:} Only the iterator to the erased element is invalidated.
                \item \textbf{Rehashing:} All iterators are invalidated.
            \end{itemize}
        \item \textbf{Map/Multimap}:
            \begin{itemize}
                \item \textbf{Insertion:} No invalidation.
                \item \textbf{Deletion:} Only the iterator to the erased element is invalidated.
            \end{itemize}
        \item \textbf{Unordered map/unordered multimap}:
            \begin{itemize}
                \item \textbf{Insertion:} No invalidation unless rehashing occurs.
                \item \textbf{Deletion:} Only the iterator to the erased element is invalidated.
                \item \textbf{Rehashing:} All iterators are invalidated.
            \end{itemize}
   \end{itemize}

   \pagebreak 
   \subsubsection{STL Containers: Reallocation}
   \begin{itemize}
       \item \textbf{Vectors}: Reallocation occurs when inserting elements exceeds the current capacity.
       \item \textbf{Deque}: Reallocation occurs when inserting elements requires more blocks (typically at both ends, but can happen internally).
        \item \textbf{List, forward list}: No reallocation occurs, as they allocate nodes dynamically and do not store elements contiguously.
        \item \textbf{set, multiset, map, multimap}: No reallocation occurs, as they use balanced trees, and elements are not stored contiguously.
        \item \textbf{unordered set, unordered multiset, unordered map, unordered multimap}:  Reallocation occurs when the load factor exceeds a threshold, triggering a rehash to a larger bucket array.
   \end{itemize}

   \pagebreak 
   \subsubsection{STL Containers: Element access}
\begin{itemize}
    \item \textbf{std::vector}
    \begin{itemize}
        \item Direct access via index: \texttt{v[i]}, \texttt{v.at(i)}
        \item Front element: \texttt{v.front()}
        \item Back element: \texttt{v.back()}
    \end{itemize}
    
    \item \textbf{std::deque}
    \begin{itemize}
        \item Direct access via index: \texttt{d[i]}, \texttt{d.at(i)}
        \item Front element: \texttt{d.front()}
        \item Back element: \texttt{d.back()}
    \end{itemize}
    
    \item \textbf{std::list}
    \begin{itemize}
        \item No direct access via index.
        \item Front element: \texttt{l.front()}
        \item Back element: \texttt{l.back()}
    \end{itemize}
    
    \item \textbf{std::forward\_list}
    \begin{itemize}
        \item No direct access via index.
        \item Front element: \texttt{fl.front()}
    \end{itemize}
    
    \item \textbf{std::set} / \textbf{std::multiset}
    \begin{itemize}
        \item No direct access via index.
        \item Access via iterator or functions like \texttt{find()}, \texttt{lower\_bound()}, \texttt{upper\_bound()}.
    \end{itemize}
    
    \item \textbf{std::unordered\_set} / \textbf{std::unordered\_multiset}
    \begin{itemize}
        \item No direct access via index.
        \item Access via iterator or \texttt{find()}.
    \end{itemize}
    
    \item \textbf{std::map} / \textbf{std::multimap}
    \begin{itemize}
        \item Access by key: \texttt{m[key]} (for \texttt{std::map} only, not \texttt{std::multimap}).
        \item Access via iterator or functions like \texttt{find()}, \texttt{lower\_bound()}, \texttt{upper\_bound()}.
    \end{itemize}
    
    \item \textbf{std::unordered\_map} / \textbf{std::unordered\_multimap}
    \begin{itemize}
        \item Access by key: \texttt{um[key]} (for \texttt{std::unordered\_map} only, not \texttt{std::unordered\_multimap}).
        \item Access via iterator or \texttt{find()}.
    \end{itemize}
\end{itemize}



   \pagebreak 
   \subsubsection{STL Containers: Uses and advantages}
   \begin{itemize}
    \item \textbf{std::vector}
    \begin{itemize}
        \item Advantages: Fast random access, contiguous memory, efficient for dynamic arrays.
        \item Uses: When frequent random access and dynamic resizing are needed.
    \end{itemize}
    
    \item \textbf{std::deque}
    \begin{itemize}
        \item Advantages: Fast insertion/removal at both ends, efficient dynamic array.
        \item Uses: Double-ended queue operations, efficient at both front and back.
    \end{itemize}
    
    \item \textbf{std::list}
    \begin{itemize}
        \item Advantages: Constant time insertion/removal anywhere, no reallocation.
        \item Uses: When frequent insertions/removals in the middle are needed.
    \end{itemize}
    
    \item \textbf{std::forward\_list}
    \begin{itemize}
        \item Advantages: Singly linked list, smaller memory overhead, constant time insertion/removal.
        \item Uses: Memory-constrained environments, where only forward traversal is needed.
    \end{itemize}
    
    \item \textbf{std::set} / \textbf{std::multiset}
    \begin{itemize}
        \item Advantages: Sorted elements, fast lookup (logarithmic time).
        \item Uses: When you need a sorted collection with unique or non-unique elements.
    \end{itemize}
    
    \item \textbf{std::unordered\_set} / \textbf{std::unordered\_multiset}
    \begin{itemize}
        \item Advantages: Fast average-time lookup (constant time), no sorting.
        \item Uses: When fast lookup is needed without element ordering.
    \end{itemize}
    
    \item \textbf{std::map} / \textbf{std::multimap}
    \begin{itemize}
        \item Advantages: Sorted key-value pairs, fast lookup (logarithmic time).
        \item Uses: Key-value pairs where keys must remain sorted.
    \end{itemize}
    
    \item \textbf{std::unordered\_map} / \textbf{std::unordered\_multimap}
    \begin{itemize}
        \item Advantages: Fast average-time lookup (constant time), no sorting.
        \item Uses: Key-value pairs where fast lookup is needed without ordering.
    \end{itemize}
\end{itemize}






   \pagebreak 
   \subsubsection{STL Iterators}
    An object that iterates/navigates over elements in the container. They are essentially an abstraction of pointer
   \begin{itemize}
       \item \textbf{Some notes about iterators}: 
           \begin{enumerate}
               \item each container provides its own iterator
               \item interfaces of iterators of different containers are largely the same
               \item internal behaviors depend on the data structure of the container
           \end{enumerate}
       \item \textbf{Operations}: 
            \begin{enumerate}
                \item operator * returns the element of the current positions
                \item operator -> access a member of the element
                \item operator ++ step forward
                \item operator -- step backward
                \item operator == and != whether two iterators represent the same position
                \item operator = assign an iterator
            \end{enumerate}
        \item \textbf{Important iterators}:
            \begin{enumerate}
                \item begin() gets you the beginning of a container
                \item end() gets you just past the end
            \end{enumerate}
        \item \textbf{Iterator types}
            \begin{itemize}
                \item \textbf{iterator}
                \item \textbf{reverse\_iterator}
                \item \textbf{const\_iterator}
                \item \textbf{const\_reverse\_iterator}
            \end{itemize}
        \item \textbf{Iterator categories}
            \begin{enumerate}
                \item \textbf{Input Iterator:}
                    \begin{itemize}
                        \item \textbf{Purpose:} Read-only access to elements in a single-pass manner.
                        \item \textbf{Operations:} Can be incremented (++), compared for equality (==), and dereferenced (*) to access elements.
                    \end{itemize}
                \item \textbf{Output Iterator:}
                    \begin{itemize}
                        \item \textbf{Purpose:} Write-only access to elements in a single-pass manner.
                        \item \textbf{Operations:} Can be incremented (++) and dereferenced (*) to assign values.
                    \end{itemize}
                \item \textbf{Forward Iterator:}
                    \begin{itemize}
                        \item \textbf{Purpose:} Read and write access to elements; can traverse the container in a single direction.
                        \item \textbf{Operations:} Can be incremented (++), compared for equality (==), and dereferenced (*).
                    \end{itemize}
                \item \textbf{Bidirectional iterator}:
                    \begin{itemize}
                        \item \textbf{Purpose:} Read and write access to elements; can traverse the container in both directions.
                        \item \textbf{Operations:} Supports both increment (++) and decrement (--) operations.
                    \end{itemize}
                    \pagebreak 
                \item \textbf{Random Access Iterator:}
                    \begin{itemize}
                        \item \textbf{Purpose}: Read and write access with the ability to jump to any element in constant time.
                        \item \textbf{Operations:} Supports all operations of bidirectional iterators plus direct arithmetic operations like addition (+), subtraction (-), and subscript ([]).
                    \end{itemize}
            \end{enumerate}
        \item \textbf{Containers and their iterators}:
            \begin{enumerate}
                \item \textbf{Vector}: Random access iterator
                \item \textbf{Deque}: Random access iterator
                \item \textbf{List}: Bidirectional iterator
                \item \textbf{Forward\_list}: Forward iterator
                \item \textbf{Set}: Bidirectional iterator
                \item \textbf{Multiset}: Bidirectional iterator
                \item \textbf{Map}: Bidirectional iterator
                \item \textbf{Multimap}: Bidirectional iterator
                \item \textbf{Unordered\_map}: Forward iterator
            \end{enumerate}
        \item \textbf{Insert iterators}: Insert iterators in C++ are special types of iterators that allow you to insert elements into a container at specific positions rather than overwriting existing elements. There are three primary types of insert iterators provided by the C++ Standard Library:
            \bigbreak \noindent 
            if a container has an insert method, you can and often should use it directly when inserting elements, especially if you want to insert a single element or a specific range of elements into the container.
            \bigbreak \noindent 
            Containers that have an insert method are: vector, deque, list, forward list, set, multiset, unordered set, unordered multiset,map, multimap, unordered map, unordered multi map.
            \bigbreak \noindent 
            Insert iterators (std::back\_inserter, std::front\_inserter, and std::inserter) should be used when working with algorithms or situations where automatic insertion logic simplifies your code.
            \bigbreak \noindent 
            Some things in <algorithm> require these inserters
            \begin{enumerate}
                \item \textbf{std::front\_inserter}: Inserts elements at the front of a container. Calls the container's push\_front method to add elements to the front. Used with containers that support push\_front 
                    \bigbreak \noindent 
                    \begin{cppcode}
                        #include <list>
                        #include <algorithm>
                        #include <iterator>

                        int main() {
                            std::list<int> lst = {1, 2, 3};
                            std::list<int> to_add = {4, 5, 6};

                            // Insert elements at the front of lst
                            std::copy(to_add.begin(), to_add.end(), std::front_inserter(lst));

                            // lst now contains: 6, 5, 4, 1, 2, 3
                        }
                    \end{cppcode}
                \item \textbf{std::back\_inserter}: Inserts elements at the end of a container. Inserts elements at the end of a container. Used with containers that support push\_back 
                    \bigbreak \noindent 
                    \begin{cppcode}
                        #include <vector>
                        #include <algorithm>
                        #include <iterator>

                        int main() {
                            std::vector<int> vec = {1, 2, 3};
                            std::vector<int> to_add = {4, 5, 6};

                            // Insert elements at the end of vec
                            std::copy(to_add.begin(), to_add.end(), std::back_inserter(vec));

                            // vec now contains: 1, 2, 3, 4, 5, 6
                        }
                    \end{cppcode}
                \item \textbf{std::inserter}: Inserts elements at a specific position in a container.  Takes an iterator indicating the insertion position and calls the container's insert method. Used with containers that support insertion at arbitrary positions
                    \bigbreak \noindent 
                    \begin{cppcode}
                        #include <vector>
                        #include <algorithm>
                        #include <iterator>

                        int main() {
                            std::vector<int> vec = {1, 2, 3};
                            std::vector<int> to_add = {4, 5, 6};

                            // Insert elements starting at the second position (before 2)
                            std::copy(to_add.begin(), to_add.end(), std::inserter(vec, vec.begin() + 1));

                            // vec now contains: 1, 4, 5, 6, 2, 3
                        }
                    \end{cppcode}
            \end{enumerate} 
   \end{itemize}











   % \subsubsection{The Basics of STL containers}
   % \bigbreak \noindent 
   % The STL is a generic library that manages collections of data with efficient algorithms. It has template classes, functions, parameters. The idea is to have the same/single implementation works for many data types
   % \bigbreak \noindent 
   % \textbf{Components:}
   % \begin{enumerate}
   %     \item \textbf{Containers}: manage collections of data
   %         \begin{itemize}
   %             \item \textbf{sequence containers e.g. vector, list, deque}: Sequence containers store elements in a linear sequence, where the order of elements is strictly maintained. They allow for sequential access to elements
   %             \item \textbf{associative containers e.g. set, map}: Associative containers store elements in a way that allows for fast retrieval based on keys. They automatically order elements based on their keys or some criterion.
   %                 \bigbreak \noindent 
   %                 \textbf{Note:} Sets in C++ are considered associative containers because they store elements in a way that allows for efficient retrieval based on the value of the elements themselves. This differs fundamentally from sequence containers, which maintain elements in a specific order based on the sequence of insertion.
   %         \end{itemize}
   %     \item \textbf{Iterators}: Step through elements in an container
   %     \item \textbf{Algorithms}: Procedures that process the elements of collections
   % \end{enumerate}
   % \bigbreak \noindent 
   % \textbf{Global algorithms for all containers in the <algorithm> header}:
   % \begin{itemize}
   %     \item \textbf{copy}: Copies elements from one range to another.
   %     \item \textbf{transform}: Applies a function to each element in a range and stores the result in another range.
   %     \item \textbf{find}: Searches for the first occurrence of a value in a range.
   %     \item \textbf{search}: Searches for a subsequence within a range.
   %     \item \textbf{mismatch}: Finds the first position where two ranges differ.
   %     \item \textbf{fill}: Assigns a value to each element in a range.
   %     \item \textbf{replace}: Replaces occurrences of a value in a range with another value.
   %     \item \textbf{sort}: Sorts elements in a range.
   % \end{itemize}
   % \pagebreak \bigbreak \noindent 
   % \textbf{Signatures}:
   % \begin{cppcode}
   %     template <class InputIterator, class OutputIterator>
   %     OutputIterator copy(InputIterator first, InputIterator last, OutputIterator result);
   %
   %     template <class InputIterator, class OutputIterator, class UnaryOperation>
   %     OutputIterator transform(InputIterator first, InputIterator last, OutputIterator result, UnaryOperation op);
   %
   %     template <class InputIterator, class T>
   %     InputIterator find(InputIterator first, InputIterator last, const T& value);
   %
   %     template <class ForwardIterator1, class ForwardIterator2>
   %     ForwardIterator1 search(ForwardIterator1 first1, ForwardIterator1 last1, ForwardIterator2 first2, ForwardIterator2 last2);
   %
   %
   %     template <class InputIterator1, class InputIterator2>
   %     std::pair<InputIterator1, InputIterator2> mismatch(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2);
   % \end{cppcode}
   %
   % \pagebreak 
   % \begin{cppcode}
   %     template <class ForwardIterator, class T>
   %     void fill(ForwardIterator first, ForwardIterator last, const T& value);
   %
   %     template <class ForwardIterator, class T>
   %     void replace(ForwardIterator first, ForwardIterator last, const T& old_value, const T& new_value);
   %
   %     template <class RandomAccessIterator>
   %     void sort(RandomAccessIterator first, RandomAccessIterator last);
   % \end{cppcode}
   % \bigbreak \noindent 
   % \textbf{Note:} This is not an exhaustive list of signatures for these procedures
   % \bigbreak \noindent 
   % \textbf{Vectors}: One of the sequence containers
   % \begin{itemize}
   %  \item \textbf{Properties of vectors}:
   %      \begin{enumerate}
   %          \item The order of elements in the container depends on the time/space of the insertion(s) of the elements. This means that the elements in a std::vector are stored in the order in which they are inserted.
   %          \item dynamic array
   %          \item random access
   %          \item adding/removing elements at the end is fast
   %          \item inserting/removing in the middle/beginning is slow 
   %      \end{enumerate}
   %  \item \textbf{Vector constructors}
   %      \begin{enumerate}
   %          \item default constructor
   %          \item copy constructor
   %          \item constructor with given range from another (type of) container, with an array, from standard input, type may be even different provided automatic conversion
   %      \end{enumerate}
   %  \item \textbf{Vector destructor}: When dealing with vectors, destructors automatically call the destructor of each element stored in the vector in reverse order of their insertion. After destroying each element, the vector's destructor releases the internal memory used by the vector itself.
   %  \item \textbf{Vector methods}:
   %      \begin{enumerate}
   %          \item size - the actual number of elements in the vector
   %          \item empty - whether the vector is empty or not
   %          \item max\_size - the maximum number of elements a container may contain. - a constraint from the system or library implementation. this is different from capacity().
   %          \item capacity - the number of elements a vector could contain in its actual memory.
   %          \item resize - resize the vector. in case of larger size, fill the rest with a certain value. - different from reserve().
   %          \item reserve - change the capacity of the vector. exception is thrown if not successful.
   %      \end{enumerate}
   %  \item \textbf{Element access methods}:
   %      \begin{enumerate}
   %          \item operator[ ] - access the element at a certain position. it does not check the valid range.
   %          \item at() – similar to [ ]. it checks range, and throws exception.
   %          \item front() – returns a reference to the first element
   %          \item back() – returns a reference to the last element
   %      \end{enumerate}
   %  \item \textbf{assignments and assignment methods}
   %      \begin{enumerate}
   %          \item operator= - copy from another vector containing the same type
   %          \item assign() - assigns new content to the current vector. overloaded.
   %          \item swap() - exchange two vectors.
   %      \end{enumerate}
   %  \item \textbf{Insertion methods}
   %      \begin{enumerate}
   %          \item insert() - insert new element in front of a specified position
   %          \item push\_back() - append a new element to the end of the vector
   %          \item emplace\_back() - construct a new element in-place at the end, used if inserting objects that need to be constructed
   %      \end{enumerate}
   %  \item \textbf{Removal methods}
   %      \begin{enumerate}
   %          \item erase - remove an element or a range of elements
   %          \item pop\_back - remove the last element
   %          \item resize - change the number of elements
   %          \item clear - remove all elements from the vector
   %      \end{enumerate}
   %  \item \textbf{what operations may cause reallocation of the internal array?}:
   %      \begin{enumerate}
   %          \item reserve
   %          \item push\_back, emplace\_back
   %          \item insert, emplace
   %      \end{enumerate}
   %      \bigbreak \noindent 
   %      \textbf{Note:} Note that pop\_back, erase, clear do not cause reallocation
   %      \bigbreak \noindent 
   %      When reallocation happens, all references, pointers, and iterators referring to elements of the original vector become invalidated.
   %  \item \textbf{what if do want to reduce memory size for unused positions?}
   %      \begin{enumerate}
   %          \item shrink\_to\_fit() - reduce memory usage by freeing unused memory
   %      \end{enumerate}
   %  \item \textbf{Time complexity of the operations}:
   %      \begin{enumerate}
   %          \item \textbf{Linear time O(n):} clear, insert, erase, assign, resize, destructor, operator=, copy constructor, constructor with a given rang
   %              \bigbreak \noindent 
   %              \textbf{Note:} push\_back and emplace\_back are O(n) because in the worst case, the vector needs to be resized in order to fit the new elements.
   %          \item \textbf{linear time o(n):} clear, insert, erase, assign, resize, destructor, operator=, copy constructor, constructor with a given rang
   %      \end{enumerate}
   %
   % \end{itemize}
   %
   % \pagebreak 
   % \bigbreak \noindent 
   % \textbf{Deque (Double ended queue)}: Another sequence container <deque>. Involves dynamic arrays, similar to vectors, but involves multiple ararys. Random access to its elements but a little slower than vectors, because of the multiple arrays.
   % \bigbreak \noindent 
   %   almost the same interface as vector
   % \begin{itemize}
   %     \item \textbf{different from vector:} deque has two open ends
   %      \item fast for adding/removing at both ends
   %      \item \textbf{Capacity stuff}: 
   %          \begin{enumerate}
   %              \item capacity() and reserve() are not available for deque
   %              \item capacity and allocation are completely automatically managed for deque, no user suppor
   %          \end{enumerate}
   %      \item \textbf{Extra modifiers}: In deques, we have 
   %          \begin{enumerate}
   %              \item \textbf{push\_front()}
   %              \item \textbf{pop\_front()}
   %              \item \textbf{emplace\_front()}
   %          \end{enumerate}
   %          Along with the back stuff that vectors have.
   %      \item \textbf{Internal memory}: internal memory is not contiguous (split into multiple arrays). Although we can use random access is if it were. element access and iterator movement involves more calculation comparing to vector
   %          \bigbreak \noindent 
   %          Iterators may need to jump between different memory blocks. max\_size may be larger because a deque may occupy multiple blocks of memory
   %      \item \textbf{Adding at front or end}:  All iterators are invalidated; references are not invalidated
   %          \bigbreak \noindent 
   %      \item \textbf{Removing from front or end}: Iterators and references of other positions are not invalidated. end() is invalidated
   %      \item \textbf{adding or removing anywhere other than two ends}: All iterators and references are invalidated
   %      \item \textbf{Advantages of deques}:
   %          \begin{enumerate}
   %              \item fast adding/removing at both ends (though still slow inadding/removing in the middle)
   %              \item possiblely larger max\_size
   %              \item massive reallocations are avoided
   %          \end{enumerate}
   % \end{itemize}
   %
   % \pagebreak \bigbreak \noindent 
   % \textbf{List}: (doubly linked list) Another sequence container <list>
   % \begin{itemize}
   %     \item \textbf{Properties}:
   %         \begin{enumerate}
   %             \item Doubly-linked list
   %              \item No random access of elements
   %              \item Adding or removing \textbf{anywhere} is fast, as long as you have reference to the location where you want to add/remove, otherwise you need to traverse the list to reach the location
   %              \item adding/removing does not invalidate pointers, references, and iterators to other elements
   %              \item there is no reallocation
   %         \end{enumerate}
   %      \item \textbf{Capacity stuff}: Capacity and reserve are not available for lists, each element of the list has its own memory. Elements occupy non-contiguous memory.
   %      \item \textbf{Element access}: No [], no at().
   %      \item \textbf{Operations on lists}:
   %          \begin{enumerate}
   %              \item remove( ): remove all elements with a certain value
   %              \item remove\_if( ): remove all elements that satisfy certain criterion.
   %              \item erase( ): remove an element with a specified iterator (note that erase here returns an iterator for next pos.)
   %              \item unique( ): remove duplicates of consecutive elements
   %              \item splice( ): move elements from one list to another
   %              \item sort( ): sort all elements with $<$ or defined comparison
   %              \item merge( ): merge two sorted lists
   %              \item reverse( ): reverse the order of all elements
   %              \item many above methods are overloaded
   %          \end{enumerate}
   %      \item \textbf{Splicing (splice method)}: We pass iterator for position of insertion, list object to take elements from, begin, end range of source list
   % \end{itemize}
   %
   % \pagebreak 
   % \bigbreak \noindent 
   % \textbf{forward\_list}: Another sequence container <forward\_list>. Internally implemented by singly linked list. No random access of elements
   % \bigbreak \noindent 
   % Adding/removing does not invalidate pointers, references, and iterators to other elements. there is no reallocation
   % \begin{itemize}
   %     \item Only support forward iterators. (no -- operation), only forward traversal
   %      \item forward lists are more memory efficient than lists in some cases
   %      \item \textbf{Adding / removing properties}
   %          \begin{enumerate}
   %              \ite madding/removing at begin of a list is fast
   %              \item adding/removing at the next position of a given element is fast
   %      \item adding/removing anywhere requires traversal from head
   %          \end{enumerate}
   % \end{itemize}
   %
   % \pagebreak \bigbreak \noindent 
   % \textbf{Associative containers}
   % \begin{itemize}
   %     \item \textbf{Sorted}: Elements (or keys) are sorted. Internally height balanced binary search tree. 
   %         \bigbreak \noindent 
   %         orted according to a certain sorting criterion, by default its the < operator. You can provide you own criteria
   %         \bigbreak \noindent 
   %         Order of insertion does not matter
   %         \begin{enumerate}
   %             \item \textbf{Set:} Elements are sorted according to their own values. Each element only occurs once
   %             \item \textbf{multiset}: Set that allows duplicates
   %             \item \textbf{map}: each element is a key/value pair. Key is used for sorting elements. Each key occurs only once
   %             \item \textbf{multimap}: similar to map, except that it allows duplicates 
   %         \end{enumerate}
   %      \item \textbf{Unsorted}: Not sorted, internally organized as hash table
   %          \begin{enumerate}
   %              \item unordered set
   %              \item unordered multiset
   %              \item unordered map
   %              \item unordered multimap
   %          \end{enumerate}
   % \end{itemize}
   %
   % \bigbreak \noindent 
   % \textbf{Set and multiset}: When an element is added to a set, it’s automatically placed in a position to maintain the sorting status.
   % \bigbreak \noindent 
   % One cannot change an element value directly Otherwise the new value may break the correct order
   % \begin{itemize}
   %     \item No direct element access
   %     \item Elements referenced by iterators are constants
   % \end{itemize}
   % \bigbreak \noindent 
   % In order to change value, one needs to remove the element with the old value, add the new element with the new value
   % \bigbreak \noindent 
   % Sets and multisets are efficient for searching.
   % \bigbreak \noindent 
   % \textbf{Special search operations}
   % \begin{itemize}
   %     \item \textbf{count(elem)} : the number of elements with the value elem
   %     \item \textbf{find(elem)} : the position of the first element with value elem Note that it’s different from find() in <algorithm>
   %     \item \textbf{lower\_bound(elem)} : the position of first element $>=$ elem
   %     \item \textbf{upper\_bound(elem)} : the position of first element $>$ elem
   %     \item \textbf{equal\_range(elem)} : the range of elements == elem. The return value is a pair<iterator, iterator>
   % \end{itemize}
   % \bigbreak \noindent 
   % \textbf{Inserting and removing elements}
   % \begin{itemize}
   %     \item \textbf{insert( elem )}: Returns pair<iterator, bool>. The second field indicates the insertion is successful or not (since an element may already exists)
   %      \item \textbf{insert( pos, elem)}:
   %      \item \textbf{insert(begin, end)}:
   %      \item \textbf{erase(element)}:
   %      \item \textbf{erase(pos)}:
   %      \item \textbf{erase(begin, end)}
   %      \item \textbf{clear()}
   % \end{itemize}
   % \bigbreak \noindent 
   % \textbf{size related operations}:
   % \begin{itemize}
   %     \item \textbf{size()}
   %      \item \textbf{empty()}
   %      \item \textbf{max\_size()}
   % \end{itemize}
   % \bigbreak \noindent 
   % \textbf{Assignments}
   % \begin{itemize}
   %     \item \textbf{operator=}
   %      \item \textbf{swap()}
   % \end{itemize}
   %
   % \pagebreak 
   % \bigbreak \noindent 
   % \textbf{map \& multimap}: Manage key/value pairs as elements
   % \bigbreak \noindent 
   % Multimap allows duplicate, while map does not. Elements are automatically sorted based on keys according to a certain sorting criterion
   % \bigbreak \noindent 
   % \textbf{Properties}
   % \begin{itemize}
   %     \item \textbf{Automatic sorting}: When a key/value pair is added to a map, it’s automatically placed in a position to maintain the sorting status based on the key
   %     \item \textbf{One cannot change the key of an element directly}: Otherwise the new value may break the correct order based on keys The keys of elements referenced by iterators are constants
   %      \item \textbf{In order to change a key, one needs to}: Remove the element with the old key, add the new element with the new key.
   %      \item \textbf{Efficient for searching based on keys}: Not efficient for searching based on values of elements
   % \end{itemize}
   % \bigbreak \noindent 
   % \textbf{Note:} One can still modify the value of an element directly
   % \bigbreak \noindent 
   % \textbf{Search operations}: 
   % \begin{itemize}
   %     \item \textbf{count(key)} : the number of elements with the key
   %     \item  \textbf{find(key)} : the position of the first element with the key
   %     \item \textbf{lower\_bound(key)} : the position of first element whose key $>=$ key
   %     \item \textbf{upper\_bound(key)} : the position of first element whose key $>$ key
   %     \item \textbf{equal\_range(key)} : the range of elements whose key == key. The return value is a pair
   % \end{itemize}
   % \bigbreak \noindent 
   % \textbf{Inserting and removing elements}
   % \begin{itemize}
   %     \item \textbf{insert( elem )}: The return type for map is pair<iterator, bool> The second field indicates the insertion is successful or not (since an element may already exists)
   %     \item \textbf{insert( pos, elem)}:
   %     \item \textbf{insert( beg, end )}:
   %     \item \textbf{erase(elem )}:
   %     \item \textbf{erase( pos )}: Note that in sequence containers, erase returns the position after the removed element, but in associative containers, erase does not return such position because it needs to traverse to find successor.
   %     \item \textbf{erase( beg, end )}:
   %     \item \textbf{clear()}:
   % \end{itemize}
   % \bigbreak \noindent 
   % \textbf{Size related operations}
   % \begin{itemize}
   %     \item \textbf{size()}:
   %      \item \textbf{empty()}:
   %      \item \textbf{max\_size()}:
   % \end{itemize}
   % \bigbreak \noindent 
   % \textbf{Assignments}
   % \begin{itemize}
   %     \item \textbf{operator=}:
   %      \item \textbf{sawp}:
   % \end{itemize}
   % \bigbreak \noindent 
   % \textbf{Return of [] operator}
   % \begin{itemize}
   %     \item \textbf{m[k]}: Returns a reference to the value of the element with key k. Inserts an element with k if it does not yet exist
   % \end{itemize}
   %
   %
   %
   %
   %
   %
   % \pagebreak \bigbreak \noindent 

   \pagebreak 
   \subsubsection{STL Function Objects}
   \bigbreak \noindent 
   Functional arguments for algorithms don’t have to be functions. As seen with lambdas, functional arguments can be objects that behave like functions. Such an object is called a function object, or functor. Instead of using a lambda, you can define a function object as an object of a class that provides a function call operator
   \bigbreak \noindent 
   Function objects are another example of the power of generic programming and the concept of pure
   abstraction. You could say that anything that behaves like a function is a function. So, if you define
   an object that behaves as a function, it can be used like a function.
   \bigbreak \noindent 
   So, what is the behavior of a function? A functional behavior is something that you can call by
   using parentheses and passing arguments
   \bigbreak \noindent 
   All you have to do is define operator () with the appropriate parameter types:
   \bigbreak \noindent 
   \begin{cppcode}
       class c {
           public:
           void operator() (int x) {
               cout << "The value is: " << x << endl;
           }
       };

       c c1;
       c1(2); // Call the object as a function

       vector<int> v({1,2,3});
       std::for_each(b(v), e(v), c()); // Use function object for algorithms
   \end{cppcode}

   \bigbreak \noindent 
   \paragraph{Why?}
   \bigbreak \noindent \bigbreak \noindent 
   You may be wondering what all this is good for. You might even think that function objects look
   strange, nasty, or nonsensical. It is true that they do complicate code. However, function objects are
   more than functions, and they have some advantages:
   \begin{enumerate}
       \item Function objects are “functions with state.” Objects that behave like pointers are smart pointers. This is similarly true for objects that behave like functions: They can be “smart functions” because they may have abilities beyond operator (). Function objects may have other member functions and attributes. This means that function objects have a state. In fact, the same functionality, represented by two different function objects of the same type, may have different states at the same time. This is not possible for ordinary functions. Another advantage of function objects is that you can initialize them at runtime before you use/call them.
       \item Each function object has its own type. Ordinary functions have different types only when their signatures differ. However, function objects can have different types even when their signatures are the same. In fact, each functional behavior defined by a function object has its own type. This is a significant improvement for generic programming using templates because you can pass functional behavior as a template parameter. Doing so enables containers of different types to use the same kind of function object as a sorting criterion, ensuring that you don’t assign, combine, or compare collections that have different sorting criteria. You can even design hierarchies of function objects so that you can, for example, have different, special kinds of one general criterion.
       \item Function objects are usually faster than ordinary functions. The concept of templates usually allows better optimization because more details are defined at compile time. Thus, passing function objects instead of ordinary functions often results in better performance.
   \end{enumerate}

   \bigbreak \noindent 
   \paragraph{Predefined function objects}
   \bigbreak \noindent \bigbreak \noindent 
   \begin{itemize}
       \item LESS<T>
       \item GREATER<T>
    \end{itemize}
   We can use these for example, in constructor of set:
   \bigbreak \noindent 
   \begin{cppcode}
       set<ELEM> C // A SET THAT SORTS WITH LESS<>
        set<ELEM, OPERATION> C // A SET THAT SORTS WITH OP
   \end{cppcode}
   \bigbreak \noindent 
     Examples:
   \begin{itemize}
       \item SET<INT> S1; // INTEGERS ARE SORTED BY <
       \item SET<INT, GREATER<INT> > S2; // INTEGERS ARE SORTED BY >
   \end{itemize}




    \pagebreak 
    \unsect{Databases}

    \bigbreak \noindent 
    \subsection{Introduction to databases (db concepts)}
    \bigbreak \noindent 
    \subsubsection{Definitions and theorems}
    \begin{itemize}
        \item \textbf{What is a database?}: A database is a collection of stored operational data used by the application systems of some particular enterprise, better yet a collection of related data.
        \item \textbf{What is an enterprise?}: a generic term for any reasonably large-scale commercial, scientific, technical, or other application. Such as
            \begin{itemize}
                \item Manufacturing
                \item Financial
                \item Medical
                \item University
                \item Government
            \end{itemize}
        \item \textbf{Operational data}: Data maintained about the operation of an enterprise, such as
            \begin{itemize}
                \item Products
                \item Accounts
                \item Patients
                \item Students
                \item Plans
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Note:} Notice that this DOES NOT include input/output data
        \item \textbf{Database Management System (DBMS)}: A Database Management System (DBMS) is a collection of programs that enables users to create and maintain a database. Ie a general-purpose software system that facilitates
            \begin{itemize}
                \item Definition of databases
                \item Construction of databases
                \item Manipulation of data within a database
                \item Sharing of data between users/applications
            \end{itemize}
        \item \textbf{Defining a database}: For the data being stored in the database, defining the database specifies
            \begin{itemize}
                \item The data types
                \item The structures
                \item The constraints
            \end{itemize}
        \item \textbf{Constructing a Database}: Constructing a database is the process of storing the data itself on some storage device
            \bigbreak \noindent 
            \textbf{Note:} The storage device is controlled by the DBMS
        \item \textbf{Manipulating a Database}
            \begin{itemize}
                \item retrieve specific information in a query
                \item update the database to include changes
                \item generate reports from the data
            \end{itemize}
            \bigbreak \noindent 
            Most likely already defined by whatever dbms you choose
        \item \textbf{Sharing a Database}: Sharing a database Allows multiple users and programs to access the database at the same time, any conflicts between applications are handled by the DBMS
        \item \textbf{Other Important Functions of a Database}: Other important functions provided by a DBMS include
            \begin{itemize}
                \item Protection, system protection, security protection
                \item Maintenence, allows updates to be performed easily
            \end{itemize}
        \item \textbf{Simplified Database System Environment}:
            \bigbreak \noindent 
            \fig{.5}{./figures/1.png}
        \item \textbf{Main characteristics of a database system are:}
            \begin{itemize}
                \item Self-describing nature of a database system
                \item Insulation between programs and data, and data abstraction
                \item Support for multiple views of the data
                \item Sharing of data and multi-user transaction processing
            \end{itemize}
        \item \textbf{Other Capabilities of DBMS Systems}: Support for at least one data model through which the user can view the data, There is at least one abstract model of data that allows the user to see the “information” in the database, Relational, hierarchical, network, inverted list, or object-oriented
            \bigbreak \noindent 
            Support for at least one data model through which the user can view the data
            \begin{itemize}
                \item efficient file access which allows us to “find the boss of Susie Jones”
                \item allows us to “navigate” within the data
                \item allows us to combine values in 2 or more databases to obtain “information”
            \end{itemize}
            \bigbreak \noindent 
            Support for high-level languages that allow the user to define the structure of the data, access that data, and manipulate it
            \begin{itemize}
                \item Data Definition Language (DDL)
                \item Data Manipulation Language (DML)
                \item Data Control Language (DCL)
                \item query language access data
                \item operations such as add, delete, and replace
            \end{itemize}
        \item \textbf{Transaction Management}: Transaction management is a feature that provides correct, concurrent access to the database, possibly by many users at the same time, ability to simultaneously manage large numbers of \textit{transactions}
        \item \textbf{Access Control}: Access control is the ability to limit access to data by unauthorized users along with the capability to check the validity of the data. This is to protect against loss when database crashes and prevent unauthorized access to portions of the data
        \item \textbf{Resiliency}: Resiliency is the ability to recover from system failures without losing data, Ideally, should be able to recover from any type of failure, such as 
            \begin{itemize}
                \item sabotage
                \item acts of God
                \item hardware failure
                \item software failure
                \item etc.
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Note}: Obviously, some of these would require more than just software - offsite backups, etc
        \item \textbf{Use of Conceptual Modeling}:
            \bigbreak \noindent 
            \fig{.5}{./figures/2.png}
        \item \textbf{Leveled Architecture of a DBMS}:
            \bigbreak \noindent 
            \fig{.5}{./figures/3.png}
        \item \textbf{External level}: a view or sub-schema, a portion of the logical database, may be in a higher level language
        \item \textbf{Logical Level}: abstraction of the real world as it pertains to the users of the database. DBMS provides a data definition language (DDL) to describe the logical schema in terms of a specific data model such as relational, hierarchical, network, inverted list, etc.
        \item \textbf{Physical Level}: The collection of files and indices, the collection of files and indices, this is the actual data
        \item \textbf{Instance}: An instance of the database is the actual contents of the data, it could be 
            \begin{itemize}
                \item the extension of the database
                \item current state of the database
                \item a snapshot of the data at a given point in time
            \end{itemize}
        \item \textbf{Schema}: The schema of a database is the data about what the data represents. Such as,
            \begin{itemize}
                \item plan of the database
                \item logical plan
                \item physical plan
                \item the intention of the database
            \end{itemize}
        \item \textbf{Schema vs Instance}:
            \bigbreak \noindent 
            \fig{.5}{./figures/4.png}
        \item \textbf{Data Independence}: Data Independence is a property of an appropriately designed database system,  it has to do with the mapping of logical level to physical level, and logical to external
            \begin{itemize}
                \item \textbf{Physical data independence}:  Physical schema can be changed without modifying logical schema
                \item \textbf{Logical data independence}: logical schema can be changed without having to modify any of the external views
            \end{itemize}
        \item \textbf{DCL (Control), DDL (Definition), DML (Manipulation)}: may be completely separate (example is IMS), may be intermixed (DB2), or may be a host language, for example an  application program in which DML commands are embedded such as COBOL or PL/I
        \item \textbf{DBMS Components}:
            \bigbreak \noindent 
            \fig{.5}{./figures/5.png}
        \item \textbf{Overall DBMS Usage Scenario}: Database Administrator (DBA) define the conceptual, logical, and physical levels using DDL.  DBMS software stores instances of these in schemas.  User defines views (External Schema) in DDL. User accesses database using DML
        \item \textbf{Advantages of a Database}:
            \begin{itemize}
                \item Controlled redundancy
                \item Reduced inconsistency in the data
                \item Shared access to data
                \item Standards enforced
                \item Security restrictions maintained
                \item Integrity maintained more easily
                \item Provides capability for backup and recovery
                \item Permitting inferences and actions using rules
            \end{itemize}
        \item \textbf{Disadvantages of a Database}:
            \begin{itemize}
                \item Increased complexity needed to implement concurrency control
                \item Increased complexity needed for centralized access control
                \item Security needed to allow the sharing of data
                \item Necessary redundancies can cause complexity when updating
            \end{itemize}
        \item \textbf{Data vs Information}:
            \begin{itemize}
                \item \textbf{Data}: Data refers to raw, unprocessed facts, figures, and details. It represents basic elements that have not been interpreted or given any meaning.
                \item \textbf{Information}: Information is processed, organized, or structured data that is meaningful and useful. It is data that has been interpreted or analyzed to provide context, relevance, and purpose.
            \end{itemize}
    \end{itemize}

    \pagebreak 
    \subsection{Conceptual Modeling and ER Diagrams}
    \bigbreak \noindent 
    \subsubsection{Definitions and theorems}
    \begin{itemize}
        \item \textbf{Data Models}: A means of describing the structure of data, we typically have A set of operations that manipulate the data (for data models that are implemented)
        \item \textbf{Types of data models}:
            \begin{itemize}
                \item Conceptual data model
                \item  Logical data models - relational, network, hierarchical, inverted list, or object-oriented
            \end{itemize}
        \item \textbf{Conceptual Data Model}:
            \begin{itemize}
                \item Shows the structure of the data including how things are related
                \item Communication tool
                \item Independent of commercial DBMSes
                \item Relatively easy to learn and use
                \item Helps show the semantics or meaning of the data
                \item Graphical representation
                \item Entity-Relationship Model is very common
            \end{itemize}
        \item \textbf{Logical Data Models - Relational}: Data is stored in relations (tables). These tables have one value per cell. Based upon a mathematical model.
        \item \textbf{Logical Data Models - Network}: Data is stored in records (vertices) and associations between them (edges), Based upon a model called CODASYL
        \item \textbf{Logical Data Models - Hierarchical}: Data is stored in a tree structure with parent/child relationships
        \item \textbf{Logical Data Models - Inverted List}: Tabular representation of the data using indices to access the tables, Almost relational, but it allows for non-atomic data values \footnote{ "Non-atomic data values" refer to data structures or values that are composed of multiple components, as opposed to atomic data values, which are indivisible and represent a single value.}, which are not allowed in relations
        \item \textbf{Logical Data Models - Object Oriented}: Data stored as objects which contain
            \begin{itemize}
                \item Identifier
                \item Name
                \item Lifetime
                \item Structure
            \end{itemize}
        \item \textbf{Entity-Relationship Model}: Meant to be simple and easy to read. Should be able to convey the design both to database designers and unsophisticated users
        \item \textbf{Entities}: Principle objects about which information is kept - These are the *things* we store data about. If you look at the ER Diagram like a spoken language, the entities are nouns - Person, place, thing, event. When drawn on the ER diagram, entities are shown as rectangles with the name of the entity inside.
            \bigbreak \noindent 
            \fig{.5}{./figures/7.png}
        \item \textbf{Relationships}:  Relationships connect one or more entities together to show an association. A relationship \textit{cannot} exist without at least one associated entity.  Graphically represented as a diamond with the name of the relationship inside, or just beside it
            \bigbreak \noindent 
            \fig{.7}{./figures/8.png}
        \item \textbf{Attributes}: Characteristics of entities \textbf{OR} of relationships, Represent some small piece of associated data, Represented by either a rounded rectangle or an oval.
            \bigbreak \noindent 
            \fig{.5}{./figures/9.png}
        \item \textbf{Attributes on Entities}: When an attribute is attached to an entity, it is expected to have a value for every instance of that entity, unless it is
            allowed to be null. For instance, in the diagram above, Name was an attribute of Person. Every person
            that we store data about will have a value for Name.
        \item \textbf{Attributes on Relationships}: When an attribute is attached to a relationship, it is only expected to have a value when the entities involved in the
            relationship come together in the appropriate way.
            In the diagram from before, the Amount attribute is attached to the donates relationship, which connects the
            Person and Charity entities. Amount will have one value for each time a Person donates to a Charity, denoting how
            much that person donated to the charity. It will not necessarily have a value for a given person, or a given charity.
            This can be referred to as the \textbf{intersection data}.
        \item \textbf{Types of attributes}:
            \fig{.5}{./figures/10.png}
        \item \textbf{Degree of a Relationship}: The degree of a relationship is defined as how many entities it associates. If one entity is associated more than once
            (such as with a recursive relationship), then the degree counts each time it is referenced.
            \bigbreak \noindent 
            \fig{.5}{./figures/11.png}
            \bigbreak \noindent 
            \textbf{Note:} There is no limit to how many entities there can be in a relationship. After binary, and ternary, we start to call the relationships $n$-ary, where $n$ is the degree
        \item \textbf{Connectivity of a Relationship}:
            \begin{itemize}
                \item A constraint of the mapping of associated entities
                \item Written as (minimum, maximum).
                \item Minimum is usually zero or one.
                \item Maximum is a number (commonly one) or can be a letter denoting many.
                \item The actual number is called the cardinality.
            \end{itemize}
            \bigbreak \noindent 
            \fig{.5}{./figures/12.png}
            \bigbreak \noindent 
            Together (from the image) both sides make up the connectivity, to refer to a single side, we use the term "cardinality", ie the cardinality of a person is (1,1). If we hold Address constant (We know a specific address and are therefore refering to that), how many persons may live at that address, in this case (1,1)
        \item \textbf{Attributes on Relationships (revisited)}: Must be on a many-to-many relationship. (1-many and 1-to-1 relationships should have the attribute on one of
the entities involved.  Someone needs to know all of the associated entities to access the attribute.
        \item \textbf{Reading Cardinalities}: For binary relationships:
            \begin{itemize}
                \item For each Thing that smurfs, there are a minimum of $c$, and a maximum of $d$ Objects.
                \item For each Object that smurfs/is smurfed, there is a minimum of $a$ and a maximum of $b$ Things
            \end{itemize}
            \bigbreak \noindent 
            \fig{.5}{./figures/13.png}
        \item \textbf{Weak Entities}: Sometimes you may run into an entity that depends upon another entity for its existence. The weak entity is a tool you can use to represent this.:w
            \bigbreak \noindent 
            Weak entities are written like normal entities, except that they have a double rectangle outline. The relationship
that connects the weak entity to the strong entity it depends upon will be written with a double diamond. This
does not mean that the relationship is weak. It is just to indicate upon which entity the weak entity depends.
\bigbreak \noindent 
\fig{.5}{./figures/14.png}
        \item \textbf{Recursive Relationships}: It is possible for an entity to have a relationship with itself. This is called a recursive relationship. It makes more sense if you think of entities as collections of objects of their appropriate type
        \item \textbf{Recursive Relationships - Many-To-Many}: A many-to-many recursive relationship means that the objects are arranged in a network structure, Notice that the minimum is 0 on both sides. This is important.
            \bigbreak \noindent 
            \fig{.5}{./figures/15.png}
        \item \textbf{Recursive Relationships - One-To-Many}: A one-to-many recursive relationship means that the objects are arranged in a tree structure, Notice that the minimum is still 0 on both sides. This is important.
            \bigbreak \noindent 
            \fig{.4}{./figures/16.png}
        \item \textbf{Entity or Attribute?}: 
            Sometimes it isn’t clear whether something should be an entity or an attribute of some other entity. Usually the
decision will come down to how complicated it is to store the data, and how important it is. If it ends up being used
in multiple places, it might be a clue that you should use an entity
        \item \textbf{Inheritance}: Two types of inheritance available
            \begin{itemize}
                \item ”is a” inheritance. This shows that the subtype IS a member of the supertype.
                \item ”is part of ” inheritance. This shows that the supertype contains, or is made up of members of the subtypes.
            \end{itemize}
            \bigbreak \noindent 
            All attributes of the supertype entity are inherited by the subtype entities. The identifier of the subtypes will be the same as the supertype
            \bigbreak \noindent 
        \item \textbf{IS A Inheritance}:  This type of inheritance happens when you have a supertype and one or more subtypes that are members
            of the supertype. Denoted by an upside-down triangle, with the supertype on top, and the subtypes coming out the bottom.
            \bigbreak \noindent 
            \fig{.5}{./figures/17.png}
        \item \textbf{Defining IS-A inheritance}: There are two things you need to choose when using IS-A inheritance:
            \begin{itemize}
                \item \textbf{Generalization (no) vs. specialization (yes)}: can the supertype occur without being a member of the specified subtypes?
                \item \textbf{Overlapped (yes) vs. disjoint subtypes (no)}: is it possible for a single occurrence of the supertype to be a member of more than one subtype?
            \end{itemize}
            \bigbreak \noindent 
            They are mutually exclusive so you need to pick one of each, ie. GO, GD, SO, SD
        \item \textbf{IS-A inheritance - Generalization}:  Supertype is the union of all of the subtypes, This means that an instance of the supertype CANNOT EXIST without belonging to at least one subtype.
        \item \textbf{IS-A inheritance - Specialization}: The subtype entities specialize the supertype, This means that an instance of the supertype CAN exist without being related to any of the subtypes
        \item \textbf{IS-A inheritance - Overlapping Subtypes}: It is possible for an instance of the supertype to be related to more than one of the subtypes
        \item \textbf{IS-A inheritance - Disjoint Subtypes}: the subtype entities are mutually exclusive, it is not possible for an instance of the supertype to be related to more than one subtype.
        \item \textbf{IS-PART-OF Inheritance}: ”Is part of ” inheritance indicates that the
supertype is constructed from instances of the
subtypes. It is shown on an ER diagram as a circle,
with the supertype on the top, and subtypes on
the bottom.
\bigbreak \noindent 
\fig{.5}{./figures/18.png}
    \item \textbf{Warning about IS-PART-OF}:  The IS PART OF inheritance operator does have its uses, but it is not very commonly used, If you see something involving a certain number of things being present, there are several possibilities
        \begin{itemize}
            \item Sometimes a number is specified that isn’t actually important for what we are modeling. This won’t even be represented on an ER Diagram. This is the case when changing the number wouldn’t have any effect on the necessary structure of a database.
            \item If you need a certain number of items for a relationship to hold, you should explore using the connectivity of the relationship to express that.
            \item Finally, this IS PART OF inheritance might be useful. It is almost never necessary, however.
        \end{itemize}
    \item \textbf{Are you actually representing what you want to?}: Let’s say you’re running a business selling used cars. A simple ER diagram for the sales might look like the following:
        \bigbreak \noindent 
        \fig{.4}{./figures/19.png}
        \bigbreak \noindent 
        The resulting database would have one entry for each time a specific person buys a specific car. If the same person
buys the same car more than once (obviously selling it to someone else at some point), this model would no longer
be appropriate.
\bigbreak \noindent 
Adding a new entity to the relationship for the date/time of the purchase can fix this problem.
\bigbreak \noindent 
\fig{.5}{./figures/20.png}
\bigbreak \noindent 
Notice that the connectivities can change when you add new entities to the relationship.
\item \textbf{Weak Entities - Introduction}: So far, all of the entities we have used have been things that stand on their own. There are some situations where
we are modeling an object for which we certainly need to store data, but the items exist only in the context of some
other entity. Many of these examples can occur
\bigbreak \noindent 
One example of a time that an entity depends on another would be the idea of a city. Within a state, we can
generally be assured that cities will have unique names. If we were working only at that level, the City could be an
entity as we saw above. A good identifier for it would be the name of the city, so we would see the following:
\bigbreak \noindent 
\fig{.5}{./figures/21.png}
\bigbreak \noindent 
In some situations, this would be valid. The Name attribute can serve, in those circumstances, as an appropriate
identifier.
\bigbreak \noindent 
To indicate this sort of dependency, we can make the dependent entity a “weak” entity. This is drawn with a
double-edged rectangle, shown below.
\bigbreak \noindent 
\fig{.4}{./figures/22.png}
\bigbreak \noindent 
Notice that the City entity is now drawn as a weak entity, with a double border. The relationship between the weak
entity and the strong entity is also drawn with a double border. The relationship is not weak, per se, but it is used to
indicate which strong entity the weak entity depends upon.
    \item \textbf{Discriminant (partial key)}:  The discriminant, also known as the partial key, is an attribute (or a set of attributes) within the weak entity that can uniquely identify the weak entity, but only in combination with the primary key of the strong entity it is associated with. In other words, the discriminant helps to distinguish instances of the weak entity when they are tied to a particular instance of the strong entity.
    \item \textbf{Schema}: In databases, a schema is the structural definition of how data is organized in a database. It outlines the way data is stored

    \end{itemize}

    \pagebreak 
    \subsection{The Relational Model}
    \begin{itemize}
        \item \textbf{Basic Structure}: 
            \begin{itemize}
                \item \textbf{Relations}: In the relational data model, our database is made up of one or more \textbf{relations} (tables). Each relation should have a unique name.
                \item \textbf{Schema}: The schema of a relation is written as \textbf{Relation\_Name}($A_{1}, A_{2}, ...,A_{n} $), Where $A_{1}, A_{2}, ...,A_{n}$ are placeholders for the attribute names
                \item \textbf{Column headers (attributes)}: The attributes becomes the column headers of the relation.
                \item \textbf{Instance data, tuples}: When there is instance data, it will come in the form of \textbf{tuples} (rows), which have a value for each attribute, as shown below
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Note:} No field may contain than one value.

            \begin{table}[h!]
                \centering
                \begin{tabular}{|>{\centering\arraybackslash}m{2cm}|>{\centering\arraybackslash}m{2cm}|>{\centering\arraybackslash}m{2cm}|c|>{\centering\arraybackslash}m{2cm}|}
                    \hline
                    \multicolumn{5}{|c|}{\textbf{Relation\_Name}} \\ \hline
                    $A_1$ & $A_2$ & $A_3$ & $\dots$ & $A_n$ \\ \hline
                    $x_1$ & $x_2$ & $x_3$ & $\dots$ & $x_n$ \\ \hline
                    $y_1$ & $y_2$ & $y_3$ & $\dots$ & $y_n$ \\ \hline
                    $\dots$ & $\dots$ & $\dots$ &  & $\dots$ \\ \hline
                \end{tabular}
            \end{table}
        \item \textbf{The domain of an attribute}: Each attribute becomes a column heading
            \bigbreak \noindent 
            Each attribute (column) also has an associated \textbf{domain}. The domain of an attribute is the set of all valid values for it.  The domain may be looked at as a data type, but may have additional constraints.
        \item \textbf{The domain of a set of attributes}: The domain of a set of attributes is the set of all possible combinations of values for the attributes in the set.
        \item \textbf{Tuples (Rows)}: A tuple is a special type of (mathematical) set containing values for each attribute within the relation. Tuples are shown as rows in the table, with the value for each attribute under the appropriate column
        \item \textbf{Atomic tuples}:  The values are required to be atomic; there can be only one value per tuple per attribute
        \item \textbf{Relation vs relationship}: Though they have similar names, A relation (table) and a relationship (from an ER diagram) \textbf{ARE NOT} the same thing.
            \begin{itemize}
                \item \textbf{Degree of relation}: The degree of a relation is the number of attributes present.
                \item \textbf{Cardinality of a Relation}: The cardinality of a relation is the number of tuples present.
            \end{itemize}
        \item \textbf{Keys}: Speaking generally, the purpose of a key is to uniquely identify a tuple in some relation.
            \begin{itemize}
                \item \textbf{Super keys}: A super key within a relation is an attribute or set of attributes whose values can uniquely identify any tuple within that relation
                \item \textbf{The trivial key}: Every relation has at least one - the set of all attributes in the relation 
                \item \textbf{Candidate Keys}: A candidate key is a minimal super key – the minimum set of attributes necessary to uniquely identify a tuple within the relation
                \item \textbf{Primary Key}: The primary key for a relation is chosen by the database designer from among the relation’s candidate keys. It becomes the “official” key that is used to reference tuples within the relation. There can be only one
                \item \textbf{Prime, non-prime attributes}: Once a primary key is chosen, each of the attributes in the relation will be either \textbf{prime} or \textbf{non-prime} with respect to the relation. A prime attribute is one of the attributes that can be found in any of the candidate keys. A non-prime attribute is one of the attributes not found in any of the candidate keys
                    \bigbreak \noindent 
                    Once a primary key is chosen for it, the schema of a relation is written with the primary key’s attributes underlined
                \item \textbf{Foreign Keys}: A foreign key is a tool used to link relations within a database. Since every relation has a primary key that uniquely identifies each tuple, the values of those key attributes can be used from another relation to reference individual tuples.
                    \bigbreak \noindent 
                    The relation whose primary key is being used is the \textbf{home relation}
            \end{itemize}
        \item \textbf{Order Independence}: In relations, the order things appear doesn’t matter. There are ways to force them to sort later when we’re working with SQL, but the relation itself has no order for either rows or attributes...
        \item \textbf{Order Independence - Attributes}: It doesn’t matter what order the attributes appear in, if two relational schemas have the same name, the same attributes, and the same primary key, then they are equivalent.
        \item \textbf{Order Independence - Tuples}: Tuples are stored unordered. If you need to have them appear in some order later, you will be able to sort based on the values inside of them using SQL.
        \item \textbf{Constraints}: Constraints are limits imposed on the domains of various attributes. These can come from the system your database is modeling
        \item \textbf{Entity Integrity Constraint}: The entity integrity constraint applies to all relations. It states that no tuple may exist within a relation that has null value for any of attributes that make up the primary key. This is a consequence of the primary key being a candidate key, which is minimal and cannot do its job with any less data.
        \item \textbf{Referential Integrity Constraint}: It constrains the values of foreign keys in relations to values that actually exist as primary keys for tuples within the home relation. If the foreign key is otherwise allowed to be NULL, then that is also an acceptable value.
    \end{itemize}

    \pagebreak 
    \subsection{Relational Model Normalization}
    \begin{itemize}
        \item \textbf{Designing Relational Databases}: There are a large number of possible ways to represent each problem with using relations. Some choices will perform better than others for various reasons. The option chosen should be the best one, but how do we know which one that is?
            \bigbreak \noindent 
            We should study:
            \begin{itemize}
                \item Problems that can come up
                \item How to avoid them
                \item Desirable properties
                \item How to guarantee them
            \end{itemize}
        \item \textbf{Basic Example}: If our database is a single relation with schema \textbf{SP}(\underline{SuppName}, SuppAddr, \underline{Item}, Price) with the instance data:
            \bigbreak \noindent 
            \begin{center}
                \begin{tabular}{|l|l|l|l|}
                    \hline
                    \textbf{SuppName} & \textbf{SuppAddr} & \textbf{Item} & \textbf{Price} \\ \hline
                    John    & 10 Main   & Apple   & \$2.00  \\ \hline
                    John    & 10 Main   & Orange  & \$2.50  \\ \hline
                    Jane    & 20 State  & Grape   & \$1.25  \\ \hline
                    Jane    & 20 State  & Apple   & \$2.25  \\ \hline
                    Frank   & 30 Elm    & Mango   & \$6.00  \\ \hline
                \end{tabular}
            \end{center}
            \bigbreak \noindent 
            There are some common things that we might want to do that would cause issues
            \begin{itemize}
                \item \textbf{Insertion Anomaly}: Let’s say we want to add a new vendor, “Sally”, and store her address, “40 Pine”, but she is not selling anything yet. Can this be inserted into the relation SP?
                    \bigbreak \noindent 
                    \textbf{NO}. The primary key is (SuppName, Item), but we only have SuppName. The entity integrity constraint is violated if we try to insert the data as a tuple in this relation. It cannot fit. We call this an insertion anomaly.
                \item \textbf{Deletion Anomaly}: This time, let’s say that Frank no longer sells Mango. We want to take that out of the database so nobody can order a mango that is not available. Can this tuple remain in the relation with the Mango information removed?
                    \bigbreak \noindent 
                    \textbf{NO}. The primary key is (SuppName, Item), and the Item is going away. The entity integrity constraint is violated if we remove the data from the tuple in this relation. We can either keep the whole tuple, advertising fake mango, or delete the whole tuple and lose the information on Frank, which doesn’t exist in any other tuples. We call this a deletion anomaly.
                \item \textbf{Update Anomaly}: Next, let’s say that John is moving to a different address. We would have to change it once for every item John is selling. This isn’t a big deal with only two items, but as John’s list of supplied items grows, so does the amount of database work that needs to be done every time he moves. If any of the SuppAddr values for John don’t agree, then it may not be clear which is the right address for John. This is an update anomaly.
                \item \textbf{Redundancy}: Redundancy is when values are repeated.
                    \bigbreak \noindent 
                    It can be
                    \begin{itemize}
                        \item \textbf{Good:} If you have an off-site backup of your entire database, the redundancy is useful, and can be used to restore in case of a failure.
                        \item \textbf{Bad:} Redundancy on the same physical device is unnecessary. It wastes space and comes with the potential for update anomalies.
                    \end{itemize}
                \item \textbf{Note:} The good redundancy is something the DBA/IT department should handle. When we talk about redundancy in the design of our database, we will be talking about the bad kind.
            \end{itemize}
        \item \textbf{Anomolies summarized}:
            \bigbreak \noindent 
            \textbf{Insertion anomalies}:
            \begin{itemize}
                \item When a piece of data cannot be inserted because it violates some constraint of the relation.
                \item Usually this is the entity integrity constraint being violated, but not always. See the Sally example
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Deletion anomalies}: 
            \begin{itemize}
                \item When deleting some piece of data, a deletion anomaly is when more data is lost than intended
                \item Usually this is caused when the data removed is part of the primary key, which would cause a violation of the entity integrity constraint. See the Frank example
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Update anomalies}:
            \begin{itemize}
                \item When updating a single value requires changes to multiple tuples, this is an update anomaly. See the John example.
                \item This is caused by unnecessary redundancies in the data.
                \item These cause inefficiency, and potential inconsistencies.
            \end{itemize}
            \bigbreak \noindent 
        \item \textbf{Decomposition}: There is no rule that says that a relational database must be made up of a single relation. The way we will solve these anomalies is to add new relations to our database and change the old ones. This is called decomposition.
            \bigbreak \noindent 
            Using the example from above, we can remove the anomalies by decomposing the database into two relations.
            \bigbreak \noindent 
            \textbf{SP}(\underline{SuppName}, \underline{Item}, Price)
            \bigbreak \noindent 
            \begin{center}
                \begin{tabular}{|l|l|l|}
                    \hline
                    \textbf{SuppName} & \textbf{Item} & \textbf{Price} \\ \hline
                    John    & Apple   & \$2.00  \\ \hline
                    John    & Orange  & \$2.50  \\ \hline
                    Jane    & Grape   & \$1.25  \\ \hline
                    Jane    & Apple   & \$2.25  \\ \hline
                \end{tabular}
            \end{center}
            \bigbreak \noindent 
            \textbf{S}(SuppName, SuppAddr)
            \bigbreak \noindent 
            \begin{center}
                \begin{tabular}{|l|l|}
                    \hline
                    \textbf{SuppName} & \textbf{SuppAddr} \\ \hline
                    John    & 10 Main   \\ \hline
                    Jane    & 20 State  \\ \hline
                    Frank   & 30 Elm    \\ \hline
                    Sally   & 40 Pine   \\ \hline
                \end{tabular}

            \end{center}
        \item \textbf{When to decompose}: One way of designing a database could be to list all of the possible anomalies and then decompose to fix each of them. The problem with this is that any anomalies you don’t see coming will not be fixed.
            \bigbreak \noindent 
            We will look at a systematic method of identifying the potential for anomalies. This method is called normalization
        \item \textbf{Normalization}: Normalization involves making sure that each of your relations follows certain rules. Depending on which rules are followed, each of the relations in your database will be in one or more normal forms. These rules are based on functional dependencies
        \item \textbf{Functional Dependencies}: A functional dependency is a statement about which attributes can be inferred from other attributes. If we take $X$ and $Y$ as sets of attributes, we can write:
            \begin{align*}
                X \to Y
            .\end{align*}
            \bigbreak \noindent 
            Which means, if, whenever unique values for \textbf{all} of the attributes in $X$ are known, unique values for \textbf{each} of the attributes of $Y$ are guaranteed to be possible to look up or to infer using those values.
            \bigbreak \noindent 
            This is read either as:
            \begin{itemize}
                \item $X$ functionally determines $Y$
                \item $Y$ is functionally dependent upon $X$
            \end{itemize}
        \item \textbf{Functional Dependencies: Real-life Examples}: 
            \begin{itemize}
                \item \textbf{ZID $\to$ StudentFirstName, StudentLastName, Birthday}: If I identify a student using their ZID, that student has one first name, last name, and birthday
                \item \textbf{StudentFirstName \not \to ZID}: The first name is not enough to determine a single ZID, as there are multiple students with the same first name
                \item \textbf{ZID, CourseID, Semester \to Grade}: If I know which student, which course, and which semester, I can find a single grade
            \end{itemize}
        \item \textbf{Functional Dependencies: Keep In Mind}: FDs are constraints present within the operational data your database models. They don’t necessarily describe how things work in the real world, but they do have to accurately describe any data you will store in your database
            \bigbreak \noindent 
            FDs \textbf{must} hold for all possible data values. Attempts to add data that does not obey the FDs will result in anomalies.
            \bigbreak \noindent 
            FDs can be enforced during insertion if the database is set up properly
        \item \textbf{Armstrong’s Axioms}: Armstrong’s Axioms are a set of rules for operations that are permissible when manipulating functional dependencies
            \begin{itemize}
                \item \textbf{Reflexivity}: If $Y \subseteq X$, then $X \to Y $
                \item \textbf{Augmentation}: If $X \to Y$, the $XZ \to YZ$ for any $Z$
                \item \textbf{Transitivity}: If $X \to Y$ and $Y \to Z$, then $X \to Z $
                \item \textbf{Decomposition}: If $X \to YZ$, then $X \to Y$ and $X \to Z $
                \item \textbf{Composition}: If $X \to Y$ and $A \to B$, then $XA \to YB $
                \item \textbf{Union (Notation)}: If $X\to Y$ and $Y \to Z$, then $X \to YZ $
                \item \textbf{Pseudo-transitivity}: If $X \to Y$ and $YZ \to W$, then $XZ \to W $
                \item \textbf{Self-determination}: $I \to I $ for any $I$
            \end{itemize}
        \item \textbf{Functional Dependencies: Keys Revisited}: Now that we know about functional dependencies (FDs), we can assert:
            \bigbreak \noindent 
            \begin{center}
                The attributes of a superkey must functionally determine all of the attributes of the relation.
            \end{center}
            \bigbreak \noindent 
            Candidate keys and primary keys are superkeys, so this is true of them as well, and they also satisfy additional requirements.
            \bigbreak \noindent 
            \textbf{Example:} As an example, say we have the relation \textbf{R}(\underline{a},b,c,d,e,f). We can say
            \begin{align*}
                a &\to a,b,c,d,e,f \\
                \implies a&\to b,c,d,e,f
            .\end{align*}
        \item \textbf{First Normal Form (1NF)}: You should recall from the introduction to relations that all of the values in a tuple with a relation must be atomic. This means that there is a maximum of one value per attribute per tuple
            \bigbreak \noindent 
            The requirement for a relation to be in First Normal Form (1NF) is this same requirement that all of the values must be atomic
            \bigbreak \noindent 
            What this usually looks like is a table with mutltiple values in a single cell. A non-1NF relation would not even technically count as a relation.
            \bigbreak \noindent 
            Given the table:
            \bigbreak \noindent 
            \begin{center}
                \begin{tabular}{|c|c|c|}
                    \hline
                    X  & Y  & Z  \\ \hline
                    x1 & y1 & z1 \\ 
                       &    & z2 \\ 
                       &    & z3 \\ \hline
                    x2 & y2 & z4 \\ \hline
                    x3 & y2 & z5 \\ \hline
                \end{tabular}
            \end{center}
            \bigbreak \noindent 
            It looks like $X$ would have been the primary key, but it’s not doing its job of uniquely determining $Z$, which is showing as a repeating group so $X$ can’t be a key
            \bigbreak \noindent 
            What usually causes this is not having the correct primary key
            \bigbreak \noindent 
            The table above has the following function dependencies:
            \begin{align*}
                X &\to Y \\
               X,Z &\to Z
            .\end{align*}
            \bigbreak \noindent 
            To move this pseudo-relation into an actual relation that doesn’t violate 1NF, we need to choose a real primary key that meets the requirements. We do that using the FDs. In this case, ($X$ , $Z$) works.
            \bigbreak \noindent 
            Changing the primary key yields: - $R$($X$, $Y$ , $Z$))
            \bigbreak \noindent 
            \begin{center}
                \begin{tabular}{c|c|c}
                    X  & Y  & Z  \\ \hline
                    x1 & y1 & z1 \\ \hline
                    x1 & y1 & z2 \\ \hline
                    x1 & y1 & z3 \\ \hline
                    x2 & y2 & z4 \\ \hline
                    x3 &y2 & z5 
                \end{tabular}
            \end{center}
        \item \textbf{Pseudo-relation}: The notation for a “pseudo-relation” like the one above would be to use inner parenthesis on the repeating group, ie. \textbf{R}($X$, $Y$ , ($Z$))
        \item \textbf{Second Normal Form (2NF)}: Second Normal Form (2NF) has to do with the concept of full dependence.
            \bigbreak \noindent 
            Given two sets of attributes, $X$ and $Y$ , we can say that $Y$  is fully dependent on $X$, if (and only if)
            \begin{align*}
                X \to Y
            .\end{align*}
            And no subset of $X$ determines $Y$
            \bigbreak \noindent 
            A relation is in 2NF if:
            \begin{itemize}
                \item It already meets the requirements of 1NF, and
                \item All non-prime attributes of the relation are fully dependent upon the entire primary key
            \end{itemize}
            \bigbreak \noindent 
            What breaks 2NF is when attributes are dependent upon only part of the primary key. To fix 2NF violations once we’re in 1NF, decomposition is the solution.
            \bigbreak \noindent 
            \textbf{Example:} Going back to our earlier example: \textbf{EmpProj}(\underline{EmpID}, \underline{Project}, Supv, Dept, Case)
            \bigbreak \noindent 
            \begin{center}
            \begin{tabular}{|c|c|c|c|c|}
                \hline
                EmpID & Project & Supv & Dept & Case \\ \hline
                e1    & p1      & s1   & d1   & c1   \\ \hline
                e2    & p2      & s2   & d2   & c2   \\ \hline
                e1    & p3      & s1   & d1   & c3   \\ \hline
                e3    & p3      & s1   & d1   & c3   \\ \hline
            \end{tabular}
        \end{center}
        \bigbreak \noindent 
            \textbf{Functional Dependencies}:
            \begin{center}
                EmpID, Project $\to$ Supv, Dept, Case \\
                EmpID $\to$ Supv, Dept \\
                Supv $\to$ Dept
            \end{center}
            \bigbreak \noindent 
            A quick glance confirms all of the values are atomic, so 1NF is confirmed.
            \bigbreak \noindent 
            There is a 2NF violation caused by (EmpID $\to$ Supv, Dept) because the primary key is (EmpID, Project), but only EmpID is on the LHS.
            \bigbreak \noindent 
            Observing the instance data, you should easily see that the attributes of the RHS cause update anomalies in this
            table. We also can’t insert a new employee with no project (insertion anomaly), and removing e2 from p2 would
            remove e2 from the database entirely (deletion anomaly). These are symptoms of the 2NF violation.
            \bigbreak \noindent 
            \textbf{Decomposition Pattern}: There is a pattern to follow for the decomposition. Start with the original relation, and the FD that causes the violation.
            \begin{align*}
                &\text{\textbf{EmpProj}(\underline{EmpID}, \underline{Project}, Supv, Dept, Case)} \\
                &\text{\textbf{EmpID} $\to$ Supv, Dept}
            .\end{align*}
            \bigbreak \noindent 
            The attributes on the RHS of the FD are removed from the original relation and placed into a newly created relation that has the FD’s LHS as its primary key. A foreign key links the attribute from the LHS in the original table (the LHS is not removed) to the corresponding tuple in the new table, where it is the primary key.
            \bigbreak \noindent 
            \begin{align*}
                &\text{\textbf{EmpProj}(EmpID, Project, Case)} \\
                &\text{\textbf{Employee}(EmpID, Supv, Dept)}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{Instance of 2NF Version}:
            \bigbreak \noindent 
            \textbf{EmpProj}(EmpID, Project, Case)                           
            \begin{center}
                \begin{tabular}{|c|c|c|}
                    \hline
                    EmpID & Project & Case \\ \hline
                    e1    & p1      & c1   \\ \hline
                    e2    & p2      & c2   \\ \hline
                    e1    & p3      & c3   \\ \hline
                    e3    & p3      & c3   \\ \hline
                \end{tabular}
            \end{center}
            \bigbreak \noindent 
            \textbf{Employee} (EmpID, Supv, Dept
            \bigbreak \noindent 
            \begin{center}
                \begin{tabular}{|c|c|c|}
                    \hline
                    EmpID & Supv & Dept \\ \hline
                    e1    & s1   & d1   \\ \hline
                    e2    & s2   & d2   \\ \hline
                    e3    & s1   & d1   \\ \hline
                \end{tabular}
            \end{center}
            \bigbreak \noindent 
        \item \textbf{Third Normal Form (3NF)}: To be in Third Normal Form (3NF), a relation must
            \begin{enumerate}
                \item already qualify to be in 2NF
                \item none of the non-prime attributes may be transitively dependent upon the primary key
            \end{enumerate}
            \bigbreak \noindent 
            By definition, all non-prime attribute are functionally dependent upon the primary key. What makes a transitive dependency is that there is also some non-prime attribute (which also depends on the key) that also functionally determines the attribute.
            \bigbreak \noindent 
            To quickly identify the transitive dependencies from the list of FDs, look on the LHS for attributes that are non-prime in the context of the current relation.
            \bigbreak \noindent 
            \textbf{Example:}
            \begin{align*}
                &\text{\textbf{EmpProj}(EmpID, Project, Case)} \\
                &\text{\textbf{Employee} (EmpID, Supv, Dept} \\
                &\text{EmpID, Project $\to$ Supv, Dept, Case} \\
                &\text{EmpID $\to$ Supv, Dept} \\
                &\text{Supv $\to$ Dept}
            .\end{align*}
            \bigbreak \noindent 
            In this case, the FD that causes our relations to violate 3NF is (Supv → Dept), and the violation happens in the
            Employee relation. If you refer back to the instance data of that in the 2NF solution, you can see that the
            violation can cause anomalies, so we want to fix it.
            \bigbreak \noindent 
            Just like 2NF, we fix 3NF by decomposing using the FD that causes the violation to occur. \textbf{AT NO POINT DO WE CHANGE THE FDs}
            \bigbreak \noindent 
            \textbf{Decomposition Pattern}: We follow the same pattern for decomposition in 3NF as we did in 2NF. Start with the relation that has the violation, and the FD that causes the violation to occur.
            \begin{align*}
                &\text{\textbf{Employee} (EmpID, Supv, Dept)} \\
                &\text{Supv $\to$ Dept}
            .\end{align*}
            \bigbreak \noindent 
            The attributes on the RHS of the FD are removed from the violating relation and placed into a newly created
            relation that has the FD’s LHS as its primary key. A foreign key links the attribute from the LHS in the original table
            (the LHS is not removed) to the corresponding tuple in the new table, where it is the primary key.
            \begin{align*}
                &\text{\textbf{Employee}(EmpID, Supv)} \\
                &\text{\textbf{SupvDept}(Supv, Dept)}
            .\end{align*}
            \bigbreak \noindent 
            The RHS (Dept) that was a violation when it was in Employee because the LHS (Supv) was non-prime is no longer
            there to cause the problem. It is in the new relation where the LHS (Supv) is the primary key, and therefore we
            don’t have a transitive dependency. These two relations no longer have the 3NF violation.
        \item \textbf{Summary of the normalization forms}:
            \bigbreak \noindent 
            \textbf{First Normal Form (1NF):}
            \begin{itemize}
                \item No repeating groups. All values are atomic.
                \item A primary key must have been chosen, and this primary key must be a proper superkey – it needs to be able to functionally determine every attribute in the relation.
            \end{itemize}
            1NF violations are fixed by choosing an appropriate primary key
            \bigbreak \noindent 
            \textbf{Second Normal Form (2NF) - To be in Second Normal Form, a relation must conform to 1NF and:}
            \begin{itemize}
                \item All of the non-prime attributes must be fully dependent upon the entire primary key.
                \item No non-prime attribute may be functionally determined by any subset of the primary key.
                \item No partial key dependencies
            \end{itemize}
            \bigbreak \noindent 
            2NF violations are fixed by decomposition.
            \bigbreak \noindent 
            \textbf{Third Normal Form (3NF) - To be in Third Normal Form, a relation must conform to 2NF and:}
            \begin{itemize}
                \item There may be no transitive dependencies.
                \item No non-prime attribute may functionally determine another non-prime attribute.
            \end{itemize}
            \bigbreak \noindent 
            3NF violations are fixed by decomposition.




    \end{itemize}

    \pagebreak 
    \subsection{ERD to Relations (Conceptual to logical)}
    \begin{itemize}
        \item \textbf{The basic outline (steps)}
            \begin{enumerate}
                \item Handle all of the entities
                \item Handle all of the relationships
            \end{enumerate}
        \item \textbf{Entity handling}: We will start with entities, because they can stand on their own, unlike relationships or attributes. In general, each entity will get its own relation. The attributes of the entity will become attributes in the schema of the relation created. There are some special cases to take into account, which will be handled from most independent to least, so:
            \begin{enumerate}[label=\alph*.]
                \item Strong (non-weak) entities that are not subtypes
                \item Strong.(non-weak) entities that are subtypes
                \item Weak entities
            \end{enumerate}
        \item \textbf{Entities like date}: there is no reason to make a relation for a “Date” entity or similar. The single value for the date is enough to determine it, and any other data associated with it is generally happening through a relationship anyway. Think about what data would go into such a table and how little use there would be for storing it separately.
        \item \textbf{Handling strong, non subtype entities}: Make a new relation, whose name will be the same as the name of the entity ▶ The primary key of the relation will be all of the identifier attributes, taken together ▶ All attributes of the entity become attributes of the relation ▶ Every instance of the entity gets the relevant values put into a new tuple in the relation
            \bigbreak \noindent 
            \textbf{Example:} Suppose we had an entity $A$ with attributes $\underline{ID}$, and other:
            \bigbreak \noindent 
            Then, we would make a relation $A(\underline{ID}, other)$
        \item \textbf{Handling strong, subtype entities}: Suppose
            \bigbreak \noindent 
            \fig{.5}{./figures/42.png}
            \bigbreak \noindent 
            \textbf{Employee} is a supertype (not subtype) so it gets handled in the previous step
            \begin{center}
                \textbf{Employee}(\underline{EmpId}, name)
            \end{center}
            \bigbreak \noindent 
            \textbf{Hourly} and \textbf{Salaried} are each strong, but they are subtypes (each is a type of Employee), so they are handled here
            \bigbreak \noindent 
            This type of inheritance means that the subtypes are types of the supertype, so they are identified by \textbf{Employee’s} EmpID
            \bigbreak \noindent 
            There are two methods of handling these.
            \begin{enumerate}
                \item \textbf{Big table}: The first method involves putting the attributes of the subtypes into the relation made for the supertype. So, the original relation:
                    \begin{center}
                        \textbf{Employee}(\underline{EmpID}, Name)
                    \end{center}
                    Would become something like:
                    \begin{center}
                        \textbf{Employee}(\underline{EmpID}, Name,Wage, Salary)
                    \end{center}
                    but it would need to be modified to indicate which subtypes a given employee belongs to. Let’s examine that on the next page.
                    \bigbreak \noindent 
                    The big table method needs a way to know which of the subtypes the current instance of the supertype belongs to, which is handled differently depending on the IS-A’s configuration.
                    \bigbreak \noindent 
                    For \textbf{disjoint subtypes}, where an instance of the supertype can only be one of the subtypes at a timei, we can add an attribute, EmpType that has a value indicating which type this employee is.:
                    \begin{center}
                        \textbf{Employee}(\underline{EmpID}, Name, EmpType,Wage, Salary)
                    \end{center}
                    \bigbreak \noindent 
                    For generalization, EmpType would not allow NULL. For specialization, it would be allowed.
                    \bigbreak \noindent 
                    For \textbf{overlapping subtypes}, it is possible to be more than one at a time, so we need an individual true/false answer for each type:
                    \bigbreak \noindent 
                    \begin{center}
                        \textbf{Employee}(\underline{EmpID}, Name, IsHourly,Wage, IsSalaried, Salary)
                    \end{center}
                    \bigbreak \noindent 
                    In this case, nothing about the schema would indicate generalization vs. specialization
                \item \textbf{New relation}: Method 2 involves creating a new relation for the subtype entity
                    The name of new relation would be the same as the name of the entity.
                    \bigbreak \noindent 
                    The primary key of the new relation would be the same as the primary key for the supertype’s relation.
                    \bigbreak \noindent 
                    The primary key is also a foreign key to the existing table.
                    \bigbreak \noindent 
                    An instance of the supertype entity will only have a tuple in the subtype relation if it is a member of that subtype, so we will not need any extra attributes like we did in method 1.
                    \bigbreak \noindent 
                    The foreign key can be used to look up any of the attributes that are being inherited from the supertype
                    \bigbreak \noindent 
                    Thus, we would have 
                    \begin{align*}
                        &\text{\textbf{Employee}(\underline{EmpID}, Name} \\
                        &\text{\textbf{Hourly}(\underline{EmpID\dag},Wage)} \\
                        &\text{\textbf{Salaried}(\underline{EmpID\dag}, Salary)}
                    .\end{align*}
                    \bigbreak \noindent 
                    \textbf{Note:} The (\dag) (dagger symbol) will be used in these slides to indicate that the attribute is part of a foreign key (and, in this example, the whole thing).
            \end{enumerate}
        \item \textbf{Handling weak entities}:  Suppose
            \bigbreak \noindent 
            \fig{.5}{./figures/43.png}
            \bigbreak \noindent 
            The strong entity would already have a relation. 
            \begin{center}
                \textbf{Strong}(\underline{id}, x)
            \end{center}
            \bigbreak \noindent 
            The weak entity gets its own relation. The primary key will be the concatenation of the weak entity’s discriminator with the strong entity’s identifier. The other attributes of the entity are brought in as non-prime attributes.
            \begin{center}
                \textbf{Weak}(\underline{id}\dag, \underline{disc}, y)
            \end{center}
            \bigbreak \noindent 
            The \underline{id} portion is a foreign key to the Strong relation
        \item \textbf{Entities: Functional Dependencies}: The only functional dependencies introduced by the entities of an ER diagram are the ones introduced when the identifiers become primary keys. Remember that a primary key has to functionally determine all of the other attributes in a relation
        \item \textbf{Handle relationships}: The relationships will be handled in order from lowest degree to highest degree, and within that, from simplest cardinality (one-to-one) to more complicated cardinalities (many-to-many, etc.).
            \bigbreak \noindent 
            The purpose of a relationship is to form connections between entities. We know that we are using relations to represent our entities, so we will need to use a tool that can link those relations to each other.
            \bigbreak \noindent 
            The tool best suited to linking tuples from relations together is the foreign key.
            \bigbreak \noindent 
            Every relationship we model in the relational model will have one or more foreign key involved. Where we put these foreign keys will depend on the cardinality, and the decisions are motivated by the normal forms we discussed.
            \begin{enumerate}
                \item \textbf{Binary one-to-one Relationships}: In a binary relationship, we will already have made a relation for each of the entities involved.
                    \bigbreak \noindent 
                    \fig{.5}{./figures/44.png}
                    \begin{center}
                        \textbf{A}(\underline{a},p) $\quad$ \textit{and} $\quad$ \textbf{B}(\underline{b}, q)
                    \end{center}
                    \bigbreak \noindent 
                    Since each instance of B will have one of A, and each instance of A will have one of B through C, we can represent this one-to-one relationship by putting a new foreign key into the entity for either side. Choose either:
                    \begin{center}
                        \textbf{A}(\underline{a},p,b\dag) $\quad$ \textit{or} $\quad$ \textbf{B}(\underline{b}, q, a\dag)
                    \end{center}
                    \bigbreak \noindent 
                    The relationship implies the functional dependencies:
                    \begin{align*}
                        a \to b \\
                        b \to a
                    .\end{align*}
                \item \textbf{Binary one-to-many Relationships}: In a binary relationship, we will already have made a relation for each of the entities involved.
                    \begin{center}
                        \textbf{A}(\underline{a},p) $\quad$ \textit{and} $\quad$ \textbf{B}(\underline{b}, q)
                    \end{center}
                    \bigbreak \noindent 
                    For this one-to-many relationship, there can be many instances of B for each of A, so we can’t have the foreign key in the A table (wouldn’t be atomic, so 1NF would be violated). We still do have the option of putting a foreign key in the B table pointing to the corresponding A, so our only option is: \begin{center}
                        \textbf{B}(\underline{b},q,a\dag)
                    \end{center}
                    \bigbreak \noindent 
                    The only FD is 
                    \begin{align*}
                        b \to a 
                    .\end{align*}
                    \bigbreak \noindent 
                \item \textbf{Binary many-to-many Relationships}: In a binary relationship, we will already have made a relation for each of the entities involved.
                    \begin{center}
                        \textbf{A}(\underline{a},p) $\quad$ \textit{and} $\quad$ \textbf{B}(\underline{b}, q)
                    \end{center}
                    \bigbreak \noindent 
                    There are no new functional dependencies introduced by the relationship, and putting a foreign key into either relation would not be atomic (1NF violation). The many-to-many relationship requires a new relation. Its foreign key will be the concatenation of the primary keys of each of the entity relations, which will be used as foreign keys to the corresponding tables. Any intersection data is put into this new relation as a non-prime attribute.
                    \bigbreak \noindent 
                    \begin{center}
                        \textbf{C}(\underline{a}\dag, \underline{b}\dag, x)
                    \end{center}
                \item \textbf{Relationships Greater than Binary: one-to-one-to-one}:
                    \bigbreak \noindent 
                    \fig{.7}{./figures/45.png}
                    \bigbreak \noindent 
                    So we have 
                    \begin{center}
                        \textbf{A}(\underline{a}, p) and \textbf{B}(\underline{b}, q) and \textbf{C}(\underline{c},r
                    \end{center}
                    \bigbreak \noindent 
                    Each of the “one legs” represents a functional dependency, and each of them gives us a potential relation to choose from for our relation.
                    \bigbreak \noindent 
                    \begin{table}[h!]
                        \centering
                        \begin{tabular}{ll}
                            \toprule
                            \textbf{Functional Dependency} & \textbf{Potential Relation for \textbf{D}} \\ 
                            \midrule
                            $a, b \rightarrow c$ & $\mathbf{D} \left( a^\dagger, b^\dagger, c^\dagger, x \right)$ \\[8pt]
                            $b, c \rightarrow a$ & $\mathbf{D} \left( a^\dagger, b, c^\dagger, x \right)$ \\[8pt]
                            $a, c \rightarrow b$ & $\mathbf{D} \left( a^\dagger, b, c^\dagger, x \right)$ \\ 
                            \bottomrule
                        \end{tabular}
                    \end{table}
                    \textbf{Note:} If we have say only two ones, like a one to one to many relationship, we would just have less functional dependencies and therefore less options to choose from (see table above)
                \item \textbf{Greater than Binary without any “ones”}:
                    No functional dependencies are implied by this relationship. To stay in 3NF, the relation we must use is:
                    \begin{center}
                        \textbf{D}(\underline{a}\dag, \underline{b}\dag, \underline{c}\dag, x)
                    \end{center}
                \item \textbf{Date entities (and similar)}: For relationships that have a “Date” entity (or the equivalent), recall that we did not make a relation for that entity. The only change necessary for your relationship involving that entity is that the date value is used instead of a foreign key, and that attribute will not be a foreign key, because the home relation would not exist
                    \bigbreak \noindent 
                    As an example, if the C entity in the ternary relationship with no “ones” ER diagram were a Date entity, we would not create the C relation for it, and the relation to represent the relationship would be modified. Notice that the 𝑐 attribute is still part of the primary key, but no longer a foreign key.
                    \begin{align*}
                        &\text{From: \textbf{D}(\underline{a}\dag, \underline{b}\dag, \underline{c}\dag, x)} \\
                        &\text{To: \textbf{D}(\underline{a}\dag, \underline{b}\dag, \underline{c}, x)} \\
                   .\end{align*}
                \item \textbf{Recursive Relationships: one-to-many}: Recursive relationships will be handled as if they were normal relationships of the same degree and cardinality. The practical difference is that the entity that is linked multiple times will still only have one relation, so multiple foreign keys might go to the same table.
                    \bigbreak \noindent 
                    Suppose: 
                    \bigbreak \noindent 
                    \fig{.7}{./figures/46.png}
                    \bigbreak \noindent 
                    There should obviously only be one relation for the entity Department, because it is only a single entity.
                    \begin{center}
                        \textbf{Department}(\underline{DeptNo}, Name)
                    \end{center}
                    \bigbreak \noindent 
                    With a non-recursive one-to-many binary relationship, we would have put a foreign key to the relation for the one
                    side into the relation on the one side. In this version, we only have one table, so the decision is easy. We will need
                    to come up with another name for the foreign key, as we cannot have two attributes with the same name inside the
                    same relation. Thus, we grow Department into the following:
                    \begin{center}
                        \textbf{Department}(\underline{DeptNo}, Name, ReportsToDept\dag)
                    \end{center}
                    \bigbreak \noindent 
                    Where the home relation for the new attribute, ReportsToDept, is that same relation, Department. The tuple of
                    the department that the current department reports to will be have a DeptNo that equals the ReportsToDept in
                    the current tuple. Alternatively, ReportsToDept can be NULL if the department does not report to another.
                \item \textbf{Recursive Relationships, many-to-many}: Suppose 
                    \bigbreak \noindent 
                    \fig{.87}{./figures/47.png}
                    \bigbreak \noindent 
                    Like non-recursive many-to-many relationships, we will need to create a new relation. Unlike the non-recursive
                    version, we only have one home relation for our two foreign keys. As in the one-to-many version, we will need to
                    choose a new name for at least one copy of the foreign key, since they can’t share the same name. The relation for
                    our Person entity would be \textbf{Person}(\underline{ID}, Name)
                    \bigbreak \noindent 
                    The new relation created to represent the relationship would be in the following form:
                    \begin{center}
                        \textbf{Friends}(\underline{activeFriend}\dag, \underline{passiveFriend}\dag)
                    \end{center}
                    \bigbreak \noindent 
                    ActiveFriend and PassiveFriend are foreign keys to the tuple in Person with data for the person that is taking part in
                    the relationship. This can be done in a directed or undirected way, and you probably want to put a comment
                    somewhere about which way you intend to use it.
                    \bigbreak \noindent 
                    directed: (Person1, Person2) would not imply (Person2, Person1)
                    \bigbreak \noindent 
                    undirected: (Person1, Person2) does imply (Person2, Person1)
                    \bigbreak \noindent 
                    \fig{.6}{./figures/48.png}

            \end{enumerate}

    \end{itemize}

    \pagebreak 
    \subsection{MariaDB, SQL}
    \begin{itemize}
        \item \textbf{DDL}:
            \begin{itemize}
                \item CREATE TABLE
                \item ALTER TABLE
                \item DROP TABLE
            \end{itemize}
        \item \textbf{DML}:
            \begin{itemize}
                \item INSERT 
                \item UPDATE
                \item DELETE
            \end{itemize}
        \item \textbf{MariaDB navigation}:
            \begin{itemize}
                \item \textbf{USE <x>}: select the database <x>
                \item \textbf{SHOW TABLES} list all of the tables in the current database
                \item \textbf{DESCRIBE <x>} show the properties of each column of table <x>
                \item \textbf{SHOW CREATE TABLE} <x> show a CREATE TABLE statement that can be used to reconstruct table <x>
            \end{itemize}
        \item \textbf{Creating a new table with CREATE TABLE}: The basic format of a CREATE TABLE statement. []’s and <>’s are not to be typed. [] indicates that the contents are optional, and the <>’s indicate placeholders:
            \bigbreak \noindent 
            \begin{sqlcode}
                CREATE TABLE <table_name> (
                    <attribute> <type> [NOT NULL] [UNIQUE] [PRIMARY KEY], [ ... ]
                    [PRIMARY KEY(<pkattrs>),]
                    [FOREIGN KEY(<attr_here>) REFERENCES <home_table>(<attr_home>)]
                );
            \end{sqlcode}
            \begin{itemize}
                \item <table\_name> name of the table
                \item <attribute> name of the current attribute
                \item <type> data type of the current attribute
                \item <pkattrs> comma-separated list of the attributes makeing up the table’s primary key
                \item <attr\_here> comma-separated list of attributes in the current table forming a foreign key
                \item <home\_table> name of the home table
                \item <attr\_home> comma-separated list of attributes in the home table, matching the attributes in <attr\_here>
            \end{itemize}
        \item \textbf{Table / Column names}: When choosing a name for a table or a column, we can use the following characters:
            \begin{itemize}
                \item any of the normal upper or lower case letters (regexp: [A-Za-z]
                \item an underscore – _
                \item a dollar sign – \$
                \item digits, but only after the first character
            \end{itemize}
            \bigbreak \noindent 
            The following limits are in place:
            \begin{itemize}
                \item Table names must be unique within the database. They share the same namespace with views.
                \item Attribute/column names must be unique with each table.
                \item Unless quoted properly with backticks, reserved keywords cannot be used as identifier
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Note:} These identifiers may or may not be case sensitive, depending on the locale setting of the server.
            \bigbreak \noindent 
            Generally, the maximum length of an identifier is 64 characters.
        \item \textbf{Data types}
            \begin{itemize}
                \item \textbf{INT/INTEGER}: integer values
                \item \textbf{FLOAT}: single precision floating point numbers
                \item \textbf{DOUBLE/REAL}: double precision floating point numbers
                \item \textbf{DECIMAL(i,j)}: decimal numbers, i digits total, j after the decimal point .
                \item \textbf{CHAR(n)}: character string exactly n characters long
                \item \textbf{VARCHAR(n)}: variable-length character string up to n characters long
                \item \textbf{DATE}: date in 'YYYY-MM-DD' format
                \item \textbf{TIME}: time in 'HH:MM:SS' format
                \item \textbf{DATETIME}: date/time in 'YYYY-MM-DD HH:MM:SS' format, no timezone conversion
                \item \textbf{TIMESTAMP}: date/time in 'YYYY-MM-DD HH:MM:SS' format, timezone conversion
            \end{itemize}
        \item \textbf{Column Options}: Here are some common options that can be applied to a column/attribute. They are written right after the type when defining a new column in a CREATE TABLE statement
            \begin{itemize}
                \item \textbf{NULL}: allows NULL to be stored as the value for this attribute (default)
                \item \textbf{NOT NULL}: prevents NULL from being stored as the value for this attribute
                \item \textbf{UNIQUE}: ensures that no two tuples have the same value for this attribute
                \item \textbf{PRIMARY KEY}: declares this attribute to be the entire primary key
                \item \textbf{AUTO\_INCREMENT}: next-available value auto-assigned for this attribute when not provided
                \item \textbf{DEFAULT <x>}: sets the default value of the attribute to <x> when not supplied
            \end{itemize}
        \item \textbf{Setting the Primary Key}: There are two ways to set the primary key:
            \begin{enumerate}
                \item For single-attribute primary keys, you can use the PRIMARY KEY column option. The option may only be used once, and proclaims that the single attribute is the entirety of the primary key.
                \item If you have multiple attributes in the primary key, the only way is to add the separate constraint:
                    \begin{center}
                        \texttt{PRIMARY KEY(<x>,<y>,<z>,<etc>)}
                    \end{center}
                    \bigbreak \noindent 
                    This can also be used for single attribute primary keys.
                    \bigbreak \noindent 
                    \textbf{Note:} It should be obvious that only one primary key can be set.
            \end{enumerate}
        \item \textbf{Comments}: MariaDB supports the following comment syntax
            \begin{enumerate}
                \item \textbf{Pound (#)}:
                \item \textbf{Double hypen (\texttt{--})}: This is the standard style
                \item \textbf{C-style multiline comments (\textbackslash * ... *\textbackslash)}
            \end{enumerate}
        \item \textbf{Quotes}: There are two types of quotes that you may encounter in SQL.
            \begin{enumerate}
                \item \textbf{Quotes for values – single quotes 'value'}: not necessary for numeric values, but can be used without breaking them, always required for string values. If it is ambiguous whether something is a value or an identifier, use these quotes
                \item \textbf{Quotes for identifiers – backticks `identifier}: not necessary for identifiers that follow the rules from above, but can be used anyway, can allow identifier names to contain characters not otherwise allowed.  Can allow identifiers to use names that would normally be reserved keywords
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{Note:} Notice that identifier in the SQL context is a different thing than an identifier in an ER diagram. Here, identifier will mean the name of some table, column, variable, etc.
        \item \textbf{An example of CREATE TABLE}: Let’s go ahead and make the SQL CREATE TABLE statement to create a table for the relation:
            \begin{center}
                \textbf{Person}(\underline{SSN}, FNAME, LNAME, PHONE)
            \end{center}
            \bigbreak \noindent 
            \begin{sqlcode}
                CREATE TABLE Person(
                    SSN CHAR(9) PRIMARY KEY, # SSN BAD IDEA, PK on same line (1)
                    FNAME CHAR(20) NOT NULL, # First name
                    LNAME CHAR(20) NOT NULL, # Last name
                    PHONE CHAR(10) # Phone number
                ); 
            \end{sqlcode}
            \bigbreak \noindent 
            The relational schema we started with does not have information on data types or column options other than PRIMARY KEY, so we choose them while creating the table.
        \item \textbf{Setting up a foreign key}: A foreign key links the current table to another table, which we call the home relation.
            \begin{enumerate}
                \item The foreign key must contain all of the attributes of the primary key of the home relation.
                \item They may have different names in each of the tables, but there needs to be a match for each.
                \item Each of these attributes must have the exact same data type as its counterpart in the home table.
            \end{enumerate}
            \bigbreak \noindent 
            If a table is to contain a foreign key, we include a constraint in our CREATE TABLE statement like the following:
            \begin{sqlcode}
                FOREIGN KEY (<localnames>) REFERENCES <home_table>(<homenames>)
            \end{sqlcode}
            This can be done for multiple foreign keys, filling in the placeholders <localnames>, <home\_table>, and <homenames> appropriately for each.
    \item \textbf{Table with foreign key example}: Let’s make a table for a subtype of Person, Student:
        \begin{center}
            \textbf{Student}(\underline{SSN}\dag, CLSYEAR, GPA, TOTALHRS)
        \end{center}
        \bigbreak \noindent 
        \begin{sqlcode}
            CREATE TABLE Student (
                SSN CHAR(9) NOT NULL, -- SSN is BAD IDEA
                CLSYEAR CHAR(9), -- fresh/soph/junior/senior
                GPA DECIMAL(4.3), -- 4.000, we hope
                TOTALHRS INT,

                PRIMARY KEY (SSN), -- set up the primary key separately (2)
                FOREIGN KEY (SSN) REFERENCES Person(SSN) -- a Student is a Person
            );
        \end{sqlcode}
        \bigbreak \noindent 
        \textbf{Note:} We need to use SHOW CREATE TABLE to show the get information of the foreign keys of a table.
    \item \textbf{Change existing table schema: ALTER TABLE}: An ALTER TABLE statement will allow you to have the DBMS make changes to the schema of a table that has already been created. It works with various subcommands. The three we will cover are:
        \begin{enumerate}
            \item ALTER TABLE ADD
            \item ALTER TABLE MODIFY
            \item ALTER TABLE DROP
        \end{enumerate}
    \item \textbf{ALTER TABLE ADD}: The ALTER TABLE ADD command can be used to add a new column or new columns to the schema of an existing table.
        \bigbreak \noindent 
        To add a single column/attribute
        \bigbreak \noindent 
        \begin{sqlcode}
            ALTER TABLE <table_name> ADD <attribute> <type>; 
        \end{sqlcode}
        \bigbreak \noindent 
        To add multiple columns/attributes:
        \bigbreak \noindent 
        \begin{sqlcode}
            ALTER TABLE <table_name> ADD (<attribute> <type>, ...);
        \end{sqlcode}
    \item \textbf{ALTER TABLE MODIFY}: The ALTER TABLE MODIFY command can be used to change properties of a column/attribute (including type, length, and other column options) in a table that already exists.
        \bigbreak \noindent 
        \begin{sqlcode}
            ALTER TABLE <table_name> MODIFY <col_name> <new_options>;
        \end{sqlcode}
    \item \textbf{ALTER TABLE DROP}: The ALTER TABLE DROP command can be used to remove a column/attribute from the schema of a table.
        \bigbreak \noindent 
        \begin{sqlcode}
            ALTER TABLE <table_name> DROP <col_name>;
        \end{sqlcode}
    \item \textbf{SHOW TABLES}: In MariaDB/MySQL, if you want to see a list of the tables present in the current database, you can use the command:
        \bigbreak \noindent 
        \begin{sqlcode}
            SHOW TABLES;
        \end{sqlcode}
    \item \textbf{DROP TABLE}: To remove a table from the database, we can use the DROP TABLE command.
        \bigbreak \noindent 
        \begin{sqlcode}
        DROP TABLE <table_name>;
        \end{sqlcode}
    \item \textbf{Termination of commands (;)}: Notice in all sql code examples we have a semi colon after the command / line, this is needed to execute the command.








    \end{itemize}





\end{document}

