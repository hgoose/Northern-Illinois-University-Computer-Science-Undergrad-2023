 \documentclass{report}
 
 \input{~/dev/latex/template/preamble.tex}
 \input{~/dev/latex/template/macros.tex}
 
 \title{\Huge{}}
 \author{\huge{Nathan Warner}}
 \date{\huge{}}
 \fancyhf{}
 \rhead{}
 \fancyhead[R]{\itshape Warner} % Left header: Section name
 \fancyhead[L]{\itshape\leftmark}  % Right header: Page number
 \cfoot{\thepage}
 \renewcommand{\headrulewidth}{0pt} % Optional: Removes the header line
 %\pagestyle{fancy}
 %\fancyhf{}
 %\lhead{Warner \thepage}
 %\rhead{}
 % \lhead{\leftmark}
 %\cfoot{\thepage}
 %\setborder
 % \usepackage[default]{sourcecodepro}
 % \usepackage[T1]{fontenc}
 
 % Change the title
 \hypersetup{
     pdftitle={}
 }

 \geometry{
  left=1in,
  right=1in,
  top=1in,
  bottom=1in
}
 
 \begin{document}
     % \maketitle
     %     \begin{titlepage}
     %    \begin{center}
     %        \vspace*{1cm}
     % 
     %        \textbf{}
     % 
     %        \vspace{0.5cm}
     %         
     %             
     %        \vspace{1.5cm}
     % 
     %        \textbf{Nathan Warner}
     % 
     %        \vfill
     %             
     %             
     %        \vspace{0.8cm}
     %      
     %        \includegraphics[width=0.4\textwidth]{~/niu/seal.png}
     %             
     %        Computer Science \\
     %        Northern Illinois University\\
     %        United States\\
     %        
     %             
     %    \end{center}
     % \end{titlepage}
     % \tableofcontents
    \pagebreak \bigbreak \noindent
    Nate Warner \ \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad \quad  MATH 434 \quad  \quad \quad \quad \quad \quad \quad \quad \quad \ \ \quad \quad Fall 2025
    \begin{center}
        \textbf{Problem set 2 - Due: Wednesday, October 15}
    \end{center}
    \bigbreak \noindent 
    \begin{mdframed}
        1.7.10. Let 
        \[
            A = 
            \begin{bmatrix}
                2 & 1 & -1 & 3 \\
                -2 & 0 & 0 & 0 \\
                4 & 1 & -2 & 6 \\
                -6 & -1 & 2 & -3
            \end{bmatrix},
            \qquad
            b =
            \begin{bmatrix}
                13 \\
                -2 \\
                24 \\
                -14
            \end{bmatrix}.
        \]
        \begin{enumerate}[label=(\alph*)]
            \item Calculate the appropriate (four) determinants to show that $A$ can be transformed 
                to (nonsingular) upper-triangular form by operations of type 1 only. 
                (By the way, this is strictly an academic exercise. 
                In practice one never calculates these determinants in advance.)

            \item Carry out the row operations of type 1 to transform the system $Ax = b$ 
                to an equivalent system $Ux = y$, where $U$ is upper triangular. 
                Save the multipliers for use in Exercise 1.7.18.

            \item Carry out the back substitution on the system $Ux = y$ 
                to obtain the solution of $Ax = b$. 
                Donâ€™t forget to check your work.
        \end{enumerate}
    \end{mdframed}
    \bigbreak \noindent 
    \begin{remark}
        Let $A \in \mathbb{R}^{n\times n}$. $A$ admits an $LU$ factorization $A = LU$ where $L$ is unit lower triangular and $U$ is upper triangular if and only if all leading principal submatrices are nonsingular. $\endpf $
    \end{remark}
    \bigbreak \noindent 
    a.) So, we check that
    \begin{align*}
        \det\left(\begin{bmatrix} 2 \end{bmatrix}\right),\; \det\left(\begin{bmatrix} 2 & 1 \\ -2 & 0 \end{bmatrix}\right),\; \det\left(\begin{bmatrix} 2 & 1 & -1 \\ -2 & 0 & 0 \\ 4 & 1 & -2 \end{bmatrix}\right),\; \det\left(            \begin{bmatrix} 2 & 1 & -1 & 3 \\ -2 & 0 & 0 & 0 \\ 4 & 1 & -2 & 6 \\ -6 & -1 & 2 & -3 \end{bmatrix} \right)
    \end{align*}
    are all nonzero. We see that
    \begin{align*}
        \det\left(\begin{bmatrix} 2 \end{bmatrix}\right) &= 2 \ne 0, \\
        \det\left(\begin{bmatrix} 2 & 1 \\ -2 & 0 \end{bmatrix}\right) &= 2(0) - (1)(-2) = 2 \ne 0, \\
        \det\left(\begin{bmatrix} 2 & 1 & -1 \\ -2 & 0 & 0 \\ 4 & 1 & -2 \end{bmatrix}\right) &= -1 \cdot -2(1(-2) - (-1)(1)) = -1 \cdot  2(-2+1) = -2 \ne 0, \\
        \det\left(\begin{bmatrix} 2 & 1 & -1 & 3 \\ -2 & 0 & 0 & 0 \\ 4 & 1 & -2 & 6 \\ -6 & -1 & 2 & -3 \end{bmatrix}\right) &= -1 \cdot -2\det\left(\begin{bmatrix} 1 & -1 & 3 \\ 1 & -2 & 6 \\ -1 & 2 & -3 \end{bmatrix}\right) \\
                                    &= 2\left( 1(-2(-3) - 6(2)) - (-1)(1(-3) - 6(-1)) + 3(1(2) - (-2)(-1)) \right) \\
                                    &= 2(-3) = -6 \ne 0
    .\end{align*}
    Thus, all leading principal submatrices are nonsingular and $A$ can be transformed to nonsingular upper-triangular form by operations of type 1 only.
    \bigbreak \noindent 
    b.) We use Gaussian Elimination on the augmented system $[A|b] \to [U|y]$. We have
    \begin{align*}
        \begin{bmatrix}
            \begin{array}{cccc|c}
                2 & 1 & -1 & 3 & 13\\
                -2 & 0 & 0 & 0 & -2\\
                4 & 1 & -2 & 6 & 24\\
                -6 & -1 & 2 & -3 &14
            \end{array}
        \end{bmatrix}
    .\end{align*}
    The opertions to get $a_{21} = a_{31} = a_{41} = 0$ are
    \begin{align*}
        &-(-1)r_{1} + r_{2} \to r_{2}^{\prime} \\
        &-2r_{1} + r_{3} \to r_{3}^{\prime} \\
        &-(-3)r_{1} + r_{4} \to r_{4}^{\prime}
    .\end{align*}
    Thus, $m_{21} = -1$, $m_{31} = 2$, $m_{41} = -3$ and the system becomes
    \begin{align*}
        \begin{bmatrix}
            \begin{array}{cccc|c}
                2 & 1 & -1 & 3 & 13\\
                0 & 0 & 0 & 0 & -2\\
                0 & 1 & -2 & 6 & 24\\
                0 & -1 & 2 & -3 &14
            \end{array}
        \end{bmatrix}
    .\end{align*}

    
    

    \bigbreak \noindent 
    \begin{mdframed}
        1.7.18. Solve the linear system $A x = \hat{b}$, where $A$ is as in Exercise 1.7.10 and 
        \[
            \hat{b} = 
            \begin{bmatrix}
                12 \\
                -8 \\
                21 \\
                -26
            \end{bmatrix}^{T}.
        \]
        Use the $L$ and $U$ that you calculated in Exercise 1.7.10.
    \end{mdframed}

    \bigbreak \noindent 
    \begin{mdframed}
        1.7.26. Use the inner-product formulation to calculate the $LU$ decomposition of the matrix $A$ in Exercise 1.7.10 
    \end{mdframed}

    \bigbreak \noindent 
    \begin{mdframed}
        1.7.34.  In this exercise you will show that performing an elementary row operation of type 1 is equivalent to left multiplication by a matrix of a special type. Suppose $\tilde{A}$ is obtained from $A$ by adding $m$ times the $j$th row to the $i$th row.

        \begin{enumerate}[(a)]
            \item Show that $\tilde{A} = M A$, where $M$ is the triangular matrix obtained 
                from the identity matrix by replacing the zero by an $m$ in the $(i,j)$ position. 
                For example, when $i > j$, $M$ has the form
                \[
                    M = \begin{bmatrix}
                        1 &        &        &        &   \\
                          & \ddots &        &        &   \\
                          &        & 1      &        &   \\
                          &        & m      & 1      &   \\
                          &        &        &        & \ddots \\
                          &        &        &        &        1
                    \end{bmatrix}.
                \]
                Notice that this is the matrix obtained by applying the type 1 row operation 
                directly to the identity matrix. We call $M$ an \textit{elementary matrix of type 1}.

            \item Show that $\det(M) = 1$ and $\det(\tilde{A}) = \det(A)$. 
                Thus we see (again) that $\tilde{A}$ is nonsingular if and only if $A$ is.

            \item Show that $M^{-1}$ differs from $M$ only in that it has $-m$ instead of $m$ 
                in the $(i,j)$ position. $M^{-1}$ is also an elementary matrix of type 1. 
                To which elementary operation does it correspond?
        \end{enumerate}
    \end{mdframed}

    \bigbreak \noindent 
    \begin{mdframed}
        1.7.36. Suppose $\tilde{A}$ is obtained from $A$ by multiplying the $i$th row by the nonzero constant $c$.
        \begin{enumerate}[(a)]
            \item Find the form of the matrix $M$ (an \textit{elementary matrix of type 3}) 
                such that $\tilde{A} = M A$.

            \item Find $M^{-1}$ and state its function as an elementary matrix.

            \item Find $\det(M)$ and determine the relationship between $\det(\tilde{A})$ 
                and $\det(A)$. Deduce that $\tilde{A}$ is nonsingular if and only if $A$ is.
        \end{enumerate}
    \end{mdframed}

    \bigbreak \noindent 
    \begin{mdframed}
        1.8.4. Let 
        \[
            A = 
            \begin{bmatrix}
                2 & 2 & -4 \\
                1 & 1 & 5 \\
                1 & 3 & 6
            \end{bmatrix},
            \qquad
            b =
            \begin{bmatrix}
                10 \\
                -2 \\
                -5
            \end{bmatrix}.
        \]
        Use Gaussian elimination with partial pivoting (by hand) to find matrices $L$ and $U$ such that $U$ is upper triangular, $L$ is unit lower triangular with $|l_{ij}| \leq 1$ for all $i > j$, and $LU = \tilde{A}$, where $\tilde{A}$ can be obtained from $A$ by making row interchanges. Use your $LU$ decomposition to solve the system $Ax = b$.
    \end{mdframed}

    \bigbreak \noindent 
    \begin{mdframed}
        1.8.9. Let $A$ be the matrix in Exercise 1.8.4. Determine matrices $P$, $L$, and $U$ with the properties stated in Theorem 1.8.8, such that $A = P^{T}LU$
    \end{mdframed}

    \bigbreak \noindent 
    \begin{mdframed}
        1.8.12. Write an algorithm that implements Gaussian elimination with partial pivoting. Store $L$ and $U$ over $A$, and save a record of the row interchanges. 
    \end{mdframed}

    \bigbreak \noindent 
    \begin{mdframed}
        2.1.10. Prove that the 1-norm is a norm. 
    \end{mdframed}


    \bigbreak \noindent 
    \begin{mdframed}
        2.1.13.  Prove that the $\infty$-norm is a norm.
    \end{mdframed}

    \bigbreak \noindent 
    \begin{mdframed}
        2.1.17. \begin{enumerate}[(a)]
            \item Let $A$ be a positive definite matrix, and let $R$ be its Cholesky factor, 
                so that $A = R^{T}R$. Verify that for all $x \in \mathbb{R}^n$, 
                \[
                    \|x\|_{A} = \|Rx\|_{2}.
                \]

            \item Using the fact that the $2$-norm is indeed a norm on $\mathbb{R}^n$, 
                prove that the $A$-norm is a norm on $\mathbb{R}^n$.
        \end{enumerate}
    \end{mdframed}

    \bigbreak \noindent 
    \begin{mdframed}
        2.2.6.
        \begin{enumerate}[label=(\alph*)]
            \item Show that $\kappa(A) = \kappa(A^{-1})$
            \item Show that for any nonzero scalar $c$, $\kappa(cA) = \kappa(A)$
        \end{enumerate}
    \end{mdframed}

    \bigbreak \noindent 
    \begin{mdframed}
        2.2.15. Let us take another look at the ill-conditioned matrices
        \[
            A = 
            \begin{bmatrix}
                1000 & 999 \\
                999  & 998
            \end{bmatrix},
            \qquad
            A^{-1} =
            \begin{bmatrix}
                -998 & 999 \\
                999  & -1000
            \end{bmatrix}
        \]
        from Example 2.2.8. Notice that
        \[
            A
            \begin{bmatrix}
                1 \\
                1
            \end{bmatrix}
            =
            \begin{bmatrix}
                1999 \\
                1997
            \end{bmatrix}.
            \tag{2.2.16}
        \]
        If we use the $\infty$-norm to measure lengths, the magnification factor 
        \[
            \frac{\|Ax\|_{\infty}}{\|x\|_{\infty}}
        \]
        is $1999$, which equals $\|A\|_{\infty}$. Thus 
        \(
        \begin{bmatrix}
            1 \\ 1
        \end{bmatrix}
        \) 
        is a vector that is magnified maximally by $A$. 
        \bigbreak \noindent 
        Since the amount by which a vector is magnified depends only on its direction and not on its length, 
        we say that 
        \(
        \begin{bmatrix}
            1 \\ 1
        \end{bmatrix}
        \) 
        is in a \textit{direction of maximum magnification} by $A$. 
        \bigbreak \noindent 
        Equivalently we can say that 
        \(
        \begin{bmatrix}
            1999 \\ 1997
        \end{bmatrix}
        \) 
        lies in a \textit{direction of minimum magnification}.
        \bigbreak \noindent 
        Looking now at $A^{-1}$, we note that
        \[
            A^{-1} 
            \begin{bmatrix}
                -1 \\
                1
            \end{bmatrix}
            =
            \begin{bmatrix}
                1997 \\
                -1999
            \end{bmatrix}.
        \]
        The magnification factor 
        \(
        \frac{\|A^{-1}x\|_{\infty}}{\|x\|_{\infty}}
        \)
        is $1999$, which equals $\|A^{-1}\|_{\infty}$, so 
        \(
        \begin{bmatrix}
            -1 \\ 1
        \end{bmatrix}
        \)
        is in a direction of maximum magnification by $A^{-1}$. Equivalently
        \[
            A 
            \begin{bmatrix}
                1997 \\
                -1999
            \end{bmatrix}
            =
            \begin{bmatrix}
                -1 \\
                1
            \end{bmatrix},
            \tag{2.2.17}
        \]
        and 
        \(
        \begin{bmatrix}
            1997 \\ -1999
        \end{bmatrix}
        \)
        is in a direction of minimum magnification by $A$.
        \bigbreak \noindent 
        We will use the vectors in (2.2.16) and (2.2.17) to construct a spectacular example.  Suppose we wish to solve the system
        \[
            \begin{bmatrix}
                1000 & 999 \\
                999  & 998
            \end{bmatrix}
            \begin{bmatrix}
                x_{1} \\
                x_{2}
            \end{bmatrix}
            =
            \begin{bmatrix}
                1999 \\
                1997
            \end{bmatrix}.
            \tag{2.2.18}
        \]
        That is, $Ax = b$, where 
        \(
        b =
        \begin{bmatrix}
            1999 \\
            1997
        \end{bmatrix}.
        \) 
        Then by (2.2.16) the unique solution is
        \[
            x =
            \begin{bmatrix}
                1 \\
                1
            \end{bmatrix}.
        \]
        Now suppose that we solve instead the slightly perturbed system
        \[
            \begin{bmatrix}
                1000 & 999 \\
                999  & 998
            \end{bmatrix}
            \begin{bmatrix}
                \hat{x}_{1} \\
                \hat{x}_{2}
            \end{bmatrix}
            =
            \begin{bmatrix}
                1998.99 \\
                1997.01
            \end{bmatrix}.
            \tag{2.2.19}
        \]
        This is $\hat{A}x = b + \delta b$, where 
        \(
        \delta b =
        \begin{bmatrix}
            -0.01 \\
            0.01
        \end{bmatrix}
        = 0.01
        \begin{bmatrix}
            -1 \\
            1
        \end{bmatrix},
        \)
        which is in a direction of maximum magnification by $A^{-1}$. By (2.2.17), $A\delta x = \delta b$, where 
        \(
        \delta x =
        \begin{bmatrix}
            19.97 \\
            -19.99
        \end{bmatrix}.
        \)
        Therefore 
        \(
        \hat{x} = x + \delta x =
        \begin{bmatrix}
            20.97 \\
            -18.99
        \end{bmatrix}.
        \)
        Thus the nearly identical problems (2.2.18) and (2.2.19) have very different solutions.
    \end{mdframed}

    \bigbreak \noindent 
    \begin{mdframed}
        Repeat the proof of Theorem 2.3.3.
    \end{mdframed}
    \bigbreak \noindent 
    \begin{remark}
        \textbf{Theorem 2.3.3}. 
        Let $A$ be nonsingular, let $b \neq 0$, and let $x$ and $\hat{x} = x + \delta x$ be 
        solutions of $Ax = b$ and $(A + \delta A)\hat{x} = b$, respectively. Then,
        \[
            \frac{\|\delta x\|}{\|\hat{x}\|} 
            \leq \kappa(A) \frac{\|\delta A\|}{\|A\|}.
            \tag{2.3.4}
        \]
        \textbf{\textit{Proof.}} Rewriting the equation $(A + \delta A)\hat{x} = b$ as 
        $Ax + A\delta x + \delta A\hat{x} = b$, using the equation $Ax = b$, and reorganizing 
        the resulting equation, we obtain
        \[
            \delta x = -A^{-1} \delta A \hat{x}.
        \]
        Thus
        \[
            \|\delta x\| \leq \|A^{-1}\| \, \|\delta A\| \, \|\hat{x}\|.
            \tag{2.3.5}
        \]
        Dividing through by $\|\hat{x}\|$ and using the definition 
        $\kappa(A) = \|A\| \, \|A^{-1}\|$, we obtain the desired result.
    \end{remark}
    


\end{document}
