\documentclass{report}

\input{~/dev/latex/template/preamble.tex}
\input{~/dev/latex/template/macros.tex}

\title{\Huge{}}
\author{\huge{Nathan Warner}}
\date{\huge{}}
\pagestyle{fancy}
\fancyhf{}
\lhead{Warner \thepage}
\rhead{}
% \lhead{\leftmark}
\cfoot{\thepage}
%\setborder
% \usepackage[default]{sourcecodepro}
% \usepackage[T1]{fontenc}

\begin{document}
    % \maketitle
        \begin{titlepage}
       \begin{center}
           \vspace*{1cm}
    
           \textbf{Comprehensive Compendium:} \\
            Calculus II
    
           \vspace{0.5cm}
            
                
           \vspace{1.5cm}
    
           \textbf{Nathan Warner}
    
           \vfill
                
                
           \vspace{0.8cm}
         
           \includegraphics[width=0.4\textwidth]{~/niu/seal.png}
                
           Computer Science \\
           Northern Illinois University\\
           August 28,2023 \\
           United States\\
           
                
       \end{center}
    \end{titlepage}
    \tableofcontents
    \pagebreak \bigbreak \noindent
    \section{\LARGE Calc II}
    \bigbreak \noindent 

    \bigbreak \noindent 
    \subsection{Chapter 1 Key Equations}
    \bigbreak \noindent 
    \begin{itemize}
        \item \textbf{Mean Value Theorem For Integrals}: If  $f(x)$ is continuous over an interval  [a,b], then there is at least one point  $c\in[a,b]$ such that 
            \begin{align*}
                f(c) = \frac{1}{b-a}\int f(x)\ dx
            .\end{align*}
        \item \textbf{Integrals resulting in inverse trig functions}
                \begin{enumerate}
        \item \begin{align*}
                \int \frac{dx}{\sqrt{a^{2}-x^{2}}} = \sin^{-1}{\frac{x}{\abs{a}}} + C
        .\end{align*}
    \item \begin{align*}
        \int \frac{dx}{a^{2}+x^{2}} = \frac{1}{a}\tan^{-1}{\frac{x}{a}} + C
    .\end{align*}
    \item \begin{align*}
            \int \frac{dx}{x\sqrt{x^{2}-a^{2}}} = \frac{1}{\abs{a}}\sec^{-1}{\frac{\abs{x}}{a}} + C
    .\end{align*}
    \end{enumerate}
    \end{itemize}

    % \pagebreak \bigbreak \noindent 
    % \subsection{Chapter 2 Key Terms / Ideas}
    % \bigbreak \noindent 
    % \begin{itemize}
    %     \item \textbf{Finding limits of integration for region between two functions}: Usually, we want our limits of integration to be the points where the functions intersect
    %     \item A \textbf{"complex region"} between curves usually refers to an area that is not easily described by a single, continuous function over the interval of interest.
    %     \item \textbf{compound regions} are regions bounded by the graphs of functions that cross one another
    %     \item \textbf{Cross-section:} The intersection of a plane and a solid object.
    %     \item a \textbf{cylinder} is a three-dimensional shape that has two parallel, congruent bases connected by a curved surface. The bases are usually circles, but they can be other shapes as well
    %     \item The line segment connecting the centers of the two bases is called the \textbf{"axis" of the cylinder.}
    %     \item \textbf{Slicing method:} A method of calculating the volume of a solid that involves cutting the solid into pieces, estimating the volume of each piece, then adding these estimates to arrive at an estimate of the total volume; as the number of slices goes to infinity, this estimate becomes an integral that gives the exact value of the volume.
    %     \begin{enumerate}
    %         \item Examine the solid and determine the shape of a cross-section of the solid. It is often helpful to draw a picture if one is not provided.
    %         \item Determine a formula for the area of the cross-section.
    %         \item Integrate the area formula over the appropriate interval to get the volume.
    %     \end{enumerate}
    %     \item \textbf{Solid of revolution:} A solid generated by revolving a region in a plane around a line in that plane.
    %     \item \textbf{Disk method:} A special case of the slicing method used with solids of revolution when the slices are disks.
    %     \item A \textbf{Washer (Annuli)} is a disk with holes in the center.
    %     \item \textbf{Washer method:} A special case of the slicing method used with solids of revolution when the slices are washers.
    %     \item \textbf{Method of cylindrical shells:} A method of calculating the volume of a solid of revolution by dividing the solid into nested cylindrical shells; this method is different from the methods of disks or washers in that we integrate with respect to the opposite variable.
    %     % \item A \textbf{cylinder} is defined as any solid that can be generated by translating a plane region along a line perpendicular to the region, called the \textbf{axis of the cylinder}.
    %      \item \textbf{Arc length:} The arc length of a curve can be thought of as the distance a person would travel along the path of the curve.
    %     \item \textbf{Surface area:} The surface area of a solid is the total area of the outer layer of the object; for objects such as cubes or bricks, the surface area of the object is the sum of the areas of all of its faces.
    %     % \item \textbf{Catenary:} A curve in the shape of the function \(y = a \cosh(x/a)\) is a catenary; a cable of uniform density suspended between two supports assumes the shape of a catenary.
    %     % \item \textbf{Center of mass:} The point at which the total mass of the system could be concentrated without changing the moment.
    %     % \item \textbf{Centroid:} The centroid of a region is the geometric center of the region; laminas are often represented by regions in the plane; if the lamina has a constant density, the center of mass of the lamina depends only on the shape of the corresponding planar region; in this case, the center of mass of the lamina corresponds to the centroid of the representative region.
    %     % \item \textbf{Density function:} A density function describes how mass is distributed throughout an object; it can be a linear density, expressed in terms of mass per unit length; an area density, expressed in terms of mass per unit area; or a volume density, expressed in terms of mass per unit volume; weight-density is also used to describe weight (rather than mass) per unit volume.
    %     % \item \textbf{Doubling time:} If a quantity grows exponentially, the doubling time is the amount of time it takes the quantity to double, and is given by \(\frac{\ln 2}{k}\).
    %     % \item \textbf{Exponential decay:} Systems that exhibit exponential decay follow a model of the form \(y = y_0 e^{-kt}\).
    %     % \item \textbf{Exponential growth:} Systems that exhibit exponential growth follow a model of the form \(y = y_0 e^{kt}\).
    %     % \item \textbf{Frustum:} A portion of a cone; a frustum is constructed by cutting the cone with a plane parallel to the base.
    %     % \item \textbf{Half-life:} If a quantity decays exponentially, the half-life is the amount of time it takes the quantity to be reduced by half. It is given by \(\frac{\ln 2}{k}\).
    %     % \item \textbf{Hooke's Law:} This law states that the force required to compress (or elongate) a spring is proportional to the distance the spring has been compressed (or stretched) from equilibrium; in other words, \(F = kx\), where \(k\) is a constant.
    %     % \item \textbf{Hydrostatic pressure:} The pressure exerted by water on a submerged object.
    %     % \item \textbf{Lamina:} A thin sheet of material; laminas are thin enough that, for mathematical purposes, they can be treated as if they are two-dimensional.
    %     % \item \textbf{Moment:} If \(n\) masses are arranged on a number line, the moment of the system with respect to the origin is given by \(M = \sum_{i=1}^{n} m_i x_i\); if, instead, we consider a region in the plane, bounded above by a function \(f(x)\) over an interval \([a, b]\), then the moments of the region with respect to the \(x\)- and \(y\)-axes are given by \(M_x = \rho \int_{a}^{b} \frac{[f(x)]^2}{2} dx\) and \(M_y = \rho \int_{a}^{b} x f(x) dx\), respectively.
    %     % \item \textbf{Symmetry principle:} The symmetry principle states that if a region \(R\) is symmetric about a line \(l\), then the centroid of \(R\) lies on \(l\).
    %     % \item \textbf{Theorem of Pappus for volume:} This theorem states that the volume of a solid of revolution formed by revolving a region around an external axis is equal to the area of the region multiplied by the distance traveled by the centroid of the region.
    %     % \item \textbf{Work:} The amount of energy it takes to move an object; in physics, when a force is constant, work is expressed as the product of force and distance.
    % \end{itemize}

    \pagebreak \bigbreak \noindent 
    \subsection{Chapter 2 Key Equations}
    \bigbreak \noindent 
    \begin{itemize}

    \item \textbf{Area between two curves, integrating on the x-axis}
    \begin{align}
        A = \int_{a}^{b} [f(x) - g(x)] \, dx
    \end{align}
    Where $f(x) \geq g(x)$
    \begin{align*}
        A = \int_{a}^{b}\ [g(x) - f(x)]\ dx
    .\end{align*}
    for $g(x) \geq f(x)$

    \item \textbf{Area between two curves, integrating on the y-axis}
    \begin{align}
        A = \int_{c}^{d} [u(y) - v(y)] \, dy
    \end{align}

    \item \textbf{Areas of compound regions}
        \begin{align*}
          \int_{a}^{b}\ \abs{f(x)-g(x)}\ dx 
        .\end{align*}
    \item \textbf{Area of complex regions}
        \begin{align*}
            \int_{a}^{b}\ f(x)\ dx + \int_{b}^{c}\ g(x)\ dx
        .\end{align*}
    \item \textbf{Slicing Method}
        \begin{align*}
            V(s) = \summation{n}{i=1}\ A(x_{i}^{*})\ \Delta x  = \int_{a}^{b}\ A(x)\ dx
        .\end{align*}
    \item \textbf{Disk Method along the x-axis}
    \begin{align}
        V = \int_{a}^{b} \pi [f(x)]^2 \, dx
    \end{align}

    \item \textbf{Disk Method along the y-axis}
    \begin{align}
        V = \int_{c}^{d} \pi [g(y)]^2 \, dy
    \end{align}

    \item \textbf{Washer Method along the x-axis}
    \begin{align}
        V = \int_{a}^{b} \pi [(f(x))^2 - (g(x))^2] \, dx
    \end{align}

    \item \textbf{Washer Method along the y-axis}
    \begin{align}
        V = \int_{c}^{d} \pi [(u(y))^2 - (v(y))^2] \, dy
    \end{align}

    \item \textbf{Radius if revolved around other line (Washer Method)}
        \begin{align*}
           If:\ x=-k\\
           Then:\ r = Function + k
        .\end{align*}
        \begin{align*}
           If:\ x=k\\
           Then:\ r = k - Function
        .\end{align*}

    \item \textbf{Method of Cylindrical Shells (x-axis)}
    \begin{align}
        V = \int_{a}^{b} 2\pi x f(x) \, dx
    \end{align}

    \item \textbf{Method of Cylindrical Shells (y-axis)}
    \begin{align}
        V = \int_{c}^{d} 2\pi y g(y) \, dy
    \end{align}

    \item \textbf{Region revolved around other line (method of cylindrical shells):}
        \begin{align*}
            If:\ x=-k \\
            Then:\ V = \int_{a}^{b}\ 2\pi (x+k)(f(x))\ dx
        .\end{align*}
        \begin{align*}
             If:\ x=k \\
            Then:\ V = \int_{a}^{b}\ 2\pi (k-x)(f(x))\ dx
        .\end{align*}
    \item \textbf{A Region of Revolution Bounded by the Graphs of Two Functions (method cylindrical shells)}
        \begin{align*}
            V = \int_{a}^{b}\ 2\pi x\left[f(x)-g(x)\right]\ dx
        .\end{align*}

    \item \textbf{Arc Length of a Function of x}
    \begin{align}
        \text{Arc Length} = \int_{a}^{b} \sqrt{1 + [f'(x)]^2} \, dx
    \end{align}

    \item \textbf{Arc Length of a Function of y}
    \begin{align}
        \text{Arc Length} = \int_{c}^{d} \sqrt{1 + [g'(y)]^2} \, dy
    \end{align}

    \item \textbf{Surface Area of a Function of x}
    \begin{align}
        \text{Surface Area} = \int_{a}^{b} 2\pi f(x) \sqrt{1 + [f'(x)]^2} \, dx
    \end{align}
    \item \textbf{Natural logarithm function}
    \begin{align}
        \ln x = \int_{1}^{x} \frac{1}{t} \, dt\ Z
    \end{align}

    \item \textbf{Exponential function}
    \begin{align}
        y = e^x, \quad \ln y = \ln(e^x) = x\ Z
    \end{align}

    \item  \textbf{Logarithm Differentiation}
    \begin{align*}
        f^{\prime}(x) = f(x) \cdot \frac{d}{dx}\ln{\left(f^{\prime}(x)\right)}
    .\end{align*}
    \textbf{Note:} Use properties of logs before you differentiate whats inside the logarithm

    % \item \textbf{Mass of a one-dimensional object}
    % \begin{align}
    %     m = \int_{a}^{b} \rho(x) \, dx
    % \end{align}
    %
    % \item \textbf{Mass of a circular object}
    % \begin{align}
    %     m = \int_{0}^{r} 2\pi x \rho(x) \, dx
    % \end{align}
    %
    % \item \textbf{Work done on an object}
    % \begin{align}
    %     W = \int_{a}^{b} F(x) \, dx
    % \end{align}
    %
    % \item \textbf{Hydrostatic force on a plate}
    % \begin{align}
    %     F = \int_{a}^{b} \rho w(x) s(x) \, dx
    % \end{align}
    %
    % \item \textbf{Mass of a lamina}
    % \begin{align}
    %     m = \rho \int_{a}^{b} f(x) \, dx
    % \end{align}
    %
    % \item \textbf{Moments of a lamina}
    % \begin{align}
    %     M_x = \rho \int_{a}^{b} \frac{[f(x)]^2}{2} \, dx, \quad M_y = \rho \int_{a}^{b} x f(x) \, dx
    % \end{align}
    %
    % \item \textbf{Center of mass of a lamina}
    % \begin{align}
    %     \bar{x} = \frac{M_y}{m},\ \ \text{and}\ \  \bar{y} = \frac{M_x}{m}
    % \end{align}

    \end{itemize}


    % \pagebreak \bigbreak \noindent 
    % \subsection{Chapter 3 Key Terms}
    % \bigbreak \noindent 
    % \begin{itemize}
    %     \item \textbf{integration by parts}: a technique of integration that allows the exchange of one integral for another using the formula 
    %     \item \textbf{integration table}: a table that lists integration formulas.
    %     \item \textbf{power reduction formula}: a rule that allows an integral of a power of a trigonometric function to be exchanged for an integral involving a lower power.
    %     \item \textbf{trigonometric integral}: an integral involving powers and products of trigonometric functions.
    %     \item \textbf{trigonometric substitution}: an integration technique that converts an algebraic integral containing expressions of the form \( \sqrt{a^2 - x^2} \), \( \sqrt{a^2 + x^2} \), or \( \sqrt{x^2 - a^2} \) into a trigonometric integral.
    %     \item \textbf{partial fraction decomposition}: a technique used to break down a rational function into the sum of simple rational functions.
    %     \item \textbf{improper integral}: an integral over an infinite interval or an integral of a function containing an infinite discontinuity on the interval; an improper integral is defined in terms of a limit. The improper integral converges if this limit is a finite real number; otherwise, the improper integral diverges.
    %      % \item \textbf{absolute error}: if \( B \) is an estimate of some quantity having an actual value of \( A \), then the absolute error is given by \( |A-B| \).
    %     % \item \textbf{computer algebra system (CAS)}: technology used to perform many mathematical tasks, including integration.
    %     % \item \textbf{midpoint rule}: a rule that uses a Riemann sum of the form 
    %     % \item \textbf{numerical integration}: the variety of numerical methods used to estimate the value of a definite integral, including the midpoint rule, trapezoidal rule, and Simpson’s rule.
    %     % \item \textbf{relative error}: error as a percentage of the absolute value, given by 
    %     % \item \textbf{Simpson’s rule}: a rule that approximates \( \int_{a}^{b} f(x) \, dx \) using the integrals of a piecewise quadratic function. The approximation \( S_n \) to \( \int_{a}^{b} f(x) \, dx \) is given by 
    %     % \item \textbf{trapezoidal rule}: a rule that approximates \( \int_{a}^{b} f(x) \, dx \) using trapezoids.
    % \end{itemize}
    %
    \pagebreak \bigbreak \noindent 
    \subsection{Chapter 3 Key Equations}
    \bigbreak \noindent 
    \begin{itemize}
        \item \textbf{Integration by parts formula} 
            \begin{align*}
                \int u \, dv &= uv - \int v \, du 
            .\end{align*}
        \item \textbf{Integration by parts for definite integral}
            \begin{align*}
                \int_{a}^{b} u \, dv &= uv\big|_{a}^{b} - \int_{a}^{b} v \, du
            \end{align*}
        \item \textbf{To integrate products involving  sin(ax), sin(bx), cos(ax), and  cos(bx), use the substitutions:}
            \begin{itemize}
                \item \textbf{Sine Products}
                \begin{align*}
                    \sin(ax) \sin(bx) &= \frac{1}{2} \cos((a-b)x) - \frac{1}{2} \cos((a+b)x)
                \end{align*}

                \item \textbf{Sine and Cosine Products}
                \begin{align*}
                    \sin(ax) \cos(bx) &= \frac{1}{2} \sin((a-b)x) + \frac{1}{2} \sin((a+b)x)
                \end{align*}

                \item \textbf{Cosine Products}
                \begin{align*}
                    \cos(ax) \cos(bx) &= \frac{1}{2} \cos((a-b)x) + \frac{1}{2} \cos((a+b)x)
                \end{align*}

                \item \textbf{Power Reduction Formula (sine)}
                    \begin{align*}
                        &\int \sin^{n}{x}\ dx = -\frac{1}{n}\sin^{n-1}{x}\cos{x} + \frac{n-1}{n}\int \sin^{n-2}{x}\ dx \\
                        &\int_{0}^{\frac{\pi}{2}}\ \sin^{n}{x}\ dx = \frac{n-1}{n}\int_{0}^{\frac{\pi}{2}}\ \sin^{n-2}{x}\ dx
                    .\end{align*}
                \item \textbf{Power Reduction Formula (cosine)}
                    \begin{align*}
                        &\int \cos^{n}{x}\ dx = \frac{1}{n}\cos^{n-1}{x}\sin{x} + \frac{n-1}{n}\int \cos^{n-2}{x}\ dx \\
                        &\int_{0}^{\frac{\pi}{2}}\ \cos^{n}{x}\ dx = \frac{n-1}{n}\int_{0}^{\frac{\pi}{2}}\ \cos^{n-2}{x}\ dx
                    .\end{align*}
                \item \textbf{Power Reduction Formula (secant)}
                \begin{align*}
                    \int \sec^{n}{x}\ dx &= \frac{1}{n-1}\sec^{n-1}{x}\sin{x}+\frac{n-2}{n-1}\int \sec^{n-2}{x}\ dx \\
                    \int \sec^{n}{x}\ dx &= \frac{1}{n-1}\sec^{n-2}{x}\tan{x}+\frac{n-2}{n-1}\int \sec^{n-2}{x}\ dx
                \end{align*}

                \item \textbf{Power Reduction Formula (tangent)}
                \begin{align*}
                    \int \tan^n x \, dx &= \frac{1}{n-1} \tan^{n-1}x - \int \tan^{n-2}x \, dx
                \end{align*}
            \end{itemize}
            \item \textbf{Trigonometric Substitution}
            \begin{itemize}
                \item $\sqrt{a^{2} - x^{2}}$ use $x =a\sin{\theta }$ with domain restriction $\bigg[-\frac{\pi}{2},\frac{\pi}{2}\bigg] $
                \item $\sqrt{a^{2} + x^{2}}$ use $x=a\tan{\theta}$ with domain restriction $\left(-\frac{\pi}{2}, \frac{\pi}{2}\right)$
                \item $\sqrt{x^{2} - a^{2}}$ use $x =a\sec{\theta}$ with domain restriction $\bigg[0,\frac{\pi}{2}\bigg) \cup \bigg[\pi,\frac{3\pi}{2}\bigg)$ 
            \end{itemize}

        \item \textbf{Steps for fraction decomposition}
            \begin{enumerate}
                \item Ensure $deg(Q) < deg(P)$, if not, long divide
                \item Factor denominator
                \item Split up fraction into factors
                \item Multiply through to clear denominator
                \item Group terms and equalize
                \item Solve for constants
                \item Plug constants into split up fraction
                \item Compute integral
            \end{enumerate}

        \item \textbf{Solving for constants}
            Either:
            \begin{itemize}
                \item Plug in values (often the roots)
                \item Equalize 
            \end{itemize}
        \item \textbf{Cases for partial fractions}
            \begin{itemize}
                \item Non repeated linear factors
                \item Repeated linear factors
                \item Nonfactorable quadratic factors
            \end{itemize}
        \item \textbf{Midpoint rule}
            \begin{align*}
                M_{n} = \summation{n}{i=1}\ f(m_{i})\ \Delta x 
            .\end{align*}
        \item \textbf{Absolute error}
            \begin{align*}
                err = \bigg|\text{Actual} - \text{Estimated}\bigg|
            .\end{align*}
        \item \textbf{Relative error}
            \begin{align*}
                err = \bigg|\frac{\text{Actual} - \text{Estimated}}{\text{Actual}}\bigg| \cdot 100\%
            .\end{align*}
        \item \textbf{Error upper bound for midpoint rule}
        \begin{align*}
            E_{M} \leq \frac{M(b-a)^3}{24n^2}
        \end{align*}
        Where $M$ is the maximum value of the second derivative
        \item \textbf{Trapezoidal rule}
        \begin{align*}
            T_n \frac{1}{2} \Delta x \left( f(x_0) + 2f(x_1) + 2f(x_2) + \cdots + 2f(x_{n-1}) + f(x_n) \right)
        \end{align*}
        \item \textbf{Error upper bound for trapezoidal rule}
        \begin{align*}
            E_{T} \leq \frac{M(b-a)^3}{12n^2}
        \end{align*}
        Where $M$ is the maximum value of the second derivative
        \item \textbf{Simpson’s rule}
        \begin{align*}
            S_n = \frac{\Delta x}{3} \left( f(x_0) + 4f(x_1) + 2f(x_2) + 4f(x_3) + 2f(x_4) + 4f(x_5) + \cdots + 2f(x_{n-2}) + 4f(x_{n-1}) + f(x_n) \right)
        \end{align*}
        \item \textbf{Error upper bound for Simpson’s rule}
        \begin{align*}
            E_{S} \leq \frac{M(b-a)^5}{180n^4}
        \end{align*}
        Where $M$ is the maximum value of the fourth derivative
    \item \textbf{Finding $n$ with error bound functions}
        \begin{enumerate}
            \item Find $f^{\prime\prime}(x)$
            \item Find maximum values of $f^{\prime\prime}(x)$ in the interval
            \item Plug into error bound function 
            \item Set value $\leq$ desired accuracy (ex: 0.01)
            \item Solve: 
            \item If we were to truncate, we would use the ceil function $\ceil*{n}$ DO NOT FLOOR
        \end{enumerate}
    \item \textbf{Improper integrals (Infinite interval)}
        \begin{itemize}
            \item $\int_{a}^{+\infty}\ f(x)\ dx  = \lim\limits_{t \to +\infty}{\int_{a}^{t}\ f(x)\ dx}$  
            \item $\int_{-\infty}^{b}\ f(x)\ dx = \lim\limits_{t \to -\infty}{\int_{t}^{b}\ f(x)\ dx}$ 
            \item $\int_{-\infty}^{+\infty}\ f(x)\ dx = \int_{-\infty}^{0}\ f(x)\ dx + \int_{0}^{+\infty}\ f(x)\ dx$
        \end{itemize}
    \item \textbf{Improper integral (discontinuous)}
        \begin{itemize}
            \item Let $f(x)$ be continuous on $[a,b)$, then;
                \begin{align*}
                    \int_{a}^{b}\ f(x)\ dx = \lim\limits_{t \to b^{-}}{\int_{a}^{t}\ f(x)\ dx}\
                .\end{align*}
            \item Let $f(x)$ be continuous on $(a,b]$, then;
                \begin{align*}
                    \int_{a}^{b}\ f(x)\ dx = \lim\limits_{t \to b^{+}}{\int_{t}^{b}\ f(x)\ dx}\
                .\end{align*}
                In each case, if the limit exists, then the improper integral is said to converge. If the limit does not exist, then the improper integral is said to diverge.
            \item Let $f(x)$ be continuous on $[a,b]$ except at a point $c \in (a,b)$, then;
                \begin{align*}
                    \int_{a}^{b}\ f(x)\ dx = \int_{a}^{c}\ f(x)\ dx  +\int_{c}^{b}\ f(x)\ dx
                .\end{align*}
                If either integral diverges, then $\int_{a}^{b}\ f(x)\ dx $ diverges
        \end{itemize}
        \item \textbf{Comparison theorem}
        Let $f(x)$ and $g(x)$ be continuous over $[a,+\infty)$. Assume that $0 \leq f(x) \leq g(x)$ for $x \geq a$.
        \begin{itemize}
            \item If $\int_a^{+\infty} f(x) \, dx = \lim_{t \to +\infty} \int_a^t f(x) \, dx = +\infty$,  \\
                then $\int_a^{+\infty} g(x) \, dx = \lim_{t \to +\infty} \int_a^t g(x) \, dx = +\infty$.
            \item If $\int_a^{+\infty} g(x) \, dx = \lim_{t \to +\infty} \int_a^t g(x) \, dx = L$, where $L$ is a real number,  \\
                then $\int_a^{+\infty} f(x) \, dx = \lim_{t \to +\infty} \int_a^t f(x) \, dx = M$ for some real number $M \leq L$.
        \end{itemize}
        \pagebreak \bigbreak \noindent 
    \item \textbf{P-integrals}
        \begin{itemize}
    \item $\int_{0}^{+\infty} \frac{1}{x^{p}}\ dx =  
        \begin{cases}
            \frac{1}{p-1} & \text{if } p>1 \\
            +\infty & \text{if } p \leq 1
        \end{cases}$
    \item $\int_{0}^{1} \frac{1}{x^p}\ dx =    
        \begin{cases}
            \frac{1}{1-p} & \text{if } p<1 \\
            +\infty & \text{if } p \geq 1
        \end{cases}$
    \item $\int_{a}^{+\infty} \frac{1}{x^{p}}\ dx =  
        \begin{cases}
            \frac{a^{1-p}}{p-1} & \text{if } p>1 \\
            +\infty & \text{if } p \leq 1
        \end{cases}$
    \item $\int_{0}^{a} \frac{1}{x^p}\ dx =    
        \begin{cases}
            \frac{a^{1-p}}{1-p} & \text{if } p<1 \\
            +\infty & \text{if } p \geq 1
        \end{cases}$
\end{itemize}
    \item \textbf{Bypass L'Hospital's Rule}
        \begin{align*}
            \ln{(\ln{(x)})},\ \ln{(x)},\ \cdots\ x^{\frac{1}{100}},\ x^{\frac{1}{3}},\ \sqrt{x},\ 1,\ x^{2},\ x^{3},\ \cdots\ e^{x},\ e^{2x},\ e^{3x},\ \cdots,\ e^{x^{2}},\ \cdots\ e^{e^{x}}
        .\end{align*}
        Essentially what it means is things on the right grow faster than things on the left. Thus, if we have say:
        \begin{align*}
            \lim\limits_{x \to \infty}{\frac{x^{2}}{e^{2x}}} 
        .\end{align*}
        We can be sure that it is zero. Because this is $x^{2}\cdot e^{-2x}$. If we take  $ \lim\limits_{x \to \infty}{x^{2}e^{-2x}}$, we get $\infty \cdot 0$. As we see by the sequence $e^{-2x}$ overrules $x^{2}$ and we can say the limit is zero.
    % \item \textbf{something to consider for limits}: Suppose we have $f:\ A \rightarrow B:\ x \mapsto f(x)$. It would not be meaninful to consider some $ \lim\limits_{x \to b+n}{f(x)}$ for $n>0 $. Thus we shall conclude that the limit is undefined. For example, the domain of arcsine is $[-1,1]$, thus any $\lim\limits_{x \to a}{f(x)}$ for $(-\infty,-1)\cup (1,\infty)$ would be undefined
    \item \textbf{Consideration for Limits}: Let \(f: A \rightarrow B\) be a function defined by \(x \mapsto f(x)\). If a point \(c\) lies outside the domain \(A\), then the expression \(\lim\limits_{x \to c} f(x)\) is not meaningful, and we classify this limit as undefined. For instance, the function arcsine has a domain of \([-1,1]\). Therefore, limits like \(\lim\limits_{x \to a} \sin^{-1}(x)\) where \(a \notin [-1,1]\) are undefined.
    \item \textbf{Why does}
        \begin{align*}
            &\lim\limits_{x \to 2}{\tan^{-1}{\frac{1}{x-2}}} 
        .\end{align*}
        \begin{minipage}[]{0.47\textwidth}
            \begin{align*}
                &=\lim\limits_{x \to 2^{-}}{\tan^{-1}{\frac{1}{x-2}}} \\
                &= \lim\limits_{x \to -\infty}{\tan^{-1}{x}} \\
                &= -\pi/2
            .\end{align*}
        \end{minipage}
        \begin{minipage}[]{0.47\textwidth}
            \begin{align*}
                &=\lim\limits_{x \to 2^{+}}{\tan^{-1}{\frac{1}{x-2}}} \\
                &=\lim\limits_{x \to +\infty}{\tan^{-1}{x}} \\
                &=\frac{\pi}{2}
            .\end{align*}
        \end{minipage}
    \end{itemize}

    % \pagebreak \bigbreak \noindent 
    % \subsection{\LARGE Chapter 5 Key Terms}
    % \bigbreak \noindent 
    % \begin{itemize}
    % 
    % \item Alternating series: 
    % \[
    % \text{A series of the form } \sum_{n=1}^{\infty} (-1)^{n+1} b_n \text{ or } \sum_{n=1}^{\infty} (-1)^n b_n, \text{ where } b_n \geq 0, \text{ is called an alternating series.}
    % \]
    % 
    % \item Alternating series test: 
    % \[
    % \text{For an alternating series of either form, if } b_{n+1} \leq b_n \text{ for all integers } n \geq 1 \text{ and } b_n \to 0, \text{ then an alternating series converges.}
    % \]
    % 
    % \item Arithmetic sequence: 
    % \[
    % \text{A sequence in which the difference between every pair of consecutive terms is the same is called an arithmetic sequence.}
    % \]
    % 
    % \item Bounded above: 
    % \[
    % \text{A sequence } \{a_n\} \text{ is bounded above if there exists a constant } M \text{ such that } a_n \leq M \text{ for all positive integers } n.
    % \]
    % 
    % \item Bounded below: 
    % \[
    % \text{A sequence } \{a_n\} \text{ is bounded below if there exists a constant } M \text{ such that } M \leq a_n \text{ for all positive integers } n.
    % \]
    % 
    % \item Bounded sequence: 
    % \[
    % \text{A sequence } \{a_n\} \text{ is bounded if there exists a constant } M \text{ such that } |a_n| \leq M \text{ for all positive integers } n.
    % \]
    % 
    % 
    % \item Convergence of a series: 
    % \[
    % \text{A series converges if the sequence of partial sums for that series converges.}
    % \]
    % 
    % \item Convergent sequence: 
    % \[
    % \text{A convergent sequence is a sequence } \{a_n\} \text{ for which there exists a real number } L \text{ such that } a_n \text{ is arbitrarily close to } L \text{ as long as } n \text{ is sufficiently large.}
    % \]
    % 
    % \item Divergence of a series: 
    % \[
    % \text{A series diverges if the sequence of partial sums for that series diverges.}
    % \]
    % 
    % \item Divergence test: 
    % \[
    % \text{If } \lim_{n \to \infty} a_n \neq 0, \text{ then the series } \sum_{n=1}^{\infty} a_n \text{ diverges.}
    % \]
    % 
    % \item Divergent sequence: 
    % \[
    % \text{A sequence that is not convergent is divergent.}
    % \]
    % 
    % \item Explicit formula: 
    % \[
    % \text{A sequence may be defined by an explicit formula such that } a_n = f(n).
    % \]
    % 
    % \item Geometric sequence: 
    % \[
    % \text{A sequence } \{a_n\} \text{ in which the ratio } \frac{a_{n+1}}{a_n} \text{ is the same for all positive integers } n \text{ is called a geometric sequence.}
    % \]
    % 
    % \item Geometric series: 
    % \[
    % \text{A geometric series is a series that can be written in the form } \sum_{n=1}^{\infty} ar^{n-1} = a + ar + ar^2 + ar^3 + \cdots.
    % \]
    % 
    % \item Harmonic series: 
    % \[
    % \text{The harmonic series takes the form } \sum_{n=1}^{\infty} \frac{1}{n} = 1 + \frac{1}{2} + \frac{1}{3} + \cdots.
    % \]
    % 
    % \item Index variable: 
    % \[
    % \text{The subscript used to define the terms in a sequence is called the index.}
    % \]
    % 
    % \item Infinite series: 
    % \[
    % \text{An infinite series is an expression of the form } a_1 + a_2 + a_3 + \cdots = \sum_{n=1}^{\infty} a_n.
    % \]
    % 
    % \item Integral test: 
    % \[
    % \text{For a series } \sum_{n=1}^{\infty} a_n \text{ with positive terms } a_n, \text{ if there exists a continuous, decreasing function } f \text{ such that } f(n) = a_n \text{ for all positive integers } n, \text{ then } \sum_{n=1}^{\infty} a_n \text{ and } \int_{1}^{\infty} f(x) \, dx \text{ either both converge or both diverge.}
    % \]
    % 
    % \item Limit comparison test: 
    % \[
    % \text{Suppose } a_n, b_n \geq 0 \text{ for all } n \geq 1. \text{ If } \
    % \]
    % \end{itemize}

    \pagebreak \bigbreak \noindent 
    \subsection{\LARGE Chapter 5 Key Equations}
    \bigbreak \noindent 
    \begin{itemize}
    \item \textbf{Sequence notation}
        \begin{align*}
            \{a_{n}\}_{n=1}^{\infty},\ \text{or simply } \{a_{n}\}
        .\end{align*}
    \item \textbf{Sequence notation (ordered list)}
        \begin{align*}
            a_{1},\ a_{2},\ a_{3},\ \cdots,\ a_{n},\ \cdots
        .\end{align*}
    \item \textbf{Arithemetic Sequence Difference}
        \begin{align*}
            d = a_{n} - a_{n-1}
        .\end{align*}
    \item \textbf{Arithmetic sequence (common difference between subsequent terms) general form}
        \begin{align*}
            &\text{Index starting at 0}:\ a_{n} = a + nd \\
            &\text{Index starting at 1}:\ a_{n} = a + (n-1)d \\
        .\end{align*}
    \item \textbf{Arithmetic sequence (common difference between subsequent terms) recursive form}
        \begin{align*}
            a_{n} = a_{n-1} + d
        .\end{align*}
    \item \textbf{Sum of arithmetic sequence}
        \begin{align*}
            &S_{n} = \frac{n}{2}\left[a + a_{n}\right] \\
            &S_{n} = \frac{n}{2}\left[2a + (n-1)d\right]
        .\end{align*}
    \item \textbf{Geometric sequence form common ratio}
        \begin{align*}
            r = \frac{a_{n}}{a_{n-1}}
        .\end{align*}
    \item \textbf{Geometric sequence general form}
        \begin{align*}
            &a_{n} = ar^{n}\ \text{(Index starting at 0)} \\
            &a_{n} = a^{n+1} \text{(index starting at 0 and a=r)} \\
            &a_{n} = ar^{n-1}\ \text{(Index starting at 1)} \\
            &a_{n} = a^{n} \text{(index starting at 1 and a=r)}
        .\end{align*}
    \item \textbf{Geometric sequence recursive form}
        \begin{align*}
            &a_{n} = ra_{n-1}
        .\end{align*}
    \item \textbf{Sum of geometric sequence (finite terms)}
        \begin{align*}
            S_{n} = \frac{a(1-r^{n})}{1-r}\ \quad r\ne 1
        .\end{align*}
    \item \textbf{Convergence / Divergence}: If 
        \begin{align*}
            \lim\limits_{n \to +\infty}{a_{n}} = L
        .\end{align*}
        We say that the sequence converges, else it diverges
    \item \textbf{Formal definition of limit of sequence}
        \begin{align*}
            \lim\limits_{n \to +\infty}{a_{n}= L} \iff \forall \varepsilon > 0, \exists N \in \mathbb{Z} \mid \abs{a_{n} - L} < \varepsilon,\ \text{if } n \geq n
        .\end{align*}
        Then we can say 
        \begin{align*}
            \lim\limits_{n \to +\infty}{a_{n} = L}\ \text{or } a_{n} \rightarrow L 
        .\end{align*}
    \item \textbf{Limit of a sequence defined by a function}:         Consider a sequence \( \{a_n\} \) such that \( a_n = f(n) \) for all \( n \geq 1 \). If there exists a real number \( L \) such that
        \[
        \lim_{{x \to \infty}} f(x) = L,
        \]
        then \( \{a_n\} \) converges and
        \[
        \lim_{{n \to \infty}} a_n = L.
        \]
    \item \textbf{Algebraic limit laws}:
          Given sequences \( \{a_n\} \) and \( \{b_n\} \) and any real number \( c \), if there exist constants \( A \) and \( B \) such that \( \lim_{{n \to \infty}} a_n = A \) and \( \lim_{{n \to \infty}} b_n = B \), then
          \begin{itemize}
            \item \( \lim_{{n \to \infty}} c = c \)
            \item \( \lim_{{n \to \infty}} c a_n = c \lim_{{n \to \infty}} a_n = cA \)
            \item \( \lim_{{n \to \infty}} (a_n \pm b_n) = \lim_{{n \to \infty}} a_n \pm \lim_{{n \to \infty}} b_n = A \pm B \)
            \item \( \lim_{{n \to \infty}} (a_n \cdot b_n) = (\lim_{{n \to \infty}} a_n) \cdot (\lim_{{n \to \infty}} b_n) = A \cdot B \)
            \item \( \lim_{{n \to \infty}} \frac{a_n}{b_n} = \frac{\lim_{{n \to \infty}} a_n}{\lim_{{n \to \infty}} b_n} = \frac{A}{B} \), provided \( B \neq 0 \) and each \( b_n \neq 0 \).
        \end{itemize}
    \item \textbf{Continuous Functions Defined on Convergent Sequences}:
          Consider a sequence \( \{a_n\} \) and suppose there exists a real number \( L \) such that the sequence \( \{a_n\} \) converges to \( L \). Suppose \( f \) is a continuous function at \( L \). Then there exists an integer \( N \) such that \( f \) is defined at all values \( a_n \) for \( n \geq N \), and the sequence \( \{f(a_n)\} \) converges to \( f(L) \).
    \item \textbf{Squeeze Theorem for Sequences}:           Consider sequences \( \{a_n\} \), \( \{b_n\} \), and \( \{c_n\} \). Suppose there exists an integer \( N \) such that
        \[ a_n \leq b_n \leq c_n \text{ for all } n \geq N. \]
        If there exists a real number \( L \) such that
        \[ \lim_{{n \to \infty}} a_n = L = \lim_{{n \to \infty}} c_n, \]
        then \( \{b_n\} \) converges and \( \lim_{{n \to \infty}} b_n = L \)
    \item \textbf{Bounded above}:           A sequence \( \{a_n\} \) is bounded above if there exists a real number \( M \) such that
        \[ a_n \leq M \]
        for all positive integers \( n \).
    \item \textbf{Bounded below}:
        A sequence \( \{a_n\} \) is bounded below if there exists a real number \( M \) such that
        \[ M \leq a_n \]
        for all positive integers \( n \).
    \item \textbf{Bounded}:
        A sequence \( \{a_n\} \) is a bounded sequence if it is bounded above and bounded below. 
    \item \textbf{Unbounded}:
        If a sequence is not bounded, it is an unbounded sequence.
    \item \textbf{If a sequence  $\{a_{n}\} $ converges, then it is bounded.}
    \item \textbf{Increasing sequence}: A sequence \( \{a_n\} \) is increasing for all \( n \geq n_0 \) if
        \[ a_n \leq a_{n+1} \text{ for all } n \geq n_0. \]
    \item \textbf{Decreasing sequence}: A sequence \( \{a_n\} \) is decreasing for all \( n \geq n_0 \) if
        \[ a_n \geq a_{n+1} \text{ for all } n \geq n_0. \]
    \item \textbf{Monotone sequence}: A sequence \( \{a_n\} \) is a \textbf{monotone sequence} for all \( n \geq n_0 \) if it is increasing for all \( n \geq n_0 \) or decreasing for all \( n \geq n_0 \)
    \item \textbf{Monotone Convergence Theorem}:         If \( \{a_n\} \) is a bounded sequence and there exists a positive integer \( n_0 \) such that \( \{a_n\} \) is monotone for all \( n \geq n_0 \), then \( \{a_n\} \) converges.
    \item \textbf{Infinite Series form:}
        \begin{align*}
            \sum_{n=1}^{\infty} a_n = a_1 + a_2 + a_3 + \cdots.
        .\end{align*}
    \item \textbf{Partial sum ($k^{th}$ partial sum)}
        \begin{align*}
            S_k = \sum_{n=1}^{k} a_n = a_1 + a_2 + a_3 + \cdots + a_k
        .\end{align*}
    \item \textbf{Convergence of infinity series notation}
        \bigbreak \noindent 
        For a series, say...
        \begin{align*}
            \summation{\infty}{n=1}\ a_{n}\ 
        .\end{align*}
        its convergence is determined by the limit of its sequence of partial sums. Specifically, if
        \begin{align*}
            \lim\limits_{n \to +\infty}{S_{n}} = S \rightarrow \summation{\infty}{n=1}\ a_{n}\ = S 
        .\end{align*}
    \item \textbf{Harmonic series}
        \begin{align*}
            \summation{\infty}{n=1}\ \frac{1}{n}  =  \frac{1}{2} + \frac{1}{3} + \frac{1}{4} + \ldots\ 
        .\end{align*}
        Which diverges to $+\infty$
    \item \textbf{Algebraic Properties of Convergent Series}
        Let $ \sum_{n=1}^{\infty} a_n$ and $\sum_{n=1}^{\infty} b_n$ be convergent series. Then the following algebraic properties hold:
        \begin{enumerate}
            \item The series 
            $\sum_{n=1}^{\infty} (a_n + b_n)$ converges and 
            \begin{align*}
                \sum_{n=1}^{\infty} (a_n + b_n) = \sum_{n=1}^{\infty} a_n + \sum_{n=1}^{\infty} b_n. \quad \text{(Sum Rule)}
            .\end{align*}
            \item The series $\sum_{n=1}^{\infty} (a_n - b_n)$ converges and 
                \begin{align*}
                    \sum_{n=1}^{\infty} (a_n - b_n) = \sum_{n=1}^{\infty} a_n - \sum_{n=1}^{\infty} b_n. \quad \text{(Difference Rule)}
                .\end{align*}
            \item For any real number \( c \), the series $\sum_{n=1}^{\infty} c a_n$ converges and 
                \begin{align*}
                    \sum_{n=1}^{\infty} c a_n = c \sum_{n=1}^{\infty} a_n. \quad \text{(Constant Multiple Rule)}
                .\end{align*}
        \end{enumerate}

    \item \textbf{Geometric series convergence or divergence: }
    \begin{align*}
       \summation{\infty}{n=1}\ ar^{n-1} \  = \quad \quad 
        \begin{cases}
             \frac{a}{1-r} & \text{if }  \abs{r} < 1\\
             diverges & \text{if }  \abs{r} \geq 1
        \end{cases}
    .\end{align*}

    \item \textbf{Divergence test}: In the context of sequences, if $\lim_{{n \to \infty}} a_n = c \neq 0$ or the limit does not exist, then the series $\sum_{{n=1}}^{\infty} a_n$ is said to diverge. The converse is not true.
        \bigbreak \noindent 
        Because:
        \begin{align*}
                \lim_{k \to \infty} a_k = \lim_{k \to \infty} (S_k - S_{k-1}) = \lim_{k \to \infty} S_k - \lim_{k \to \infty} S_{k-1} = S - S = 0.
        .\end{align*}
    \item \textbf{Integral Test Prelude}:
        for any integer $k$, the $k$th partial sum $S_k$ satisfies
        \begin{align*}
                S_k = a_1 + a_2 + a_3 + \cdots + a_k < a_1 + \int_{1}^{k} f(x) \, dx < a_1 + \int_{1}^{\infty} f(x) \, dx.
        .\end{align*}
        and
        \begin{align*}
                S_k = a_1 + a_2 + a_3 + \cdots + a_k > \int_{1}^{k+1} f(x) \, dx.
        .\end{align*}

    \item \textbf{Intgeral test}
        Suppose  $\summation{\infty}{n=1}\ a_{n}\  $ is a series with positive terms  $a_{n}$ Suppose there exists a function  $f $
        and a positive integer  $N$ 
      such that the following three conditions are satisfied:
        \begin{enumerate}
            \item \( f \) positive, continuous, and decreasing on $[N,\infty)$
            \item \( f(n) = a_n \) for all integers \( n \geq N \), $N \in \mathbb{Z^{+}} $
        \end{enumerate}
        \begin{align*}
            \text{Then the series} \sum_{n=1}^{\infty} a_n \text{ and the improper integral} \int_{N}^{\infty} f(x) \, dx \text{ either both converge or both diverge.}
        .\end{align*}

    \item \textbf{P-series}
       $\forall p \in \mathbb{R}$, the series 
       \begin{align*}
           \summation{\infty}{n=1}\ \frac{1}{n^{P}}\ 
       .\end{align*}
       Is called a \textbf{p-series}. Furthermore, 
       \begin{align*}
           \sum_{n=1}^{\infty} \frac{1}{n^p} \begin{cases}
        \text{converges if } p>1 \\
        \text{diverges if } p \leq 1.
        \end{cases}
       .\end{align*}

    \item \textbf{P-series extended}
        \begin{align*}
            \summation{\infty}{n=2}\ \frac{1}{n\ln{(n)}^{p}}\ 
            \begin{cases}
        \text{converges if } p>1 \\
        \text{diverges if } p \leq 1.
        \end{cases}
        .\end{align*}
    \item \textbf{Remainder estimate for the integral test}
                Suppose \( \sum_{n=1}^{\infty} a_n \)
        is a convergent series with positive terms. Suppose there exists a function \( f \)
        satisfying the following three conditions:
        \begin{enumerate}
            \item \( f \) is continuous,
            \item \( f \) is decreasing, and
            \item \( f(n) = a_n \) for all integers \( n \geq 1 \).
        \end{enumerate}
        Let \( S_N \) be the \( N \)th partial sum of \( \sum_{n=1}^{\infty} a_n \).
        For all positive integers \( N \),
        \[
        S_N + \int_{N+1}^{\infty} f(x) \, dx < \sum_{n=1}^{\infty} a_n < S_N + \int_{N}^{\infty} f(x) \, dx.
        \]
        In other words, the remainder \( R_N = \sum_{n=1}^{\infty} a_n - S_N = \sum_{n=N+1}^{\infty} a_n \)
        satisfies the following estimate:
        \[
        \int_{N+1}^{\infty} f(x) \, dx < R_N < \int_{N}^{\infty} f(x) \, dx.
        \]
        This is known as the remainder estimate 
        \bigbreak \noindent 
        To find a value of $N$ such that we are withing a desired margin of error, Since we know $R_{n} < \int_{N}^{\infty}\ f(x)\ dx $. Simply compute the improper integral and set the result < the desired error to solve for $N$
    \item \textbf{Find $a_{n}$ given the expression for the partial sum}
        \begin{align*}
            a_{n} = S_{n} - S_{n-1}
        .\end{align*}
    \item \textbf{telescoping series}: Telescoping series are a type of series where each term cancels out a part of another term, leaving only a few terms that do not cancel. When you sum the series, most of the terms collapse or "telescope," which simplifies the calculation of the sum. Here are some key points and generalizations you can note about telescoping series:
        \begin{itemize}
            \item Partial Fraction Decomposition
            \item Cancellation Pattern: In a telescoping series, look for a pattern where a term in one fraction will cancel out with a term in another fraction.
            \item Write out Terms
            \item What is left is $S_{n}$, thus the sum of the series is the $\lim\limits_{n \to \infty}{S_{n}} $
        \end{itemize}
        Try: 
        \begin{align*}
            \summation{\infty}{n=2}\ \frac{1}{n^{2}-1}\ 
        .\end{align*}
        Hint, its not only the first and last terms cancel, we also have a $\frac{\frac{1}{2}}{n}$, when $a_{n-1}$: Answer is $\frac{3}{4}$
    \item \textbf{Comparison test for series}
        \begin{enumerate}
            \item Suppose there exists an integer \( N \) such that \( 0 \leq a_n \leq b_n \) for all \( n \geq N \). If \( \sum_{n=1}^{\infty} b_n \) converges, then \( \sum_{n=1}^{\infty} a_n \) converges. 
            \item  Suppose there exists an integer \( N \) such that \( a_n \geq b_n \geq 0 \) for all \( n \geq N \). If \( \sum_{n=1}^{\infty} b_n \) diverges, then \( \sum_{n=1}^{\infty} a_n \) diverges.
        \end{enumerate}
    \item \textbf{Limit Comparison Test}
         Let \( a_n, b_n \geq 0 \) for all \( n \geq 1 \).
        \begin{itemize}
          \item If \( \lim_{n \to \infty} \frac{a_n}{b_n} = L \neq 0 \), then \( \sum_{n=1}^{\infty} a_n \) and \( \sum_{n=1}^{\infty} b_n \) both converge or both diverge.
          \item If \( \lim_{n \to \infty} \frac{a_n}{b_n} = 0 \) and \( \sum_{n=1}^{\infty} b_n \) converges, then \( \sum_{n=1}^{\infty} a_n \) converges.
          \item If \( \lim_{n \to \infty} \frac{a_n}{b_n} = \infty \) and \( \sum_{n=1}^{\infty} b_n \) diverges, then \( \sum_{n=1}^{\infty} a_n \) diverges.
        \end{itemize}
    \textbf{Note:} Note that if $\frac{a_n}{b_n} \to 0$ and $\sum_{n=1}^{\infty} b_n$ diverges, the limit comparison test gives no information. Similarly, if $\frac{a_n}{b_n} \to \infty$ and $\sum_{n=1}^{\infty} b_n$ converges, the test also provides no information. 
    \bigbreak \noindent 
    Consider the series 
    \begin{align*}
        \summation{\infty}{n=1}\ \frac{n^{4} + 6}{n^{5} + 4}\ 
    .\end{align*}
    To find our $b_{n}$ we can only focus on the leading coefficients. Thus: 
    \begin{align*}
        b_{n} = \frac{n^{4}}{n^{5}} = \frac{1}{n}
    .\end{align*}
    So our test...
    \smallbreak \noindent
    \begin{minipage}[t]{0.47\textwidth}
    \begin{align*}
        &\lim\limits_{n \to \infty}{\frac{a_{n}}{b_{n}}} = \frac{\frac{n^{4} + 6}{n^{5} + 4}}{\frac{1}{n}} \\
        &=\lim\limits_{n \to \infty}{\frac{n(n^{4}+6)}{n^{5} + 4}} \\
        &=\lim\limits_{n \to \infty}{\frac{n^{5}+6n}{n^{5} + 4}} \\
        &=1
    .\end{align*}
    \end{minipage}
    \begin{minipage}[t]{0.47\textwidth}
        Since $\lim\limits_{n \to \infty}{\frac{a_{n}}{b_{n}}} \ne 0 \lor +\infty$. And $\frac{1}{n}$ diverges, we can conclude that $a_{n}$ will also diverge.
    \end{minipage}

    \item \textbf{Determine which series (or function) is greater}

        \begin{itemize}
            \item \textbf{Subtraction}: Given two functions $f(x) = \frac{1}{x}$ and $g(x) = \frac{x^4 + 6}{x^5 + 4}$, we want to compare them by considering the function $h(x) = f(x) - g(x)$:

\[
h(x) = f(x) - g(x) = \frac{1}{x} - \frac{x^4 + 6}{x^5 + 4}
\]

To compare these directly, it would be helpful to have a common denominator:

\[
h(x) = \frac{x^4 + 4 - (x^4 + 6)}{x(x^5 + 4)} = \frac{-2}{x(x^5 + 4)}
\]

Now, we can see that the sign of $h(x)$ depends on the sign of $x$ because the denominator $x(x^5 + 4)$ is always positive for $x \neq 0$. So:

\begin{itemize}
  \item For $x > 0$, $h(x) < 0$, which means $f(x) < g(x)$.
  \item For $x < 0$, $h(x) > 0$, which means $f(x) > g(x)$.
\end{itemize}
    \end{itemize}

    \item \textbf{Alternating Series}
      Any series whose terms alternate between positive and negative values is called an alternating series. An alternating series can be written in the form 
      \begin{align*}
          \sum_{n=1}^{\infty} (-1)^{n+1} b_n = b_1 - b_2 + b_3 - b_4 + \cdots
      .\end{align*}
      or
      \begin{align*}
          \sum_{n=1}^{\infty} (-1)^n b_n = -b_1 + b_2 - b_3 + b_4 - \cdots
      .\end{align*}
      Where  $b_n > 0$  for all positive integers $n$.
  \item \textbf{alternating series test (Leibniz criterion)}
         An alternating series of the form
        \[
        \sum_{n=1}^{\infty} (-1)^{n+1} b_n \quad \text{or} \quad \sum_{n=1}^{\infty} (-1)^n b_n
        \]
        converges if
        \begin{itemize}
            
            \item $0 < b_{n+1} \leq b_n\ \forall\ n \geq 1$
            \item $\lim_{n \to \infty} b_n = 0.$
    \end{itemize}
    \textbf{Note:} We remark that this theorem is true more generally as long as there exists some integer \( N \) such that \( 0 < b_{n+1} \leq b_n \) for all \( n \geq N \).
    \bigbreak \noindent 
    \textbf{Additional note:} The AST allows us to consider just the positive terms to check for these two conditions because if a series of decreasing positive terms that approach zero is alternated in sign, the alternating series will converge. This is a special property of alternating series that does not generally hold for non-alternating series.

    \item \textbf{Show decreasing (For the AST)}: Consider the series
        \begin{align*}
            \summation{\infty}{n=1}\ \frac{(-1)^{n+1}}{n^{2}}\ 
        .\end{align*}
        \bigbreak \noindent 
        So you see we have $b_{n}=  \frac{1}{n^{2}}$. For the AST, we must show that this is decreasing. If $b_{n+1} = \frac{1}{(n+1)^{2}}$. Then we see
        \begin{align*}
           \frac{1}{(n+1)^{2}} < \frac{1}{n^{2}}
        .\end{align*}
        \bigbreak \noindent 
        Thus it is decreasing for $n \geq 1$ ($b_{n+1} < b_{n}$)
        \blacksquare
    \item \textbf{Remainders in alternating series}
        Consider an alternating series of the form
        \[
        \sum_{n=1}^{\infty} (-1)^{n+1} b_n \quad \text{or} \quad \sum_{n=1}^{\infty} (-1)^n b_n,
        \]
        that satisfies the hypotheses of the alternating series test. Let \( S \) denote the sum of the series and \( S_N \) denote the \( N \)-th partial sum. For any integer \( N \geq 1 \), the remainder \( R_N = S - S_N \) satisfies
        \[
        \lvert R_N \rvert \leq b_{N+1}.
        \]
        This tells us that if we stop at the $N^{th}$ term, the error we are making is at most the size of the next term
    \item \textbf{Absolute and conditional convergence}
        \begin{itemize}
            \item A series \(\sum_{n=1}^{\infty} a_n\) exhibits absolute convergence if \(\sum_{n=1}^{\infty} |a_n|\) converges.
            \item A series \(\sum_{n=1}^{\infty} a_n\) exhibits conditional convergence if \(\sum_{n=1}^{\infty} a_n\) converges but \(\sum_{n=1}^{\infty} |a_n|\) diverges.
            \item If $\summation{\infty}{n=1}\ \lvert a_{n} \rvert\ $ converges then $\summation{\infty}{n=1}\ a_{n}\ $ converges
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Note:} if $\abs{a_{n}}$ diverges, we cannot have absolute convergence, thus we must examine to see if normal $a_{n}$ converges, in which case we would have conditional convergence
    \item \textbf{Ratio test}
       Let \(\sum_{n=1}^{\infty} a_n\) be a series with nonzero terms. Let
       \begin{align*}
           \rho = \lim_{n \to \infty} \left| \frac{a_{n+1}}{a_n} \right|.
       .\end{align*}
        Then:
        \begin{enumerate}[label=\roman*.]
            \item If \(0 \leq \rho < 1\), then \(\sum_{n=1}^{\infty} a_n\) converges absolutely.
            \item If \(\rho > 1\) or \(\rho = \infty\), then \(\sum_{n=1}^{\infty} a_n\) diverges.
            \item If \(\rho = 1\), the test does not provide any information.
        \end{enumerate}
        \bigbreak \noindent 
        \textbf{Note:} The ratio test is useful for series whose terms involve factorials
    \item \textbf{Root test}
        Consider the series \(\sum_{n=1}^{\infty} a_n\). Let
        \begin{align*}
            \rho = \lim_{n \to \infty} \sqrt[n]{|a_n|}.
        .\end{align*}
        \begin{enumerate}[label=\roman*.]
            \item If \(0 \leq \rho < 1\), then \(\sum_{n=1}^{\infty} a_n\) converges absolutely. 
            \item If \(\rho > 1\) or \(\rho = \infty\), then \(\sum_{n=1}^{\infty} a_n\) diverges. 
            \item If \(\rho = 1\), the test does not provide any information.
        \end{enumerate}
        \bigbreak \noindent 
        \textbf{Note:} The root test is useful for series whose terms involve exponentials
    \end{itemize}

    \pagebreak \bigbreak \noindent 
    \subsection{\LARGE Chapter 6 Key equations}
    \begin{itemize}
        \item \textbf{Euler definition for $e$}
            \begin{align*}
                &e^{a} = \lim\limits_{n \to \infty}{\left(1+\frac{a}{n}\right)^{n}} \\
                &\frac{1}{e^{a}} = \lim\limits_{n \to \infty}{\left(1+\frac{-a}{n}\right)^{n}} \\ 
                &\frac{1}{e^{a}} = \lim\limits_{n \to \infty}{\left(\frac{n}{n+a}\right)^{n}}
            .\end{align*}
        \item \textbf{Other definition for $e $}
            \begin{align*}
                &e = \summation{\infty}{n=0}\ \frac{1}{n!}\  \\
                &e-1 = \summation{\infty}{n=1}\ \frac{1}{n!}\ 
            .\end{align*}
    \end{itemize}

    \pagebreak \bigbreak \noindent 
    \section{\LARGE Vectors}
    \bigbreak \noindent 
    \subsection{Vector vocab}
    \begin{itemize}
        \item A \textbf{vector} is two pieces of information. 
        \begin{enumerate}
            \item Length 
            \item Direction (Magnitude)
        \end{enumerate}
    \end{itemize}

    \bigbreak \noindent 
    \subsection{Vector notation}
    \begin{itemize}
        \item \textbf{Defining a vector}                
            \begin{align*}
                \vec{v} = [x,y] \text{ or } 
                \begin{bmatrix}
                    x \\ y
                \end{bmatrix}
            .\end{align*}
        \item \textbf{Length of a vector}
            \begin{align*}
                || \vec{v} || = \sqrt{x^{2} + y^{2}}
            .\end{align*}
        \item \textbf{Vector addition}
            Suppose we have two vectors $\vec{v} = \begin{bmatrix} x_{1} \\ y_{1} \end{bmatrix} $ and $\vec{u} = \begin{bmatrix} x_{2} \\ y_{2} \end{bmatrix} $. Then
            \begin{align*}
                \vec{v}  +\vec{u} = \begin{bmatrix} x_{1} + x_{2} \\ y_{1} + y_{2} \end{bmatrix}   = \vec{c}             
            .\end{align*}
            \textbf{Note:} we call this new vector the \textbf{resultant}
        \item \textbf{Multiplying by a scalar}
            Suppose we have the vector $\vec{v} = \begin{bmatrix} x \\ y \end{bmatrix} $. Then
            \begin{align*}
               2\vec{v}  = \begin{bmatrix} 2x \\ 2y \end{bmatrix}
            .\end{align*}
        \item \textbf{Vector subtraction}
            \begin{align*}
                \vec{v} - \vec{u} = \begin{bmatrix} x_{1} - x_{2} \\ y_{1} - y_{2} \end{bmatrix}
            .\end{align*}
        \item \textbf{Vector in three dimensions}
            \begin{align*}
                \vec{v} = \begin{bmatrix} x \\ y \\ z \end{bmatrix}
            .\end{align*}
        \item \textbf{Length of a vector in three dimensions}
            \begin{align*}
                =\sqrt{x^{2} + y^{2} + z^{2}}
            .\end{align*}
            \textbf{Note:} The length of a  vector in $n$ dimensions is the square root of the squares of all the components
        \item \textbf{Definition for $\mathbb{R}^{n}$}: $\mathbb{R}^{n}$ is the set of all $n-tuples$ of real numbers  
            \begin{align*}
                &\vec{v} = [v_{1}, v_{2}]\ \vec{v} \in \mathbb{R}^{2} \\
                &\vec{u} = [u_{1}, u_{2},u_{3}]\ \vec{u} \in \mathbb{R}^{3} \\
                &\vec{w} = [w_{1}, w_{2},w_{3}, w_{n}]\ \vec{w} \in \mathbb{R}^{n} \\
            .\end{align*}
    \end{itemize}










\end{document}
