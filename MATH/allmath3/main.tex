\documentclass{report}

\input{~/dev/latex/template/preamble.tex}
\input{~/dev/latex/template/macros.tex}

\title{\Huge{}}
\author{\huge{Nathan Warner}}
\date{\huge{}}
\fancyhf{}
\rhead{}
\fancyhead[R]{\itshape Warner} % Left header: Section name
\fancyhead[L]{\itshape\leftmark}  % Right header: Page number
\cfoot{\thepage}
\renewcommand{\headrulewidth}{0pt} % Optional: Removes the header line
%\pagestyle{fancy}
%\fancyhf{}
%\lhead{Warner \thepage}
%\rhead{}
% \lhead{\leftmark}
%\cfoot{\thepage}
%\setborder
% \usepackage[default]{sourcecodepro}
% \usepackage[T1]{fontenc}

% Change the title
\hypersetup{
    pdftitle={Math 3}
}

\begin{document}
    % \maketitle
        \begin{titlepage}
       \begin{center}
           \vspace*{1cm}
    
           \textbf{Undergraduate Topics in Mathematics 3} \\
           Proof writing, The theory of sets, Axiomatic geometry, Numerical analysis
    
           \vspace{0.5cm}
            
                
           \vspace{1.5cm}
    
           \textbf{Nathan Warner}
    
           \vfill
                
                
           \vspace{0.8cm}
         
           \includegraphics[width=0.4\textwidth]{~/niu/seal.png}
                
           Computer Science \\
           Northern Illinois University\\
           United States\\
           
                
       \end{center}
    \end{titlepage}
    \tableofcontents
    \pagebreak 
    \unsect{Proofs}
    \bigbreak \noindent 
    \subsection{Intro to proof writing, intuitive proofs}
    \begin{itemize}
        \item \textbf{Intro to definitions, propositions and proofs: the chessboard problem}: Suppose you have a chessboard (8$\times$8 grid of squares) and a bunch of dominoes (2$\times$1 block of squares), so each domino can perfectly cover two squares of the chessboard.
            \bigbreak \noindent 
            Note that with 32 dominoes you can cover all 64 squares of the chessboard. There are many different ways you can place the dominoes to do this, but one way is to cover the first column by 4 dominoes end-to-end, cover the second column by 4 dominoes, and so on
            \bigbreak \noindent 
            Math runs on definitions, so let’s give a name to this idea of covering all the squares. Moreover, let’s not define it just for 8 $\times$ 8 boards — let’s allow the definition to apply to boards of other dimensions
            \bigbreak \noindent 
            \textbf{Definition.} A perfect cover of an $m\times n$ board with 2 $\times$ 1 dominoes is an arrangement of those dominoes on the chessboard with no squares left uncovered, and no dominoes stacked or left hanging off the end.
            \bigbreak \noindent 
            As we demonstrated above, there exist perfect covers of the 8 $\times$ 8 chessboard. This is a book about proofs, so let’s write this out as a proposition (something which is true and requires proof) and then let’s write out a formal proof of this fact.
            \bigbreak \noindent 
            \textbf{Proposition.} There exists a perfect cover of an 8 $\times$ 8 chessboard.
            \bigbreak \noindent 
            This proposition is asserting that "there exists" a perfect cover. To say "there exists" something means that there is at least one example of it. Therefore, any proposition like this can be proven by simply presenting an example which satisfies the statement.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Observe that the following is a perfect cover.
            \bigbreak \noindent 
            \fig{.7}{./figures/1.png}
            \bigbreak \noindent 
            We have shown by example that a perfect cover exists, completing the proof. $\blacksquare$
            \bigbreak \noindent 
            We typically put a small box at the end of a proof, indicating that we have completed our argument. This practice was brought into mathematics by Paul Halmos, and it is sometimes called the Halmos tombstone
            \bigbreak \noindent 
            One apocryphal story is that Halmos regarded proofs as living until proven. Once proven, they have been defeated — killed. And so he wrote a little tombstone to conclude his proof
            \bigbreak \noindent 
            What if I cross out the bottom-left and top-left squares, can we still perfectly cover the 62 remaining squares?
            \bigbreak \noindent 
            As you can probably already see, the answer is yes. For example, the first column can now be covered by 3 dominoes and the other columns can be covered by 4 dominoes each.
            \bigbreak \noindent 
            What if I cross out just one square, like the top-left square? Can this be perfectly covered? 
            \bigbreak \noindent 
            The answer is no
            \bigbreak \noindent 
            \textbf{Proposition.} If one crosses out the top-left square of an 8 $\times$ 8 chessboard, the remaining squares can not be perfectly covered by dominoes.
            \bigbreak \noindent 
            \textbf{Proof Idea}. The idea behind this proof is that one domino, wherever it is placed, covers two squares. And two dominoes must cover four squares. And three cover six. In general, the number of squares covered — 2, 4, 6, 8, 10, etc. — is always an even number. This insight is the key, because the number of squares left on this chessboard is 63— an odd number
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Since each domino covers 2 squares and the dominoes are non-overlapping, if one places our k dominoes on the board, then they will cover $2k$ squares, which is always an even number. Therefore, a perfect cover can only cover an even number of squares. Notice, though, that the board has 63 remaining squares, which is an odd number. Thus, it can not be perfectly covered.
            \bigbreak \noindent 
            What if I take an 8$\times$8 chessboard and cross out the top-left and the bottom-right squares? Then can it be covered by dominoes?
            \bigbreak \noindent 
            \textbf{Proposition.} If one crosses out the top-left and bottom-right squares of an 8 $\times$ 8 chessboard, the remaining squares can not be perfectly covered by dominoes.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Observe that the chessboard has 62 remaining squares, and since every domino covers two squares, if a perfect cover did exist it would require
            \begin{align*}
                \frac{62}{2} = 31 \text{ dominoes}
            .\end{align*}
            \bigbreak \noindent 
            Also observe that every domino on the chessboard covers exactly one white square and exactly one black square
            \bigbreak \noindent 
            Thus, whenever you place 31 non-overlapping dominoes on a chessboard, they will collectively cover 31 white squares and 31 black squares.
            \bigbreak \noindent 
            Next observe that since both of the crossed-out squares are white squares, the remaining squares consist of 30 white squares and 32 black squares. Therefore, it is impossible to have 31 dominoes cover these 62 squares. $\blacksquare$
        \item \textbf{Naming Results}: So far, all of our results have been called "propositions." Here’s the run-down on the naming of results:
            \begin{itemize}
                \item A theorem is an important result that has been proved.
                \item A proposition is a result that is less important than a theorem. It has also been proved.
                \item A lemma is typically a small result that is proved before a proposition or a theorem, and is used to prove the following proposition or theorem.
                \item A corollary is a result that is proved after a proposition or a theorem, and which follows quickly from the proposition or theorem. It is often a special case of the proposition or theorem.
            \end{itemize}
            All of the above are results that have been proved — a conjecture, though, has not.
            \begin{itemize}
                \item A conjecture is a statement that someone guesses to be true, although they are not yet able to prove or disprove it.
            \end{itemize}
        \item \textbf{Conjectures and counterexamples}: As an example of a conjecture, suppose you were investigating how many regions are formed if one places $n$ dots randomly on a circle and then connects them with lines.
            \bigbreak \noindent 
            \fig{.7}{./figures/2.png}
            \bigbreak \noindent 
            At this point, if you were to conjecture how many regions there will be for the $n = 6$ case, your guess would probably be 32 regions — the number of regions certainly seems to be doubling at every step. In fact, if it kept doubling, then with a little more thought you might even conjecture a general answer: that n randomly placed dots form $2^{n-1}$ regions;
            \bigbreak \noindent 
            Surprisingly, this conjecture would be incorrect. One way to disprove a conjecture is to find a counterexample to it. And as it turns out, the $n = 6$ case is such a counterexample
            \bigbreak \noindent 
            \fig{.8}{./figures/3.png}
            \bigbreak \noindent 
            This counterexample also underscores the reason why we prove things in math. Sometimes math is surprising. We need proofs to ensure that we aren’t just guessing at what seems reasonable. Proofs ensure we are always on solid ground. Further, proofs help us understand why something is true — and that understanding is what makes math so fun
            \bigbreak \noindent 
            Lastly, we study proofs because they are what mathematicians do
        \item \textbf{The pingeonhole principal}
            \bigbreak \noindent 
            \textbf{principal}. The principal has a simple form and a general form. Assume $k$ and $n$ are positive integers
            \bigbreak \noindent 
            \textbf{Simple form:} If $n + 1$ objects are placed into $n$ boxes, then at least one box has at least two objects in it.
            \bigbreak \noindent 
        \textbf{General form:} If $kn + 1$ objects are placed into $n$ boxes, then at least one box has at least $k + 1$ objects in it.
            \bigbreak \noindent 
            \textbf{Birthday example}: If there are 330 million people in the united states, how many U.S. residents are guaranteed to have the same birthday according to the pigeonhole principal?
            \bigbreak \noindent 
            To determine this, let’s see what would happen if each date of the year had exactly the same number of people born on it
            \begin{align*}
                \frac{330\times10^{6}}{366} = 901,639.344
            .\end{align*}
            \bigbreak \noindent 
            Since 901,639.344 people are born on an average day of the year, we should be able round up and say that at least one day of the year has had at least 901,640 people born on it. That is, with the pigeonhole principal we should be able to prove that there are at least 901,640 people in the USA with the same birthday
            \bigbreak \noindent 
            \textbf{Solution.} Imagine you have one box for each of the 366 dates of the (leap) year, and each person in the U.S. is considered an object. Put each person in the box corresponding to their birthday. By the general form of the pigeonhole principal (with $n = 366$ and $k = 901, 639$ and thus $k + 1 = 901, 640$), any group of
            \begin{align*}
                (901, 639)(366) + 1
            .\end{align*}
            \bigbreak \noindent 
            people is guaranteed to contain 901,640 people which have the same birthday.
        \item \textbf{Another pingeonhole example}:
            \bigbreak \noindent 
            \textbf{Proposition.} Given any five numbers from the set $\{1, 2, 3, 4, 5, 6, 7, 8\}$, two of the chosen numbers will add up to 9.
            \bigbreak \noindent 
            We may think to start by listing the pairs that sum to 9. We have
            \begin{align*}
                1 &+ 8 \\ 
                2 &+ 7 \\
                3 &+ 6 \\
                4 &+ 5 
            .\end{align*}
            And of course $8+1,7+2,..$ etc. We see we have four sums, we choose these sums as our boxes. If each of the four sums is a box, and each number is an object, then we are placing five objects into four boxes 
            \bigbreak \noindent 
            \textbf{Proof.} Let one box correspond to the numbers 1 and 8, a second box correspond to 2 and 7, another to 3 and 6, and a final box to 4 and 5. Notice that each of these pairs adds up to 9.
            \bigbreak \noindent 
            Given any five numbers from $\{1, 2, 3, 4, 5, 6, 7, 8\}$, place each of these five numbers in the box to which it corresponds; for example, if your first number is a 6, then place it in the box labeled "3 and 6." Notice that we just placed five numbers into four boxes. Thus, by the simple form of the pigeonhole principal, there must be some box which contains two numbers in it. These two numbers add up to 9, as desired
        \item \textbf{Another pingeonhole example}:
            \bigbreak \noindent 
            \textbf{Proposition.} Given any collection of 10 points from inside the following square (of side-length 3), there must be at least two of these points which are of distance at most $\sqrt{2}$
            \bigbreak \noindent 
            \fig{1}{./figures/4.png}
            \bigbreak \noindent 
            \textbf{Proof.} Divide the $3\times 3$ square into nine $1\times 1$ boxes. Placing 10 arbitrary points amongst the boxes gaurantees that at least one box will have at least two points. We observe that the farthest these two points can be from each other is when they sit in two corners such that a diagonal line through the box hits both points. The length of this line is given by
            \begin{align*}
                \sqrt{1^{2} + 1^{2}} = \sqrt{2}
            .\end{align*}
            Thus, we observe that the maximum distance of these two points is $\sqrt{2}$ $\blacksquare$
        \item \textbf{Another pingeonhole example}:
            \bigbreak \noindent 
            \textbf{Proposition.} Given any 101 integers from $\{1, 2, 3, . . . , 200\}$, at least one of these numbers will divide another
            \bigbreak \noindent 
            \textbf{Solution.} As we ponder about how to construct 100 boxes from the properties of the set, we may wonder how the even and odd members partition this set. Call $S = \{1,2,3,...,200\} $, $E=\{2,4,6,...,200\} $, and $O = \{1,3,5,...,199\} $. Note that $E \cup O = S$. We notice that these two sets are arithmetic sequences, each with difference two. If $a_{n} = a_{1} +  (n-1)d$, then 
            \begin{align*}
                n &= \frac{a_{n} - a_{1}}{2} + 1 \\
                \implies n&= 100
            .\end{align*}
            \bigbreak \noindent 
            Let's make the odd numbers are boxes. We note that any even number $\ell$ can be written as $\ell = 2^{k}m$, where $m$ is odd, and $k$ is the highest power of two that divides $\ell$. Thus, in box $m$, we place any number of the form $2^{k}m$
            \bigbreak \noindent 
            \fig{.5}{./figures/5.png}
            \bigbreak \noindent 
            For any pair of numbers in the same box, the smaller divides the larger. Picking 101 numbers from the set $S$, and only 100 boxes... by the pigeonhole principal we must have atleast two numbers in the same box, and thus the smaller divides the larger. $\blacksquare$.
            \bigbreak \noindent 
            \textbf{Formal proof.} 
            \textbf{Proof.} For each number $n$ from the set $\{1, 2, 3, \dots, 200\}$, factor out as many 2's as possible, and then write it as $n = 2^k \cdot m$, where $m$ is an odd number. So, for example, $56 = 2^3 \cdot 7$, and $25 = 2^0 \cdot 25$. Now, create a box for each odd number from 1 to 199; there are 100 such boxes.
            \bigbreak \noindent 
            Remember that we are given 101 integers and we want to find a pair for which one divides the other. Place each of these 101 integers into boxes based on this rule:
            \bigbreak \noindent 
            \begin{quote}
                If the integer is $n$, then place it in Box $m$ if $n = 2^k \cdot m$ for some $k$.
            \end{quote}
            \bigbreak \noindent 
            For example, $72 = 2^3 \cdot 9$ would go into Box 9, because that's the largest odd number inside it.
            \bigbreak \noindent 
            Since 101 integers are placed in 100 boxes, by the pigeonhole principal (principal 1.5) some box must have at least 2 integers placed into it; suppose it is Box $m$. And suppose these two numbers are $n_1 = 2^k \cdot m$ and $n_2 = 2^\ell \cdot m$, and let’s assume the second one is the larger one, meaning $\ell > k$. Then we have now found two integers where one divides the other; in particular $n_1$ divides $n_2$, because:
            \[
                \frac{n_2}{n_1} = \frac{2^\ell \cdot m}{2^k \cdot m} = 2^{\ell - k}.
            \]
            This completes the proof.$\blacksquare$
        \item \textbf{Another pigeonhole example}
            \bigbreak \noindent 
            \textbf{Proposition}. Suppose $G$ is a graph with $n \geq 2$ vertices. Then $G$ contains two vertices which have the same degree.
            \bigbreak \noindent 
            We start by observing that the minimum degree is zero, and the maxmium is $n-1$. It could happen that a vertex is connected to no other vertices, and a vertex could be connected to all other vertices. If a vertex is connected to all other vertices, than it has degree $n-1$, because it has an edge going to all vertices but itself. Thus, we have our boxes. But you may notice that we have $n$ boxes for $n$ vertices. This may seem like a problem, but after some thought you may see that it is not possible for the zero box and the $n-1$ box to both be used for a specific graph $G$. Thus, we have only $n-1$ boxes for $n$ vertices.
            \bigbreak \noindent 
            The rest of the proof is left as an exercise for the reader.
        \item \textbf{Classic Geometry Theorem}. Given any two points on the sphere, there is a great circle that passes through those two points. 
            \bigbreak \noindent 
            Given a sphere, there are infinitely many ways to cut it in half, and each of these paths of the knife is called a great circle
            \bigbreak \noindent 
            \fig{.5}{./figures/6.png}
        \item \textbf{Final pigeonhole example}
            \bigbreak \noindent 
            \textbf{Proposition}. If you draw five points on the surface of an orange in marker, then there is always a way to cut the orange in half so that four points (or some part of the point) all lie on one of the halves.
            \bigbreak \noindent 
            \textbf{\textit{Proof}}. Consider an orange with five points drawn on it. Pick any two of these points, and call them $p$ and $q$. By the Classic Geometry Theorem, there exists a great circle passing through these points; angle your knife to cut along this great circle. Because the points are drawn in marker, they are wide enough so that part of these two points appear on both halves.
            \bigbreak \noindent 
            Now consider the remaining three points and the two halves that you just cut the orange into. Consider these three points to be objects and the halves to be boxes; by the simple form of the pigeonhole principal, at least two of these three points are on the same orange half. These two, as well a portion of $p$ and of $q$, give four points or partial points, as desired $\quad \blacksquare $



    \end{itemize}

    \pagebreak 
    \subsection{Direct proofs}
    \begin{itemize}
        \item \textbf{Fact about integers}: The sum of integers is an integer, the difference of integers is an integer, and the product of integers is an integer. Also, every integer is either even or odd.
            \bigbreak \noindent 
            We are calling these facts because, while they are true and one could prove them, we will not be proving them here
        \item \textbf{Even and odd integers}: An integer $n$ is \textit{even} if $n=2k$ for some integer $k $
            \bigbreak \noindent 
            An integer $n$ is \textit{odd} if $n=2k+1$ for some integer $k$
        \item \textbf{Sum of two even integers}
            \bigbreak \noindent 
            \textbf{Proposition.} The sum of two even integers is even
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $n$ and $m$ are even integers, then $n = 2a$, and $m = 2b$ for some integers $a$ and $b$. Furthermore,
            \begin{align*}
                n + m &= 2a + 2b = 2(a+b)
            .\end{align*}
            \bigbreak \noindent 
            Since the sum of two integers is itself an integer, then we have two times an integer, which satisfies the definition of an even number. Hence, the sum $n + m$ is even, where $n$ and $m$ are even. $\int$
        \item \textbf{More on propositions}: We can rewrite our propositions to take the form
            \begin{quote}
               if \textit{statement} is true, then \textit{other statement} is also true 
            \end{quote}
            For example, 
            \begin{quote}
               if $m$ and $n$ are even, then $m+n$ is also even
            \end{quote}
            \bigbreak \noindent 
            Another way to summarize such statements is this:
            \begin{quote}
               \textit{some statement} is true implies \textit{some other statement} is true. 
            \end{quote}
            Which allows us to use the implies symbol $\implies$. For example, 
            \begin{quote}
               $m$ and $n$ being even $\implies$ $m+n$ is even 
            \end{quote}
            We have the general form $P \implies Q$, where $P$  and $Q$ are statements
            \bigbreak \noindent 
             However, when writing formally, like when writing up the final draft of your homework, these symbols are rarely used. You should write out solutions with words, complete sentences, and proper grammar. Pick up any of your math textbooks, or look online at math research articles, and you will find that such practices are standard.
        \item \textbf{The structure of direct proofs}: A direct proof is a way to prove a "$P \Rightarrow Q$" proposition by starting with $P$ and working your way to $Q$. The "working your way to $Q$" stage often involves applying definitions, previous results, algebra, logic, and techniques. Here is the general structure of a direct proof:
            \bigbreak \noindent 
            \begin{mdframed}
                \textbf{Proposition}. $P\implies Q$
                \bigbreak \noindent 
                \textbf{\textit{Proof.}} Assume $P$
                \bigbreak \noindent 
                \hspace{1cm}\textit{Explain what $P $ means by applying definitions and/or other results}
                \begin{align*}
                    &\vdots \quad \text{Apply algebra,} \\
                    &\vdots \quad \text{logic techniques}
                .\end{align*}
                \bigbreak \noindent 
                \hspace{1cm} \textit{Hey look, that's what $Q$ means}
                \bigbreak \noindent 
                Therefore $Q$ \hspace{10cm} $\blacksquare $
            \end{mdframed}
        \item \textbf{Proof by cases}: A related proof strategy is proof by cases. This is a "divide and conquer" strategy where one breaks up their work into two or more cases 
            \bigbreak \noindent 
            The below example of proof by cases will also give us more practice with direct proofs involving definitions. Indeed, when you break up a problem in two parts, those two parts still need to be proven, and a direct proof is often the way to tackle each of those parts
            \bigbreak \noindent 
            \textbf{Proposition.} If $n$ is an integer, then $n^{2} + n + 6$ is even.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $n$ is an integer, then either $n$ is even or it is odd.
            \begin{tcolorbox}[penv]
                \textit{Case I}. Assume $n$ is even, then $n=2m$ for some integer $m$. Thus, we have
                \begin{align*}
                    n^{2} + n + 6 &= (2m)^{2} + 2m + 6 \\
                      &=4m^{2} + 2m + 6 \\
                      &= 2 (2m^{2} + m + 3)
              .\end{align*}
              \bigbreak \noindent 
              Observe that $2m^{2} + m + 3 \in \mathbb{Z}$. Thus, we have two times an integer, which satisfies the definition of an even number.
              \bigbreak \noindent 
              \textit{Case 2.} Assume $n$ is odd, then $n=2m+1$ for some integer $m$. Thus,
              \begin{align*}
                  n^{2} + n + 6 &= (2m+1)^{2} + 2m + 1 + 6 \\
                                &=4m^{2} + 4m + 1 + 2m + 7 \\
                                &= 4m^{2} + 6m + 8 \\
                                &= 2(2m^{2} + 3m + 4)
              .\end{align*}
              \bigbreak \noindent 
              Since $m$ is an integer, $2m^{2} + 3m +4$ is an integer, and we again have two times an integer, which is an even integer.
              \bigbreak \noindent 
              We have shown that $n^{2} + n  + 6 $ is even whether $n$ is even or odd. Combined, this shows that $n^{2} + n + 6$ is even for all integers $n$ $\quad \blacksquare$
                
            \end{tcolorbox}
        \item \textbf{Proof by exhaustion (brute force proof)}: A proof by cases cuts up the possibilities into more manageable chunks. If the theorem refers to a collection of elements and your proof is simply checking each element individually, then it is called a \textit{proof by exhaustion} or a \textit{brute force proof}
        \item \textbf{Divisibility}: An integer \(a\) is said to divide an integer \(b\) if \(b = ak\) for some integer \(k\). When \(a\) does divide \(b\), we write \(a \mid b\), and when \(a\) does not divide \(b\), we write \(a \nmid b\).
            \bigbreak \noindent 
            \textbf{Note:} A common mistake is to see something like "$2 \mid 8$" and think that this equals 4. The expression "$a \mid  b$" is either true or false
            \bigbreak \noindent 
            \textbf{Remark.} $a\mid 0$ for any integer $a$, because $0 = a \cdot 0$ for every such $a$
            \bigbreak \noindent 
            $0\nmid b$ for any nonzero integer $b$, because for any such $b$, we have $b\ne 0 \cdot k $ for any integer $k$
        \item \textbf{The transitive property of divisibility}:
            \bigbreak \noindent 
            \textbf{Proposition}. Let $a,b$, and $c$ be integers, if $a\mid b$ and $b \mid c$, then $a\mid c$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $a,b$, and $c$ are integers. Further assume that $a\mid b$, and $b\mid c$
            \penv {
                By the definition of divisibility, $a\mid b$ and $b \mid c$ implies $b = ak$ for some integer $k$, and $c = bs$ for some integer $s$
                \bigbreak \noindent 
                If $a\mid c$, we require that $c = ar$ for some integer $r$
                \bigbreak \noindent 
                \begin{align*}
                    b &= ak  \\
                    \implies c &= (ak)s \\
                    \implies c&= a(ks)
                .\end{align*}
                \bigbreak \noindent 
            }
            Since $k$ and $s$ are integers, then their product $ks$ is itself an integer. Let $r = ks$. Then $c  = ar$, which is precisely the definition of divisiblity, and we conclude that $a\mid c$. $\quad \blacksquare$
        \item \textbf{The division algorithm}:
            \bigbreak \noindent 
            \textbf{Theorem.} For all integers $a$ and $m $ with $m>0 $, there exist unique integers $q $ and $r $ such that
            \begin{align*}
                a = mq + r
            .\end{align*}
            Where $0 \leq r < m$. We call $q$ the \textit{quotient} and $r$ the \textit{remainder}
        \item \textbf{Common divisor, greatest common divisor}:
            Let $a$ and $b$ be integers. If $c \mid a$ and $c \mid b$, then $c$ is said to be a common divisor of $a$ and $b$.
            \bigbreak \noindent 
            The greatest common divisor of $a$ and $b$ is the largest integer $d$ such that $d \mid a$ and $d \mid b$. This number is denoted $\text{gcd}(a, b)$.
            \bigbreak \noindent 
            Note that there is one pair of integers that does not have a greatest common divisor; if $a = 0$ and $b = 0$, then every positive integer $d$ is a common divisor of $a$ and $b$. This means that no divisor is the greatest divisor, since you can always find a bigger one. Thus, in this one case, $gcd(a, b)$ does not exist
        \item \textbf{Bezout's identity}: If $a$ and $b$ are positive integers, then there exist integers $k$ and $\ell$ such that
            \begin{align*}
                \gcd{(a, b)} = ak + b\ell
            .\end{align*}
            \bigbreak \noindent 
            As an example, suppose $a=12$ and $b=20$, then $\gcd{(12,20)} =4$, and we have
            \begin{align*}
                4 &= 12k + 20 \ell  \\
                \implies \ell &= \frac{1}{5}-\frac{3}{5}k
            .\end{align*}
            Let $k=2$, then we see $\ell = -1$. We see that there are infinitely many solutions, $k=2, \ell = -1$ is just one of them. Nevertheless, this theorem simply says that at least one solution must exist. 
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $a$ and $b$ are fixed positive integers, notice that the expression $ax + by$ can take many values for integers $x$ and $y$. Let $d$ be the \textit{smallest positive integer} that $ax + by$ can be equal. Let $k$ and $\ell$ be the $x$ and $y$ that obtain this $d$. That is, 
            \begin{align*}
                d = ak + b\ell
            .\end{align*}
            \penv{
               We now must show that $d$ is a common divisor of $a$ and $b$, and then that it is the \textit{greatest common divisor}
               \bigbreak \noindent 
               \textit{Part 1 (common divisor)}. $d$ is a common divisor of $a$ and $b$ if $d\mid a$ and $d\mid b$. To see that $d \mid a$, we examine the division algorithm. We know that there exsits unique integers $q $ and $r $ such that
               \begin{align*}
                   a = dq + r
               .\end{align*}
               With $0 \leq r < d$. We have
               \begin{align*}
                   r &= a-dq \\
                     &=a-(ak + b\ell)q \\
                     &=a-akq -b\ell q \\
                     &= a(1-kq) + b(-\ell q)
               .\end{align*}
               Observe that $1-kq$, and $-\ell q$ are both integers, Since $r$ is written in the form $ax + by$, $0 \leq r < d$, and $d$ is the smallest positive integer that this form can produce (with the given $a,b$), it must be that $r=0$. Thus,
               \begin{align*}
                   a = dq + 0 = dq
               .\end{align*}
               And we see that $d\mid a$. A similar argument will show that $d\mid b$ as well. This proves that $d$ is a common divisor of $a$ and $b$.
               \bigbreak \noindent 
           }
           \penv{
               \textit{Part 2 (gcd)}. Assume that $d^{\prime}$ is some other common divisor of $a$ and $b$. We must show that $d^{\prime} \leq d$. If $d^{\prime}$ is a common divisor of $a$ and $b$, then $d^{\prime} \mid a$ and $d^{\prime} \mid b$, which implies $a = d^{\prime}n$, and $b = d^{\prime} m$, for some integers $n$ and $m$. If $d = ak + b\ell$, then
               \begin{align*}
                   d &= d^{\prime}nk + d^{\prime}m\ell \\
                   &=d^{\prime}(nk + m\ell) \\
                   \implies d^{\prime} &=\frac{d}{nk + m\ell}
               .\end{align*}
               Since $n,k,m,\ell \in \mathbb{Z}$, it follows that $nk +m\ell \in \mathbb{Z}$. Thus, $d^{\prime} \leq d$.
           }
           \bigbreak \noindent 
           Therefore, we have shown that $d$ is not only a common divisor of $a$ and $b$, but that it is also the largest, and hence the $gcd$. Thus,
           \begin{align*}
               \gcd{(a,b)} = d = ak + b \ell
           .\end{align*}
           $\blacksquare$
           \bigbreak \noindent 
           A corollary from this result is that $\gcd{(ma, mb)} = m \gcd{(a,b)}$. If $\gcd{(a,b)} = ak + b\ell$, we have
           \begin{align*}
               \gcd{(ma,mb)} &= mak + mb\ell  \\
                             &=m(ak + b\ell) \\
                             &=m\gcd{(a,b)}
           .\end{align*}
       \item \textbf{Modulo and congruence}: 
           For integers \(a\), \(r\), and \(m\), we say that \(a\) is congruent to \(r\) modulo \(m\) and we write \(a \equiv r \pmod{m}\) if \(m \mid (a - r)\).
           \bigbreak \noindent 
           For example, $18 \equiv  4 \pmod{7}$ because $18 = 7(2) +4 $, we see that $7 \mid (18-4)$
           \bigbreak \noindent 
           If \(a\) divided by \(m\) leaves a remainder of \(r\), then \(a \equiv r \pmod{m}\). However, this is not the only way to have \(a \equiv r \pmod{m}\) — it is not required that \(r\) be the remainder when \(a\) is divided by \(m\); all that is required is that \(a\) and \(r\) have the same remainder when divided by \(m\). For example:
           \begin{align*}
               18 =11 \pmod{7}
           .\end{align*}
        \item \textbf{Properties of modular congruence}: Assume that $a, b, c, d$
            and $m$ are integers, $a \equiv b \pmod{m}$ and $c \equiv d\pmod{m}$. Then
            \begin{enumerate}[label=(\roman*)]
                \item $a + c  \equiv b + d \pmod{m} $ 
                \item $a - c  \equiv b - d \pmod{m} $ 
                \item $a \cdot  c  \equiv b \cdot  d \pmod{m} $ 
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof of property $i$}}. Assume that $a \equiv b \pmod{m}$, and $c \equiv d \pmod{m}$, we must show that $a + c \equiv b + d \pmod{m}$
            \penv{
                If $a\equiv b \pmod{m}$, then $m \mid a-b$, which implies $a-b = mk$ for some $k\in \mathbb{Z}$. Similarly, $c \equiv d \pmod{m} \implies m \mid c-d \implies c-d = m\ell$, for some $\ell \in \mathbb{Z}$. Adding these two equations yields
                \begin{align*}
                    (a-b) + (c-d) &= mk + m\ell \\
                    \implies (a+c) - (b + d) &= m(k+\ell)
                .\end{align*}
        }
        Since $k+\ell \in \mathbb{Z}$, then by the definition of divisibility
        \begin{align*}
            m \mid (a+c) - (b+d)
        .\end{align*}
        Which then by the definition of congruence
        \begin{align*}
            a+c \equiv b+d \pmod{m}
        .\end{align*}
        $\blacksquare$
        \bigbreak \noindent 
        \textbf{\textit{Proof of property $iii$}}. Assume $a \equiv b \pmod{m}$, and $c \equiv d \pmod{m}$
        \penv{
            From above we know it follows that $a - b = mk $, and $c-d = m\ell$, for $k,\ell \in \mathbb{Z}$. If $ ac \equiv bd \pmod{m}$, it must be that $ac -bd = ms$, for some $s\in \mathbb{Z}$. Let's see if we can derive $ac-bd$ in terms of what we know, namely $a-b$ and $c-d$. Amazingly,
            \begin{align*}
                ac -bd &= (a-b)c + (c-d)b \\
                &= mkc + m\ell b \\
                &= m(kc +\ell b)
            .\end{align*}
        }
        It then follows that
        \begin{align*}
            m \mid ac-bd
        .\end{align*}
        Thus,
        \begin{align*}
            ac \equiv bd \pmod{m}
        .\end{align*}
        $\blacksquare$
    \item \textbf{Prime and composite integers}: An integer $p \geq 2$ is prime if its only positive divisors are 1 and $p$. An integer $n \geq 2$ is composite if it is not prime. Equivalently, $n$ is composite if it can be written as $n = st$, where $s$ and $t$ are integers and $1 < s, t < n$.
        \bigbreak \noindent 
        \textbf{Note:} To be clear, "$1 < s, t < n$" means that both $s$ and $t$ are between 1 and $n$.
    \item \textbf{Properties of primes and divisibility}:
        \bigbreak \noindent 
        \textbf{Lemma}. Let \( a, b \) and \( c \) be integers, and let \( p \) be a prime:
        \begin{enumerate}[label=(\roman*)]
            \item If \( p \nmid a \), then \( \gcd(p, a) = 1 \).
            \item If \( a \mid bc \) and \( \gcd(a, b) = 1 \), then \( a \mid c \).
            \item If \( p \mid bc \), then \( p \mid b \) or \( p \mid c \) (or both).
        \end{enumerate}
        \bigbreak \noindent 
        \textbf{\textit{Proof of property $i$}}. Assume that $p$ does not divide $a$, then $p$ cannot possibly be a common divisor of $a$ and $p$, because it is not a divisor of $a$. 
        \bigbreak \noindent 
        Since $p \in \mathbb{P}\footnote{Where $\mathbb{P}$ is the family of primes}$, then the only divisors of $p$ are one and itself. Thus, the only option left is one. Hence, the greatest common divisor is one. $\blacksquare$
        \pagebreak \bigbreak \noindent 
        \textbf{\textit{Proof of property $ii$}}. Assume $a\mid bc$, and $\gcd{(a,b)} = 1$. Then, $bc = ar$ for some integer $r$, and by Bezout's identity, there exist some integers $k, \ell$ such that
        \begin{align*}
            \gcd{(a,b)} &= ak + b\ell \\
            \implies 1&= ak + b\ell 
        .\end{align*}
        If $a\mid c$, we require $c = as$, for some integer $s$. If we multiply the above expression by c, we get
        \begin{align*}
            c &= cak + cb\ell
        .\end{align*}
        Since we assumed $a\mid bc$, then it must be that $bc = ar$, for $r\in \mathbb{Z}$. Thus, we have
        \begin{align*}
            c &= cak + ar\ell \\
              &= a(ck + r\ell)
        .\end{align*}
        Since $c,k,r,\ell \in \mathbb{Z}$, the expression $ck+r\ell$ is also an integer, and by the definition of divisibility, it must be that $a\mid c$  $\quad \blacksquare $
        \bigbreak \noindent 
        \textbf{\textit{Proof of property $iii$}}. Assume that $p \mid bc$. Then there are two cases, either $p\mid b$, or $p\nmid b$.
        \bigbreak \noindent 
        \textit{Case I}. If $p\mid b$, then the statement is true and we are done
        \bigbreak \noindent 
        \textit{Case II}. If $p\nmid b$, then by property $i$, it must be that $\gcd{(p,b)} = 1$. By property $ii$, if $p \mid bc$, and $\gcd{(p,b)} = 1$, then it must be that $p \mid c$. $\quad \blacksquare$.
    \item \textbf{More on properties of congruence}: We return to congruence to examine the statement
        \begin{align*}
            ak \equiv bk \pmod{m} \stackrel{?}{\implies} a\equiv b \pmod{m}
        .\end{align*}
        \bigbreak \noindent 
        \textbf{Proposition (\textit{modular cancellation law})}. Let $a,b,k,m$ be integers. If $ak \equiv bk \pmod{m}$, and $\gcd{(m,k)} = 1$, then $a \equiv b \pmod{m}$
        \bigbreak \noindent 
        \textbf{\textit{Proof}}. Assume $ak \equiv bk\pmod{m}$, and $\gcd{(m,k)} =1$, then $m \mid ak-bk$, and $ak-bk = m\ell$, for some integer $\ell$. 
        \bigbreak \noindent 
        \penv{
            If $a\equiv b\pmod{m}$, then $m\mid a-b$, and $a-b = mr$, for some integer $r$. Since $ak \equiv bk\pmod{m}$, then it must be that
            \begin{align*}
                ak-bk &= m\ell \\
                \implies k(a-b) &= m\ell \\
                \implies a-b &= \frac{m\ell}{k}
            .\end{align*}
            Thus, we require $\frac{\ell}{k}$ to be an integer, it then follows that the proposition holds true.
            \bigbreak \noindent 
            We know that if $a\mid bc$, and $\gcd{(a,b)} = 1$, then $a\mid c$. Thus, since $k\mid m\ell$, and $\gcd{(m,k)} = 1$, it must be that $k\mid \ell$. Hence, $ \frac{\ell}{k} \in \mathbb{Z}$, and 
            \begin{align*}
                a-b = m\left(\frac{\ell}{k}\right)
            .\end{align*}
            And by the definition of divisibility, $m\mid a-b$, which implies $a \equiv b \pmod{m}$ $\quad \blacksquare$.
        }
    \item \textbf{Fermat's little theorem}: If $a$ is an integer and $p$ is a prime which does not divide $a$, then
        \begin{align*}
            a^{p-1} \equiv 1 \pmod{p}
        .\end{align*}
        \bigbreak \noindent 
        \textbf{\textit{Proof.}} 
        Assume that $a$ is an integer and $p$ is a prime which does not divide $a$. We begin by proving that when taken modulo $p$,
        \[
            \{a, 2a, 3a, \dots, (p-1)a\} \equiv \{1, 2, 3, \dots, p-1\}.
        \]
        To do this, observe that the set on the right has every residue modulo $p$ except $0$, and each such residue appears exactly once. Therefore, since both sets have $p-1$ elements listed, in order to prove that the left set is the same as the right set, it suffices to prove this:
        \begin{enumerate}
            \item No element in the left set is congruent to $0$, and
            \item Each element in the left set appears exactly once.
        \end{enumerate}
        In doing so, we will twice use the modular cancellation law (Proposition 2.18) to cancel out an $a$, and so we note at the start that by Lemma 2.17 part (i) we have $\gcd(p, a) = 1$.
        \bigbreak \noindent 
        \textbf{Step 1.} First we show that none of the terms in $\{a, 2a, 3a, \dots, (p-1)a\}$, when considered modulo $p$, are congruent to $0$. To do this, we will consider an arbitrary term $ia$, where $i$ is anything in $\{1, 2, 3, \dots, p-1\}$. Indeed, if we did have some
        \[
            ia \equiv 0 \pmod{p},
        \]
        which is equivalent to
        \[
            ia \equiv 0a \pmod{p},
        \]
        then by the modular cancellation law (Proposition 2.18) we would have
        \[
            i \equiv 0 \pmod{p}.
        \]
        That is, in order to have $ia \equiv 0 \pmod{p}$, that would have to have $i \equiv 0 \pmod{p}$. Therefore we are done with Step 1, since no $i$ from $\{1, 2, 3, \dots, p-1\}$ is congruent to $0$ modulo $p$.
        \bigbreak \noindent 
        \textbf{Step 2.} Next we show that every term in $\{a, 2a, 3a, \dots, (p-1)a\}$, when considered modulo $p$, does not appear more than once in that set. Indeed, if we did have
        \[
            ia \equiv ja \pmod{p},
        \]
        for $i$ and $j$ from $\{1, 2, 3, \dots, p-1\}$, then by the modular cancellation law (Proposition 2.18) we have
        \[
            i \equiv j \pmod{p}.
        \]
        And since $i$ and $j$ are both from the set $\{1, 2, 3, \dots, p-1\}$, this means that $i = j$. In other words, each term in $\{a, 2a, 3a, \dots, (p-1)a\}$ is not congruent to any other term from that set — it is only congruent to itself. This completes Step 2.
        \bigbreak \noindent 
        We have succeeded in proving that when taken modulo $p$,
        \[
            \{a, 2a, 3a, \dots, (p-1)a\} \equiv \{1, 2, 3, \dots, p-1\},
        \]
        even though the numbers in these sets may be in a different order. But since the order does not matter when multiplying numbers, we see that
        \[
            a \cdot 2a \cdot 3a \cdot 4a \cdot \dots \cdot (p-1)a \equiv 1 \cdot 2 \cdot 3 \cdot 4 \cdot \dots \cdot (p-1) \pmod{p}.
        \]
        Then, since $\gcd(2, p) = 1$ by Lemma 2.17 part (i), by the modular cancellation law (Proposition 2.18) we may cancel a $2$ from both sides:
        \[
            a \cdot 3a \cdot 4a \cdot \dots \cdot (p-1)a \equiv 1 \cdot 3 \cdot 4 \cdot \dots \cdot (p-1) \pmod{p}.
        \]
        Then, since $\gcd(3, p) = 1$ by Lemma 2.17 part (i), by the modular cancellation law (Proposition 2.18) we may cancel a $3$ from both sides:
        \[
            a \cdot a \cdot 4a \cdot \dots \cdot (p-1)a \equiv 1 \cdot 4 \cdot \dots \cdot (p-1) \pmod{p}.
        \]
        Continuing to do this for the $4, 5, \dots, (p-1)$ on each side (each of which has a greatest common divisor of $1$ with $p$, by Lemma 2.17 part (i)), by the modular cancellation law (Proposition 2.18) we obtain
        \[
            \underbrace{a \cdot a \cdot a \cdot \dots \cdot a}_{p-1 \text{ copies}} \equiv 1 \pmod{p},
        \]
        which is equivalent to what we sought to prove:
        \[
            a^{p-1} \equiv 1 \pmod{p}.
        \]
    \item \textbf{Bonus proof}:
        \bigbreak \noindent 
        \textbf{Proposition.} If $x$ and $y$ are positive integers, and $x \geq y$, then $\sqrt{x} \geq \sqrt{y} $
        \bigbreak \noindent 
        \textbf{\textit{Proof.}} Assume $x$ and $y$ are positive integers, and $x \geq y$. Then
        \begin{align*}
            x &\geq y \\
            \implies x -y & \geq 0  \\
        .\end{align*}
        Since $x,y \geq 0$, $\sqrt{x^{2}} = \abs{x} = x$, and $\sqrt{y^{2}} = \abs{y} = y $. Thus,
        \begin{align*}
            x-y &\geq 0 \\
            \implies \sqrt{x^{2}} - \sqrt{y^{2}} &\geq 0  \\
            \implies (\sqrt{x} - \sqrt{y})(\sqrt{x} + \sqrt{y}) &\geq 0 \\
            \implies \sqrt{x} - \sqrt{y} &\geq 0  \quad \quad \blacksquare
        .\end{align*}
    \item \textbf{The AM-GM inequality}:
        \bigbreak \noindent 
        \textbf{Theorem (\textit{AM-GM inequality})}. If $x,y \geq 0 \in \mathbb{Z}$, then $\sqrt{xy} \leq \frac{x+y}{2} $
        \bigbreak \noindent 
        \textbf{\textit{Proof.}} Assume $x,y \geq 0 \in \mathbb{Z}$. Consider
        \begin{align*}
            0 \leq (x-y)^{2}
        .\end{align*}
        Which we know to be true, squaring an integer is always positive, and we know $x-y$ to be an integer. It then follows that
        \begin{align*}
            0 \leq x^{2} -2xy + y^{2}
        .\end{align*}
        If we add $4xy$ to both sides, we get
        \begin{align*}
            4xy &\leq x^{2} + 2xy + y^{2} \\
            \implies 4xy &\leq (x + y)^{2} \\
        .\end{align*}
        Now let's take the square root of both sides
        \begin{align*}
            2\sqrt{xy} \leq \abs{x+y}
        .\end{align*}
        Since $x,y \geq 0$, $\abs{x+y} = x+y$. Thus,
        \begin{align*}
            2\sqrt{xy} \leq x + y \\
            \therefore \sqrt{xy} \leq \frac{x+y}{2}
        .\end{align*}
        \bigbreak \noindent 
        \textbf{Note:} Some of the steps taken in this proof may seem a bit random, but if we start at the proposition $\sqrt{xy} \leq \frac{x+y}{2}$ and work backwards algebraically, we see
        \begin{align*}
            \sqrt{xy} &\leq \frac{x+y}{2} \\
            2\sqrt{xy} &\leq x+y \\
            4xy &\leq (x+y)^{2} \\
            4xy &\leq x^{2} + 2xy + y^{2} \\
            0 &\leq x^{2} + 2xy + y^{2} - 4xy \\
            0 &\leq x^{2} - 2xy + y^{2} \\
            0 &\leq (x-y)^{2}
        .\end{align*}
        \bigbreak \noindent 
        We see that we have derived a starting point, and were just working backwards in the proof.
            
    \end{itemize}

    \pagebreak 
    \subsection{Sets}
    \begin{itemize}
        \item \textbf{Vacuous truth}: a vacuous truth is a conditional or universal statement (a universal statement that can be converted to a conditional statement) that is true because the antecedent cannot be satisfied.[1] It is sometimes said that a statement is vacuously true because it does not really say anything. For example, the statement "all cell phones in the room are turned off" will be true when no cell phones are present in the room. In this case, the statement "all cell phones in the room are turned on" would also be vacuously true, as would the conjunction of the two: "all cell phones in the room are turned on and turned off", which would otherwise be incoherent and false.
        \item \textbf{Review: Proper subset}: If $A = B$, then $A \subseteq B$. In the case that $A \subseteq B$ and $A \ne B$, we say that $A$ is a proper subset of $B$. the correct notation for this is "$A \subset B$."
        \item \textbf{Proving $A \subseteq B $}
            \bigbreak \noindent 
            \textbf{Definition}. Suppose $A$ and $B$ are sets. If every element in $A$ is also an element of $B$, then $A$ is a subset of $B $, which is denoted $A \subseteq B$
            \bigbreak \noindent 
            \textbf{Note:} For every set $B$, it is true that $\varnothing \subseteq B $. 
            To see it, first note that, because there are no elements in $\varnothing$, it would be true to say  
            "for any $x \in \varnothing$, $x$ is a purple elephant that speaks German.'' It’s vacuously\footnote{A statement is vacuously true if it asserts something about all elements of the empty set.} true!  
            You certainly can’t disprove it, right? You can’t present to me any element in $\varnothing$ that is not a purple elephant that speaks German.
            \bigbreak \noindent 
            By this reasoning, I could switch out "is a purple elephant that speaks German" for any other statement, and it would still be true! And this includes the subset criteria: if $x \in \varnothing$, then $x \in B$, which by definition means that $\varnothing \subseteq B$.  
            Again, you certainly can not present to me any $x \in \varnothing$ which is not also an element of $B$, can you?
            \bigbreak \noindent 
            in order to prove that $A \subseteq B$, what we would have to show is this:
            \begin{align*}
                \text{If } x\in A, \text{ then } x\in B 
            .\end{align*}
            In other words, for any arbitrary element in $A$, that same element is also in $B$
            \bigbreak \noindent 
            \textbf{Proposition.} It is the case that 
            \begin{align*}
                \{n \in \mathbb{Z}:\ 12 \mid n\} \subseteq \{n\in\mathbb{Z}:\ 3\mid n\}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Let $A = \{n\in\mathbb{Z}:\ 12\mid n\} $, and $B =\{n\in\mathbb{Z}:\ 3\mid n\} $. Assume $a\in A$
            \penv{
                Since $a\in A$, then $12 \mid a$, which implies $a = 12k$, for some $k\in \mathbb{Z}$. If $a\in B$, then $3\mid a \implies a = 3\ell$
                \bigbreak \noindent 
                Since $a =12k$, and $a=3\ell$, then $12k=3\ell \implies \ell = 4k$. Thus, we have
                \begin{align*}
                    a = 3(4k)
                .\end{align*}
                Which by the definition of divisiblity, and since $4k \in \mathbb{Z}$, we have $3\mid a$. 
                \bigbreak \noindent 
                Therefore, $a \in B \quad \blacksquare$
            }
        \item \textbf{Proving $A = B$}:
            Recall that, for sets $A$ and $B$, to say that ``$A = B$'' is to say that these two sets contain \textit{exactly} the same elements. Said differently, it means these two things:
            \begin{enumerate}
                \item Every element in $A$ is also in $B$ (which means $A \subseteq B$), and
                \item Every element in $B$ is also in $A$ (which means $B \subseteq A$).
            \end{enumerate}
            Indeed, a slick way to prove that $A = B$ is to prove both $A \subseteq B$ and $B \subseteq A$, both of which can be done using the approach discussed above.
        \item \textbf{Review of set operations}:
            \begin{itemize}
                \item The \textit{union} of sets $A$ and $B$ is the set $A \cup B = \{x : x \in A \text{ or } x \in B\}$.
                \item The \textit{intersection} of sets $A$ and $B$ is the set $A \cap B = \{x : x \in A \text{ and } x \in B\}$.
                \item Likewise, if $A_1, A_2, A_3, \dots, A_n$ are all sets, then the union of all of them is the set
                    \[
                        A_1 \cup A_2 \cup \cdots \cup A_n = \{x : x \in A_i \text{ for some } i\}.
                    \]
                    This set is also denoted
                    \[
                        \bigcup_{i=1}^n A_i.
                    \]
                \item Likewise, if $A_1, A_2, A_3, \dots, A_n$ are all sets, then the intersection of all of them is the set
                    \[
                        A_1 \cap A_2 \cap \cdots \cap A_n = \{x : x \in A_i \text{ for all } i\}.
                    \]
                    This set is also denoted
                    \[
                        \bigcap_{i=1}^n A_i.
                    \]
            \end{itemize}
            \bigbreak \noindent 
            Assume $A$ and $B$ are sets and ``$x \notin B$'' means that $x$ is not an element of $B$.
            \begin{itemize}
                \item The \textit{subtraction} of $B$ from $A$ is $A \setminus B = \{x : x \in A \text{ and } x \notin B\}$.
                \item If $A \subseteq U$, then $U$ is called a \textit{universal set} of $A$. The \textit{complement} of $A$ in $U$ is $A^c = U \setminus A$.
            \end{itemize}
            \bigbreak \noindent 
            Furthermore, 
            \begin{itemize}
                \item The \textit{power set} of a set $A$ is $\mathcal{P}(A) = \{X : X \subseteq A\}$.
                \item The \textit{cardinality} of a set $A$ is the number of elements in the set, and it is denoted $|A|$.
            \end{itemize}
            \bigbreak \noindent 
            Assume $A$ and $B$ are sets, The Cartesian product of A and B is 
            \begin{align*}
                A \times B = \{(a, b):\  a \in A and b \in B\}.
            .\end{align*}
            \pagebreak \bigbreak \noindent 
        \item \textbf{More on power sets}: 
            \bigbreak \noindent 
            \textbf{Proposition.} Suppose $A$ and $B $ are sets. If $\mathcal{P}(A)\subseteq \mathcal{P}(B)$, then $A\subseteq B$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A$ and $B$ are sets, and $\mathcal{P}(A) \subseteq \mathcal{P}(B)$.
            \bigbreak \noindent 
            \penv{
                Choose $x\in \mathcal{P}(A)$, which means $x \subseteq A$. Since $\mathcal{P}(A) \subseteq \mathcal{P}(B)$, it follows that $x \in \mathcal{P}(B)$, which means $x \subseteq B$. Let $x=A$, since $A\in\mathcal{P}(A)$. Since $x \subseteq B$, then $A \subseteq B $
            }
            \bigbreak \noindent 
            Therefore, $A\subseteq B \quad \blacksquare$
        \item \textbf{De Morgan's law}:
            \bigbreak \noindent 
            \textbf{Theorem}. Suppose $A$ and $B$ are subsets of a universal set $U$. Then,
            \begin{align*}
                (A \cup B)^{C} &= A^{C} \cap B^{C} \tag{1}
            .\end{align*}
            And
            \begin{align*}
                (A \cap B)^{C} &= A^{C} \cup B^{C} \tag{2}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof (1)}}. Assume $A$ and $B$ are subsets of a universal set $U$, since $(A \cup B)^{C}$, and $A^{C} \cap B^{C} $ are sets, we show equality by showing $(A\cup B)^{C} \subseteq A^{C}\cap B^{C}$, and $A^{C} \cap B^{C} \subseteq (A\cup B)^{C}$. It then follows that $(A \cup B)^{C} = A^{C} \cap B^{C} $
            \penv{
                Choose $x\in (A\cup B)^{C} $, by the definition of the complement, we have $x\not\in(A\cup B)$, which by the definition of the union means $x$ cannot be in $A$, and it cannot be in $B$. In other words, $x\not\in A$ and $x\not\in B \implies x \in A^{C}$ and $x\in B^{C} $. Therefore,
                \begin{align*}
                    x\in A^{C} \cap B^{C}
                .\end{align*}
                Which by the definition of the subset, means $(A\cup B)^{C} \subseteq A^{C} \cap B^{C}$
                \bigbreak \noindent
                Next, let $x\in A^{C} \cap B^{C}$, then $x \in A^{C}$ and $x\in B^{C}$, which means $x\not\in A$ and $x\not\in B$, which implies $x\not\in (A\cup B) \implies x\in (A\cup B)^{C}$.
                \bigbreak \noindent 
                Therefore, since $x\in A^{C} \cap B^{C} \implies x\in (A\cup B)^{C}$, by the definition of a subset, we have $A^{C} \cap B^{C} \subseteq (A\cup B)^{C} $
            }
            Since both $(A\cup B)^{C} \subseteq A^{C} \cap B^{C}$, and $A^{C} \cap B^{C} \subseteq (A \cup B)^{C}$, it must be the case that $(A\cup B)^{C} = A^{C} \cap B^{C} \quad \blacksquare$
            \bigbreak \noindent 
            It should be addressed that this proof can be done by simply manipulating the set builder notation. We have
            \begin{align*}
                A^{C} \cap B^{C} &= \{x \in \mathbb{R}:\ x \in A^{C} \text{ and } x\in B^{C}\} \\
                                 &=\{x\in\mathbb{R}:\ x\not\in A \text{ and } x\not\in B\} \\
                                 &=\{x\in\mathbb{R}:\ x\not\in (A\cup B)\}  \\
                                 &=\{x\in\mathbb{R}:\ x\in (A\cup B)^{C}\}
            .\end{align*}
            $\blacksquare$
        \item \textbf{Proving $a\in A$}: Consider the set $\{x\in S:\ P(x)\}$, where $P(x)$ is some condition on $x$
            \bigbreak \noindent 
            Given a set of this form, if you are presented with a specific $a$ and you wish to prove that $a \in A$, then you must show that
            \begin{enumerate}
                \item $a\in S$
                \item $P(a)$ is true
            \end{enumerate}
            \bigbreak \noindent 
            For example, Let $A = \{(x,y) \in \mathbb{Z} \times \mathbb{N}:\ x\equiv y\pmod{5}\} $, then $(17,2) \in A$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} First, note that $(17,2) \in\mathbb{Z} \times \mathbb{N}$ because $17\in \mathbb{Z}$, and $2 \in \mathbb{N} $, Next, observe that
            \begin{align*}
                17 \equiv 2 \pmod{5}
            .\end{align*}
            Because $5\mid (17-2)$
        \item \textbf{Indexed Families of Sets}: Consider a set $\mathcal{F}$, If every element of $\mathcal{F} $ is itself a set, then $\mathcal{F}$ is called a \textit{family of sets}. Then, one can ask questions about such a family, — like, what is the union of all of the sets in $\mathcal{F}$. That is,
            \begin{align*}
                \bigcup_{S \in \mathcal{F}} S &= \{x:\ x\in S \text{ for some } S \in \mathcal{F}\}
            .\end{align*}
            Likewise, 
            \begin{align*}
                \bigcap_{S\in \mathcal{F}} S &= \{x:\ x\in S \text{ for every } S \in \mathcal{F}\}
            .\end{align*}
        \item \textbf{Bonus example I}.
            \bigbreak \noindent 
            \textbf{Proposition}. It is the case that 
            \begin{align*}
                \{n \in \mathbb{Z}:\ 12\mid n\} = \{n\in\mathbb{Z}:\ 3\mid n\} \cap \{n\in \mathbb{Z}:\ 4\mid n\}
            .\end{align*}
            \textbf{\textit{Proof.}} Let $A = \{n \in \mathbb{Z}:\ 12\mid n\}$, $B =\{n\in\mathbb{Z}:\ 3\mid n\}$, and $C= \{n\in \mathbb{Z}:\ 4\mid n\}$
            \penv{
                \textit{Part i.)} Choose $x\in A$, we then have $ 12\mid x$, and $x = 12k$, for some $k\in \mathbb{Z}$. Thus,
                \begin{align*}
                    x = 12k = 3(4k) = 4(3k)
                .\end{align*}
                Which by the definition of divisibility implies both $3\mid x $ and $4\mid x$, since both $4k$ and $3k \in \mathbb{Z}$. Hence, $x\in B \cap C$
                \bigbreak \noindent 
                \textit{Part ii.)} Choose $x\in B\cap C$, then both $x = 3r$ and $x=4s$, for $r,s\in\mathbb{Z} $. We have
                \begin{align*}
                    3r = 4s
                .\end{align*}
                Which implies $3\mid 4s$, since $r \in \mathbb{Z}$. Because $3\in \mathbb{P}$, we know that either $3\mid 4$ or $3\mid s$. Since it is clear that $3\nmid 4$, it must be the case that $3\mid s$, and thus $s = 3\ell$ for an integer $\ell$. It then follows that
                \begin{align*}
                    x=4s = 4(3\ell) = 12\ell
                .\end{align*}
                Which by the definition of divisibility implies $12\mid x$, and thus $x\in A$
            }
            Since choosing an $x\in A \implies x\in B\cap C$, it must be that $A\subseteq B\cap C$, and choosing an $x\in B\cap C \implies x\in A$, it must also be that $B\cap C \subseteq A$. With these two facts, we can assert that $A = B \cap C \quad \blacksquare$
        \item \textbf{The Cardinality of the Power Set}: Suppose $A$ is a set with $n$ elements. How many subsets of $A$ are there? Said differently, what is $\abs{P(A)}$?
            \bigbreak \noindent 
            We could check the first few cases by hand
            \begin{center}
                \begin{tabular}{c|c|c}
                    $A$& $\abs{A} = n$ & $\abs{\mathcal{P}(A)}$ \\
                    \hline
                    $\{1\}$ & $1$ & 2 \\
                    $\{1,2\}$ & 2 & 4 \\
                    $\{1,2,3\}$ & 3 & 8 \\
                    $\{1,2,3,4\}$ & 4 & 16
                \end{tabular}
            \end{center}
            \bigbreak \noindent 
            It sure looks like if $|A| = n$, then $|P(A)| = 2^n$.  Why would this be true? There is actually a pretty slick way to see it. Every subset  of $\{1, 2, 3\}$ can be thought of by asking whether or not each element is included in the  subset. For example, $\{1, 3\}$ can be thought of as $\langle \text{yes, no, yes} \rangle$, since 1 was included,  2 was not, and 3 was.
            \bigbreak \noindent 
            Suppose you’re trying to generate a subset of $\{1, 2, 3\}$. You could think about  doing so by asking three yes/no questions, the answers to which uniquely determine  your set. With 2 options for the first element, 2 for the second, and 2 for the third, in  total there are $2 \times 2 \times 2 = 8$ ways to answer the three questions, and hence 8 subsets!
            \bigbreak \noindent 
            With $n$ straight yes/no questions, there are $2 \times 2 \times \cdots \times 2 = 2^n$ ways to answer  the questions, each corresponding uniquely to a subset of $A$. Thus, if $|A| = n$, then  $|P(A)| = 2^n$.
        \item \textbf{A consequence of the above fact}:
            \bigbreak \noindent 
            \textbf{Proposition}. Given any $A \subseteq \{1, 2, 3, \ldots, 100\}$ for which $|A| = 10$, there  exist two different subsets $X \subseteq A$ and $Y \subseteq A$ for which the sum of the elements  in $X$ is equal to the sum of the elements in $Y$.
            \bigbreak \noindent 
            For example, consider the set $\{6, 23, 30, 39, 44, 46, 62, 73, 90, 91\}$, If we let 
            \begin{align*}
                X = \{6, 23, 46, 73, 90\} \text{ and } Y = \{30, 44, 73, 91\}
            .\end{align*}
            then the elements in both sets sum to $238$:
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We prove this fact using the pigeonhole principal. Consider the smallest and largest possible subset sums. If $A = \varnothing \subseteq \{1,2,3,...,100\} $, then the sum is $0$. If $A = \{91,92,93,94,95,96,97,98,99,100\} $, then the subset sum is $955$. Thus, there are no more than $956$ possible subset sums for the set $A \subseteq \{1,2,3,...,100\} $, for which $\abs{A} = 10$.
            \bigbreak \noindent 
            Consider $956$ boxes, each representing a unique subset sum. Since we have $2^{\abs{A}} = 2^{10} = 1024$ subsets and only $956$ boxes to place each subset in, there must be a box containing two subsets $A$, which means they must have the same sum $\quad \blacksquare$.
        \item \textbf{The symmetric difference of sets}. The \textit{symmetric difference} of two sets $A$ and $B$, denoted $A \Delta B $, or $A \ominus B$, is the set which contains the elements which are either in set $A$ or in set $B$ but not in both 

    \end{itemize}

    \pagebreak 
    \subsection{Induction}
    \begin{itemize}
        \item \textbf{Dominoes}: Consider a line of dominoes, perfectly arranged, just waiting to be knocked over. Dominoes stacked up like this have the following properties:
            \begin{enumerate}
                \item If you give the first domino a push, it will fall (in particular, it will fall into the second domino, knocking it over).
                \item Moreover, every domino, when it’s knocked over, falls into the next one and knocks it over.
            \end{enumerate}
            Given these two properties, it must be the case that if you knock over the first domino, then every domino will eventually fall. The first premise gets the process going, as it implies that the first domino will fall. And then the second premise keeps it going: Applying the second premise means that the falling first domino will cause the second domino to fall. Applying the second premise again means that the second falling domino will cause the third domino to fall. Applying the second premise again means that the third falling domino will cause the fourth domino to fall. And so on.
        \item \textbf{Sum of the first $n$  odd numbers}: Take a look at the following
            \begin{align*}
                1 = 1 &= 1^{2} \\
                1 + 3 = 4 &= 2^{2}\\
                1 + 3 + 5 = 9 &= 3^{2}\\
                1 + 3 + 5 + 7 = 16 &= 4^{2}\\
                1 + 3 + 5 + 7 + 9 = 25 &= 5^{2}\\
                1 + 3 + 5 + 7 + 9 + 11 = 36 &= 6^{2}\\
                1 + 3 + 5 + 7 + 9 + 11 + 13 = 49 &= 7^{2}
            .\end{align*}
            \bigbreak \noindent 
            It sure looks like the sum of the first $n$ odd numbers is $n^{2}$. But how can we prove that it’s true for every one of the infinitely many $n$? The trick is to use the domino idea. Imagine one domino for each of the above statements.
            \bigbreak \noindent 
            \fig{.7}{./figures/7.png}
            \bigbreak \noindent 
            Suppose we do the following:
            \begin{itemize}
                \item Show that the first domino is true (this is trivial, since obviously $1=1^{2} $).
                \item Show that any domino, if true, implies that the following domino is true too
            \end{itemize}
            Given these two, we may conclude that all the dominoes are true. It’s exactly the same as noting that all the dominoes from earlier will fall. This is a slick way to prove infinitely many statements all at once, and it is called the \textit{principal of mathematical induction}, or, when among friends, it is simply called \textit{induction}.
        \item \textbf{Induction}: Consider a sequence of mathematical statements, $S_{1}, S_{2}, S_{3}, . . . .$
            \begin{itemize}
                \item Suppose $S_{1}$ is true, and
                \item Suppose, for each $k \in \mathbb{N}$, if $S_{k}$ is true then $S_{k+1}$ is true.
            \end{itemize}
            Then, $S_{n} $ is true for every $n\in \mathbb{N}$.
        \item \textbf{Induction framework}:
            \bigbreak \noindent 
            \textbf{Proposition}. $S_{1}, S_{2}, S_{3},... $ are all true
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} \textit{General setup or assumptions if needed}
            \penv{
                \textit{Base case.} $\left\langle\left\langle \text{Demonstration that $S_{1}$ is true} \right\rangle\right\rangle$
                \bigbreak \noindent 
                \textit{Inductive hypothesis}. Assume that $S_{k}$ is true
                \bigbreak \noindent 
                \textit{Induction step}. $\left\langle \left\langle \text{Proof that $S_{k}$ implies $S_{k+1} $} \right\rangle \right\rangle $
            }
            \textit{Conclusion}. Therefore, by induction, all the $S_{n}$ are true. \hspace{5cm} $\blacksquare $
        \item \textbf{Induction example 1}: Let’s simply sum the first $n$ natural numbers: $1 + 2 + 3 + 4 + · · · + n$. These sums are called the triangular numbers since they can be pictured as the number of balls in the following triangles.
            \bigbreak \noindent 
            \fig{.6}{./figures/8.png}
            \bigbreak \noindent 
            \textbf{Proposition.} For any $n\in \mathbb{N}$, $\sum_{i=1}^{n} i = 1 + 2 + 3 + \ldots + n = \frac{n(n+1)}{2} $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by induction
            \penv{
                \underline{Base case:} The base case is when $n=1$, and
                \begin{align*}
                    1 = \frac{1(1+1)}{2} = 1
                .\end{align*}
                \bigbreak \noindent 
                \underline{Inductive hypothesis}: Let $k\in \mathbb{N}$, assume 
                \begin{align*}
                    1 + 2 + 3 + ... + k = \frac{k(k+1)}{2}
                .\end{align*}
                \bigbreak \noindent 
                \underline{Inductive step}: We aim to show that the result holds for $k+1$. Thus,
                \begin{align*}
                    1+ 2 + 3 + ... + k+k+1 = \frac{(k+1)((k+1)+1)}{2} 
                .\end{align*}
                We have
                \begin{align*}
                    1 + 2 + 3 + ... + k + k+1 &= \frac{(k+1)(k+2)}{2}  \\
                    \implies \frac{k(k+1)}{2} + k+1 &= \frac{(k+1)(k+2)}{2} \\
                    \implies \frac{k^{2} + k + 2k + 1}{2} &= \frac{k^{2} + 2k + k + 2}{2}
                .\end{align*}
            }
            Therefore, by induction, $1+2+3+...+n = \frac{n(n+1)}{2} $ for all $n\in \mathbb{N} \quad \blacksquare$
        \item \textbf{Induction example 2}: 
            \bigbreak \noindent 
            \textbf{Proposition}. Let $S_{n}$ be the sum of the first $n$ natural numbers. Then, for any $n \in \mathbb{N}$,
            \begin{align*}
                S_{n} + S_{n+1} = (n+1)^{2}
            .\end{align*}
            \bigbreak \noindent 
            We will prove this proposition twice. The first proof is a direct proof, the second will be by induction.
            \bigbreak \noindent 
            \textbf{\textit{Direct proof.}} We have
            \begin{align*}
                S_{n} + S_{n+1} &= \frac{n(n+1)}{2} + \frac{(n+1)((n+1)+1)}{2} \\
                                &= \frac{n^{2} + n}{2} + \frac{n^{2} + 2n + n + 2}{2} \\
                                &= \frac{n^{2} + n + n^{2} + 3n + 2}{2} \\
                                &= \frac{2n^{2} + 4n + 2}{2} \\
                                &= \frac{2(n^{2} + 2n + 1)}{2} \\
                                &= n^{2} + 2n + 1 \\
                                &= (n+1)^{2} \quad \blacksquare
            .\end{align*}
            \pagebreak \bigbreak \noindent 
            \textbf{\textit{Proof by induction}}. We proceed by induction
            \penv{
                \underline{Base case}: The base case is when $n=1$, and 
                \begin{align*}
                    S_{1} + S_{2} = 1 + 3 = 4 = (1+1)^{2}
                .\end{align*}
                as desired
                \bigbreak \noindent 
                \underline{Inductive hypothesis}. Let $k\in\mathbb{N}$, and assume that 
                \begin{align*}
                    S_{k} + S_{k+1} = ( k+1)^{2}
                .\end{align*}
                \bigbreak \noindent 
                \underline{Inductive step}. We aim to prove that the result holds for $k+1$. That is, 
                \begin{align*}
                    S_{k+1} + S_{k+2} = (k+2)^{2}
                .\end{align*}
                For this, we use the fact that $S_{k+1} $ is the sum of the first $k+1$ natural numbers, thus we can write it as $S_{k} + (k+1)$. Likewise, $S_{k+2} = S_{k+1} + (k+2)$. Thus,
                \begin{align*}
                    S_{k+1} + S_{k+2} &= S_{k} + (k+1) + S_{k+1} + (k+2) \\
                                      &= S_{k} + S_{k+1} + 2k+3 \\
                                      &=(k+1)^{2} + 2k + 3\\
                                      &= k^{2} + 2k + 1 + 2k + 3 \\
                                      &= k^{2} + 4k + 4 \\
                                      &= (k+2)^{2}
                .\end{align*}
            }
            \underline{Conclusion.} Therefore, by induction, the proposition holds for all $n\in \mathbb{N} \quad \blacksquare$
        \item \textbf{A quick note about induction}: For some proof techniques, adding a sentence at the end of your proof is nice but not required. For induction, though, it really is required. You can prove that the first domino will fall, and you can prove that each domino — if fallen— will knock over the next domino, but why does this mean they all fall? Because induction says so! Until you say "by induction. . . " your work will not officially prove the result
        \item \textbf{Induction example 3.}
            \bigbreak \noindent 
            \textbf{Proposition.} For every $n \in N$, the product of the first $n$ odd natural numbers equals $\frac{(2n)!}{2^{n}n!} $. That is, 
            \begin{align*}
                1 \cdot  3 \cdot 5 \cdot ... \cdot (2n-1) = \frac{(2n)!}{2^{n}n!}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by induction.
            \bigbreak \noindent 
            \underline{Base case:} The base case occurs when $n=1$, 
            \begin{align*}
                1 = \frac{(2(1))!}{2^{1}1!} = 1
            .\end{align*}
            As desired
            \bigbreak \noindent 
            \underline{Inductive hypothesis}. Let $k\in \mathbb{N}$, assume
            \begin{align*}
                1 \cdot 3 \cdot 5 \cdot ... \cdot (2k-1) = \frac{(2k)!}{2^{k}k!}
            .\end{align*}
            \bigbreak \noindent 
            \underline{Inductive step}. We aim to prove that the result holds for $k+1$. Thus, we wish to show
            \begin{align*}
                1 \cdot 3 \cdot 5 \cdot ... \cdot (2k-1) \cdot (2(k+1)-1) &= \frac{(2(k+1))!}{2^{k+1}(k+1)!}\\
                                                                          &=\frac{(2k+2)!}{2^{k+1}(k+1)!}
            .\end{align*}
            By the inductive hypothesis, we have
            \begin{align*}
                1 \cdot 3 \cdot 5 \cdot ... \cdot (2k-1) \cdot (2k+1) &= \frac{(2k)!}{2^{k}k!}(2k+1) \\
                                                                      &= \frac{(2k)!(2k+1)}{2^{k}k!} \\
                                                                      &= \frac{(2k+1)!}{2^{k}k!} \\
                                                                      &=\frac{(2k+1)!}{2^{k}k!} \cdot \frac{(2k+2)}{(2k+2)} \\
                                                                      &= \frac{(2k+2)!}{2^{k}k!(2k+2)} \\
                                                                      &= \frac{(2k+2)!}{2^{k}k! \cdot 2(k+1)} \\
                                                                      &= \frac{(2k+2)!}{2^{k+1}(k+1)!}
            .\end{align*}
            Therefore, by induction, the proposition holds for all $n\in \mathbb{N} \quad \blacksquare$
        \item \textbf{Induction example 4}. 
            \bigbreak \noindent 
            \textbf{Proposition.} For every $n \in \mathbb{N}$, if any one square is removed from a $2^n \times 2^n$ chessboard, the result can be perfectly covered with $\text{L}$-shaped tiles.
            \bigbreak \noindent 
            The tiles cover three squares and look like this:
            \bigbreak \noindent 
            \fig{1}{./figures/9.png}
            \bigbreak \noindent 
            Since the proposition refers to something being true "for every \( n \in \mathbb{N} \)," that’s a pretty good indication that induction is the way to proceed. The base case (when \( n = 1 \)) will be fine. For the inductive hypothesis, we will be assuming that any \( 2^k \times 2^k \) board, with one square removed, can be perfectly covered by L-shaped tiles.
            \bigbreak \noindent 
            In the induction step we are going to consider a $2^{k+1} \times 2^{k+1}$ board — a board that is twice as big in each dimension— with one square missing.
            \pagebreak \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by induction
            \bigbreak \noindent 
            \penv{
                \underline{Base Case}. The base case is when $n = 1$, and among the four possible squares that one can remove from a $2 \times 2$ chessboard, each leaves a chessboard which can be perfectly covered by a single $L$-shaped tile:
                \bigbreak \noindent 
                \fig{.9}{./figures/10.png}
                \bigbreak \noindent 
                \underline{Inductive Hypothesis}. Let $k \in \mathbf{N}$, and assume that if any one square is removed from a $2^{k} \times 2^{k}$ chessboard, the result can be perfectly covered with $L$–shaped tiles.
                \bigbreak \noindent 
                \underline{Induction Step.} Consider a $2^{k+1} \times 2^{k+1}$ chessboard with any one square removed.  Cut this chessboard in half vertically and horizontally to form four $2^k \times 2^k$ chessboards.  One of these four will have a square removed, and hence, by the induction hypothesis, can be perfectly covered.
                \bigbreak \noindent 
                Next, place a single $L$-shaped tile so that it covers one square from each of the other three $2^{k} × 2^{k}$ chessboards, as shown in the picture below.
                \bigbreak \noindent 
                \fig{.7}{./figures/11.png}
                \bigbreak \noindent 
                Each of these other three $2^k \times 2^k$ chessboards can be perfectly covered by the  inductive hypothesis, and hence the entire $2^{k+1} \times 2^{k+1}$ chessboard can be perfectly covered.
                \bigbreak \noindent 
            }
            \textbf{Conclusion.} By induction, for every $n \in \mathbb{N}$, if any one square is removed from a  $2^n \times 2^n$ chessboard, the result can be perfectly covered with L-shaped tiles.
        \item \textbf{Another note about induction}: So far, in all of our examples we proved that a statement holds from all $n \in \mathbb{N}$.  
            The base case was $n = 1$ and in the inductive hypothesis we assumed that the result holds for some $k \in \mathbb{N}$.  
            \bigbreak \noindent 
            There are times where one instead wants to prove that a statement holds for only the natural numbers past some point.  
            For example, it is possible to prove the $p$-test by induction, a result that you might remember from your calculus class:
            \[
                \sum_{i=1}^\infty \frac{1}{i^n} \text{ converges for all integers } n \geq 2.
            \]
            To prove this result, the base case would be $n = 2$ and in the inductive hypothesis we would assume that the result holds for some $k \in \{2, 3, 4, 5, \ldots\}$.  
            \bigbreak \noindent 
            At other times, you may want to prove that a result holds for more than just the natural numbers.  
            For example, a result from combinatorics is that
            \[
                \sum_{i=1}^n \binom{n}{i} = 2^n \text{ holds for all integers } n \geq 0.
            \]
            Here, the base case is $n = 0$, and the inductive hypothesis is the assumption that this holds for some $k \in \{0, 1, 2, 3, \ldots\}$.
        \item \textbf{Strong induction idea}: The idea behind strong induction is that at the point when the 100th domino is the  next to get knocked down, you know for sure that all of the first 99 dominoes have  fallen, not just the 99th. Likewise, when you are proving some sequence of statements  $S_1, S_2, S_3, S_4, \ldots$, instead of just assuming that $S_k$ is true in order to prove $S_{k+1}$,  why not just assume that $S_1, S_2, \ldots, S_k$ are all true in order to prove $S_{k+1}$ — because  by the time you are proving $S_{k+1}$, you have shown them all to be true!
        \item \textbf{Strong induction}: Consider a sequence of mathematical statements, $S_{1}, S_{2}, S_{3}, ...$
            \begin{itemize}
                \item Suppose $S_1$ is true, and  
                \item Suppose, for any $k \in \mathbb{N}$, if $S_1, S_2, \ldots, S_k$ are all true, then $S_{k+1}$ is true.
            \end{itemize}
            Then $S_n$ is true for every $n \in \mathbb{N}$.
            \bigbreak \noindent 
            \textbf{Note:} In regular induction, you essentially use $S_1$ to prove $S_2$, and then $S_2$ to prove $S_3$,  and then $S_3$ to prove $S_4$, and so on. With strong induction, you use $S_1$ to prove $S_2$,  and then $S_1$ and $S_2$ to prove $S_3$, and then $S_1, S_2$, and $S_3$ to prove $S_4$, and so on.
        \item \textbf{Fundemental theorem of arithmetic}: If $n$ is an integer and $n \geq 2$,  then $n$ is either prime or composite. An integer $p$ is prime if $p \geq 2$ and its only  positive divisors are $1$ and $p$. A positive integer $n \geq 2$ that is not prime is called  composite, and is therefore one that can be written as $n = st$, where $s$ and $t$ are  integers smaller than $n$ but larger than $1$. And with that, it is time for a really big  and important result.
            \bigbreak \noindent 
            \textbf{Theorem 4.8 (Fundamental Theorem of Arithmetic).}  Every integer $n \geq 2$ is either prime or a product of primes.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by strong induction
            \pagebreak \bigbreak \noindent 
            \penv{
                \underline{Base case.} The base case occurs when $n=2$. Observe that $2\in \mathbb{P} $
                \bigbreak \noindent 
                \underline{Inductive hypothesis}. Let $k\in \mathbb{N}$ such that $k \geq 2$. Assume that the integers $2,3,4,...,k$ are either prime or a product of primes.
                \bigbreak \noindent 
                \underline{Induction step}. Next, we consider $k+1$. We aim to show that $k+1$ is either prime or a product of primes. Since $k+1$ is larger than one, it is either prime or composite. Consider these two cases separately. Case 1 is that $k+1$ is prime. In this case, our goal is achieved.
                \bigbreak \noindent 
                Case 2 is that $k+1$ is composite; that is, $k+1$ has positive factors other than one and itself. Say, $k+1 = st$, where $s,t$ are positive integers greater than zero, and  
                \begin{align*}
                    1 < s < k+1 \quad 1<t<k+1
                .\end{align*}
                By the inductive hypothesis, both $s$ and $t$ can be written as a product of primes, say
                \begin{align*}
                    s &= p_{1} \cdot p_{2} \cdot ... \cdot p_{m} \\
                    t &= q_{1} \cdot q_{2} \cdot  ... \cdot q_{\ell}
                .\end{align*}
                Where each $p_{i}, q_{j} \in \mathbb{P}$, then 
                \begin{align*}
                    k + 1 = st = (p_{1} \cdot p_{2} \cdot ... \cdot p_{m})(q_{1} \cdot q_{2} \cdot  ... \cdot q_{\ell})
                .\end{align*}
                \bigbreak \noindent 
                Is written as a product of primes
                \bigbreak \noindent 
                Note that if $s$ or $t$ where prime, then $m$ or $\ell$ would be one. Say $s$ was prime, then $s = p_{1} $
                \bigbreak \noindent 
                \textbf{Conclusion}. By strong induction, every positive integer larger than 2 can be written as a product of primes.
            }
        \item \textbf{Chocolate bar example}:
            \bigbreak \noindent 
            \textbf{Proposition.} Suppose you have a chocolate bar that is an $m \times n$ grid of squares. The entire bar, or any smaller rectangular piece of that bar, can be broken along the vertical or horizontal lines separating the squares. 
             
            The number of breaks to break up that chocolate bar into individual squares is precisely $mn - 1$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by strong induction
            \penv{
                \underline{Base case}: The base case occurs when $n=1$, which is an $1\times 1$ chocolate bar. Since the number of breaks needed to break the bar into individual squares is clearly zero, we have
                \begin{align*}
                    0 = 1(1) -1 = 0
                .\end{align*}
                As desired
                \bigbreak \noindent 
                \underline{Inductive hypothesis}: Let $k\in\mathbb{N}$, assume that all bars with at most $k$ squares satisfy the proposition.
                \bigbreak \noindent 
                \underline{Induction step}: Consider now any bar with $k+1$ squares, suppose this bar has dimensions $m\times n $. Consider an arbitrary first break, and suppose the two smaller bars have $a$ squares and $b$ squares, respectively. Note that we must have $a + b = mn$, because the number of squares in the smaller bars must add up to the number of squares in the original $m \times n$ bar.
                \bigbreak \noindent 
                By the inductive hypothesis, the bar with $a$ squares will require $a - 1$ breaks to completely break it up, and the bar with $b$ breaks will require $b-1$ breaks. Therefore, to break up the $m \times n$ bar, we must make a first break, followed by $(a - 1) + (b - 1)$ additional breaks. The total number of breaks is then
                \begin{align*}
                    1 + (a-1) + (b-1) &= a+b-1 \\
                                      &=mn - 1
                .\end{align*}
                And $mn - 1$ is indeed one less than the number of squares in the $m \times n$ bar.
                \bigbreak \noindent 
            }
            \underline{Conclusion}. By strong induction, a chocolate bar of any size requires one break less than its number of squares to break it up into individual squares $\quad \blacksquare $
            \bigbreak \noindent 
            \textbf{Note:} What if the pieces were in the shape of a triangle? If it had $T$ squares would it still require $T - 1$ breaks?
            \bigbreak \noindent 
            What about other shapes? What if there are pieces missing in the middle? Interestingly, the answer is $T - 1$ no matter the bar’s shape, and even if pieces are missing! As long as each of your "breaks" divides one chunk into two, that’s the answer.
            \bigbreak \noindent 
            Here is some intuition for that: No matter the shape, the bar starts out as a  
            single "chunk" of chocolate, and after your sequence of breaks the bar is broken into  
            $T$ chunks of chocolate — the $T$ individual squares. How many breaks does it take to  
            move from 1 chunk to $T$ chunks? Notice that every break increases the number of  
            chunks by 1. So after 1 break, there will be 2 chunks. After 2 breaks, there will be 3  
            chunks. And so on. Thus, after $T - 1$ breaks there will be $T$ chunks, which is why  
            $T - 1$ breaks is guaranteed to be the answer, no matter which shape you started with.

        \item \textbf{Multiple base cases}: When proving the $(k + 1)$st case within the induction step, strong induction allows  you to apply not just the $k$th step, but any of the steps $1, 2, 3, \ldots, k$. In the previous  two examples, you had no idea which earlier steps you will need, so it was vital that  you assumed them all. At times, though, you really only need, say, the previous two  steps. The $k$th step is perhaps not enough, but the $(k - 1)$st step and the $k$th step is  guaranteed to be enough.
            \bigbreak \noindent 
            If you rely on the two previous steps, then that is analogous to saying that it takes the previous two dominoes to knock over the next one. Thus, if you knock over dominoes 1 and 2, then they will collectively knock over the third. Then, since the second and third have fallen, those two will collectively knock over the fourth. Then the third and fourth will knock over the fifth. And so on. Thus, the induction relies on two base cases, because without knocking over the first two the third won’t fall and the process won’t begin
            \bigbreak \noindent 
            \textbf{Example:} 
            \bigbreak \noindent 
            \textbf{Proposition.} Every $n \in N$ with $n \geq 11$ can be written as $2a + 5b$ for some natural numbers $a$ and $b$.
            \bigbreak \noindent 
            \textbf{Base Cases.} In the induction step, we will need two cases prior, so we show two base  
            cases here: $n = 11$ and $n = 12$. Both of these can be written as asserted:
            \[
                11 = 2 \cdot 3 + 5 \cdot 1 \\
                12 = 2 \cdot 1 + 5 \cdot 2.
            \]
            \textbf{Inductive Hypothesis.} Assume that for some integer $k \geq 12$, the results hold for  
            \[
                n = 11, 12, 13, \ldots, k.
            \]
            \textbf{Induction Step.} We aim to prove the result for $k + 1$. By the inductive hypothesis,  
            \[
                k - 1 = 2a + 5b
            \]
            for some $a, b \in \mathbb{N}$. Adding 2 to both sides,
            \[
                k + 1 = 2(a + 1) + 5b.
            \]
            Observe that $(a + 1) \in \mathbb{N}$ and $b \in \mathbb{N}$, proving that this is indeed a representation of  
            $(k + 1)$ in the desired form.
            \bigbreak \noindent 
            \textbf{Conclusion.} Therefore, by strong induction, every integer $n \geq 11$ can be written as  
            the proposition asserts. \(\blacksquare\)
            \pagebreak 
        \item \textbf{False proofs with induction}: 
            \bigbreak \noindent 
            \textbf{Proposition}. Everyone on Earth has the same name
            \bigbreak \noindent 
            \textit{Fake Proof.} We will consider groups of $n$ people at a time, and by induction we will  
            ``prove'' that for every $n \in \mathbb{N}$, every group of $n$ people must have everyone with the  
            same name.
            \penv{
                \textbf{Base Case.} If $n = 1$, then of course everyone in the group has the same name, since  
                there’s only one person in the group!
                \bigbreak \noindent 
                \textbf{Inductive Hypothesis.} Let $k \in \mathbb{N}$, and assume that any group of $k$ people all have  
                the same name.
                \bigbreak \noindent 
                \textbf{Induction Step.} Consider a group of $k + 1$ people.
                \bigbreak \noindent 
                \fig{.7}{./figures/12.png}
                \bigbreak \noindent 
                But notice that we can look at the first $k$ of these people and then the last $k$ of these people, and to each of these groups we can apply the inductive hypothesis:
                \bigbreak \noindent 
                \fig{.7}{./figures/13.png}
                \bigbreak \noindent 
                And the only way that this can all happen, is if all $k + 1$ people have the same name.
            }
            Conclusion. This "proves" by induction that for every $n \in N$, every group of $n$ people must have the same name. So if you let $n$ be equal to the number of people on Earth, this "proves" that everyone has the same name.
            \bigbreak \noindent 
            For $k+1$ people, the proof assumes that you can take the first $k$ people and the last  
            $k$ people, and both of these subsets must have the same name because the induction  
            hypothesis applies to them individually.  
            \bigbreak \noindent 
            However, this reasoning fails when $k+1 = 2$. For $k+1 = 2$, the first subset has one  
            person, and the second subset also has one person. These subsets do not overlap, so  
            there is no logical connection ensuring that these two people share the same name.
            \bigbreak \noindent 
            The induction relies on overlapping subsets of $k$ people to conclude that all $k+1$ people  must have the same name. However, this overlap only works if $k+1 > 2$, meaning the proof  doesn't actually establish the result for $k+1 = 2$, which breaks the induction chain.  Without the foundation for $n = 2$, the argument fails for all larger $n$.
        \item \textbf{Induction bonus example 1}.
            \bigbreak \noindent 
            \textbf{Lemma 4.13}. For every $n\in \mathbb{N}_{0} $,
            \begin{align*}
                1 + 2 + 4 + 8 + ... + 2^{n} = 2^{n+1}-1
            .\end{align*}
            For example, 
            \begin{align*}
                1 &= 2^{1}-1 \\
                1 + 2 &= 2^{2}-1 \\
                1 + 2 + 4 &= 2^{3}-1 \\
                1 + 2 + 4 + 8 &= 2^{4}-1
            .\end{align*}
            \penv{
                \underline{Base case}. The base case occurs when $n=1$, we have
                \begin{align*}
                    1 = 2^{1}-1 = 1
                .\end{align*}
                As desired
                \bigbreak \noindent 
                \underline{Inductive hypothesis}. Let $k\in \mathbb{N}_{0}$, assume that
                \begin{align*}
                    1 + 2 + 4 +... + 2^{k} = 2^{k+1}-1
                .\end{align*}
                \bigbreak \noindent 
                \underline{Induction step}. We wish to show that the result holds for $k+1$. That is, 
                \begin{align*}
                    1 + 2 + 4+ ... + 2^{k} + 2^{k+1} = 2^{(k+1)+1}-1 = 2^{k+2} -1
                .\end{align*}
                By the inductive hypothesis, we have
                \begin{align*}
                    1 + 2 + 4 + ... + 2^{k} + 2^{k+1} &= 2^{k+1}-1 + 2^{k+1} \\
                                                      &=2(2^{k+1})-1 \\
                                                      &=2^{k+2} -1
                .\end{align*}
                As desired

            }
            \bigbreak \noindent 
            Therefore, by induction, the proposition holds for all $n\in \mathbb{N}_{0} $
            \bigbreak \noindent 
        \item \textbf{Induction bonus example 2}. \textbf{Proof.} We proceed by strong induction.
            \textbf{Base Case.} Our base case is when \( n = 1 \). Note that 1 can be written as \( 2^0 \), and this is the only way to write 1 as a sum of distinct powers of 2, because all other powers of 2 are larger than 1.
            \bigbreak \noindent 
            \textbf{Inductive Hypothesis.} Let \( k \in \mathbb{N} \), and assume that each of the integers \( 1, 2, 3, \dots, k \) can be expressed as a sum of distinct powers of 2 in precisely one way.
            \bigbreak \noindent 
            \textbf{Induction Step.} We now aim to show that \( k+1 \) can be expressed as a sum of distinct powers of 2 in precisely one way.
            \bigbreak \noindent 
            Let \( 2^m \) be the largest power of 2 such that \( 2^m \leq k+1 \). We now consider two cases: the first is if \( 2^m = k+1 \), and the second is if \( 2^m < k+1 \).
            \bigbreak \noindent 
            \textbf{Case 1:} \( 2^m = k+1 \). If this occurs, then \( 2^m \) itself is a way to express \( k+1 \) as a (one-term) sum of distinct powers of 2. Moreover, there is no other way to express \( k+1 \) as a sum of distinct powers of 2, because by Lemma 4.13 all smaller powers of 2 sum to \( 2^m - 1 = k \). Thus, even by including all smaller powers of 2, we are unable to reach \( k+1 \). So, in Case 1, there is precisely one such expression for \( k+1 \).
            \bigbreak \noindent 
            \textbf{Case 2:} \( 2^m < k+1 \). In order to apply the inductive hypothesis, we will consider \( (k+1) - 2^m \). First, note that \( (k+1) - 2^m \) is less than \( 2^m \), because otherwise \( k+1 \) would have two copies of \( 2^m \) within it, implying that \( 2^m + 2^m \leq k+1 \). However, since \( 2^m + 2^m = 2 \cdot 2^m = 2^{m+1} \), this would mean \( 2^{m+1} \leq k+1 \). This can't be, since \( 2^m \) was chosen to be the largest power of 2 that is at most \( k+1 \). Thus, it must be the case that \( (k+1) - 2^m < 2^m \).
            \bigbreak \noindent 
            Next, by the inductive hypothesis, \( (k+1) - 2^m \) can be expressed as a sum of distinct powers of 2 in precisely one way, and since \( (k+1) - 2^m < 2^m \), this unique expression for \( (k+1) - 2^m \) will not contain a \( 2^m \). Thus, by adding a \( 2^m \) to it, we obtain an expression for \( k+1 \) as a sum of powers of 2. And this expression is unique because \( (k+1) - 2^m \) is unique according to the inductive hypothesis, and the \( 2^m \) portion is unique because, again by Lemma 4.13, even if you summed all of the smaller powers of 2, you will not reach \( 2^m \).
            \bigbreak \noindent 
            \textbf{Conclusion.} By strong induction, every \( n \in \mathbb{N} \) can be expressed as a sum of distinct powers of 2 in precisely one way. \(\Box\)
        \item \textbf{Induction bonus example 3.}
            \bigbreak \noindent 
            \textbf{Theorem 4.15 (\textit{The binomial theorem})}. For $x,y \in \mathbb{R}$, and $n\in \mathbb{N}_{0} $
            \begin{align*}
                (x+y)^{n} = \sum_{m=0}^{n}\binom{n}{m} x^{n-m}y^{m}
            .\end{align*}
            Here, when $n \geq m$, the binomial coefficient $\binom{n}{m}$ is defined to be 
            \[
                \binom{n}{m} = \frac{n!}{m!(n-m)!},
            \]
            which one can show is always an integer. The binomial coefficients can also be defined combinatorially: $\binom{n}{m}$ is equal to the number of ways to choose $m$ elements from an $n$-element set; in fact, $\binom{n}{m}$ is read "n choose m." For example, 
            \[
                \binom{4}{2} = 6
            \]
            because there are six subsets of the set $\{1, 2, 3, 4\}$ containing two elements:
            \[
                \{1, 2\}, \{1, 3\}, \{1, 4\}, \{2, 3\}, \{2, 4\}, \{3, 4\}.
            \]
            Binomial coefficients can be computed iteratively using \textit{Pascal's rule}, which says that
            \[
                \binom{n}{r} = \binom{n-1}{r-1} + \binom{n-1}{r},
            \]
            as well as the fact that
            \[
                \binom{n}{0} = 1 \quad \text{and} \quad \binom{n}{n} = 1 \quad \text{for all } n \in \mathbb{N}_0.
            \]
            A beautiful way to combine these facts is called \textit{Pascal's triangle}:
            \bigbreak \noindent 
            \fig{.6}{./figures/15.png}
            \bigbreak \noindent 
            Indeed, we can even prove the binomial theorem by induction, by making use of Pascal’s rule. Here is a sketch of that proof:
            \bigbreak \noindent 
            \textbf{\textit{Proof sketch}}. The base case is when $n = 0$, and indeed $(x + y)^0 = 1$. The next couple cases are more interesting, and you can check that $(x + y)^1 = x + y$ and $(x + y)^2 = x^2 + 2xy + y^2$ do indeed match the theorem. The inductive hypothesis will be
            \[
                (x + y)^k = x^k + \binom{k}{1}x^{k-1}y + \binom{k}{2}x^{k-2}y^2 + \cdots + \binom{k}{k-1}xy^{k-1} + y^k.
            \]
            For the induction step, we perform easy algebra, then apply the inductive hypothesis, then perform hard algebra, then apply Pascal's rule:
            \[
                (x + y)^{k+1} = (x + y)(x + y)^k
            \]
            \[
                = (x + y) \left[ x^k + \binom{k}{1}x^{k-1}y + \binom{k}{2}x^{k-2}y^2 + \cdots + \binom{k}{k-1}xy^{k-1} + y^k \right]
            \]
            \[
                = x^{k+1} + \left[\binom{k}{0}\right]x^k y + \left[\binom{k}{1}\right]x^{k-1}y^2 + \cdots + \left[\binom{k}{k}\right]xy^k + y^{k+1}
            \]
            \[
                = x^{k+1} + \binom{k+1}{1}x^k y + \binom{k+1}{2}x^{k-1}y^2 + \cdots + \binom{k+1}{k}xy^k + y^{k+1}.
            \]
            And that—a few boring algebraic details omitted—is the proof.
            \bigbreak \noindent 
            The binomial theorem tells us that in order to expand $(x + y)^5$ you can just look at the 5th row of Pascal’s triangle (where the top element counts as the $0$th row, so the 5th row is $1 \ 5 \ 10 \ 10 \ 5 \ 1$):
            \[
                (x + y)^5 = 1x^5 + 5x^4y + 10x^3y^2 + 10x^2y^3 + 5xy^4 + 1y^5.
            \]
            Moreover, by plugging in special values for $x$ and $y$, all sorts of neat identities pop out. There are loads of examples of this, but here are just three:
            \begin{itemize}
                \item By plugging in $x = 1$, $y = 1$, we prove $\sum_{k=0}^n \binom{n}{k} = 2^n$.
                \item By plugging in $x = 2$, $y = 1$, we prove $3^n = \sum_{k=0}^n \binom{n}{k}2^k$.
                \item By plugging in $x = -1$, $y = 1$, we prove $0 = \sum_{k=0}^n (-1)^k \binom{n}{k}$.
            \end{itemize}
        % \item \textbf{Fermat's little theorem with 4.15}:
        %     \bigbreak \noindent 
        %     \textbf{Theorem}. If $a$ is a natural number and $p$ is a prime which does not divide $a$, then
        %     \begin{align*}
        %         a^{p} \equiv a \pmod{p}
        %     .\end{align*}
        %     \textbf{Note: } Written just slightly differently by multiplying each side of the congruence by a, which can also be undone by using the cancellation law



    \end{itemize}

    \pagebreak 
    \subsection{Logic}
    \begin{itemize}
        \item \textbf{Statements}: A statement is a sentence or mathematical expression that is either true or false. If the logic is valid and the statements are true, then it is called sound
            \bigbreak \noindent 
            Every theorem/proposition/lemma/corollary is a (true) statement; Every conjecture is a statement (of unknown truth value); and Every incorrect calculation is a (false) statement.
        \item \textbf{Open sentence}: 
            A related notion is that of an \textit{open sentence}, which refers to sentences or mathematical expressions that:
            \begin{enumerate}
                \item do not have a truth value,
                \item depend on some unknown, like a variable $x$ or an arbitrary function $f$, and
                \item when the unknown is specified, the open sentence becomes a statement (and thus has a truth value).
            \end{enumerate}
            Their truth value depends on the specific value of $x$ or $f$ that is chosen.
            \bigbreak \noindent 
            Typically, we use capital letters for statements, like $P$, $Q$ and $R $. Open sentences are often written the same, or perhaps like $P(x)$, $Q(x)$ or $R(x)$ when one wishes to emphasize the variabl
        \item \textbf{And, or, not}: Let $P$ and $Q$ be statements or open sentences.
            \begin{enumerate}
                \item $P \land Q$ means "P and Q".
                \item $P \lor Q$ means "P or Q (or both)".
                \item $\sim P$ means "not P".
            \end{enumerate}
        \item \textbf{Implies, iff}:
            Let $P$ and $Q$ be statements or open sentences.
            \begin{enumerate}
                \item $P \implies Q$ means "P implies Q".
                \item $P \iff Q$ means "P if and only if Q".
            \end{enumerate}
            \bigbreak \noindent 
            Let’s now discuss a subtle aspect of implications: Translating them to and from English. Language can be complicated,\footnote{Language nuances can make logical translation challenging.} and we in fact have many different ways in English to say "$P$ implies $Q$." Here are some examples:
            \begin{itemize}
                \item If $P$, then $Q$
                \item $Q$ if $P$
                \item $P$ only if $Q$
                \item $Q$ whenever $P$
                \item $Q$, provided that $P$
                \item Whenever $P$, then also $Q$
                \item $P$ is a sufficient condition for $Q$
                \item For $Q$, it is sufficient that $P$
                \item For $P$, it is necessary that $Q$
            \end{itemize}
            For example, "If it is raining, then the grass is wet" has the same meaning as "The grass is wet if it is raining." These also mean the same as "The grass is wet whenever it is raining" or "For the grass to be wet, it is sufficient that it is raining."
            \bigbreak \noindent 
            Next, here are some ways to say "$P$ if and only if $Q$":
            \begin{itemize}
                \item $P$ is a necessary and sufficient condition for $Q$.
                \item For $P$, it is necessary and sufficient that $Q$.
                \item $P$ is equivalent to $Q$.
                \item If $P$, then $Q$, and conversely.
                \item $P$ implies $Q$ and $Q$ implies $P$.
                \item Shorthand: $P$ iff $Q$.
                \item Symbolically: $(P \implies Q) \land (Q \implies P)$.
            \end{itemize}
            The fact that ``$P$ implies $Q$'' is the same as ``If $P$, then $Q$'' or ``$Q$ if $P$'' is sometimes intuitive to students. But the fact that these are all the same as ``$P$ only if $Q$'' is often confusing. Most people's guts tell them that ``$P$ implies $Q$'' should be the same as ``$Q$ only if $P$.''
            \bigbreak \noindent 
            The answer is ``$P$ only if $Q$'', and the way to think about it is that ``$P$ implies $Q$'' means that whenever $P$ is true, $Q$ must also be true. And ``$P$ only if $Q$'' means that $P$ can only be true if $Q$ is true\ldots that is, whenever $P$ is true, it must be the case that $Q$ is also true\ldots that is, $P \implies Q$.
        \item \textbf{Conditional, biconditional statements}: Now, if $P$ and $Q$ are statements, then ``$P \implies Q$'' and ``$P \iff Q$'' are also statements, meaning they must also be either true or false. The statement $P \implies Q$ is called a conditional statement, whereas $P \iff Q$ is called a biconditional statement. These are minor definitions, but the following is an important definition.

        \item \textbf{Converse}: The \textit{converse} of $P \implies Q$ is $Q\implies P $
            \bigbreak \noindent 
            \textbf{Note:} If $P \implies Q$, it is not necessarily the case that $Q \implies P$
        \item \textbf{Truth tables for and, or, and not}: A truth table models the relationship between the truth values of one or more statements, and that of another
            \bigbreak \noindent 
            \begin{center}
                \begin{tabular}{c|c|c}
                    $P$& $Q$ & $P\land Q$ \\
                    \hline
                    True & True  & True \\
                    True & False & False \\
                    False &  True & False \\
                    False & False & False
                \end{tabular}
            \end{center}
            For for "$P$ and $Q$" to be a true statement, both $P$ and $Q$ must be independently true
            \bigbreak \noindent 
            Here’s how the truth values for $P$ and for $Q$ affect the truth value for $P \lor Q$.
            \begin{center}
                \begin{tabular}{c|c|c}
                    $P$ & $Q$ & $P \lor Q$ \\
                    \hline
                    True  & True & True \\
                    True  & False & True \\
                    False  & True  & True \\
                    False & False & False
                \end{tabular}
            \end{center}
            It is sufficient that either $P$ is true or that $Q$ is true (or both).
            \bigbreak \noindent 
            Finally, here is how the truth values for $P$ affects that of $\neg P$.
            \begin{center}
                \begin{tabular}{c|c}
                    $P$ &  $\neg P$ \\
                    \hline
                    True & False\\
                    False & True
                \end{tabular}
            \end{center}
            In order for ``not $P$'' to be true, it is required that $P$ be false. By applying this reasoning twice, this also implies that $\sim\sim P$ and $P$ always have the same truth value.
            \bigbreak \noindent 
            One last example shows how we proceed with more complicated statements
            \[
                \begin{array}{c|c|c|c|c|c}
                    \hline
                    P & Q & P \vee Q & P \wedge Q & \neg (P \wedge Q) & (P \vee Q) \wedge \neg (P \wedge Q) \\
                    \hline
                    \text{True} & \text{True} & \text{True} & \text{True} & \text{False} & \text{False} \\
                    \text{True} & \text{False} & \text{True} & \text{False} & \text{True} & \text{True} \\
                    \text{False} & \text{True} & \text{True} & \text{False} & \text{True} & \text{True} \\
                    \text{False} & \text{False} & \text{False} & \text{False} & \text{True} & \text{False} \\
                \end{array}
            \]
        \item \textbf{De Morgan’s Logic Laws}: Take a loot at the truth tables for $\neg(P \land Q)$ and $\neg P \lor \neg Q$, side by side:
            \begin{multicols}{2}
                \[
                    \begin{array}{c|c|c|c}
                        P & Q & P \land Q & \neg(P \land Q) \\
                        \hline
                        \text{True} & \text{True} & \text{True} & \text{False} \\
                        \text{True} & \text{False} & \text{False} & \text{True} \\
                        \text{False} & \text{True} & \text{False} & \text{True} \\
                        \text{False} & \text{False} & \text{False} & \text{True} \\
                    \end{array}
                \]

                \[
                    \begin{array}{c|c|c|c|c}
                        P & Q & \neg P & \neg Q & \neg P \lor \neg Q \\
                        \hline
                        \text{True} & \text{True} & \text{False} & \text{False} & \text{False} \\
                        \text{True} & \text{False} & \text{False} & \text{True} & \text{True} \\
                        \text{False} & \text{True} & \text{True} & \text{False} & \text{True} \\
                        \text{False} & \text{False} & \text{True} & \text{True} & \text{True} \\
                    \end{array}
                \]
            \end{multicols}
            Since the final columns are the same, if one is true, the other is true; if one is false, the other is false; that is, there is no way to select $P$ and $Q$ without these two agreeing. When two statements have the same final column in their truth tables, like in the example above, they are said to be logically equivalent (one is true if and only if the other is true), which we denote with an ``$\iff$'' symbol. De Morgan’s logic law, for example, can be written like this:
            \[
                \neg(P \land Q) \iff (\neg P \lor \neg Q)
            \]
            \bigbreak \noindent 
            "$P$ and $Q$ are not both true" is the same as "$P$ is false or $Q$ is false."
            \bigbreak \noindent 
            \textbf{Theorem}: If $P$ and $Q$ are statements, then
            \[
                \neg(P \land Q) \iff \neg P \lor \neg Q \quad \text{and} \quad \neg(P \lor Q) \iff \neg P \land \neg Q.
            \]
        \item \textbf{$P$, $Q$, and their names}:
            In logical statements involving \( P \) and \( Q \), the terms \( P \) and \( Q \) are referred to as propositions or statements. Depending on the logical operator used, they may also have more specific names:
            \begin{enumerate}
                \item \textbf{In a conjunction (\( P \land Q \)):}
                    \begin{itemize}
                        \item \( P \) and \( Q \) are called \textbf{conjuncts}.
                    \end{itemize}
                \item \textbf{In a disjunction (\( P \lor Q \)):}
                    \begin{itemize}
                        \item \( P \) and \( Q \) are called \textbf{disjuncts}.
                    \end{itemize}
                \item \textbf{In an implication (\( P \implies Q \)):}
                    \begin{itemize}
                        \item \( P \) is called the \textbf{antecedent} (or \textbf{hypothesis}, \textbf{premise}).
                        \item \( Q \) is called the \textbf{consequent} (or \textbf{conclusion}).
                    \end{itemize}
                \item \textbf{In a biconditional (\( P \iff Q \)):}
                    \begin{itemize}
                        \item \( P \) and \( Q \) are called \textbf{equivalents} (since \( P \iff Q \) means \( P \) and \( Q \) are logically equivalent).
                    \end{itemize}
                \item \textbf{In negation (\( \neg P \)):}
                    \begin{itemize}
                        \item \( P \) is simply the proposition being negated.
                    \end{itemize}
            \end{enumerate}

        \item \textbf{Implications}: We call the conditional statemests, $P \implies Q$ \textit{implications}. They are called implications because they express a logical relationship where one statement (the premise, $P$) ``implies'' or leads to another statement (the conclusion, $Q$). The word ``implication'' comes from the Latin root \textit{implicare}, meaning ``to entwine'' or ``to involve,'' reflecting the idea that $P$ is connected to $Q$.
            \bigbreak \noindent 
            A biconditional statement combines two implications, $P \implies Q$ AND $Q\implies P $
        \item \textbf{Truth Tables with Implications}: Consider the truth table for the implication $P\implies Q$
            \begin{center}
                \begin{tabular}{c|c|c}
                    $P$& $Q$ & $P\implies Q$ \\
                    \hline 
                    True & True  & True \\
                    True  & False & False \\
                    False & True & True \\
                    False & False & True
                \end{tabular}
            \end{center}
            The results of the first two rows are trivial, but the last two may be hard to grasp.
            \bigbreak \noindent 
            Why is the implication true if the assumption, $P$, is false? It’s kind of like how we said that this is true: "If $x \in \varnothing$, then $x$ is a purple elephant that speaks German." Since there is nothing in the empty set, if you suppose $x \in \varnothing$, you can then claim anything you want about $x$ and it is inherently true — you certainly cannot present to me any element in the empty set that is not a purple elephant that speaks German. In the set theory chapter, we called such a claim \textit{vacuously true}. 
            \bigbreak \noindent 
            Likewise, in a universe where $P$ is true, the statement $P \implies Q$ has some real meaning that needs to be proven or disproven: Does $P$ being true imply $Q$ is true, or not? But in a universe where $P$ is not true, it claims nothing, and hence $P \implies Q$ is \textit{vacuously true}.
            \bigbreak \noindent 
            "If unicorns exist, then they can fly" can certainly not be considered false, because unicorns do not exist, so any claim about them is considered vacuously true. Indeed, the way to falsify that proposition would be to locate a unicorn that cannot fly, which is impossible to do. Every unicorn in existence can indeed fly! Also, every unicorn in existence cannot fly! Neither can be disproven!
        \bigbreak \noindent 
        Let's now consider the truth table for the statement $P \iff Q $
        \begin{center}
            \begin{tabular}{c|c|c}
                $P$& $Q$ & $P\iff Q$ \\
                \hline
                True &True & True \\
                True & False & False \\
                False & True & False \\
                False & False & True
            \end{tabular}
        \end{center}
        We can see this by writing $P\iff Q $ as $(P\implies Q) \land (Q\implies P)$
    \item \textbf{Quantifiers}: Consider the sentence
        \begin{center}
           $n$ is even 
        \end{center}
        Which is not a statement because it is neither true nor false. One way to turn a sentence like this into a statement is to give n a value. For example,
        \begin{center}
           If $n=5$, then $n$ is even 
        \end{center}
        What I’d like to discuss now are two other basic ways to turn "$n$ is even" into a statement: add quantifiers. A quantifier is an expression which indicates the number (or quantity) of our objects
        \begin{center}
          $\forall \ n\in \mathbb{N}$, $n$ is even \\
          $\exists \ n \in \mathbb{N}$ such that $n$ is even
        \end{center}
        Where $\forall$ means "for all", and $\exists$ means "there exists". The symbol $\forall$ is known as the \textit{universal quantifer}. Whereas $\exists$ is known as the \textit{existential quantifier.}
        \bigbreak \noindent 
        \textbf{Note}: We also have $\not\exists $ "there does not exist", and $\exists! $ "there exists a unique"
    \item \textbf{Rules of negating}: We have the following rules for negating statements
        \begin{itemize}
            \item $\neg\land = \lor $ 
            \item $\neg\lor = \land $
            \item $\neg\forall = \exists $ 
            \item $\neg\exists = \forall $ 
        \end{itemize}
        Consider the statement, $R: $ for every real number $x$, there is some real number $y$ such that $y^{3} = x $. Symbolically, we have
        \begin{align*}
            \forall\ x\in \mathbb{R},\ \exists \ y\in \mathbb{R} \text{ such that } y^{3} = x
        .\end{align*}
        Then,
        \begin{align*}
            \neg(\forall\ x\in \mathbb{R},\ \exists \ y\in \mathbb{R} \text{ such that } y^{3} = x)
        .\end{align*}
        Is equivalent to the statement
        \begin{align*}
            \exists \ x\in \mathbb{R}, \text{ such that } \forall \ y\in \mathbb{R},\ y^{3} \ne x
        .\end{align*}
    \item \textbf{Negations with implications}: First, recall the truth table for $P\implies Q$
        \begin{center}
            \begin{tabular}{c|c|c}
                $P$& $Q$ & $P\implies Q $ \\
                \hline
                True  & True & True \\
                True & False & False \\
                False & True & True \\
                False & False & True
            \end{tabular}
        \end{center}
        \bigbreak \noindent 
        The only way for $P \implies Q$ to be false is for both $P$ to be true and for $Q$ to be false. This shows that
        \begin{align*}
            \neg(P \implies Q) \Leftrightarrow P \land \neg Q
        .\end{align*}
        Consider the statement
        \begin{align*}
            S:\ \forall \ n \in \mathbb{N}, (3\mid n) \implies (6\mid n)
        .\end{align*}
        Then,
        \begin{align*}
            \neg S:\ &\neg( \forall \ n \in \mathbb{N}, (3\mid n) \implies (6\mid n)) \\
                     &\eq \exists \ n \in \mathbb{N} \text{ such that } (3\mid n) \land (6\nmid n)
        .\end{align*}
    \item \textbf{The contrapositive (and the inverse)}: The \textit{contrapositive} of $P\implies Q$ is $\neg Q \implies \neg P $
        \bigbreak \noindent 
        \textbf{Note:} The \textit{inverse} of $P \implies Q$ is $\neg P \implies \neg Q $
        \bigbreak \noindent 
        \textbf{Theorem}: An implication is logically equivalent to its contrapositive. That is,
        \begin{align*}
            P \implies Q \eq \neg Q \implies \neg P
        .\end{align*}
        The truth table easily verifys this
    \item \textbf{Proving quantified statements: Existential proofs}: To prove an existence statement, it suffices to exhibit an example satisfying the criteria. The above strategy is called a constructive proof — you literally construct an example. There are also non-constructive ways to prove something exists. Often (but not always!) non-constructive proofs make use of some other theorem. 
    \item \textbf{Proving quantified statements: Universal proofs}: To prove a universal statement, it suffices to choose an arbitrary case and prove it works there. We have seen several examples of this. For example, if you were asked to prove that "For every odd number $n$, it follows that $n + 1$ is even," your proof wouldn’t explicitly check 1 and 3 and 5 and so on. Rather, you would say "Since $n$ is odd, $n = 2a + 1$ for some $a \in \mathbb{Z}$." Then you would note that 
        \[
            n + 1 = (2a + 1) + 1 = 2(a + 1)
        \]
        is even. The point here is that by letting $n = 2a + 1$, you were essentially selecting an arbitrary odd number, and operating on that. Every odd number can be written in that form, and every odd number can have 1 added to it and then factored like we did. Since our $n$ was completely arbitrary, everything we did could be applied to any particular odd number. Proving something holds for an arbitrary element of a set, proves that it in turn holds for every element in that set.
    \item \textbf{Proving biconditional statements}: In order to prove a statement in the form $P\implies Q$, we must prove both directions. That is, $P\implies Q$ and $Q\implies P $


    \end{itemize}

    \pagebreak 
    \subsection{Proof using the contrapositive}
    \begin{itemize}
        \item \textbf{Proof outline}:
            \bigbreak \noindent 
            \textbf{Proposition.} $P\implies Q$
            \bigbreak \noindent 
            \textbf{\textit{Proof}}. We will use the contrapositive. Assume not-$Q$
            \penv{
                $\left\langle \left\langle \text{ An explanation of what not-$Q$ means } \right\rangle \right\rangle $, use definitions, and/or other results
                \begin{align*}
                    &\vdots  \quad \text{ Apply algebra,}\\
                    &\vdots  \quad \text{ logic, techniques}
                .\end{align*}
                $\left\langle \left\langle \text{ Hey look, that's what not-$P$  means } \right\rangle \right\rangle $
                \bigbreak \noindent 
                Therefore not-$P$
            }
            Since not-$Q \implies $ not-$P$, by the contrapositive $P\implies Q $ \hspace{2.5cm} $\blacksquare $
        \item \textbf{Contrapositive proof 1.}
            \bigbreak \noindent 
            \textbf{Proposition}. Suppose $n\in \mathbb{N}$, if $n^{2}$ is odd, then $n$ is odd.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We will use the contrapositive. The statement, $\forall \ n \in \mathbb{N},\ n^{2} = 2k+1 \implies n = 2\ell + 1,\ k,\ell \in \mathbb{Z}$ has the logically equivalent contrapositive $\forall n \in \mathbb{N},\ n \ne 2\ell + 1 \implies n^{2}\ne 2k+1$. Since $n\in \mathbb{N}$, if $n, n^{2}$  is not odd, then it must be even. Thus, the statement becomes $\forall n \in \mathbb{N},\ n = 2\ell \implies n^{2} = 2k,\ k,\ell \in \mathbb{N}$ which becomes much easier to proof. For some extra practice negating statements, here is the negation
            \begin{align*}
                \neg(&\forall n \in \mathbb{N},\ n^{2} = 2k+1 \implies n  = 2\ell  + 1,\ k,\ell \in \mathbb{N}) \\
                =\ &\exists n \in \mathbb{N} \text{ such that } n^{2}= 2k+1 \land n \ne 2\ell + 1
            .\end{align*}
            Recall $\neg(P\implies Q) = P \land \neg Q $
            \bigbreak \noindent 
            Assume $n\in \mathbb{N}$, and that $n$ is even. Since $n$ is even, it must be that $n = 2\ell$, for some integer $\ell$. Squaring both sides, we get
            \begin{align*}
                n^{2} &= (2\ell)^{2} \\
                      &=4\ell^{2} =2(2\ell^{2})
            .\end{align*}
            Since $\ell \in \mathbb{Z}$, we know $2\ell^{2} \in \mathbb{Z} $, and thus $n^{2}$ is even.
            \bigbreak \noindent 
            Therefore, since $n$ not being odd implies $n^{2}$ is also not odd, we have shown by the contrapositive that if $n^{2}$ is odd, $n$ is also odd $\quad \blacksquare $
        \item \textbf{Contrapositive proof 2.} 
            \bigbreak \noindent 
            \textbf{Proposition}. Suppose $n \in N$. Then, $n$ is odd if and only if $3n + 5$ is even
            \pagebreak \bigbreak \noindent 
            \textbf{\textit{Proof.}} We will prove this in two parts
            \penv{
                \underline{Part 1: If $n$ is odd then $3n+5$ is even}. Assume $n\in \mathbb{N}$ is odd, then $n = 2k+1$, for $k\in \mathbb{N}_{0}$. Thus,
                \begin{align*}
                    3n+5 &= 3(2k+1) + 5 \\
                         &= 6k + 3 + 5 = 6k + 8\\
                         &= 2(3k+4)
                     .\end{align*}
                     Thus even.
                     \bigbreak \noindent 
                     \underline{Part 2: $3n+5$ being even implies $n$ is odd}. We prove this by use of the contrapositive. The given statement has the following contrapositive...
                     \begin{align*}
                         n = 2k \implies 3n+5 = 2\ell + 1,\ k,\ell \in \mathbb{N}_{0}
                     .\end{align*}
                     Thus,
                     \begin{align*}
                         3n+5 &= 3(2k) + 5 \\
                              &= 6k+5 = 6k + 4 + 1 \\
                              &= 2(3k+2) + 1
                    .\end{align*}
                    Thus odd.
                    \bigbreak \noindent 
            }
            Since $P \implies Q$, and $Q\implies P$, it must be that $P \iff Q$ is true. Thus, we assert for $n\in \mathbb{N}$, $n$ is odd if and only if $3n+5$ is even.
        \item \textbf{Contrapositive proof 3.}:
            \bigbreak \noindent 
            \textbf{Proposition}. Let $a,b\in \mathbb{Z}$, and $p \in \mathbb{P}$. If $p\nmid ab$, then $p\nmid a$ and $p\nmid b $
            \textbf{Proof.} Suppose $a, b \in \mathbb{Z}$ and $p$ is a prime. We will use the contrapositive. Suppose that it is not true that $p \nmid a$ and $p \nmid b$. By the logic form of De Morgan’s law (Theorem 5.9), this is equivalent to saying it is not true that $p \nmid a$ \textit{or} it is not true that $p \nmid b$. That is, $p \mid a$ \textit{or} $p \mid b$. Let’s consider these two cases separately.
            \penv{
                \textbf{Case 1.} Suppose $p \mid a$, which by the definition of divisibility (Definition 2.8) means that $a = pk$ for some $k \in \mathbb{Z}$. Thus,
                \[
                    ab = (pk)b = p(kb).
                \]
                Since $k, b \in \mathbb{Z}$, also $(kb) \in \mathbb{Z}$. And so, by the definition of divisibility (Definition 2.8), $p \mid ab$.
                \bigbreak \noindent 
                \textbf{Case 2.} Suppose $p \mid b$, which by the definition of divisibility (Definition 2.8) means that $b = p\ell$ for some $\ell \in \mathbb{Z}$. Thus,
                \[
                    ab = a(p\ell) = b(a\ell).
                \]
                Since $a, \ell \in \mathbb{Z}$, also $(a\ell) \in \mathbb{Z}$. And so, by the definition of divisibility (Definition 2.8), $p \mid ab$.
                \bigbreak \noindent 
                In either case, we concluded that $p \mid ab$, which is equivalent to saying that it is not true that $p \nmid ab$.
                \bigbreak \noindent 

            }
            We proved that if it is not true that $p \nmid a$ and $p \nmid b$, then it is not true that $p \nmid ab$. Hence, by the contrapositive, this implies that if $p \mid ab$, then $p \mid a$ and $p \mid b$. \(\square\)
            \bigbreak \noindent 
            \textbf{Note:} Mathematicians have agreed that we should be allowed to skip essentially-identical cases
            \bigbreak \noindent 
            If you have two cases, like $p \mid a$ and $p \mid b$, and there is literally no mathematical distinction between them, then you are allowed to say "without loss of generality, assume $p \mid a$." This allows you to skip the "$p \mid b$" case entirely.
            \bigbreak \noindent 
            \textbf{Condensed, Elder-Approved Proof.} Suppose $a, b \in \mathbb{Z}$ and $p$ is a prime. We will use the contrapositive. Suppose that it is not true that $p \nmid a$ and $p \nmid b$. By the logic form of De Morgan’s law (Theorem 5.9), this is equivalent to saying it is not true that $p \nmid a$ \textit{or} it is not true that $p \nmid b$. That is, $p \mid a$ \textit{or} $p \mid b$. Without loss of generality, assume $p \mid a$.
            \bigbreak \noindent 
            By the definition of divisibility (Definition 2.8), this means that $a = pk$ for some $k \in \mathbb{Z}$. Thus,
            \[
                ab = (pk)b = p(kb).
            \]
            Since $k, b \in \mathbb{Z}$, also $(kb) \in \mathbb{Z}$. And so, by the definition of divisibility (Definition 2.8), $p \mid ab$.
            \bigbreak \noindent 
            We proved that if it is not true that $p \nmid a$ and $p \nmid b$, then it is not true that $p \nmid ab$. Hence, by the contrapositive, this implies that if $p \mid ab$, then $p \mid a$ and $p \mid b$. \(\square\)
        \item \textbf{Contrapositive proof 4.}
            \bigbreak \noindent 
            \textbf{Proposition}. Let $a,b,n \in \mathbb{N}$. If $36a \not\equiv 36b \pmod{n} $, then $n\nmid 36 $
            \bigbreak \noindent 
            \textbf{Proof idea}. The fact that this proposition says a lot of things are not happening is one indication that the contrapositive could be worthwhile. The contrapositive states For $a,b,n\in \mathbb{N}$,  If $ n\mid 36$, then $36a\equiv 36b \pmod{n}$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $a,b,n\in \mathbb{N}$, and $n\mid36$. In this case, we have $36 = nk$, for $k\in \mathbb{Z}$. We require $36a-36b = n\ell$, for $\ell \in \mathbb{Z}$. We then examine the quantity $36a-36b$. Since $36 = nk$, we have
            \begin{align*}
                36a - 36b &= nka - nkb \\
                          &=n(ka-kb)
            .\end{align*}
            Which is precisely the definition of divisibility, since it is clear that $ka-kb \in \mathbb{Z}$. Thus, we have $n \mid 36a -36b $, and by the definition of modular congruence $36a  \equiv 36b \pmod{n}$.
            \bigbreak \noindent 
            Therefore, by the contrapositive, $36a \not\equiv 36b \pmod{n}$ implies that $n\nmid 36 \quad \blacksquare $
        \item \textbf{Lemma 6.6} This lemma has two parts
            \begin{enumerate}[label=(\roman*)]
                \item If $m\in\mathbb{Z} $, then $m^{2}  + m $ is even 
                \item If $a\in \mathbb{Z}$, and $a^{2}$ is even, then $a$ is even
            \end{enumerate}
            This proof is trivial and will not be shown. Proving $i$ is simply a proof by cases. To prove $ii$, we can use the contrapositive, instead proving that if $a$ is odd, then $a^{2}$ is odd. Which, by the contrapositive shows that if $a^{2}$ is even, then $a$ must also be even.
        \item \textbf{Contrapositive proof 5.} 
            \bigbreak \noindent 
            \textbf{Proposition}. If $a$ is an odd integer, then $x^{2} + x - a^{2}=  0$ has no integer solution.
            \bigbreak \noindent 
            \textbf{Proof idea.} We will use the contrapositive, which states if $x^{2} + x - a^{2} = 0$ has an integer solution, then $a$ is even.
            \bigbreak \noindent 
            \textbf{Note:} Negating $Q$ in this case ($x^{2} + x - a^{2} = 0 $ has no integer solution) does not given $x^{2} +x - a^{2} \ne 0 $... It is important to question what it means for the given statement to be false in order to properly negate. The negation of the statement is "it is false that $x^{2} + x  -a^{2} = 0 $ has no integer solutions", which must mean that some integer $m$ exists such that $m^{2} + m -a^{2} = 0$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose that \(a\) is an odd integer. We will use the contrapositive. Assume that it is false that \(x^2 + x - a^2 = 0\) has no integer solutions; that is, assume that there is some integer \(m\) such that
            \begin{align*}
                m^2 + m - a^2 = 0
            .\end{align*}
            By the quadratic formula\(^9\) and then some algebra,
            \begin{align*}
                m &= \frac{-1 \pm \sqrt{1^2 - 4(1)(-a^2)}}{2(1)} \\
                m &= \frac{-1 \pm \sqrt{1 + 4a^2}}{2} \\
                2m &= -1 \pm \sqrt{1 + 4a^2} \\
                2m + 1 &= \pm \sqrt{1 + 4a^2} \\
                4m^2 + 4m + 1 &= 1 + 4a^2 \\
                m^2 + m &= a^2.
            .\end{align*}
            Next, observe that \(m^2 + m\) is guaranteed to be even, by Lemma 6.6 part (i). Thus, since we just deduced that \(m^2 + m = a^2\), this means that \(a^2\) must be even. And since \(a\) is an integer, \(a^2\) being even implies that \(a\) is even, by Lemma 6.6 part (ii). In particular, this means that \(a\) is not odd.

            We have shown that if it is false that \(x^2 + x - a^2 = 0\) has no integer solutions, then it is also false that \(a\) is an odd integer. By the contrapositive, if \(a\) is an odd integer, then \(x^2 + x - a^2 = 0\) has no integer solution. \(\Box\)







    \end{itemize}

    \pagebreak 
    \subsection{Contradiction}
    \begin{itemize}
        \item \textbf{The idea}: The big idea is this: If you start with something true and apply correct logic to it, you will never arrive at something false. So it can’t be true that Carmen stole the bag, if that would imply the falsity that she can be in two places at once. Indeed, if your assumptions imply something false, then something you assumed had to be false as well.
            \bigbreak \noindent 
            Suppose we had a theorem $P \implies Q$. Throughout the problem, we assume $P$ to be true. The goal is to show that $Q$ is also true. By the truth tables, either $Q$ is true or $\neg Q$ is true, not both. This gives two options.
            \begin{enumerate}
                \item $P$ is true and $Q$ is true $(P \land Q) $
                \item $P$ is true and $\neg Q$ is true $(P \land \neg Q) $
            \end{enumerate}
            If $P \land \neg Q $ implies anything false, that can't be the correct option. That is, it must be $P \land Q$. Thus, we have shown $P\implies Q $
            \bigbreak \noindent 
            Notice that the only way that \(P \implies Q\) can be false is if \(P\) is true and \(Q\) is false.
            \bigbreak \noindent 
            \begin{center}
                \begin{tabular}{c|c|c}
                    $P$ &$Q$ &$P \implies  Q$ \\
                    \hline
                    True &True &True \\
                    True &False &False \\
                    False &True &True \\
                    False &False &True
                \end{tabular}
            \end{center}
            Thus, this is the only case we have to rule out in order to prove our theorem: that \(P \implies Q\) is true. So, if you assume that \(P\) is true and \(Q\) is false, and manage to use that to deduce a contradiction, then you will have ruled out the one and only bad case, which in turn means that the theorem must be true!
            \bigbreak \noindent 
            In other words, if $P \land \neg Q$ cannot be, then it must be that $P \implies Q$
        \item \textbf{Contradiction example 1.} 
            \bigbreak \noindent 
            \textbf{Proposition.} There does not exist a largest natural number
            \bigbreak \noindent 
            \textbf{Proof Idea.} One quick note: This proposition is not phrased explicitly as 
            ``\(P \implies Q\),'' but you are probably starting to see how to rephrase propositions 
            in this form. For example, this proposition could instead be stated as: 
            ``If \(N\) is the set of natural numbers, then \(N\) does not have a largest element.'' 
            Or, equivalently: ``If \(N\) is larger than every natural number, then \(N \notin \mathbb{N}\)'' 
            Or, equivalently: ``If \(N\) is a natural number, then there exists a natural number 
            larger than \(N\).''
            \bigbreak \noindent 
            For our proof by contradiction, we will assume that there \emph{is} a largest natural number, 
            and then deduce a contradiction. There are several ways to do this, but one way is to assume 
            that \(N\) is the largest and then show that \(N + 1\) must be larger—if it weren’t, we could 
            deduce that \(0 \geq 1\), which is clearly a contradiction. Here’s that:
            \bigbreak \noindent 
            \textbf{Proof.} Assume for a contradiction that there is a largest element of \(\mathbb{N}\), and call this number \(N\). Being larger than every other natural number, \(N\) has the property that \(N \geq m\) for all \(m \in \mathbb{N}\).
            \bigbreak \noindent 
            Observe that since \(N \in \mathbb{N}\), also \((N + 1) \in \mathbb{N}\). And so, by assumption,
            \[
                N \geq N + 1.
            \]
            Subtracting \(N\) from both sides,
            \[
                0 \geq 1.
            \]
            This is a contradiction\(^1\) since we know that \(0 < 1\), and therefore there must not be a largest element of \(\mathbb{N}\). \(\Box\)

        \item \textbf{Contradiction example 2.}
            \bigbreak \noindent 
            \textbf{Proposition}. There does not exist a smallest positive rational number.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume for the sake of contradiction that there does exist a smallest positive rational number. Call this number $q$. Since $q\in \mathbb{Q}$, we have
            \begin{align*}
                q = \frac{a}{b}
            .\end{align*}
            Where $a,b \in \mathbb{Z}$, and $a,b > 0$. Since $q$ is the smallest, than for all $r \in \mathbb{Q}$, we have $q \leq r$. Let $r = \frac{a}{2b} $. Then,
            \begin{align*}
                \frac{a}{b} &\leq \frac{a}{2b} \\
                \implies 2ab &\leq ab \\
                \implies 2 &\leq 1
            .\end{align*}
            This is a contradiction, since we know $2 > 1$. It must be that there is no smallest positive rational number.
        \item \textbf{Proof by contradiction general form}: 
            \bigbreak \noindent 
            \textbf{Proposition.} $P\implies Q$
            \bigbreak \noindent 
            \textbf{Proof.} Assume for the sake of contradiction $P$ and $\neg Q$
            \penv{
                $\left\langle \left\langle \text{ An explanation of what these mean } \right\rangle \right\rangle $
                \begin{align*}
                    &\vdots \quad \text{ Apply algebra,} \\
                    &\vdots \quad \text{ logic, techniques} 
                .\end{align*}
                $\left\langle \left\langle \text{ Hey look, that contradicts something we know to be true } \right\rangle \right\rangle $
            }
            We obtained a contradiction, therefore $P\implies Q \quad \blacksquare$
        \item \textbf{Proof by contradiction example 3.}
            \bigbreak \noindent 
            \textbf{Proposition.} If $A,B$ are sets, then $A \cap (B \setminus A) = \varnothing $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume for the sake of contradiction, that $A \cap (B\setminus A) \ne \varnothing $
            \penv{
                Since $A\cap (B \setminus A) \ne \varnothing$, then $\exists x \in A \cap (B \setminus A) $. Thus, $x\in A \ \land \ x\in (B\setminus A) $. Rewrite $B\setminus A$ as $B \cap A^{C}$. Thus, $x\in B \ \land \ x\in A^{C}$. Since $x\in A^{C}$, it must be that $x \not\in A$. Thus, we have $x\in A$, $x\in B$, and $x\not\in A $
            }
            Therefore, since $x \in A $ and $x \not\in A$ is a contradiction, it must be that if $A$, and $B$ are sets, then $A \cap (B \setminus A) = \varnothing $ $\quad \blacksquare $.
        \item \textbf{Proof by contradiction example 4.}
            \bigbreak \noindent 
            \textbf{Proposition.} There does not exists integers $m,n$ such that $15m + 35n = 1 $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume for the sake of contradiction there does exist integers $m,n $ such that $15m + 35n = 1$, since $m,n \in \mathbb{Z}$, $3m + 7n \in \mathbb{Z} $, but
            \begin{align*}
                15m + 35n &=  1\\
                \implies 3m + 7n &= \frac{1}{5}
            .\end{align*}
            Since $3m+7n \not\in \mathbb{Z} $, we have a contradiction. Thus, it must be that there does not exist integers $m,n$ such that $15m + 35n = 1$.
            \bigbreak \noindent 
            Alternatively, we could have done
            \begin{align*}
                15m + 35n &= 1 \\
                \implies 5(3m + 7n) &= 1
            .\end{align*}
            Which implies $5\mid 1$. But it is clearly the case that $5\nmid 1$, since there exists no $k\in \mathbb{Z}$ such that $1 = 5k$. Thus, another way to arrive at a contradiction. $\quad \blacksquare $
        \item \textbf{Proof by contradiction example 5.}
            \bigbreak \noindent 
            \textbf{Proposition.} There are infinitely many primes.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose for the sake of contradiction that there are finitely many primes, say $k$ in total. Let $p_{1}, p_{2},p_{3},...,p_{k}$ be the complete list. Consider the number $N = p_{1} \cdot p_{2} \cdot p_{3} \cdot ...\cdot p_{k}$. Next, consider $N + 1 $. That is, $p_{1}p_{2}p_{3}...p_{k} + 1$. Either $N + 1 $ is prime or it is composite, we consider both cases separately
            \bigbreak \noindent 
            \underline{Case 1: $N+1$ is prime.} In this case, $N+1$ is prime and greater than all the $p_{i}$s we have previously considered. Thus, we have found a new prime.
            \bigbreak \noindent 
            \underline{Case 2: $N+1$ is composite}. We begin by showing that no such $p_{i}$ divides $N+ 1$. Because we know that $p_{i} \mid N$, we have
            \begin{align*}
                N \equiv 0 \pmod{p_{i}}
            .\end{align*}
            Adding one to both sides, we get
            \begin{align*}
                N+1 \equiv 1 \pmod{p_{i}}
            .\end{align*}
            Hence, it must be that $p_{i}\nmid N+1$. Since $p_{i}$ was arbitrary, this shows that none of our $k$ primes divide $N+1 $
            \bigbreak \noindent 
            We assumed that \( p_1, p_2, \ldots, p_k \) was the complete list of prime numbers. 
            And recall that \( N + 1 \) is assumed to be composite, which means it is a product of primes. 
            But since none of the \( p_i \) divide \( N + 1 \), there must be some other prime number, \( q \),
            which divides \( N + 1 \). And hence, we have again found a new prime.
            \bigbreak \noindent 
            In either case, we have contradicted the claim that \( p_1, p_2, \ldots, p_k \) was an exhaustive
            list of the prime numbers. Therefore, there must be infinitely many primes. $\quad \blacksquare $
        \item \textbf{Proof by contradiction example 6.}
            \bigbreak \noindent 
            \textbf{Proposition} The number $\sqrt{2}$ is irrational
            \bigbreak \noindent 
            \textbf{Proof.} Assume for a contradiction that $\sqrt{2}$ is rational. Then there must be some non-zero integers $p$ and $q$ where
            \[
                \sqrt{2} = \frac{p}{q}.
            \]
            Moreover, we may assume that this fraction is written in \textit{lowest terms}, meaning that $p$ and $q$ have no common divisors. Then,
            \[
                \sqrt{2}q = p.
            \]
            By squaring both sides,
            \[
                2q^2 = p^2.
            \]
            Since $q^2 \in \mathbb{Z}$, by the definition of divisibility, this implies that $2 \mid p^2$, and hence $2 \mid p$ by Lemma 2.17 part (iii). By a second application of the definition of divisibility, this means that $p = 2k$ for some non-zero integer $k$. Plugging this in:
            \begin{align*}
                2q^2 &= p^2,\\
                2q^2 &= (2k)^2,\\
                2q^2 &= 4k^2,\\
                q^2 &= 2k^2
            \end{align*}
            Therefore, $2 \mid q^2$, and hence $2 \mid q$, again by Lemma 2.17 part (iii). But this is a contradiction: We had assumed that $p$ and $q$ had no common factors, and yet we proved that $2$ divides each. Therefore, $\sqrt{2}$ cannot be rational, meaning it is irrational.
            \bigbreak \noindent 
            The following is a geometric proof that $\sqrt{2} \in \bar{\mathbb{Q}}$. Recall that $\bar{\mathbf{Q}}$ is the set of irrational numbers.
            \bigbreak \noindent 
            Assume for a contradiction that $\sqrt{2} = \frac{p}{q}$ where $p, q \in \mathbb{N}$ and the fraction is written in lowest terms. This implies that 
            \[
                2q^2 = p^2,
            \]
            but this time let’s think about this as 
            \[
                p^2 = 2q^2.
            \]
            Or, better yet,
            \[
                p^2 = q^2 + q^2.
            \]
            Since $p$ and $q$ are integers, $p^2$ represents the area of a square with side length $p$, and each $q^2$ represents the area of a square with side length $q$.
            \bigbreak \noindent 
            \fig{.6}{./figures/15.png}
            \bigbreak \noindent 
            Recall that $\sqrt{2} = \frac{p}{q}$ was written in lowest terms. In particular, this means that there do not exist any smaller integers $a$ and $b$ for which $\sqrt{2} = \frac{a}{b}$. Our contradiction will be to find such $a$ and $b$.
            \bigbreak \noindent 
            Getting back to the squares above, we are now going to imagine each square is a piece of paper and we are going to place the two $q^{2}$ squares on top of the $p^{2}$ square. If one $q^{2}$ square is placed in the lower-left, and the other is placed in the upper-right, this happens
            \bigbreak \noindent 
            \fig{.6}{./figures/17.png}
            \bigbreak \noindent 
            Notice that there is one square region in the middle that was covered twice, and two small squares in the upper-left and lower-right that were not covered at all. And remember: The amount of area in the $p^2$ square is equal to the amount of area in the two $q^2$ squares. Therefore, the area that was covered twice must equal the area that was not covered at all! Let’s suppose the middle square has dimensions $a \times a$, and the two corner squares have dimensions $b \times b$. Then, this reasoning shows that
            \bigbreak \noindent 
            \fig{.8}{./figures/18.png}
            \bigbreak \noindent 
            And those $a$ and $b$ must also be integers, since they are the difference of integers from the overlap picture:
            \bigbreak \noindent 
            \fig{.8}{./figures/19.png}
            \bigbreak \noindent 
            We had assumed that $p$ and $q$ were the smallest integers for which $\sqrt{2} = \frac{p}{q}$, and yet the above image shows that $a$ and $b$ are also integers, and since $a^2 = b^2 + b^2$, which implies $2b^2 = a^2$, we have $2 = \frac{a^2}{b^2}$. And so, finally, by taking the square root of each side, we see that
            \[
                \sqrt{2} = \frac{a}{b}.
            \]
            We have shown that $a$ and $b$ are integers with the above property. The picture above also shows that $a$ is smaller than $p$, and $b$ is smaller than $q$. Combined, this contradicts our assumption that $p$ and $q$ are the smallest integers where $\sqrt{2} = \frac{p}{q}$.
        \item \textbf{The irrational numbers}:
            The fact that irrational numbers exist explains why we need the real numbers $\mathbb{R}$—the rational numbers $\mathbb{Q}$ are clearly not enough! Next, note that while $\sqrt{2}$ is not a ratio of integers, it is a root of $x^2 - 2 = 0$, which is a polynomial with integer coefficients.
            \bigbreak \noindent 
            \textbf{Big Question:} Is every irrational number a root of a polynomial with integer coefficients? 
            \bigbreak \noindent 
            \textbf{Big Answer:} Nope! In 1844, Joseph Liouville proved that
            \[
                \sum_{k=1}^\infty \frac{1}{10^{k!}} = 0.11000100000000000000000100\ldots
            \]
            is not the root of any polynomial with integer coefficients.
            \bigbreak \noindent 
            The irrational numbers were thus partitioned into \textit{algebraic numbers}, which are the roots of such polynomials, and \textit{transcendental numbers}, which are not. Today, $\pi$ and $e$ are the most famous numbers which have been proved to be transcendental.
        \item \textbf{Proof of the halting problem}:
            \bigbreak \noindent 
            \textbf{Theorem}. Assume that $P$ is an arbitrary program and $i$ is a possible input of $P$; we write $P(i)$ to be the result of plugging input $i$ into the program $P$. There does not exist a program $H(P(i))$ which determines whether $P(i)$ will eventually halt.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume for a contradiction that such a program $H$ did exist. Create a new program $T(x)$; its input, $x$, is itself a program with some input. Now, we define the program $T(x)$ as follows:
            \bigbreak \noindent 
            \begin{cppcode}
            Input: A program |$x$|, with its own input
            Run |$H(x)$|
            if |$H(x)$| answers |\textit{Program $x$ will halt} \textbf{then}|
                begin an infinite loop
            else halt
            \end{cppcode}
            \bigbreak \noindent 
            The program $T$ is designed to run counter to $x$: If the input program $x $ was going to halt, then $T$ begins an infinite loop. And if the input program was going to run forever, then $T$ says to halt
            \bigbreak \noindent 
            The program $T$ accepts as input any program. And since $T$ is itself a program, we are allowed to \textit{plug $T$ into itself!} What is the result? Well, since $T(T)$ is a program, like any program either $T(T)$ contains an infinite loop or it does not. Let’s consider each of these two cases.
            \bigbreak \noindent 
            \underline{Case 1:} Observe that if $T(T)$ has an infinite loop, then like all programs with infinite loops, it will not halt — but by looking at the above pseudocode for $T$, it is clear that if $T(T)$ has an infinite loop, then it will halt! This is a contradiction.
            \bigbreak \noindent 
            \underline{Case 2:} Conversely, if $T(T)$ does not have an infinite loop, then like all programs without an infinite loop it must eventually halt — but by looking at the above pseudocode for $T$, it is clear that if $T(T)$ will eventually halt, then it will begin an infinite loop which will prevent it from halting! This is again a contradiction.
            \bigbreak \noindent 
            Whether $T$ does or does not have an infinite loop, we have reached a contradiction. And since $T$ was built from $H $, our assumption that there exists a halting program $H$ must have been incorrect. This concludes the proof. $\quad \blacksquare $
        \item \textbf{Proof by contradiction example 7}:
            \bigbreak \noindent 
            \textbf{Proposition.} Every natural number is interesting
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume for a contradiction that not every natural number is interesting. Then, there must be a smallest uninteresting number, which we call $n$. But being the smallest uninteresting number is a very interesting property for a number to have! So $n$ is both uninteresting and interesting, which gives the contradiction. Therefore, every natural number must be interesting. $\quad \blacksquare $
        \item \textbf{Proof by minimal counterexample}: We proved that every natural number is interesting. The way we did this was by assuming for a contradiction that not every number is interesting. Under this assumption, there exist uninteresting natural numbers, and so there must exist a smallest uninteresting natural number.
            \bigbreak \noindent 
            Despite it being a silly example, there is an important idea behind it which is sometimes called \textit{proof by minimal counterexample}. Consider a theorem which asserts something is true for every natural number, and you are attempting to prove it by contradiction. Then you would assume for a contradiction not every natural number satisfies the result — that is, you’re assuming there is at least one counterexample. Well, among all of the counterexamples, one of them must be the smallest. And thinking about that smallest counterexample — such as the smallest uninteresting number — can at times be a powerful variant of proof by contradiction.
            \bigbreak \noindent 
            We used strong induction to prove the fundamental theorem of arithmetic. But there’s another slick proof of this theorem that uses a proof by minimal counterexample
            \bigbreak \noindent 
            \textbf{Theorem (\textit{Fundemental theorem of arithmetic})}. Every integer $n \geq 2 $ is either prime or a product of primes.
            \bigbreak \noindent 
            Recall that every integer $n \geq 2$ is either prime or composite, and being composite means it is a product of smaller integers
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} 
            Assume for a contradiction that this is not true. Then there must be a minimal counterexample; let’s say $N$ is the smallest natural number at least 2 which is neither prime nor the product of primes. The fact that it is not prime means that it is composite: $N = ab$ for some $a, b \in \{2, 3, \ldots, N - 1\}$.
            \bigbreak \noindent 
            We now make use of the fact that $N$ is assumed to be the minimal counterexample to this result — which means that everything smaller than $N$ must satisfy the result. In particular, since $a$ and $b$ are smaller than this smallest counterexample, $a$ and $b$ must each be prime or a product of primes.
            \bigbreak \noindent 
            And this gives us a contradiction: Since $N = ab$, if $a$ and $b$ are each prime or a product of primes, then their product — which equals $N$ — must be as well. This contradicts our assumption that $N$ was a counterexample, completing the proof.
            \bigbreak \noindent 
            Another way to think about this proof is that it argues that if $N$ were a counterexample, then since $N = ab$, it can’t possibly be that both $a$ and $b$ are primes or a product of primes, since as we just saw, that would produce a contradiction. And therefore, it must be the case that either $a$ or $b$ is also a counterexample. This implies that every counterexample produces a smaller counterexample — every $N$ produces an $a$ or a $b$. But this is a contradiction, since you can not repeatedly find smaller and smaller natural numbers — at some point you reach the bottom.
        \item \textbf{Proof of the division algorithm}
            \bigbreak \noindent 
            \textbf{Theorem (\textit{The division algorithm})}: For all integers $a$ and $m$ with $m > 0$, there exist unique integers $q$ and $r$ such that
            \[
                a = mq + r,
            \]
            where $0 \leq r < m$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} 
            \textbf{Existence.} First, note that if $a = 0$, then by simply choosing $q = 0$ and $r = 0$, the theorem follows. Thus, we may assume that $a \neq 0$.
            \bigbreak \noindent 
            Next, we will argue that if the theorem holds for all positive $a$, then it also holds for all negative $a$. Indeed, assume that $a > 0$, and suppose $a$ and $m$ can be expressed as
            \[
                a = mq + r,
            \]
            where $0 \leq r < m$. Then, $-a$ has an expression as well. In particular, if we let $q' = -q - 1$ and $r' = m - r$, then
            \[
                mq' + r' = m(-q - 1) + (m - r) = -mq - m + m - r = -(mq + r) = -a.
            \]
            Therefore, for these integers $q'$ and $r'$,
            \[
                -a = mq' + r',
            \]
            where $0 \leq r' < m$. Because of this, any expression for $a > 0$ immediately produces one for $-a$. Thus, we need only prove the case where $a$ is a positive integer.
            \bigbreak \noindent 
            We will implement a proof by minimal counterexample in order to prove the case where $a$ is positive. Fix any $m > 0$, and assume for a contradiction that not every $a \in \mathbb{N}$ satisfies the theorem, which in turn means that there is a smallest $a$ for which the theorem fails. Consider three cases.
            \bigbreak \noindent 
            \textbf{Case 1:} $a < m$. In this case, we can simply let $q = 0$ and $r = a$, and we have obtained
            \[
                a = m \cdot q + r,
            \]
            with $0 \leq r < m$, and the theorem is satisfied.
            \bigbreak \noindent 
            \textbf{Case 2:} $a = m$. In this case, we can simply let $q = 1$ and $r = 0$, and we have obtained
            \[
                a = m \cdot q + r,
            \]
            with $0 \leq r < m$, and the theorem is satisfied.
            \bigbreak \noindent 
            \textbf{Case 3:} $a > m$. Recall that the theorem assumes that $m > 0$, and so in this case we have $a > m > 0$. In particular, note that $a > a - m$ and also $a - m > 0$.
            \bigbreak \noindent 
            Since $a$ is the smallest positive counterexample to this theorem, and $a - m$ is both positive and less than $a$, the integer $a' = a - m$ must satisfy this theorem! That is, there must exist integers $d$ and $s$ for which
            \[
                (a - m) = m \cdot d + s,
            \]
            with $0 \leq s < m$. By moving the $m$ on the left side over,
            \[
                a = m \cdot d + s + m.
            \]
            By factoring,
            \[
                a = m \cdot (d + 1) + s.
            \]
            Thus, by letting $q = d + 1$ and $r = s$, we have shown that our smallest counterexample is not a counterexample at all:
            \[
                a = m \cdot q + r,
            \]
            with $0 \leq r < m$. Since there cannot exist a smallest counterexample, there cannot exist any counterexample. Thus, for each $a$ and $m$, there must exist a $q$ and $r$ as the theorem asserts.
            \bigbreak \noindent 
            \textbf{Uniqueness.} Assume for a contradiction that for our fixed $a$ and $m$, the $q$ and $r$ are not unique. That is, assume there exist two different representations of $a$:
            \[
                a = mq + r \quad \text{and} \quad a = mq' + r',
            \]
            where $q, r, q', r' \in \mathbb{Z}$ and $0 \leq r, r' < m$. Then,
            \[
                mq + r = mq' + r'.
            \]

            By some algebra, we find:
            \[
                r - r' = mq' - mq,
            \]
            which means
            \[
                r - r' = m(q' - q).
            \]
            \bigbreak \noindent 
            Since $q$ and $q'$ are integers, so is $q - q'$ (by Fact 2.1), which means the above expression matches the definition of divisibility (Definition 2.8)! That is, $m \mid (r - r')$.
            \bigbreak \noindent 
            Notice that since $0 \leq r, r' < m$, the difference $r - r'$ would have these restrictions:
            \[
                -m < r - r' < m.
            \]
            And the only number in this range which is divisible by $m$ is zero. That is, $r - r' = 0$, or $r = r'$.
            \bigbreak \noindent 
            Next, since $r = r'$, the fact that $r - r' = m(q - q')$ implies that
            \[
                0 = m(q - q').
            \]
            Since $m > 0$, we may divide both sides by $m$, which means $0 = q - q'$, or $q = q'$.
            \bigbreak \noindent 
            We assumed that
            \[
                a = mq + r \quad \text{and} \quad a = mq' + r'
            \]
            were two different representations of $a$ and $m$, but we have proven that $q = q'$ and $r = r'$, proving that they are in fact the same representation, giving the contradiction and concluding the proof.


    \end{itemize}

    \pagebreak 
    \subsection{Functions}
    \begin{itemize}
        \item \textbf{The definition of a function}: Given a pair of sets \( A \) and \( B \), suppose that each element \( x \in A \)
            is associated, in some way, to a unique element of \( B \), which we denote \( f(x) \). Then
            \( f \) is said to be a function from \( A \) to \( B \). This is often denoted
            \( f : A \to B \).
            \bigbreak \noindent 
            Furthermore, \( A \) is called the \textbf{domain} of \( f \), and \( B \) is called the \textbf{codomain} of \( f \).
            \bigbreak \noindent 
            The set \( \{f(x) : x \in A\} \) is called the \textbf{range} of \( f \).
        \item \textbf{The \textit{Existence}, and \textit{uniqueness} property of functions}: When discussing functions, the ideas of existence and uniqueness will come up repeatedly. We defined a function \( f : A \to B \) to be a rule which sends each \( x \in A \) to some \( f(x) \in B \). What this means is that \( f(x) \) must exist (it must be equal to some \( b \in B \)), and it must be unique (it must be equal to only one \( b \in B \)).
            \bigbreak \noindent 
            For example, defining $f: \mathbb{R} \to \mathbb{R}$, $f(x) = \ln{(x)}$ fails the \textit{existence} requirement of functions, because the natural logarithm function $\ln{(x)}$ is not defined for negative values of $x$ or $x=0 $. his means that the function $\ln(x)$ would fail the requirement of existence for all elements in the domain $\mathbb{R}$.
            \bigbreak \noindent 
            To make $f(x) = \ln(x) $ a valid function, we must adjust the domain to only include values for which $\ln(x)$ is defined. The correct domain is $(0,\infty)$, the set of positive real numbers. Thus, we would write
            \begin{align*}
                f: (0, \infty) \to \mathbb{R}
            .\end{align*}
            A "function" that fails the uniqueness requirement of functions would assign a single element in the domain to more than one element in the codomain.
            \bigbreak \noindent 
            Consider a rule $f: A \to B $ defined as 
            \begin{align*}
                f(x) = \begin{cases}
                    b_{1} & \text{ if } x= a \\     
                    b_{2} & \text{ if } x= a 
                \end{cases}
            .\end{align*}
            Where $b_{1} \ne b_{2}$, and $a\in A $. This rule clearly violates the \textit{uniqueness} criterion, and is therefore not a function.
            \bigbreak \noindent 
            In high school you were probably taught the \textit{vertical line test} to check whether a graph corresponds to a function. The vertical line test says that if every vertical line hits the graph in one (existence) and only one (uniqueness) spot, then the graph corresponds to a function
        \item \textbf{Injections, Surjections and Bijections}: A function $f : A \to B$ is injective (or one-to-one) if $f(a_{1}) = f(a_{2})$ implies that $a_{1} = a_{2}$.
            \bigbreak \noindent 
            The contrapositive of the second half states, A function $f: A \to B$ is \textit{injective} if $a_{1} \ne a_{2}$ implies that $f(a_{1}) \ne f(a_{2}) $
            \bigbreak \noindent 
            A function $f:\  A \to B$ is surjective (or onto) if, for every $b \in B$, there exists some $a \in A$ such that $f(a) = b$
            \bigbreak \noindent 
            Let’s take a look at another way to define this same idea, by again applying the contrapositive (and doing a little rearranging).
            \bigbreak \noindent 
            A function $f:\ A \to B$ is surjective (or onto) if there does not exist any $b \in B$ for which $f(a) \ne b$ for all $a \in A$.
            \bigbreak \noindent 
            When defining a function \( f : A \to B \), the ideas of existence and uniqueness were focused on \( A \) — for every \( x \in A \), we demanded that \( f(x) \) exist and be unique. To be injective and surjective, the attention shifts to \( B \). To be surjective means that \( B \) has an existence criterion (for every \( b \in B \), there exists some \( a \in A \) that maps to it). And to be injective means that \( B \) has a uniqueness-type criterion (for every \( b \in B \), there is at most one \( a \in A \) that maps to it).
            \bigbreak \noindent 
            A function $f:\  A \to B$ is \textit{bijective} if it is both injective and surjective.
            \bigbreak \noindent 
            Defining a function \( f : A \to B \) placed existence and uniqueness criteria on \( A \). If \( f \) is both injective and surjective, then this adds existence and uniqueness criteria to \( B \). Thus, if \( f \) is a bijection, then it has these criteria on both sides: Every \( a \in A \) is mapped to precisely one \( b \in B \), and every \( b \in B \) is mapped to by precisely one \( a \in A \). In effect, this pairs up each element of \( A \) with an element of \( B \); namely, \( a \) is paired with \( f(a) \) in this way.
        \item \textbf{Proving $x$jectiveness for $x\in \{\text{in,sur,bi}\}$}: Based on its definition, this is the outline to prove a function is injective.
            \bigbreak \noindent 
            \begin{mdframed}
                \textbf{Proposition}. $f:\ A \to B$ is an injection
                \bigbreak \noindent 
                \textbf{\textit{Proof.}} Assume $x,y \in A $, and $f(x) = f(y)$
                \begin{align*}
                    &\vdots \quad \text{ Apply algebra}, \\
                     &\vdots \quad \text{ logic, techniques}
                .\end{align*}
                Therefore, $x=y $
                \bigbreak \noindent 
                Since $f(x) =f(y)$ implies $x=y$, $f$ is injective $\quad \blacksquare $
            \end{mdframed}
            \bigbreak \noindent 
            Alternatively, one could use the contrapositive, which would mean one starts by assuming $x \ne y$, and then concludes that $f(x) \ne f(y)$.
            \bigbreak \noindent 
            Next, here’s the outline for a surjective proof.
            \begin{mdframed}
                \textbf{Proposition.} $f:\ A \to B$ is a surjection
                \bigbreak \noindent 
                \textbf{\textit{Proof.}} Assume $b\in B $
                \begin{align*}
                    &\vdots \quad \text{ Magic  to find an $a\in A$}\\
                    &\vdots \quad \text{ where $f(a) = b $}
                .\end{align*}
                Since every $b\in B$ has an $a\in A$ where $f(a) = b $, $f$ is surjective $\quad \blacksquare $
            \end{mdframed}
        \item \textbf{Proving jectiveness examples}
            \begin{itemize}
                \item \( f : \mathbb{R} \to \mathbb{R} \) where \( f(x) = x^2 \) is not injective, surjective, or bijective.
                \item \( g : \mathbb{R}^+ \to \mathbb{R} \) where \( g(x) = x^2 \) is injective, but not surjective or bijective.
                \item \( h : \mathbb{R} \to \mathbb{R}^+ \) where \( h(x) = x^2 \) is surjective, but not injective or bijective.
                \item \( k : \mathbb{R}^+ \to \mathbb{R}^+ \) where \( k(x) = x^2 \) is injective, surjective, and bijective.
            \end{itemize}
            \bigbreak \noindent 
            \textbf{\textit{Proof (part a).}} Observe that $f(-2) = f(2) =4 $, while $-2 \ne 2 $. Thus, $f$ is not injective. Next, notice that $f(x) = x^{2} > 0$. Thus, there is no such $a\in \mathbb{R}$ such that $f(a) = -4$. Since $-4$ is in the codomain and is not hit, $f$ is not surjective. Since $f$ is not both injective and surjective, it is therefore not bijective. 
            \bigbreak \noindent 
            \textbf{Part b}. Let $a_{1}, a_{2} \in \mathbb{R}^{+}$, assume $g(a_{1}) = g(a_{2})$. Thus,
            \begin{align*}
                a_{1}^{2} &= a_{2}^{2} \\
                \implies a_{1} &= \pm a_{2}
            .\end{align*}
            But, for all $a\in \mathbb{R}^{+}$, $a >0$. Thus, $a_{1} = a_{2}$ and $g $ is injective. Observe that again there is no such value in the domain of $g$ such that $g(x) = -4$. Since $-4$ is in the codomain of $g$, it is not surjective, and is therefore not bijective.
            \bigbreak \noindent 
            \textbf{Part c.} Observe that $h(-2) = h(2) = 4$, while $-2 \ne 2$. Thus, $ h$ is not injective. Further, let $b\in \mathbb{R}^{+}$, then
            \begin{align*}
                h(a) &= b \\
                \implies a^{2} &= b \\
                \implies a &= \pm b
            .\end{align*}
            But, the codomain is restricted to positive values, thus $a=b$ and $h $ is surjective. Since $h$ is not injective, it is not bijective.
            \bigbreak \noindent 
            \textbf{Part d.} Let $a_{1}, a_{2} \in \mathbb{R}^{+}$, assume $f(a_{1}) = f(a_{2}) $, which implies
            \begin{align*}
                a_{1}^{2} &= a_{2}^{2} \\
                \implies a_{1} &= \pm a_{2}
            .\end{align*}
            Again, since the domain is restricted to positive values, we have $a_{1} = a_{2}$ and $f$ is injective. Next, let $b\in \mathbb{R}^{+}$, then
            \begin{align*}
                f(a) &= b \\
                \implies a^{2} &= b \\
                \implies a &= \pm b
            .\end{align*}
            But since the codomain is restricted to positive values, $a=b$ and the function is surjective. Since the function is both onto and one-to-one, the function is bijective (invertible). $\quad \blacksquare $
        \item \textbf{Proving jectiveness example 2.} Show $f: (\mathbb{Z} \times \mathbb{Z}) \to (\mathbb{Z} \times \mathbb{Z})$, with $f(x,y) = (x+2y, 2x+3y) $ is a bijection.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} First, we show injectiveness. Let $(a,b), (c,d) \in \mathbb{Z}^{2}$. Assume $f(a,b) = f(c,d) $. Thus,
            \begin{align*}
                &(a+2b,2a+3b) = (c+2d, 2c+3d) \\
                \implies &\begin{cases} a+2b &=c+2d \\ 2a+3b &=2c+3d \end{cases} \\
                \implies &\begin{cases} a+2b-2a-3b &=0 \\ 2a+3b-2c-3d &=0 \end{cases} 
            .\end{align*}
            We then solve this system,
            \begin{align*}
                \begin{array}{cccc|c} 1 & 2 & -1 & -2 & 0\\ 2 & 3 & -2 & -3 & 0 \end{array} \implies \begin{array}{cccc|c} 1 & 0 & -1 & 0 & 0 \\ 0 &1 & 0 & -1 & 0\end{array}
            .\end{align*}
            Which implies 
            \begin{align*}
                \begin{cases}
                    a &= c \\
                    b &=d
                \end{cases}
           \end{align*}
            As desired. Thus, $f$ is injective. Next, let $(c,d) \in \mathbb{Z}^{2}$. Require $f(a,b) = (c,d)$ for some $(a,b) \in \mathbb{Z}^{2} $. Thus,
            \begin{align*}
                &(a+2b, 2a+3b) = (c,d) \\
                \implies &\begin{cases} a + 2b &= c\\ 2a+3b &=d \end{cases}
            .\end{align*}
            Solving this system yields
            \begin{align*}
                \begin{array}{cc|c} 1 & 2 & c \\ 2 & 3 & d \end{array} \implies \begin{array}{cc|c} 1 & 0 & -3c + 2d \\0&1 &2c-d \end{array}
            .\end{align*}
            Thus, $(a,b) = (-3c +2d, 2c-d)$ and the function is surjective. Because the function is both injective and surjective, it is therefore bijective.
            \bigbreak \noindent 
            Alternatively, observe that $f:\ \mathbb{Z}^{2} \to \mathbb{Z}^{2}$, $f(x,y) = (x+2y, 2x+3y) $ is given by the matrix representation $A\vec{\mathbf{x}} = \vec{\mathbf{b}} $
            \begin{align*}
                \begin{pmatrix} 1 & 2\\2&3 \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix} &= \begin{pmatrix} a \\b \end{pmatrix}
            .\end{align*}
            Thus, since $A$ is square, we can simply check its determinant. \footnote{Common linear algebra $W$} 
            \begin{align*}
                \det\begin{pmatrix} 1 & 2 \\ 2 & 3 \end{pmatrix} &= 1(2)-2(3) = -1
            .\end{align*}
            Since $\det(A) \ne 0$, the function is invertible
        \item \textbf{The func-y pigeonhole principal}:
            \bigbreak \noindent 
            \textbf{Theorem 8.10 (The func-y pigeonhole principal)}: Suppose $A$ and $B$ are finite sets and $f:\  A \to B$ is any function.
            \begin{enumerate}[label=(\alph*)]
                \item If $|A| > |B|$, then $f$ is not injective.
                \item If $|A| < |B|$, then $f$ is not surjective.
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} \textbf{Part (a).} Consider each element in \( A \) to be an object and each element of
            \( B \) to be a box. Given an \( a \in A \), place object \( a \) into box \( b \) if \( f(a) = b \). 
            Since there are more objects than boxes, by the pigeonhole principal at least one box has at least
            two objects in it. That is, \( f(a_1) = f(a_2) \) for some distinct \( a_1 \) and \( a_2 \), implying that
            \( f \) is not injective.
            \bigbreak \noindent 
            \textbf{Part (b).} Since \( f \) is a function, each \( a \in A \) is mapped to only one \( b \in B \). 
            Thus, \( k \) elements in \( A \) can map to at most \( k \) elements of \( B \). 
            And so the \( |A| \) elements in \( A \) can map to at most \( |A| \) elements in \( B \). 
            However, since \( |A| < |B| \), there must be some elements not hit, meaning that \( f \) is not surjective.
            \bigbreak \noindent 
            It is again useful to think about what the contrapositive tells us:
            \begin{itemize}
                \item[(a)] If \( f \) is injective, then \( |A| \leq |B| \).
                \item[(b)] If \( f \) is surjective, then \( |A| \geq |B| \).
            \end{itemize}
            Viewing the statements this way is beneficial for another reason: It demonstrates
            clearly that in order for \( f \) to be a bijection—meaning an injection and a surjection—we
            would need \( |A| = |B| \).
            \bigbreak \noindent 
            It is also worth mentioning that this theorem still holds true in the case that \( |A| \)
            and/or \( |B| \) are infinite.\footnote{But proving this to be the case would take us too far afield.}
        \item \textbf{The Composition}: Let \( A \), \( B \), and \( C \) be sets, \( g : A \to B \), and \( f : B \to C \). Then the
            composition function is denoted \( f \circ g \) and is defined as follows:
            \[
                (f \circ g) : A \to C \quad \text{where} \quad (f \circ g)(a) = f(g(a)).
            \]
            Suppose 
            \begin{align*}
                &g:\ \mathbb{R} \to \mathbb{R},\ g(x) = x+1 \\
                &f:\ \mathbb{R} \to \mathbb{R}^{+},\ f(x) = x^{2}
            .\end{align*}
            Then,
            \begin{align*}
                (f\circ g):\ \mathbb{R} \to \mathbb{R}^{+},\ (f\circ g)(x) = (x+1)^{2}
            .\end{align*}
        \item \textbf{Property of injective functions under composition}:
            \bigbreak \noindent 
            \textbf{Theorem 8.13}. Suppose $A, B$ and $C$ are sets, $g:\ A \to B$ is injective, and $f:\ B \to C$ is injective. Then $f \circ g$ is injective
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Since $(f\circ g):\ A \to C$, to show that is an injection we must show that for all $a_{1}, a_{2}\in A$, $(f\circ g)(a_{1}) = (f\circ g)(a_{2}) $ implies $a_{1} = a_{2}$. Assume $a_{1}, a_{2} \in A$, and $(f\circ g)(a_{1}) = (f\circ g)(a_{2})$. Using the definition of the composition, we have
            \begin{align*}
                f(g(a_{1})) = f(g(a_{2}))
            .\end{align*}
            Since $f$ is injective, we know that for any $b_{1}, b_{2} \in B$, $f(b_{1}) = f(b_{2}) $ implies $b_{1} = b_{2}$. Since $g(a_{1}), g(a_{2}) \in B$, we have
            \begin{align*}
                g(a_{1}) = g(a_{2})
            .\end{align*}
            Likewise, since $g$ is injective, it must be that $a_{1}  = a_{2}$
            \bigbreak \noindent 
            Thus, we have shown that for any $a_{1}, a_{2} \in A$, if $(f\circ g)(a_{1}) = (f\circ g)(a_{2})$, then $a_{1} = a_{2}$. Therefore, $(f\circ g)$ is an injection. $\quad \blacksquare $
        \item \textbf{Property of surjective functions under composition}:
            \bigbreak \noindent 
            \textbf{Theorem 8.14}: Suppose $A$, $B$ and $C$ are sets, $g:\ A \to B$ is surjective, and $f:\ B \to C$ is surjective. Then $f \circ g$ is surjective.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Since $(f\circ g):\ A \to C$, to show that $f\circ g$ is surjective, we must show that for all $c\in C$, there exists some $a\in A$ such that $(f\circ g)(a) = c$. To start, since $f$ is surjective, then for all $c\in C$, there exists some $b\in B$ such that $f(b) = c$. Further, we know that $g$ is surjective. Thus, for all $b\in B$, there exists some $a\in A$ such that $g(a) = b$. 
            \bigbreak \noindent 
            Thus, for an arbitrary $c\in C$, we have found an $a\in A$ such that
            \begin{align*}
                (f\circ g)(a) = f(g(a)) = f(b) = c
            .\end{align*}
            Completing the proof $\quad \blacksquare $
        \item \textbf{A corollary from the above two results}: Suppose $A$, $B$ and $C$ are sets, $g:\  A \to B$ is bijective, and $f:\ B \to C$ is bijective. Then $f \circ g$ is bijective.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} By Theorem 8.13, \( f \circ g \) is an injection. By Theorem 8.14, \( f \circ g \) is a surjection. Thus, by the definition of a bijection (Definition 8.7), \( f \circ g \) is a bijection.
        \item \textbf{Note about compositions}: Notice that in our definition of function composition (Definition 8.11) we had functions \( g \) and \( f \) where \( g : A \to B \), and \( f : B \to C \). Notice that we don’t really need the codomain of \( g \) to equal the domain of \( f \). If we had \( g : A \to B \) and \( f : D \to C \) where \( B \subseteq D \), that would be enough (for the definition, and for these last two theorems). As long as \( g(a) \) is a part of \( f \)’s domain, then \( f(g(a)) \) will make sense, which is all we need.
        \item \textbf{Identity function and invertibility}: For a set \( A \), the identity function on \( A \) is the function 
            \begin{align*}
                i_A : A \to A  \text{ where } i_A(x) = x  \text{ for every }  x \in A 
            \end{align*}
            \bigbreak \noindent 
            The inverse of a function \( f : A \to B \), if it exists, is the function \( f^{-1} : B \to A \) such that \( f^{-1} \circ f = i_A \) and \( f \circ f^{-1} = i_B \).
            \bigbreak \noindent 
            For example, if \( f : \mathbb{R} \to \mathbb{R} \) where \( f(x) = x + 1 \), then \( f^{-1} : \mathbb{R} \to \mathbb{R} \) is the function
            \( f^{-1}(x) = x - 1 \). To see this, simply note that
            \[
                (f \circ f^{-1})(x) = f(f^{-1}(x)) = f(x - 1) = (x - 1) + 1 = x
            \]
            and
            \[
                (f^{-1} \circ f)(x) = f^{-1}(f(x)) = f^{-1}(x + 1) = (x + 1) - 1 = x.
            \]
        \item \textbf{Arctan and the natural logarithm}: this is a great opportunity to mention a couple important functions — $\text{arctan}(x)$ and $\ln(x)$ — which are defined as the inverses to other important function.
            \begin{itemize}
                \item If \( \tan : (-\pi/2, \pi/2) \to \mathbb{R} \) is the tangent function, then its inverse is defined to be \( \arctan : \mathbb{R} \to (-\pi/2, \pi/2) \), and is called the arctangent function.\footnote{}
                \item If \( \exp : \mathbb{R} \to \mathbb{R}^+ \) is the exponential function (that is, \( \exp(x) = e^x \)), then its inverse is defined to be \( \ln : \mathbb{R}^+ \to \mathbb{R} \), and is called the natural logarithm function.
            \end{itemize}
        \item \textbf{When does an inverse exist}:
            \bigbreak \noindent 
            \textbf{Theorem}: A function $f:\ A \to B$ is invertible if and only if $f$ is a bijection.
            \bigbreak \noindent 
            \textbf{Proof.} First, suppose that \( f : A \to B \) is invertible. We will prove that \( f \) is both
            an injection and a surjection, which will prove that \( f \) is a bijection. To see that \( f \)
            is a surjection, choose any \( b \in B \). We aim to find an \( a \in A \) such that \( f(a) = b \). To 
            this end, let \( a = f^{-1}(b) \), which exists and is in \( A \) because \( f^{-1} : B \to A \). Now simply
            observe that the definition of an invertible function (Definition 8.16) implies
            \[
                f(a) = f(f^{-1}(b)) = b.
            \]
            This proves that \( f \) is a surjection.
            \bigbreak \noindent 
            To see that \( f \) is an injection, let \( a_1, a_2 \in A \) and assume \( f(a_1) = f(a_2) \). Note that 
            \( f(a_1) \) (and hence \( f(a_2) \), since they're equal) is an element of \( B \) due to the fact that 
            \( f : A \to B \). And so, since \( f^{-1} : B \to A \), we may apply \( f^{-1} \) to both sides:
            \[
                f(a_1) = f(a_2)
            \]
            \[
                f^{-1}(f(a_1)) = f^{-1}(f(a_2))
            \]
            \[
                a_1 = a_2,
            \]
            by the definition of the inverse. Thus, \( f \) is an injection. And since we already showed 
            that \( f \) is a surjection, it must be a bijection. This concludes the forward direction of 
            the theorem.
            \bigbreak \noindent 
            As for the backwards direction, assume that \( f \) is a bijection. For \( b \in B \), we will 
            now define \( f^{-1}(b) \) like this:
            \[
                f^{-1}(b) = a \quad \text{if} \quad f(a) = b.
            \]
            That is, we are defining \( f^{-1} \) to act as an inverse from \( B \) to \( A \) should act, without yet 
            claiming that \( f^{-1} \) is a function. Our goal now is to demonstrate that this definition 
            of \( f^{-1} \) satisfies the conditions to be a function, which would prove that \( f \) is invertible. 
            To do so, recall that to be a function there is an existence condition (\( f^{-1}(b) \) must be 
            equal to some \( a \in A \)) and a uniqueness condition (\( f^{-1}(b) \) must be equal to only one 
            \( a \in A \)). We will check these separately.
            \bigbreak \noindent 
            \textbf{Existence:} Let \( b \in B \). Since \( f \) is surjective, there must be some \( a \in A \) such that 
            \( f(a) = b \). Hence, by our definition of \( f^{-1} \), we have \( f^{-1}(b) = a \). We have shown that 
            for every \( b \in B \) there exists at least one \( a \in A \) for which \( f^{-1}(b) = a \), which concludes 
            the existence portion of this argument.
            \bigbreak \noindent 
            \textbf{Uniqueness:} Suppose \( f^{-1}(b) = a_1 \) and \( f^{-1}(b) = a_2 \), for some \( b \in B \) and \( a_1, a_2 \in A \). 
            By the definition of \( f^{-1} \), this means that \( f(a_1) = b \) and \( f(a_2) = b \). But since \( f \) is 
            injective, this means that \( a_1 = a_2 \). We have shown that \( f^{-1}(b) \) can not be equal to 
            two different elements of \( A \), which concludes the uniqueness portion of this argument.
            \bigbreak \noindent 
            Combined, these two parts show that \( f^{-1} : B \to A \) is a function, hence proving 
            that \( f \) is invertible.
            \bigbreak \noindent 
            We have proved the forwards and backwards directions of Theorem 8.17, which 
            completes its proof. \(\Box\)
        \item \textbf{The image and inverse image}: Let \( f : A \to B \) be a function, and assume \( X \subseteq A \) and \( Y \subseteq B \).
            The \textit{image} of \( A \) is
            \[
                f(X) = \{y \in B : y = f(x) \text{ for some } x \in X\},
            \]
            and the \textit{inverse image} of \( Y \) is
            \[
                f^{-1}(Y) = \{x \in A : f(x) \in Y\}.
            \]
        \item \textbf{The bijection principal}:
            \bigbreak \noindent 
            \textbf{principal (\textit{The bijection principal.})} Two sets have the same size if and only if there is a bijection between them.
        \item \textbf{Hilbert's hotel}: We begin by talking about the set of problems related to the so-called Hilbert’s Hotel. Assume that there is a hotel, called Hilbert’s Hotel, which has infinitely many rooms in a row.
            \bigbreak \noindent 
            \fig{.7}{./figures/20.png}
            \begin{itemize}
                \item Assume every room has someone in it, and so the "No Vacancy" sign has been
                    turned on. With most hotels, this would mean that if someone else arrives at
                    the hotel, they will not be given a room. But this isn’t the case with Hilbert’s
                    Hotel. If, for \( n \in \mathbb{N} \), the patron in room \( n \) moves to room \( n + 1 \), then nobody
                    is left without a room and suddenly room 1 is completely open! So the new
                    customer can go to room 1. We created a room out of nothing!
                \item Now imagine 2 people arrived at the hotel. Can we accommodate them?
                    Certainly! Now, just have everyone move from room \( n \) to room \( n + 2 \). This
                    leaves rooms 1 and 2 open to the newcomers, and we are again good-to-go.

                \item What if, however, we have infinitely many people lined up wanting a room?
                    Can we accommodate all of them? Yes! We still can! Just have the person in
                    room \( n \) move to room \( 2n \). Then all of the odd-numbered rooms are vacant and
                    the infinite line of people can take these rooms.
            \end{itemize}
            The first point of this exercise is to simply realize that weird stuff can happen
            when dealing with the infinite. The second point, though, is to realize that each time
            the people switched rooms, those same exact people got new rooms. So in the first
            example when they each just moved one room down, that should mean that there
            are just as many rooms from 1 to $\infty$ as there are from 2 to $\infty$. . . And likewise for the
            others.
        \item \textbf{Cardinality and infinite sets}:
            \bigbreak \noindent 
            \textbf{Example} There are the same number of natural numbers as there are natural
            numbers larger than 1 (that is, \( |\mathbb{N}| = |\{2, 3, 4, \dots \}| \)). What’s the bijection that shows
            this? Let
            \[
                f : \mathbb{N} \to \{2, 3, 4, \dots \} \quad \text{where} \quad f(n) = n + 1.
            \]

            In other (non-)words, this is the pairing
            \[
                1 \leftrightarrow 2 \quad 2 \leftrightarrow 3 \quad 3 \leftrightarrow 4 \quad 4 \leftrightarrow 5 \quad \dots
            \]
            \bigbreak \noindent 
            \textbf{The Moral}. Two sets can have the same size even though one is a proper subset of the other.
            \bigbreak \noindent 
            \textbf{Example}. There are the same number of natural numbers as even natural
            numbers (that is, \( |\mathbb{N}| = |2\mathbb{N}| \)). What’s the bijection that shows this? Let
            \[
                f : \mathbb{N} \to \{2, 4, 6, 8, \dots\} \quad \text{where} \quad f(n) = 2n.
            \]
            In other (non-)words, this is the pairing
            \[
                1 \leftrightarrow 2 \quad 2 \leftrightarrow 4 \quad 3 \leftrightarrow 6 \quad 4 \leftrightarrow 8 \quad \dots
            \]
            \textbf{The Moral.} Two sets can have the same size even though one is a proper subset of the other 
            and the larger one even has \textit{infinitely many more elements} than the smaller one.
            \bigbreak \noindent 
            And in a similar way, one can prove that \( |\mathbb{N}| = |\mathbb{Z}| \). Indeed, a bijection 
            \( f : \mathbb{N} \to \mathbb{Z} \) can be given by following this pattern:
            \[
                f(1) = 0, \quad f(2) = 1, \quad f(3) = -1, \quad f(4) = 2, \quad f(5) = -2, \quad f(6) = 3, \quad \dots
            \]
            \bigbreak \noindent 
            One way to write such a function is this:
            \[
                f : \mathbb{N} \to \mathbb{Z} \quad \text{where} \quad 
                f(n) = 
                \begin{cases} 
                    \frac{n}{2} & \text{if } n \text{ is even}; \\
                    -\frac{(n-1)}{2} & \text{if } n \text{ is odd}.
                \end{cases}
            \]


    \end{itemize}

    \pagebreak 
    \subsection{Relations}
    \begin{itemize}
        \item \textbf{Set partitions}: A partition of a set $A$ is a collection of non-empty subsets of $A$ for which each element of $A$ is in one and only one of the subsets.
            \bigbreak \noindent 
            Formally, a partition is a collection of non-empty sets $\{P_{i}\}_{i\in S} $ such that
            \begin{enumerate}
                \item $P_{i} \subseteq A $ for all $i$
                \item $\bigcup_{i\in S} P_{i} = A$
                \item $P_{i} \cap P_{j} = \varnothing$ for all $i\ne j $
            \end{enumerate}
            \bigbreak \noindent 
            A partition of \( \mathbb{Z} \) is the set of evens and the set of odds. Another partition of \( \mathbb{Z} \) is the positive integers, the negative integers, and \(\{0\}\). Another is the non-\(17\) integers and \(\{17\}\). Another is the five sets in the Mod-5 Property section on the previous page. And the simplest partition of \( \mathbb{Z} \) is simply \( \mathbb{Z} \) — a partition with only one part.
        \item \textbf{Index sets}: In the formal definition of a partition, $S$ is the index set that labels or indexes the subsets $P_{i}$ in the partition. 
            \bigbreak \noindent 
            $S$ can be any set (e.g., $N,\{1,2,...,n\}$, or any other index set), as long as it provides unique labels for each subset $P_{i}$
        \item \textbf{Equivalence Relations}: An \emph{equivalence relation} on a set \( A \) is an ordered relationship between pairs of elements of \( A \) for which the pair is either \emph{related} or is \emph{not related}. If \( a, b \in A \), we denote \( a \sim b \) if \( a \) is related to \( b \), and \( a \not\sim b \) if \( a \) is not related to \( b \).
            \bigbreak \noindent 
            For \( \sim \) to be an equivalence relation, it also must satisfy the following three properties:
            \begin{itemize}
                \item \textbf{Reflexive:} \( a \sim a \) for all \( a \in A \);
                \item \textbf{Symmetric:} If \( a \sim b \), then \( b \sim a \) for all \( a, b \in A \); and
                \item \textbf{Transitive:} If \( a \sim b \) and \( b \sim c \), then \( a \sim c \) for all \( a, b, c \in A \).
            \end{itemize}
            Lastly, if \( \sim \) is an equivalence relation and \( a \in A \), define the \emph{equivalence class} containing \( a \) to be the set
            \[
                \{ b \in A : a \sim b \}.
            \] 
        \item \textbf{Relations}: A relation on a set \( A \) is any ordered relationship between pairs of elements of \( A \) for which the pair is either \emph{related} or is \emph{not related}. If \( a, b \in A \), we denote \( a \sim b \) if \( a \) is related to \( b \), and \( a \not\sim b \) if \( a \) is not related to \( b \).
            \bigbreak \noindent 
            Lastly, if \( \sim \) is a relation and \( a \in A \), define the class containing \( a \) to be the set
            \[
                \{ b \in A : a \sim b \}.
            \]
        \item \textbf{Equivalence relations and partitions}:
            \bigbreak \noindent 
            \textbf{Theorem 9.5.} Assume $\sim$ is a relation on $A$. The relation $\sim$ partitions the elements of $A$ into classes if and only if $\sim$ is an equivalence relation.
            \bigbreak \noindent 
            Before we prove this theorem, we first define some notation. We denote the equivalence class of an element $a\in A$, $\{x\in A:\ a \sim x\} $ by $[a]$. 
            \bigbreak \noindent 
            Next, a lemma.
            \bigbreak \noindent 
            \textbf{Lemma 9.10}. Suppose $\sim$ is an equivalence relation on a set $A$, and let $a, b \in A$. Then,
            \begin{align*}
                [a] = [b] \text{ if and only if } a\sim b
            \end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof of lemma 9.10}}. For the (straight)forward direction, assume that \([a] = [b]\). Observe that since \( \sim \) is reflexive, \( b \sim b \) and so \( b \in [b] \). And since \([a] = [b]\), this in turn means that \( b \in [a] \), which by Notation 9.9 implies \( a \sim b \). This concludes the forward direction.
            \bigbreak \noindent 
            As for the backward direction, we begin by assuming \( a \sim b \), and we aim to prove that \([a] = [b]\). This will be accomplished by demonstrating that \([a] \subseteq [b]\) and \([b] \subseteq [a]\). To prove the former, choose any \( x \in [a] \); we will show that \( x \in [b] \). By assumption we have \( a \sim b \), and because \( x \in [a] \) we have \( a \sim x \). That is,
            \[
                a \sim b \quad \text{and} \quad a \sim x.
            \]
            By the symmetry property of \( \sim \),
            \[
                b \sim a \quad \text{and} \quad a \sim x.
            \]
            By the transitivity property of \( \sim \),
            \[
                b \sim x.
            \]
            And so, by Notation 9.9,
            \[
                x \in [b].
            \]
            We have shown that \( x \in [a] \) implies \( x \in [b] \), and hence \([a] \subseteq [b]\).
            \bigbreak \noindent 
            The reverse direction is nearly the same. Let \( x \in [b] \), which means \( b \sim x \). Combining this, the transitivity of \( \sim \), and our assumption that \( a \sim b \), we get \( a \sim x \), which means \( x \in [a] \). And since \( x \in [b] \) implies \( x \in [a] \), we have \([b] \subseteq [a]\).
            \bigbreak \noindent 
            We have shown that \([a] \subseteq [b]\) and \([b] \subseteq [a]\), which proves that \([a] = [b]\). This concludes the backward direction, and hence the proof.
            \qed
            \bigbreak \noindent 
            We now proceed to the proof of theorem 9.5

        \item \textbf{Equivalence relation example 1}: Let $\sim$ be the relation on $\mathbb{R}$ where
            \begin{align*}
                a \sim b \text{ if } \floor{a} = \floor{b}
            \end{align*}
            We can verify that \( \sim \) is an equivalence relation by checking that it satisfies the three criteria. It is reflexive because certainly \( \floor{a}= \floor{a} \) for any \( a \in \mathbb{R} \); it is symmetric because if \( \floor{a} = \floor{b} \), then certainly \( \floor{b} = \floor{a} \); and it is transitive because if \( \floor{a} = \floor{b} \) and \( \floor{b} = \floor{c} \), then \( \floor{a} = \floor{c} \). Each of these is immediate because the equal sign already has these properties.
            \bigbreak \noindent 
            This means that the equivalence classes must then partition all of $\mathbb{R}$, and indeed they do.
            The class of all numbers that are equivalent to \( 12.4 \) is the set of numbers in the interval \([12, 13)\); that is, all numbers \( x \) such that \( 12 \leq x < 13 \). Indeed, the equivalence classes for \( \sim \) are all intervals of the form \([n, n+1)\) for \( n \in \mathbb{Z} \). 
            \bigbreak \noindent 
            Moreover, by Theorem 9.5 this means that the equivalence classes must then partition all of \( \mathbb{R} \), and they do: every \( x \in \mathbb{R} \) is in precisely one of these intervals:
            \[
                \ldots, [2, 3), [3, 4), [4, 5), [5, 6), [6, 7), \ldots.
            \]
            \qed
    \end{itemize}

    \pagebreak 
    \unsect{Elementary fields, groups, and rings}
    \begin{itemize}
        \item \textbf{Modular congruence and congruence classes}: Recall that two integers $a$ and $b$ are said to be congruent modulo $n$ if they leave the same remainder when divided by $n$. Mathematically, this is written as
            \begin{align*}
                a\equiv b \pmod{n}
            .\end{align*}
            Which means
            \begin{align*}
                n \mid a-b
            .\end{align*}
            When an integer $a$ is divided by $n$
            \begin{align*}
                a = q_{1}n + r_{1} \quad \text{ with} 0 \leq r_{1} < n
            .\end{align*}
            Similarly, for an integer $b$ divided by $n$
            \begin{align*}
                b = q_{2}n + r_{} \quad \text{ with} 0 \leq r_{2} < n
            .\end{align*}
            Subtracting $b$ from $a$
            \begin{align*}
                a - b &= (q_{1} - q_{2})n + (r_{1} - r_{2}) \tag{1}
            .\end{align*}
            If $n\mid (a-b)$, 
            \begin{align*}
                a-b=nk, \quad k\in \mathbb{Z}
            .\end{align*}
            By (1) above, we have
            \begin{align*}
                (q_{1} - q_{2})n + (r_{1} - r_{2}) &= kn
            .\end{align*}
            For this to hold, we require $r_{1}-r_{2}$ to be a multiple of $n$, since $q_{1} - q_{2}$ is already a multiple of $n$. Since $r_{1}, r_{2}$ satisfy $0 \leq r_{1}, r_{2} < n$. It must be that $-n < r_{1}- r_{2} < n$. In this case, for $n$ to divide $r_{1} - r_{2}$. It must be that
            \begin{align*}
                r_{1} - r_{2} &= 0 
            .\end{align*}
            Which implies $r_{1} = r_{2}$. Hence, $a$ and $b$ have the same remainder when divided by $n$ when $n\mid a-b$.
            \bigbreak \noindent 
            A congruence class modulo $n$ is the set of all integers that are congruent to a particular integer $a$ modulo $n$. This set is denoted as
            \begin{align*}
                [a]_{n} = \{x\in \mathbb{Z} \mid x \equiv a \pmod{n}\}
            .\end{align*}
            For example, $[0]_{3}$ is 
            \begin{align*}
                \{x\in \mathbb{Z}:\ x \equiv 0 \pmod{3}\} \\
            .\end{align*}
            Which is the integers $x$ such that $3 \mid x-0  $. In other words, it describes the set of integers that are divisible by 3.
            \bigbreak \noindent 
            The set $[1]_{3}$ is the set
            \begin{align*}
                [1]_{3} = \{x\in \mathbb{Z}:\ x \equiv 1 \pmod{3}\}
            .\end{align*}
            Which implies $3\mid x-1$, and thus $x = 3k + 1$, for $k\in \mathbb{Z}$. In words, it is the set of integers that leave a remainder of one when divided by three.
            \bigbreak \noindent 
            The modulus $n$ partitions the integers into $n$ distinct congruence classes:
            \begin{align*}
                [0]_{n}, [1]_{n}, ...,[n-1]_{n}
            .\end{align*}
            Every integer belongs to exactly one of these classes.
            \bigbreak \noindent 
            Arithmetic operations can be performed within the framework of congruence classes
            \begin{itemize}
                \item \textbf{Addition}: If $a\equiv b \pmod{n}$ and $c \equiv d \pmod{n}$, then  
                    \begin{align*}
                        a + c \equiv b + d \pmod{n}
                    .\end{align*}
                \item \textbf{Multiplication}: If $a\equiv b \pmod{n}$ and $c \equiv d \pmod{n}$, then  
                    \begin{align*}
                        ac \equiv bd \pmod{n}
                    .\end{align*}
            \end{itemize}
        \item \textbf{Groups}: A group is a collection of objects $G$, together with one operation $\oplus$, which has the following properties:
            \begin{itemize}
                \item \textbf{Associativity}: $a \oplus (b\oplus c) = (a\oplus b) \oplus c$
                \item \textbf{Identity}: There is an element $e\in G$ such that $e \oplus g = g \oplus e = g$ for all $g \in G $
                \item \textbf{Inverse}: For every $g\in G$, there exists $g^{-1} \in G$ such that $g \oplus g^{-1} = g^{-1}\oplus g = e $
            \end{itemize}
            For example, $\mathbb{Z}$ is a group under addition.
            \begin{itemize}
                \item \textbf{Associativity}: Two integers $a,b$ are associative, $a + (b + c)  = (a+b) +c $
                \item \textbf{Identity}: Zero is the identity element, since $0 \in \mathbb{Z}$ and $0 + a = a+ 0 = a $
                \item \textbf{Inverse}: $a + (-a) = (-a) + a = 0$
            \end{itemize}
            \textbf{Note:} A group is said to be \textit{abelian} if it is commutative under its operation. In other words, $x \oplus y = y\oplus x$ for all $x,y \in G $
        \item \textbf{Rings}: A ring is a set $R$, together with two operations $\oplus $ and $* $, which has the following properties
            \begin{itemize}
                \item $R$ is an abelian group under $\oplus $
                \item $R$ is associative under $*$
                % \item There exists an element 1 such that $r * 1 =  1 * r  = r $ for all $r\in R $
                \item The operation $*$ distributes over $\oplus$
                    \begin{align*}
                        a * (b\oplus c) &= (a*b) \oplus a * c \\
                        (a\oplus b) * c &= (a*c) \oplus (b*c)
                    .\end{align*}
            \end{itemize}
            For example, $\mathbb{Z}$ is a ring under addition and multiplication. First note that $\mathbb{Z}$ is an abelian group under addition. Further, for $a,b\in \mathbb{Z}$, $a\cdot b = b\cdot a$. 
            \bigbreak \noindent 
            $1\in \mathbb{Z}$ is the identity, $1 \cdot a = a \cdot 1 =a$ for all $a\in \mathbb{Z} $, and we know that multiplication distributes over addition
            \begin{align*}
                a \cdot (b+c) &= a\cdot b + a\cdot c \\
                (a+b) \cdot c &= a\cdot c + b\cdot c
            .\end{align*}
        \item \textbf{Fields}: A field is a set $F$, together with two operations $\oplus$ and $* $, which has the following properties
            \begin{itemize}
                \item $F$ is a commutative ring under $\oplus$ and $* $ 
                \item Every nonzero $f\in F$ has a multplicative inverse, that is, some element $g\in F$ for which
                    \begin{align*}
                        f*g = g*f = 1
                    .\end{align*}
            \end{itemize}
            The sets $\mathbb{Q}, \mathbb{R}$, and $\mathbb{C}$ under addition and multiplication are examples of fields. The set of integers $\mathbb{Z}$ is not. Although it is a commutative ring under addition and multiplication, not every element has a multiplicative inverse. For example, there is no such $a\in \mathbb{Z}$ such that $2 \cdot  g = 1 $
        \item \textbf{Vector spaces}: A vector space is a set of vectors $V$, together with a set of scalars $F$, with the following properties
            \begin{itemize}
                \item $V$ is a abelian group under vector addition
                \item  $F$ is a field under multiplication
                \item For each $s\in F$, and $\mathbf{v}\in V$, scalar multiplication gives a unique element $s\cdot \mathbf{v} \in V $
                \item Additional properties
                    \begin{align*}
                        1\mathbf{v} &= \mathbf{v} \\
                        a(b\mathbf{v}) &= (ab)\mathbf{v} \\
                        a(\mathbf{u} + \mathbf{v}) &= a\mathbf{u} + a\mathbf{v} \\
                        (a+b) \mathbf{v} &= a\mathbf{v} + b\mathbf{v}
                    .\end{align*}
            \end{itemize}



    \end{itemize}


    \pagebreak 
    \unsect{Combinatorics}
    \bigbreak \noindent 
    \subsection{Introduction}
    \begin{itemize}
        \item \textbf{What is combinatorics?}: Combinatorics is a collection of techniques and a language for the study of finite or countably infinite discrete structures. Given a set of elements and possibly some structure on that set, typical questions are
            \begin{itemize}
                \item Does a specific arrangement of the elements exists?
                \item How many such arrangemets are there?
                \item What properties do these arrangements have?
                \item Which one of the arrangemetns is maximal, minimal, or optimal according to some criterion?
            \end{itemize}
        \item \textbf{Counting the number of subsets for a set}: Let $[n] = \{1,2,...,n\} $, and let $f(n)$ be the number of subsets of $[n]$. Then $f(n) = 2^{n}$. For any particular subset of $[n]$, each element is either in that subset or not. Thus, to construct a subset, we have to make one of two choices for each element of $[n]$. Furthermore, these choices are independent of each other. Hence, the total number of choices, and consequently the total number of subsets is 
            \begin{align*}
                \underbrace{2\times2\times...\times2}_{n} = 2^{n}
            .\end{align*}
        \item \textbf{Number of subsets without consecutive integers}: For a sequence $[n] = \{1,...,n\}$ we can count the number of subsets given by $f(n)$, that do not contain consecutive integers with the recurrence relation
            \begin{align*}
                f(n) = f(n-1) + f(n-2)
            .\end{align*}
            We consider two cases
            \begin{enumerate}
                \item $n$ in not included in the subsets
                \item $n$ is included in the subsets. In this case, we build the subsets considering the subsequence $[n-2]  = \{1,...,n-2\}$. Note that if we include $n$, we must exclude $n-1$, because $n-1$ and $n$ are consecutive, this will become cleare in the upcoming example.
            \end{enumerate}
            \bigbreak \noindent 
            Consider the sequence $[n] = \{1,2,3,4\}$. By the relation above, 
            \begin{align*}
                f(4) &= f(3) + f(2) 
            .\end{align*}
            Before we are able to compute this, we must define our base cases. 
            \begin{align*}
                f(n) &= \begin{cases}
                    3 & \text{if } n = 2 \\
                    2 & \text{if } n =1
                \end{cases}
            .\end{align*}
            If $n=2$, we have $\{1,2\}$, and the allowed subsets are $\varnothing, \{1\}, \{2\} $. If we have $n=1$, the subsets are $\{\varnothing, \{1\}\} $. Thus
            \begin{align*}
                f(4) &= f(3) + f(2) = f(2) + f(1) + f(2)  \\
                     &= 3 + 2 + 3 = 8               
            .\end{align*}
            Let's explicitly break up the given sequence so we can see whats going on. In the first case, $n$ is excluded, thus the sequence becomes $\{1,2,3\}$. If $n$ is included, the sequence becomes $\{1,2\}$, where we build the subsets of $\{1,2\}$, and then add 4 to each one. Thus,
            \begin{align*}
                \{1,2,3\} + \{1,2\} &= \{1,2,3\}  + \varnothing + \{1\} + \{2\} \\
                                    &= \{1,2,3\} + \{4\} + \{1,4\} + \{2,4\}
            .\end{align*}
            Since the sequence $\{1,2,3\}$ in not a base case, we must split this one up aswell, we have
            \begin{align*}
                \{1,2,3\} &= \{1,2\} + \{1\}  + \{4\} + \{1,4\} + \{2,4\} \\
                          &=  \varnothing + \{1\} + \{2\} + \varnothing + \{1\} + \{4\} + \{1,4\} + \{2,4\} \\
                          &= \varnothing + \{1\} + \{2\} + \{3\} + \{1,3\} + \{4\} + \{1,4\} + \{2,4\} 
            .\end{align*}
            Thus, we conclude all "good" subsets of $[n]$ either have $n$ or don't have $n$. The ones that don't have $n$ are exactly the "good" subsets of $[n-1]$. The "good" subsets of $[n]$ that include $n$ are exactly the "good" subsets of $[n-2]$ together with $n$. Thus $f(n) = f(n-1) + f(n-2) $ $\blacksquare$
            
    \end{itemize}

    \pagebreak 
    \subsection{Induction and recurrence relations}
    \begin{itemize}
        \item \textbf{Principal of Mathematical Induction}: Given an infinite sequence of propositions
            \begin{align*}
                P_{1}, P_{2}, P_{3},...P_{n},...,
            .\end{align*}
            In order to prove that all of them are true, it is enough to show two things
            \begin{enumerate}
                \item \textbf{The base case:} $P_{1}$ is true
                \item \textbf{The inductive step}: For all positive integers $k$, if $P_{k}$ is true, then so is $P_{k+1}$
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{Example}: Show that 
            \begin{align*}
                1 + 2 + 3 + ... + n = \frac{n(n+1)}{2}
            .\end{align*}
            \textbf{Base case}:
            \begin{align*}
                1 &= \frac{1(1+1)}{2} = \frac{2}{2} = 1
            .\end{align*}
            \bigbreak \noindent 
            \textbf{Inductive step}: $P_{k}$ is given by
            \begin{align*}
                1 + 2 + 3 + ... + k = \frac{k(k+1)}{2}
            .\end{align*}
            \bigbreak \noindent 
            $P_{k+1}$ is given by
            \begin{align*}
                1 + 2 + 3 + ... + k + k+1 = \frac{k+1(k+2)}{2}
            .\end{align*}
            If $1+2+3+...+k  = \frac{k(k+1)}{2}$, then
            \begin{align*}
                1 + 2 + 3 + ... + k + k+1 &= \frac{k+1(k+2)}{2} \\
                \frac{k(k+1)}{2} + k + 1 &= \frac{k+1(k+2)}{2} \\
                \frac{k(k+1) + 2k + 2}{2} &= \frac{k^{2} + 3k + 2}{2} \\
                \frac{k^{2} + 3k  + 2}{2} &= \frac{k^{2} + 3k + 2}{2}
            .\end{align*}
            Thus, we have showed that $P_{k} \implies P_{k+1}$ $\blacksquare$.
            \bigbreak \noindent 
            \textbf{Note}: Our aim is not to directly prove $P_{k+1}$, but to prove that $P_{k}$ implies $P_{k+1}$. In the inductive step we assume $P_{k}$ to be true, then show under this assumption, $P_{k+1}$ is also true.
        \item \textbf{Understanding gauss's formula for the sum of the first $n$ natural numbers}: Suppose we want to find the sum $1+2+3+...+(n-1)+n$. We could have discovered the formula that we proved above by first writing the sum twice
            \begin{align*}
                &1 + 2  + 3 + ... + (n-1) + n \\
                &n + (n-1) + (n-2) + ... + 2 + 1
            .\end{align*}
            The sum of the two numbres in each column is $n+1$, and there are $n$ columns, so the total sum is $n(n+1)$, it then follows that the actual sum is $\frac{1}{2}n(n+1)$
        \item \textbf{Trianglular numbers}: The sequence of integers
            \begin{align*}
                &1
                &3 = 1+2 \\
                &6 = 1 + 2  + 3 \\
                &10 = 1 + 2 + 3 + 4 \\
                &15  = 1 + 2 + 3 + 4 + 5  \\
                &...
            .\end{align*}
            Are called \textit{triangular numbers}. If you were to make a triangle of dots out of the sum, where the highest number is the base, the second highest is the layer ontop of the base, etc, you would form a triangle.
        \item \textbf{Strong induction}: Given an infinite sequence of propositions
            \begin{align*}
                P_{1}, P_{2}, P_{3}, ..., P_{n}
            .\end{align*}
            In order to demonstrate that all of them are true, it is enough to know two things.
            \begin{enumerate}
                \item \textbf{The base case}: $P_{1}$ is true
                \item \textbf{The inductive step}: For all integers $k \geq 1$, if $P_{1}, P_{2}, P_{3},...,P_{k}$ are true, then so is $P_{k+1}$
            \end{enumerate}
        \item \textbf{Pingala-fibonacci numbers}: Define a sequence of positive integers as follows: $F_{0} = 0, F_{1} = 1$, and for $n=2,3,... $ we have
            \begin{align*}
                F_{n} = F_{n-2} + F_{n-1}
            .\end{align*}
            This sequence is also known as \textit{the fibonacci sequence}.
        \item \textbf{Lucas numbers}: Change the initial values on the fibonacci sequence. Let $L_{0} = 2, L_{1} = 1$, and $L_{n} = L_{n-2} + L_{n-1}$. Then, we get the \textit{Lucas numbers}
            \begin{align*}
                2,1,3,4,7,11,18,29,47,...
            .\end{align*}
        \begin{align*}
            \mathcal{L}
        .\end{align*}

    \end{itemize}

    \pagebreak 
    \unsect{Axiomatic geometry}
    \subsection{Euclids elements and the question of parallels}
    \begin{itemize}
        \item \textbf{Mathematical axioms and postulates}: Axioms are general truths or statements accepted without proof. Postulates are assumptions specific to a particular mathematical framework, often geometry. They serve as starting points for reasoning within that system.
            \bigbreak \noindent 
            In short, axioms are universal truths in mathematics. Postulates are subject-specific assumptions.
        \item \textbf{Euclids definitions}:
            \begin{enumerate}
                \item \textbf{Point:} That which has no part.
                \item \textbf{Line:} Breadthless length.
                \item The ends of a line are points.
                \item \textbf{Straight line:} A line which lies evenly with the points on itself.
                \item \textbf{Surface:} That which has length and breadth only.
                \item The edges of a surface are lines.
                \item \textbf{Plane surface:} A surface which lies evenly with the straight lines on itself.
                \item \textbf{Angle:} The inclination to one another of two lines in a plane which meet one another and do not lie in a straight line.
                \item \textbf{Right angle:} When a straight line set up on another straight line makes the adjacent angles equal to one another, each of the equal angles is a right angle.
                \item \textbf{Perpendicular:} A straight line standing on another straight line to form right angles with it.
                \item \textbf{Obtuse angle:} An angle greater than a right angle.
                \item \textbf{Acute angle:} An angle less than a right angle.
                \item \textbf{Boundary:} That which is the extremity of anything.
                \item \textbf{Figure:} That which is contained by any boundary or boundaries.
                \item \textbf{Circle:} A plane figure contained by one line (the circumference) such that all straight lines falling upon it from one point among those lying within the figure are equal to one another.
                \item \textbf{Center of a circle:} The point from which all straight lines drawn to the circumference are equal.
                \item \textbf{Diameter of a circle:} Any straight line drawn through the center and terminated in both directions by the circumference.
                \item \textbf{Semicircle:} The figure contained by the diameter and the circumference cut off by it. The center of the semicircle is the same as that of the circle.
                \item \textbf{Segment of a circle:} The figure contained by a straight line and the circumference it cuts off.
                \item \textbf{Rectilineal figure:} A figure contained by straight lines.
                \item \textbf{Trilateral figure:} A rectilineal figure contained by three straight lines (a triangle).
                \item \textbf{Quadrilateral figure:} A rectilineal figure contained by four straight lines.
                \item \textbf{Multilateral figure (polygon):} A rectilineal figure contained by more than four straight lines.
                \item \textbf{Equilateral triangle:} A triangle with three equal sides.
                \item \textbf{Isosceles triangle:} A triangle with two equal sides.
                \item \textbf{Scalene triangle:} A triangle with three unequal sides.
                \item \textbf{Right-angled triangle:} A triangle with one right angle.
                \item \textbf{Obtuse-angled triangle:} A triangle with one obtuse angle.
                \item \textbf{Acute-angled triangle:} A triangle with three acute angles.
                \item \textbf{Parallel lines:} Straight lines which, being in the same plane and being produced indefinitely in both directions, do not meet one another in either direction.
            \end{enumerate}
        \item \textbf{Euclids postulates}
            \begin{enumerate}
                \item To draw a straight line from any point to any point
                \item To produce a finite straight line continuously in a straight line
                \item To describe a circle with any center and distance
                \item That all right angles are equal to one another
                \item That, if a straight line falling on two straight lines makes the interior angles on the same side less than two right angles, the two straight lines, if produced indefinitely, meet on that side on which are the angles less than the two right angels
            \end{enumerate}
        \item \textbf{Euclids axioms}:
            \begin{enumerate}
                \item Things which are equal to the same thing are also equal to one another
                \item If equals be added to equals, the wholes are equal
                \item If equals be subtracted from equals, the remainders are equal.
                \item Things which coincide with one another are equal to one another
                \item The whole is greater than the part
            \end{enumerate}
        \item \textbf{Definitions rephrased}:
            \begin{enumerate}
                \item \textbf{Point:} A location that has no size or dimension.
                \item \textbf{Line:} A one-dimensional object that has length but no width.
                \item \textbf{Endpoints of a line:} The points where a line begins or ends.
                \item \textbf{Straight line:} A line that does not curve and lies evenly between its endpoints.
                \item \textbf{Surface:} A two-dimensional object that has length and width but no thickness.
                \item \textbf{Edges of a surface:} The boundaries of a surface are lines.
                \item \textbf{Plane surface:} A flat surface where any straight line connecting two points on it lies entirely on the surface.
                \item \textbf{Angle:} The measure of the inclination or separation between two lines that meet at a point but are not aligned.
                \item \textbf{Right angle:} An angle formed when one line meets another to create two equal angles (90 degrees each).
                \item \textbf{Perpendicular lines:} Two lines that meet to form a right angle.
                \item \textbf{Obtuse angle:} An angle larger than a right angle (greater than 90 degrees).
                \item \textbf{Acute angle:} An angle smaller than a right angle (less than 90 degrees).
                \item \textbf{Boundary:} The edge or limit of an object.
                \item \textbf{Figure:} A shape that is enclosed by boundaries.
                \item \textbf{Circle:} A shape where all points on the boundary (the circumference) are the same distance from a central point.
                \item \textbf{Center of a circle:} The point that is equidistant from every point on the circle’s boundary.
                \item \textbf{Diameter of a circle:} A straight line passing through the center of a circle that touches the boundary on both sides.
                \item \textbf{Semicircle:} Half of a circle, defined by dividing a circle along its diameter.
                \item \textbf{Segment of a circle:} A region of a circle bounded by a chord (a straight line) and the arc it cuts off.
                \item \textbf{Polygon (rectilinear figure):} A shape enclosed by straight lines.
                \item \textbf{Triangle:} A polygon with three sides.
                \item \textbf{Quadrilateral:} A polygon with four sides.
                \item \textbf{Polygon (multilateral figure):} A shape with more than four sides.
                \item \textbf{Equilateral triangle:} A triangle where all three sides are equal in length.
                \item \textbf{Isosceles triangle:} A triangle where two sides are equal in length.
                \item \textbf{Scalene triangle:} A triangle where all three sides are of different lengths.
                \item \textbf{Right triangle:} A triangle with one right angle (90 degrees).
                \item \textbf{Obtuse triangle:} A triangle with one obtuse angle (greater than 90 degrees).
                \item \textbf{Acute triangle:} A triangle where all angles are acute (less than 90 degrees).
                \item \textbf{Parallel lines:} Two straight lines in the same plane that, no matter how far extended, will never meet
            \end{enumerate}
        \item \textbf{Postulates rephrased}
            \begin{enumerate}
                \item It is possible to draw a straight line connecting any two points.
                \item A finite straight line can be extended indefinitely in a straight line.
                \item A circle can be drawn with any center and any radius.
                \item All right angles are equal to each other.
                \item If a straight line intersects two straight lines such that the interior angles on one side add up to less than two right angles, then the two straight lines, if extended indefinitely, will meet on the side where the angles are less than two right angles.
            \end{enumerate}
        \item \textbf{Axioms rephrased}:
            \begin{enumerate}
                \item Things equal to the same thing are equal to each other.
                \item If equals are added to equals, the results are equal.
                \item If equals are subtracted from equals, the remainders are equal.
                \item Things that overlap or coincide exactly are equal.
                \item The whole is greater than any of its parts.
            \end{enumerate}
        \item \textbf{More on Euclids 5th postulate}: Unlike the other four postulates, the 5th postulate is more complex and less intuitive. It essentially describes the behavior of parallel lines, but its wording led mathematicians to wonder if it could be derived from the other postulates.
            \bigbreak \noindent 
            For centuries, mathematicians like Proclus, Ptolemy, and others tried to prove the 5th postulate as a theorem based on the other four postulates. These attempts were unsuccessful, as the postulate is independent.
            \bigbreak \noindent 
            In the 19th century, mathematicians like Lobachevsky, Bolyai, and Gauss explored what happens if the 5th postulate is replaced with different assumptions. This led to the development of non-Euclidean geometries:
            \begin{itemize}
                \item \textbf{Hyperbolic geometry:} There are infinitely many parallel lines through a point not on a given line.
                \item \textbf{Elliptic geometry:} No parallel lines exist.
            \end{itemize}
            The questioning of the 5th postulate revolutionized mathematics, leading to a broader understanding of geometry and the realization that Euclidean geometry is just one of many possible systems.
            \bigbreak \noindent 
            Observe Euclids 5th postulate
            \bigbreak \noindent 
            \fig{.2}{./figures/21.png}
        \item \textbf{ Playfair's Postulate}: Is an equivalent form of Euclid's 5th postulate which states 
            \begin{quote}
                "Through a given point not on a line, there is exactly one line parallel to the given line"
            \end{quote}
    \end{itemize}

    \pagebreak 
    \subsection{Five examples}
    \begin{itemize}
        \item \textbf{The Euclidean plane}: The Euclidean plane is a two-dimensional geometric space that forms the foundation of Euclidean geometry, as described in Euclid's Elements. It is characterized by the following properties
            \begin{enumerate}
                \item \textbf{Flat Surface:} The Euclidean plane is flat, meaning it has no curvature.
                \item \textbf{Points and Lines:} It consists of an infinite set of points. Straight lines can be drawn to connect any two points, and these lines extend infinitely in both directions.
                \item \textbf{Distance and Angles:} Distance between points is measured using the Euclidean distance formula. Angles are measured in degrees or radians.
                \item \textbf{Postulates:} The plane follows Euclid’s postulates, including the 5th (parallel postulate), which ensures the uniqueness of parallel lines.
                \item \textbf{Coordinate Representation:} Often represented using the Cartesian coordinate system, where every point is defined by an ordered pair $(x,y)$
                \item \textbf{Dimensions:} It has two dimensions: length and width.
            \end{enumerate}
            Note that the 2-dimensional cartesian plane is a mathematical representation of the Euclidean plane using a coordinate system.
            The Euclidean plane is a more general geometric concept, while the Cartesian plane provides a numerical framework (coordinates) for working with Euclidean geometry. In practical applications, the Cartesian plane is often used to model the Euclidean plane
            \bigbreak \noindent 
            Let $\mathbb{E}$ denote the Euclidean plane. 
            \bigbreak \noindent 
            \textbf{Coordinates}: The points in $\mathbb{E}$ are in one-to-one correspondence with the ordered pairs of real numbers. Each point $A$ corresponds to a pair of real numbers $(x,y)$, called the \textit{coordinates} of $A$, where the pair is assigned in the familiar way
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{e1}
                \label{fig:e1}
            \end{figure}
            We often identify $A$ with its pair of coordinates $(x,y)$
            \bigbreak \noindent 
            \textbf{Equations of lines}: Each \textit{nonvertical line} $\ell$ in $\mathbb{E}$ consists of all points $(x,y)$, where $y = mx + b$ for some fixed $m$ and $b$. each \textit{vertical line} $\ell$ consists of all $(x,y)$, where $x=a$ for some fixed $a$
            \bigbreak \noindent 
            For any two points $A(x_{1}, y_{1})$ and $B(x_{2}, y_{2})$, the \textit{slope} of the line $\ell$ through $A$ and $B$ is 
            \begin{align*}
                m  = \frac{y_{2} - y_{1}}{x_{2} - x_{1}} \quad (\text{if } x_{2} \ne x_{1})
            \end{align*}
            And an equation for $\ell$ is given by 
            \begin{align*}
                y-y_{1} = m(x - x_{1}) \quad (\text{if } x_{2} \ne x_{1})
            \end{align*}
            The \textit{Euclidean distance} $e(AB)$ between $A$ and $B$ satisfies the formula 
            \begin{align*}
                e(AB) = \sqrt{(x_{2} - x_{1})^{2} + (y_{2} - y_{1})^{2}}
            \end{align*}
            \begin{figure}[ht]
                \centering
                \incfig{e2}
                \label{fig:e2}
            \end{figure}
            \bigbreak \noindent 
            Then 
            \begin{align*}
                (e(AB))^{2} &= (x_{2} -x_{1})^{2} + (y_{2} - y_{1})^{2} \\
                e(AB) &= \sqrt{(x_{2} - x_{1})^{2} + (y_{2} - y_{1})^{2}}
            \end{align*}
        \item \textbf{More on Euclidean distance}
            \bigbreak \noindent 
            \textbf{Proposition 1.1} If $A(x_{1}, y_{1})$ and $B(x_{2}, y_{2}) $ are on the line $y=mx+b$, then $e(AB) = \abs{x_{1} - x_{2}}\sqrt{m^{2} + 1}$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A(x_{1}, y_{1})$ and $B(x_{2}, y_{2}) $ are on the line $y=mx+b$, and $e(AB) = \sqrt{(x_{2} - x_{1})^{2} + (y_{2} - y_{1})^{2}}$. Observe that the slope $m$ of the line is given by
            \begin{align*}
                m = \frac{y_{2} - y_{1}}{x_{2} - x_{1}}
            \end{align*}
            Which implies 
            \begin{align*}
                y_{2} - y_{1} = m(x_{2} - x_{1})
            \end{align*}
            Plugging this expression for $y_{2} -y_{1}$ into $e(AB)$ yields
            \begin{align*}
                e(AB) &= \sqrt{(x_{2} - x_{1})^{2} + (m(x_{2}-x_{1}))^{2}} \\
                      &= \sqrt{(x_{2} - x_{1})^{2} + (m^{2}(x_{2}-x_{1})^{2})} \\
                      &= \sqrt{(x_{2}-x_{1})^{2}[1 + m^{2}]} \\
                      &= \sqrt{(x_{2} - x_{1})^{2}} \cdot \sqrt{m^{2} + 1} \\
                      &= \abs{x_{2} - x_{1}} \sqrt{m^{2} + 1} 
            \end{align*}
            As desired \hspace*{\fill}$\blacksquare$ 
        \item \textbf{The Minkowski plane, or taxicab plane}: Let $\mathbb{M}$ denote the Minkowski plane. $\mathbb{M}$ has the same points, lines, and coordinates as $\mathbb{E}$, but distance is different. For any $A(x_{1}, y_{1})$ and $B(x_{2}, y_{2})$, define the \textit{Minkowski distance} $d_{\mathbb{M}}$ as
            \begin{align*}
                d_{\mathbb{M}} = \abs{x_{2} - x_{1}} + \abs{y_{2} - y_{1}}
            \end{align*}
            Thus, the \textit{Minkowski distance} $d_{\mathbb{M}}(AB)$ is defined as the sum of the horizontal and vertical "ordinary distances"
            \bigbreak \noindent 
            For example, consider $A(1,2), B(-1,-3)$, then 
            \begin{align*}
                d_{\mathbb{M}}(AB) &= \abs{-1-1} + \abs{-3-2} = 7
            \end{align*}
        \item \textbf{More on Minkowski distance}:
            \bigbreak \noindent 
            \textbf{Proposition 1.2} If $A(x_{1}, y_{1})$ and $B(x_{2}, y_{2}) $ are on the line $y=mx+b$, then $d_{\mathbb{M}}(AB) = \abs{x_{1} - x_{2}}(1+\abs{m})$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A(x_{1}, y_{1})$ and $B(x_{2}, y_{2}) $ are on the line $y=mx+b$, and $d_{\mathbb{M}} = \abs{x_2-x_1} + \abs{y_{2} - y_{1}}$. Observe that the slope $m$ of the line is given by
            \begin{align*}
                m = \frac{y_{2}-y_{1}}{x_{2} - x_{1}}
            \end{align*}
            Which implies 
            \begin{align*}
                y_{2} - y_{1} = m(x_{2} - x_{1})
            \end{align*}
            Plugging this expression for $y_{2} -y_{1}$ into $d_{\mathbb{M}}$ yields
            \begin{align*}
                d_{\mathbb{M}} &= \abs{x_{2} - x_{1}} + \abs{y_{2} - y_{1}} \\
                               &= \abs{x_{2} - x_{1}} + \abs{m(x_{2} - x_{1})} \\
                               &= \abs{x_{2} - x_{1}} + \abs{m}\abs{x_{2} - x_{1}} \\
                               &= \abs{x_{2} - x_{1}}(1 + \abs{m}) \\
                               &= \abs{-(x_{1} - x_{2})} (1 + \abs{m}) \\
                               &= \abs{-1}\abs{x_{1} - x_{2}} (1 + \abs{m}) \\
                               &= \abs{x_{1} - x_{2}} (1 + \abs{m}) \\
            \end{align*}
            As desired \hspace*{\fill} $\blacksquare$
        \item \textbf{The spherical plane}: Let $\mathbb{S}(r)$ denote the surface of the sphere of radius $r$; that is, the \textit{spherical plane}.
            \bigbreak \noindent 
            Once $r$ is fixed, we shorten the notation to $\mathbb{S}$. We shall assume that our spheres are centered at the origin $(0,0,0)$ in three-dimensional space. Then $\mathbb{S}$ is the set of all $(x,y,z)$ such that $x^{2} + y^{2} + z^{2} = r^{2} $. Points are as usual, and lines on $\mathbb{S}$ are defined to be the \textit{great circles}. A great circle is the intersection of the sphere with a plane that cuts the sphere in half. Then, any two points have a unique line joining them, unless they are oppoosite (antipodes). In this case, they have infinitely many lines joining them.
            \bigbreak \noindent 
            \textbf{Distance in $\mathbb{S}$}: For points $A,B$ on $\mathbb{S}$, define distance
            \begin{align*}
                d_{\mathbb{S}}(AB) = &\text{ length of the minor (shorter) arc of the} \\
                                     &\text{ great circle (line) through $A$ and $B$}
            \end{align*}
            To compute $d_{\mathbb{S}}(AB)$ more easily, we must recall the forumula for the \textit{arc length in a circle of radius $r$}. Let $\theta$ be the radian measure of $\angle POQ$. The angle that sweeps out the full circle has measure $2\pi$, and the circumference is $2\pi r $. The sector formed by $\angle POQ$ makes up $\frac{\theta}{2\pi}$ of the full circle, so
            \begin{align*}
                \text{arc length } PQ = \frac{\theta }{2\pi} \cdot 2\pi r = \theta  r
            \end{align*}
            \bigbreak \noindent 
            An explicit formula for the spherical distance between two points, in terms of their coordinates, is given next. It follows from the distance formula for three-dimensional space and the Law of Cosines.
            \bigbreak \noindent 
            If $P(a,b,c)$ and $Q(x,y,z)$ are points on the surface of the sphere of radius $r$ centered at $(0,0,0)$ then
            \begin{align*}
                d_{\mathbb{S}} = r\cos^{-1}{\left(\frac{ax+by+cz}{r^{2}}\right)}
            \end{align*}
            \bigbreak \noindent 
            First, recall the law of cosines
            \begin{remark}
               \textit{(Law of Cosines.)} 
            \end{remark}
            \begin{figure}[ht]
                \centering
                \incfig{loc}
                \label{fig:loc}
            \end{figure}
            \bigbreak \noindent 
            In trigonometry, the \textbf{law of cosines} (also known as the \textit{cosine formula} or \textit{cosine rule}) relates the lengths of the sides of a triangle to the cosine of one of its angles. For a triangle with sides $a$, $b$, and $c$, opposite respective angles $\alpha$, $\beta$, and $\gamma$ (see Fig.~1), the law of cosines states:
            \[
                c^2 = a^2 + b^2 - 2ab \cos \gamma,
            \]
            \[
                a^2 = b^2 + c^2 - 2bc \cos \alpha,
            \]
            \[
                b^2 = a^2 + c^2 - 2ac \cos \beta.
            \]
            The law of cosines generalizes the Pythagorean theorem, which holds only for \textbf{right triangles}: if $\gamma$ is a right angle then $\cos \gamma = 0$, and the law of cosines reduces to:
            \[
                c^2 = a^2 + b^2.
            \]
            The law of cosines is useful for solving a triangle when all three sides or two sides and their included angle are given. $\qed $
            \bigbreak \noindent 
            Consider the points $P(a,b,c)$ and $Q(x,y,z)$ and the line (great circle) connecting them
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{gc}
                \label{fig:gc}
            \end{figure}
            \bigbreak \noindent 
            Let $d$ be the Euclidean distance $PQ$ and $\theta$ be the radian measure of $\angle POQ$. By the law of cosines,
            \begin{align*}
                d^{2} &= r^{2} + r^{2} - 2r^{2}\cos{\left(\theta \right)} \\
                \implies \cos{\left(\theta \right)} &= \frac{d^{2} - r^{2} - r^{2}}{-2r^{2}} = \frac{d^{2} - 2r^{2}}{-2r^{2}} = \frac{2r^{2}-d^{2}}{2r^{2}}
            \end{align*}
            The Euclidean distance $d$ is given by
            \begin{align*}
                d &= \sqrt{(x-a)^{2} + (y-b)^{2} + (z-c)^{2}} \\
                  &= \sqrt{x^{2} + y^{2} + z^{2} + a^{2} + b^{2} + c^{2} - 2ax -2by - 2cz}
            \end{align*}
            Thus,
            \begin{align*}
                \cos{\left(\theta \right)} &= \frac{2r^{2} - \left(\sqrt{x^{2} + y^{2} + z^{2} + a^{2} + b^{2} + c^{2} - 2ax -2by - 2cz}\right)^{2}}{2r^{2}} \\
                                           &= \frac{2r^{2} -x^{2}-y^{2}-z^{2}-a^{2}-b^{2}-c^{2}+2ax+2by+2cz}{2r^{2}}
            \end{align*}
            Observe that since points $P,Q$ lie on a sphere, they must obey the equations
            \begin{align*}
                x^{2} + y^{2} + z^{2} = r^{2}
            \end{align*}
            Thus, since $P$ is given by the pair $(a,b,c)$, and $Q$ is given by $(x,y,z)$, we have
            \begin{align*}
                a^{2} +b^{2} + c^{2} &=r^{2} \\
                x^{2} + y^{2} + z^{2} &= r^{2}
            \end{align*}
            Thus,
            \begin{align*}
                \cos{\left(\theta \right)}  &= \frac{2r^{2} -x^{2}-y^{2}-z^{2}-a^{2}-b^{2}-c^{2}+2ax+2by+2cz}{2r^{2}} \\
                                        &= \frac{r^{2} + r^{2} -x^{2}-y^{2}-z^{2}-a^{2}-b^{2}-c^{2}+2ax+2by+2cz}{2r^{2}} \\
                                        &= \frac{a^{2} + b^{2} + c^{2} + x^{2} + y^{2} + z^{2} -x^{2}-y^{2}-z^{2}-a^{2}-b^{2}-c^{2}+2ax+2by+2cz}{2r^{2}} \\
                                        &= \frac{2ax+2by+2cz}{2r^{2}} \\
                                        &=\frac{2(ax+by+cz)}{2r^{2}} \\
                                        &= \frac{ax+by+cz}{r^{2}}
            \end{align*}
            Since $d_{\mathbb{S}} = r\theta$, we finally arrive at the expression
            \begin{align*}
                d_{\mathbb{S}} &= r\theta  = r\cos^{-1}{\left(\frac{ax+by+cz}{r^{2}}\right)}
            \end{align*}
            As desired \hspace*{\fill} $\blacksquare$
            \bigbreak \noindent 
            \textbf{Note:} There are no parallel lines in $\mathbb{S}$, any two great circles meet at a pair of antipodes.
        \item \textbf{The chords of a circle}: A chord of a circle is a straight line segment whose endpoints lie on the circle. In other words, it is a line segment that connects two points on the circumference of a circle
        \item \textbf{The hyperbolic plane (Poincare disk model)}: Let $\mathbb{H}$ denote the hypebolic plane, which is the set of all points inside (but not on) the unit circle in $\mathbb{E}$. That is, all $(x,y)$ with $x^{2} + y^{2} < 1 $
            \bigbreak \noindent 
            Lines in $\mathbb{H}$ are defined to be the chords of the circle.
            \bigbreak \noindent 
            \textbf{Distance:} If $A,B$ are two points in $\mathbb{H}$, define $d_{\mathbb{H}}(AB)$, the distance between them in $\mathbb{H}$ as follows: Draw the chord $AB$, and let $M,N$ be the points where the chord meets the unit circle ($M,N$ are in $\mathbb{E}$ but not $\mathbb{H}$). label so that $B $ separates $A$ and $N$.
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{hyper}
                \label{fig:hyper}
            \end{figure}
            \bigbreak \noindent 
            Let $e(PQ)$ denote the usual Euclidean distance between points, and define
            \begin{align*}
                d_{\mathbb{H}}(AB) = \ln{\left(\frac{e(AN)e(BM)}{e(AM)e(BN)}\right)}
            \end{align*}
            Since $e(AN)>e(BN)$ and $e(BM) > e(AM)$, we have $\frac{e(AN)}{e(BN)} > 1$ and $\frac{e(BM)}{e(AM)} > 1$. Hence $\frac{e(AN)e(BM)}{e(AM)e(BN)}  = \frac{e(AN)}{e(BN)} \cdot \frac{e(BM)}{e(AM)}> 1$. It follows from a property of ln that $d_{\mathbb{H}}(AB) > 0$. Note that $d_{\mathbb{H}}(AB) = d_{\mathbb{H}(BA)}$. Also,
            \begin{align*}
                d_{\mathbb{H}}(AB) = \bigg\lvert \ln{\left(\frac{e(AN)e(BM)}{e(AM)e(BN)}\right)} \bigg\rvert = \bigg\lvert \ln{\left(\frac{e(AM)e(BN)}{e(AN)e(BM)}\right)} \bigg\rvert
            \end{align*}
            So if absolute value is used in this way, then we need not worry about which point on the unit circle is marked $M$ and which is marked $N$.
            \bigbreak \noindent 
            If $A=B$ in $\mathbb{H}$, take any chord through $A$ and let $M,N$ be as previously. Since $\frac{e(AN)e(AM)}{e(AM)e(AN)} =1$, it is consistent with the preceding definition to set $d_{\mathbb{H}}(AA) = 0$.
            \bigbreak \noindent 
            We note that $N$ using the distance formula above is always the point from $A$ through $B$, and the point $M$ is the point from $B$ through $A$. With this in mind, it is clear that $\frac{e(AN)e(BM)}{e(AM)e(BN)} \to \infty$ as we move $A$ and $B$ closer to the opposing sides of the unit circle. Since $\ln:\ (0,\infty) \to \mathbb{R}$, and we noted earlier that $\frac{e(AN)e(BM)}{e(AM)e(BN)} > 1$, distances in the hyperbolic plane can get arbitrary large or small, without bound.
            \bigbreak \noindent 
            Further, Euclids 5th postulate/Playfairs postulate is  false on the hyperbolic plane. Observe
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{e5}
                \label{fig:e5}
            \end{figure}
            \fc{Euclids fifth postulate does not hold on the hyperbolic plane}
            \bigbreak \noindent 
            These lines will never meet, because they are stopped by the unit circle boundary. Further, they will in a sense continue on forever, because distances can get arbitrarily large
            \bigbreak \noindent 
            Also,
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{play}
                \label{fig:play}
            \end{figure}
            \bigbreak \noindent 
            We see that given a point $P$ not on the line $\ell$, there are many lines through $P$ that are parallel to $\ell$. All of these lines are parallel to $\ell$, because they will never intersect with $\ell$
        \item \textbf{The gap plane}: Let $\mathbb{G}$ denote the \textit{gap}, or \textit{missing strip} plane. The points of $\mathbb{G}$ are all those of $\mathbb{E}$ except those $(x,y)$ with $0< x \leq 1$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{gap}
                \label{fig:gap}
            \end{figure}
            So the $y$-axis is part of $\mathbb{G}$, but the line $x=1$ is not (and neither is any vertical line $x=a$ for $0 < a < 1$)
            \bigbreak \noindent 
            Lines in $\mathbb{G}$ are defined to be the same as in $\mathbb{E}$, except that for any nonvertical line $y=mx+b$, the part in the missing strip is deleted. So a typical nonvertical line $\ell$ consists of all $(x,y)$ with $y=mx+b$ ($m,b$ fixed) and with $x \leq 0$ or $x > 1$
            \bigbreak \noindent 
            Behold a line in $\mathbb{G}$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{behold}
                \label{fig:behold}
            \end{figure}
            \bigbreak \noindent 
            \textbf{Distance:} For points $A,B$ in $\mathbb{G}$, we define $d_{\mathbb{G}}(AB)$ as follows. First; if $A$ and $B$ lie on opposite sides of the gap, let $C$ be the point where segment $\overline{AB} $ meets the $y$-axis, and $D$ the point where $\overline{AB}$ meets the vertical line $x=1$ ($D$ is not in $\mathbb{G}$)
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{ex1}
                \label{fig:ex1}
            \end{figure}
            \bigbreak \noindent 
            Now define
            \begin{align*}
                d_{\mathbb{G}}(AB) = \begin{cases}
                    e(AB) & \text{ for $A,B$ on the same side of the gap} \\     
                    e(AB) - e(CD) & \text{ for $A,B$ on the opposite sides of the gap} 
                \end{cases}
            \end{align*}
        \item \textbf{Interior and Exterior angles}: Interior angles are the angles inside the triangle. Each vertex of the triangle has one interior angle. The sum of the interior angles of a triangle is always $180^{\circ}$
            \bigbreak \noindent 
            Exterior angles are the angles formed outside the triangle when one side of the triangle is extended.
            At each vertex, an exterior angle is supplementary to the interior angle (they add up to $180^{\circ} $
            \bigbreak \noindent 
            If an interior angle at a vertex is $A$, the corresponding exterior angle $E$ is:
            \begin{align*}
                E = 180^{\circ} - A
            \end{align*}
            \bigbreak \noindent 
            The sum of the exterior angles of a triangle (one at each vertex) is always $360^{\circ}$ , regardless of the shape of the triangle.
            \bigbreak \noindent 
            \fig{.8}{./figures/23.png}
        \item \textbf{Remote angles}: Remote angles refer to the interior angles of a triangle that are not adjacent to a given exterior angle
        \item \textbf{More on points}:
            \begin{itemize}
                \item \textbf{Collinear points}: Points that lie on the same straight line.
                \item \textbf{Noncollinear points}: Points that do not lie on the same straight line.
                \item \textbf{Coplanar points}: Points that lie on the same plane.
                \item \textbf{Concurrent Points}: Points where three or more lines intersect.
                \item \textbf{Equidistant Points}: Points that are all the same distance from a particular point or object.
                \item \textbf{Lattice Points}:  Points with integer coordinates.
                \item \textbf{Interior points:} Points that lie inside a given shape.
                \item \textbf{Exterior points:} Points that lie outside a given shape.
            \end{itemize}
        \item \textbf{Congruent triangles}: Congruent triangles are triangles that are exactly the same in shape and size. This means that all corresponding sides and angles of one triangle are equal to those of the other triangle.
        \item \textbf{Vertical (opposite) angles}: Vertical angles (also called opposite angles) are the angles that are formed by two intersecting lines and are opposite to each other
        \item \textbf{Reading angle notation}: Suppose you have an angle $\angle ABC$. This angle refers to the angle formed at vertex $B$ by the two line segments or rays:
            \bigbreak \noindent 
            One extending from $B$ to $A$, the other extending from $B$ to $C$. The middle letter, $B$, always represents the vertex of the angle (the point where the two lines meet).
            \bigbreak \noindent 
            \textbf{Note:} If there’s no ambiguity about which angle is being referred to, the angle might simply be denoted as $\angle B$.
        \item \textbf{Potential dangers and the exterior angle inequality}:
            \bigbreak \noindent 
            \textbf{Theorem (\textit{Exterior angle inequality})}: An exterior angle of a triangle is greater than either remote interior angle. That is, if $\triangle ABC$ is a any triangle, and point $D$ is on the extension of segment $\overline{BC}$ through $C$, then
            \begin{align*}
                \angle ACD > \text{ both } \angle A \text{ and } \angle B
            \end{align*}
            \bigbreak \noindent 
            \textbf{Background facts that are ok for both $\mathbb{E}$ and $\mathbb{S}$}
            \begin{enumerate}
                \item \textbf{Triangles:} Line segments that join any three noncollinear points
                \item \textbf{Angle measures}: Are defined for every angle
                \item \textbf{Vertical angles}: Have equal measure
                \item \textbf{side-angle-side}: Criterion for congruent triangles, If two sides and the angle between them in one triangle are equal to the corresponding parts in another triangle, the triangles are congruent.
            \end{enumerate}
            \bigbreak \noindent 
            Consider the triangle 
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{tri3}
                \label{fig:tri3}
            \end{figure}
            \bigbreak \noindent 
            \textbf{\textit{Euclid's proof of EAI}}: Let $ M$ be the midpoint of $\overline{AC}$ so $\overline{AM} = \overline{CM}$. Next, extend $\overline{BM}$ through $M$ to point $E$ such that $\overline{MB} = \overline{ME}$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{tri4}
                \label{fig:tri4}
            \end{figure}
            \bigbreak \noindent 
            Notice that since $\angle AMB$ and $\angle CME$ are vertical, they must be equal. That is, $\angle AMB = \angle CME$. Since 
            \begin{enumerate}
                \item $AM = CM $
                \item $MB = ME$
                \item $\angle AMB = \angle CME $
            \end{enumerate}
            We have met the side-angle-side criterion for congruent triangles. Thus, $\triangle AMB \cong \triangle CME$. Consequently, we have $\angle BAM = \angle ECM $. Further, notice that
            \begin{align*}
                \angle ACD &= \angle ACE + \angle ECD \\
                            &= \angle ECM + \angle ECD \\
                           &= \angle BAM + \angle ECD > \angle BAM = \angle A
            \end{align*}
            Thus, $\angle ACD > \angle A$. To show $\angle ACD > \angle B$, first, extend $AC$ through $C$ to point $F$, forming  $\angle BCF$. Notice that since $\angle ACD$ and $\angle BCF$ are vertical, they must be equal. That is, $\angle ACD = \angle BCF$ 
            \bigbreak \noindent 
            Next, let $N$ be the midpoint of $BC$ such that $BN = CN$. Extend $A$ through $N$ to point $G$ such that $AN=GN$.
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{tri5}
                \label{fig:tri5}
            \end{figure}
            \bigbreak \noindent 
            Note that since $\angle ANB$ and $\angle CNG$ are vertical, they are equal. That is, $\angle ANB = \angle CNG$. Further, since we have
            \begin{enumerate}
                \item $\angle ANB = \angle CNG $
                \item $AN = GN $
                \item $BN = CN$
            \end{enumerate}
            We have congruence, $\triangle ANB \cong \triangle CNG$. Thus, $\angle ABN = \angle NCG$. Therefore,
            \begin{align*}
                \angle ACD = \angle BCF &= \angle BCG + \angle GCF \\
                                        &= \angle NCG + \angle GCF \\
                                        &= \angle ABN + \angle GCF > \angle ABN = \angle B
            \end{align*}
            \bigbreak \noindent 
            Thus, we have shown that $\angle ACD > \angle A$ and $\angle B$ \hspace*{\fill} $\blacksquare$
            
    \end{itemize}

    \pagebreak 
    \subsection{Intro to geometric proofs and some set theory}
    \begin{itemize}
        \item \textbf{Transversal}: a transversal is a line that passes through two lines in the same plane at two distinct points.
        \item \textbf{Relationship of angles}: Consider the transversal configuration
            \bigbreak \noindent 
            % \begin{figure}[ht]
            %     \centering
            %     \incfig{tc}
            %     \label{fig:tc}
            % \end{figure}
            \bigbreak \noindent 
            We see that we get eight formed angles.
            \begin{itemize}
                \item \textbf{Interior angles}: Interior angles are the angles that are inside the transversal configuration. Angles $a,b,c,d$ are interior
                \item \textbf{Exterior angles}: Exterior angles are the angles that are inside the transversal configuration. Angles $e,f,g,h$ are exterior
                \item \textbf{Consecutive interior angles}: Pairs of interior angles that are on the same side of the transversal. Angles $c,d$ are consecutive interior, and $a,b$ are consecutive interior
                \item \textbf{Consecutive exterior angles}: Pairs of exterior angles that are on the outside of the transversal configuration. Angles $e,g$ are consecutive exterior, angles $f,h$ are consecutive exterior
                \item \textbf{Alternate interior angles}: Pairs of interior angles that are on opposite sides but not complementary, angles $b,d$ and $a,c$ are alternate interior
                \item \textbf{Alternate exterior angles}: Pairs of exterior angles that are on opposite sides but not complementary, angles $e,h$, and $f,g$ are alternate exterior
                \item \textbf{Vertical angles}: Angles that are opposite each other, formed when two lines intersect. Vertical angles are of equal measure. Pairs $d,h$ - $a,g$ - $e,b$ - and $f,c$ are vertical
                \item \textbf{Supplementary angles}: Angle pairs that sum to 180, pairs $a,h$ - $d,g$ - $f,b$ - and $e,c$ are supplementary
                \item \textbf{Complementary angles}: Angle pairs that sum to 90, none in the transversal configuration
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Proposition (Equal alternate interior angles)}. Suppose $a + b = 180$, then $b = d$, and $c=a $.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Consider the transversal configuration shown above. Assume $a+b = 180$, then $a=180-b$. Since vertical angles are equal, we have $d=h$. But since $a,h$ are supplementary, we have $a + h = 180$, which implies $h = 180 -a$. Thus,
            \begin{align*}
                d = h = 180 - a
            \end{align*}
            Since $a+b = 180$ implies $ b = 180-a$, we have
            \begin{align*}
                 d = h = 180 - a = b
            \end{align*}
            \bigbreak \noindent 
            Thus, $d=b$. Next, we show that $c=a$. Since $c$ and $f$ are vertical, we have $c = f$. Further, since $a + b =180$, we have $a = 180 -b$. Notice that $b$ and $f$ are supplementary, which implies $b + f = 180$, or $f = 180 - b $. So, since $c=f = 180 -b$, and $a = 180-b$, we have $c = f = 180 - b = a$. Thus, $c=a$
            \bigbreak \noindent 
            Therefore, we conclude that if $a+ b =180$, $b = d$ and $c = a $ \hspace*{\fill}$\blacksquare$
        \item \textbf{Background on Euclid's plane without the fifth postulate}:
            \bigbreak \noindent 
            \textbf{Assumptions}:
            \begin{itemize}
                \item Two points determine a unique line
                \item Distances between points on a line include all positive real numbers
                \item Angles are measured
                    \bigbreak \noindent 
                    \begin{figure}[ht]
                        \centering
                        \incfig{supp}
                        \label{fig:supp}
                \end{figure}
                We say that $\alpha$ and $\beta$ are \textit{supplementary} because $\alpha + \beta = 180^{\circ}$. Note that two angles that are supplementary to each other do not have to be next to each other, only the sums of their angles must be $180^{\circ}$. 
                \bigbreak \noindent 
                As a side note, recall that \textit{complementary} angles are angles that sum to $90^{\circ}$
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Definitions}:
            \begin{itemize}
                \item \textbf{Angles}: An angle is formed when two rays meet at a common endpoint, called the vertex.
                \item \textbf{Vertical angles}: Vertical angles (or opposite angles) are the angles formed when two lines intersect.
                \item \textbf{Triangle}: A triangle is a polygon with three sides, three vertices, and three angles.
                    \bigbreak \noindent 
                    The sum of the interior angles of a triangle is always $180^{\circ}$
                    \bigbreak \noindent 
                    A triangle is a closed geometric figure formed by three line segments connecting three non-collinear points
                \item \textbf{Congruent}: Congruent refers to figures or shapes that are identical in size and shape.
                    \bigbreak \noindent 
                    Two triangles are congruent if their corresponding sides and angles are equal (e.g., by SSS, SAS, ASA, or AAS congruence criteria).
                    \bigbreak \noindent 
                    We generally use the side-angle-side criterion to determine congruent triangles.
            \end{itemize}
            \bigbreak \noindent 
            Also, recall the exterior angle theorem proved above.
        \item \textbf{Example of proof by contradiction}: Suppose we are on Euclid's plane without the fifth postulate
            \bigbreak \noindent 
            \textbf{Proposition 1}. Suppose that line $\ell$ crosses $m$ and $n$ so that  the interior angles on one side of $\ell$ add to more than $180^{\circ}$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{p1}
                \label{fig:p1}
            \end{figure}
            \bigbreak \noindent 
            Then, $m,n$ do not meet on that side of $\ell$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume for the sake of contradiction that the statement is false. That is, suppose $m,n$ meet on that side of $\ell$. Then, we must have
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{p2}
                \label{fig:p2}
            \end{figure}
            \bigbreak \noindent 
            Call the point where they meet $C$, since we have three noncollinear points $A,B,C$, $\triangle ABC$ is formed.
            \bigbreak \noindent 
            Define $\angle CBD$ as the exterior angle for $\triangle ABC$, call it measure $\gamma$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{p4}
                \label{fig:p4}
            \end{figure}
            \bigbreak \noindent 
            $\beta$ and $\gamma$ are supplementary, so $\beta + \gamma = 180^{\circ}$. Thus, $\gamma = 180^{\circ} - \beta$. By the EAI, $\gamma > \alpha$, which means $180^{\circ} - \beta > \alpha$. Thus, we have $180^{\circ} > \alpha + \beta$. But, we stated that $\alpha + \beta > 180^{\circ}$, which is a contradiction. 
            \bigbreak \noindent 
            Therefore, by contradiction, are assumption that $m,n$ meet on that side is false, and therefore $m,n$ must not meet on that side.  \hspace*{\fill} $\blacksquare$
            \bigbreak \noindent
        \item \textbf{Upper bounds}: Suppose $S$ is a set of real numbers, we define $b \in \mathbb{R}$ as an \textit{upper bound} for $S$ if for all $x\in S, x \leq b$
            \bigbreak \noindent 
            The negation of this definition is, there exists $x\in S$ such that $x \nleq b$, or $x > b$. Thus, to prove some $b$ is not an upper bound for $S$, we can show that some element of $S$ is greater than $b$
            \bigbreak \noindent 
            There are of course  sets that do not have any upper bounds. Consider the set $S = \{n:\ n\in \mathbb{N} \text{ and } n>0\} $. This set has no upper bound.
            \bigbreak \noindent 
            If $S = \varnothing$, then every $b \in \mathbb{R}$ is an upper bound for $S$. This statement is vacuously true.
        \item \textbf{Least upper bound (supremum)}: $c\in \mathbb{R}$ is a \textit{least upper bound} of a set $S$ of real numbers if 
            \begin{enumerate}
                \item $c$ is an upper bound for $S$
                \item $c \leq b$ for all upper bounds $b$ of $S$
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{Note:} The supremum of a set $S$ is denoted $ b = \text{sup}(S)$, where $b$ is the supremum of the set
        \item \textbf{Least upper bound property of $\mathbb{R}$}: If $S$ is a nonempty set of real numbers that has an upper bound in $\mathbb{R}$, then $S$ has a least upper bound (l.u.b) in $\mathbb{R} $
            \bigbreak \noindent 
            This justifies, among other things, that infinite decimals exist as real numbers, since an infinite decimal can be defined as the least upper bound of the set of all its finite truncations. For example, suppose $S$ is the set of all finite decimal expansions of $\pi$.
            \begin{align*}
                S = \{3,3.1,3.14,3.141, 3.1415,...\}
            \end{align*}
            Then, $S$ as an $l.u.b$ $\pi$, and $\pi\not\in S $
        \item \textbf{Least upper bound proposition}
            \bigbreak \noindent 
            \textbf{Proposition.} Let $S$ be a nonempty set of real numbers that has a least upper bound $b \in \mathbb{R}$. Let $t \in \mathbb{R}$ such that $t < b$. Then, there exists some $s \in S$ such that $t < s \leq b$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $S$ is a nonempty subset of the real numbers with a least upper bound $b$. Let $t\in \mathbb{R}$ such that $t<b$. Since $b$ is a least upper bound of $S$, we have
            \begin{align*}
                \forall \ s \in S,\ s \leq b 
            \end{align*}
            Since $t< b$, $t$ cannot be an upper bound for $S$. If it were, then that would contradict $b$ being the least upper bound. Since $t$ is not an upper bound of $S$, then this implies the existence of some $s\in S$ such that $ t< s$. If this were not the case, then the negation which states, for all $s\in S$, $t \geq s$ would be true. Since the negation implies that $t$ is an upper bound, which we know can't be the case, there must exist some $s\in S$ such that $t < s$. 
            \bigbreak \noindent 
            Since $s \leq b$ for all $s\in S$, and we know that there exists some $s \in S$ such that $t < s$, there must be at least one $s$ that satisfies
            \begin{align*}
                t < s \leq b
            \end{align*}
            \hspace*{\fill} $\blacksquare$
        \item \textbf{Lower bounds}: Let $S$ be a nonempty set of real numbers. Then $g\in \mathbb{R}$ is a \textit{lower bound} for $S$ if $g \leq x$ for all $x\in S$.
        \item \textbf{Greater lower bounds (Infimum)}: $h\in \mathbb{R}$ is a \textit{greatest lower bound}, also called the \textit{infimum}, or \textit{inf} for $S$ if $ h$ is a lower bound for $S$ and $h \geq g$ for all lower bounds $g$ of $S$
        \item \textbf{Infimum proposition}
            \bigbreak \noindent 
            \textbf{Proposition}. Let $S$ be a nonempty set or real numbers that has a lower bound in $\mathbb{R}$. Then $S$ has a infimum in $\mathbb{R}$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $S \subseteq \mathbb{R}$, $S\ne \varnothing$ that has a lower bound in $\mathbb{R}$.
            \bigbreak \noindent 
            Let $B$ be the set of all lower bounds of $S$. Since $S$ has a lower bound, $B$ is nonempty. Define
            \begin{align*}
                B = \{b \in \mathbb{R}: b \leq s \ \forall \ s \in S\}
            \end{align*}
            \bigbreak \noindent 
            We first note that every $s \in S$ serves as an upper bound for $B$. This is because for any $b\in B,\ b \leq s$ for all $s\in S$, thus satisfying the definition of an upper bound
            \bigbreak \noindent 
            Since $B$ is nonempty and bounded above by all elements of $S$, $B$ has a least upper bound (supremum) in $\mathbb{R}$. Let $\lambda$ be this supremum. That is, $\lambda = \text{sup}\ B$. To show that this supremum is precisely the infimum for $S$ is to show two things
            \begin{enumerate}
                \item $\lambda \in B$. That is, $\lambda$ is a lower bound for $S$
                \item $\lambda \geq b$ for all lower bounds $b $ of $S$
            \end{enumerate}
            We begin by showing that $\lambda \in B$. If $\lambda \in B$, then by definition of $B$, $ \lambda \leq s \ \forall \ s \in S$. Assume for the sake of contradiction that there exists some $s \in S$ such that $\lambda > s$. This would contradict the fact that $\lambda$ is the least upper bound for $B$ because then $s$ would be an upper bound for $B$ smaller than $\lambda$. Thus, there are no such $s\in S$ such that $s < \lambda$, and $\lambda$ must therefore be in $B$
            \bigbreak \noindent 
            Next, we show that $\lambda$ is truly the greatest lower bound of $S$, that $\lambda \geq b $ for all lower bounds $b$ of $S$. Assume for the sake of contradiction that there exists some $b \in B$ such that $\lambda < b$. This would mean $\lambda$ is not actually an upper bound for $B$  which again contradicts the fact that $\lambda$ is the supremum of $B$
            \bigbreak \noindent 
            Thus, since $\lambda \in B$, and $\lambda \geq b$ for all $b\in B$. We have that $\lambda$ is the greatest lower bound of $S$, or $\lambda = \text{inf } S $ \hspace*{\fill}$\blacksquare$


    \end{itemize}

    \pagebreak 
    \subsection{An axiom system for geometry: First steps.}
    \begin{itemize}
        \item \textbf{What is projective geometry?} Projective geometry is a branch of geometry where any two distinct lines intersect in exactly one point, meaning there are no parallel lines. It extends Euclidean geometry by adding "points at infinity" to ensure this property holds. Projective geometry focuses on incidence relations (how points and lines are related) rather than distances or angles.
        \item \textbf{What is incidence?} In geometry, "incident" means that a point lies on a line (or a plane, in higher dimensions), or that a line passes through a point. More generally, it describes a fundamental relationship between geometric objects in an incidence structure.
            \bigbreak \noindent 
            For example:
            \begin{itemize}
                \item A point is incident to a line if it lies on that line.
                \item A line is incident to a point if it passes through that point.
                \item In projective geometry, two lines are incident to the same point if they intersect at that point.
            \end{itemize}
            \bigbreak \noindent 
            It is a basic, undefined term in axiomatic geometry, meaning it is taken as a fundamental concept rather than being defined in terms of simpler notions.
        \item \textbf{What is incidence geometry}: Incidence geometry is the study of geometric structures based only on points, lines, and their incidence relations (which points lie on which lines). It focuses on which objects are connected rather than distances, angles, or measurements. The main rules are typically:
            \begin{enumerate}
                \item Any two distinct points determine a unique line.
                \item Any two distinct lines intersect in at most one point.
                \item There exist at least four points, not all on the same line (to avoid trivial cases).
            \end{enumerate}
            \bigbreak \noindent 
            It includes Euclidean, affine, and projective geometries as special cases.

        \item \textbf{The Fano plane}: The Fano plane is a \textit{projective plane of order two.}
            \bigbreak \noindent 
            When we say that the Fano Plane is a projective plane of order two, we mean that
        \begin{itemize}
            \item \textbf{It is a finite projective plane}: – A projective plane is a type of incidence geometry satisfying specific axioms
                \begin{enumerate}
                    \item Any two distinct points determine a unique line.
                    \item Any two distinct lines intersect in a unique point.
                    \item There exist four points, no three of which are collinear (this ensures it is not a degenerate geometry).
                \end{enumerate}
            \item \textbf{Order two ($q = 2$)}: The order of a finite projective plane is a parameter $q$ that determines its structure. The order $q$ is defined by the number of points on each line minus one. In the Fano Plane:
                \begin{enumerate}
                    \item Every line contains exactly  $q+1=3$ points
                    \item Every point is on exactly $q+1 = 3$ lines
                    \item The total number of points is $q^{2} + q + 1 = 2^{2} + 2 + 1 = 7 $
                    \item The total number of lines is $q^{2} + q + 1 = 2^{2} + 2  + 1 = 7 $
                \end{enumerate}
        \end{itemize}
        Since the Fano Plane satisfies these properties for $q=2$, it is called a projective plane of order two.
    \item \textbf{More on the Fano plane}: There are seven points $\{A,B,C,D,E,F,G\}$, and there are seven lines $\{A,B,D\}, \{C,D,F\}, \{A,F,E\}, \{A,C,G\}, \{B,C,E\}, \{B,F,G\}, \{D,E,G\}$
        \bigbreak \noindent 
        There are three points on each line, and three points through each line
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{fano}
            \label{fig:fano}
        \end{figure}
        \bigbreak \noindent 
        Which points on which line? Write points in alphabetical order in three rows, start with $A$, then $B$, then with $D$
        \begin{align*}
            &A \ B \ C \ D \ E \ F \\
            &B \ C \ D \ E \ F \ A\\
            &D \ E \ F \ A B \ C \ \\
        \end{align*}
        Note that the columns give the lines
        \bigbreak \noindent 
        \textbf{Note:} The triangle picture is a good visual aid, but the Fano plane is not part of the Euclidean plane.
    \item \textbf{Coordinates for the Fano plane}: Each point is an ordered triple $(x,y,z) $, where $x,y,z$ are integers mod $2$
        \begin{align*}
            \begin{cases}
            0 & \text{ stands for all even numbers}     \\
            1 & \text{ stands for all odd numbers}     
            \end{cases}
        \end{align*}
        We further note that $\text{odd } + \text{ odd} = \text{ even}$. Or, $1 +1 = 0 $. Other than that it is business as usual... $0+0 =0,\ 1+0 = 0 + 1 =  1$
        \bigbreak \noindent 
        We have the points
        \begin{align*}
            &A(1,0,0) \quad B(1,1,0) \quad D(0,1,0) \quad E(0,0,1) \\
            &C(1,1,1) \quad F(1,0,1) \quad G(0,1,1) \quad \text{No point }:\ (0,0,0)
        \end{align*}
        \bigbreak \noindent 
        Given points $P,Q$, find the third point collinear with $P,Q$. We simply add the coordinate triples for $P,Q$. For example, suppose $A(1,0,0), B(1,1,0)$. Then,
        \begin{align*}
            (1,0,0) + (1,1,0) = (0,1,0) = D
        \end{align*}
    \item \textbf{Distance on the Fano plane}: We define distance for Fano points, but its not Euclidean distance
        \bigbreak \noindent 
        Given points $P,Q$,
        \begin{align*}
            d(PQ) = \text{ number of different respective coordinates}
        \end{align*}
        \bigbreak \noindent 
        For example, $B(1,1,0), G(0,1,1)$ implies $d(BG) = 2 $
    \item \textbf{General finite projective plane}:In general, for a finite projective plane of order  $q$
        \begin{enumerate}
            \item There are $q^{2} + q + 1$ points
            \item There are $q^{2} + q + 1$ lines
            \item Every line contains $q+1$ points
            \item Every point is contained in $q+1$ lines
        \end{enumerate}
        \bigbreak \noindent 
        And satisfies
        \begin{enumerate}
            \item Any two distinct points determine a unique line.
            \item Any two distinct lines intersect at a unique point.
            \item There exist at least four points, no three of which are collinear. (This ensures non-triviality.)
        \end{enumerate}
        Thus, the Fano Plane is the smallest projective plane, and it uniquely exists for order 2.
        \bigbreak \noindent 
        \textbf{Note:} The "projective" part in the name projective plane comes from its connection to projective geometry, which generalizes Euclidean geometry by removing the notion of parallel lines.
    \item \textbf{Fine projective plane with order one?}: a finite projective plane cannot have order $q=1$ because it would not satisfy the axioms of a projective plane.
        \bigbreak \noindent 
        If $q=1$:
        \begin{enumerate}
            \item \textbf{Number of points}: $1^{2} + 1 + 1 =3$
            \item \textbf{Number of lines}: $1^{2} + 1 + 1 =2$
            \item \textbf{Each line has}: $1+1 = 2$ points
            \item \textbf{Each point is on}: $1+1=2$ lines
        \end{enumerate}
        \bigbreak \noindent 
        This configuration forms a triangle, but therefore fails the requirement that a finite projective plane has at least four points (it only has three)
    \item \textbf{Some extra planes}
        \begin{itemize}
            \item \textbf{$\hat{\mathbb{E}}$: The bumpy plane}: Which is $\mathbb{E}$, but warped. Has bumps and depressions, not always flat.
            \item \textbf{$\mathbb{R}^{3}$:} Points, lines, distance of usual 3-dimensional space.
            \item \textbf{$\varnothing$}: Has the components necessary for a plane vacuously
        \end{itemize}
    \item \textbf{Define a plane}: Let's define a plane called $*$, 
        \begin{align*}
            \mathbb{P} &= \{A,B,C,D\} \quad \text{(4 points)} \\
            \mathbb{L} &= \{A,B,C\}, \{A,C,D\}, \{B,D\} \quad \text{3 lines}
        \end{align*}
        With distance function
        \begin{align*}
            \begin{array}{c|cccc}
               &A&B&C&D \\
               \hline
                A&0&1&2&\frac{1}{2} \\
                B&1&0&\frac{3}{2} &\frac{1}{2} \\
                C&2&\frac{3}{2}&0&\frac{3}{2} \\
                D&\frac{1}{2} &\frac{1}{2}&\frac{3}{2}&0
            \end{array}
        \end{align*}
    \item \textbf{Axiom system for plane geometry}: 
        \bigbreak \noindent 
        \textbf{Undefined terms:}
        \begin{itemize}
            \item \textbf{$\mathbb{P}$:} Set of elements, called \textbf{points.}
            \item \textbf{$\mathbb{L}$:} Collection of subsets of $\mathbb{P}$, called \textbf{lines}
            \item A function $d:\ \mathbb{P}\times \mathbb{P} \to \mathbb{R} $, called a \textbf{distance function}
        \end{itemize}
        \bigbreak \noindent 
        Call anything with these components a \textbf{plane}
        \bigbreak \noindent 
        \textbf{Notation, terminology}
        \begin{itemize}
            \item A line is a set of points
            \item If $P$ is on the line $m$ ($P\in m$), we say that "$P$ is on $m$", or "$m$ goes through $P$"
            \item If two or more points are on the same line, we say they are \textbf{collinear}
            \item Denote distance $d(P,Q)$, or $d(PQ)$, or just $PQ$
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Axiom of distance}: For all points $P,Q$
        \begin{enumerate}
            \item $PQ \geq 0 $
            \item $PQ = 0 \iff P=Q $
            \item $PQ = QP $
        \end{enumerate}
        These are true for all planes mentioned so far, even $*$ and $\varnothing $
        \bigbreak \noindent 
        \textbf{The distance set}: Define $\mathbb{D} = \{PQ:\ P,Q \in \mathbb{R}\}$. This is the set of all distances that occur between points of $\mathbb{P}$, with respect to the given distance function.
        \bigbreak \noindent 
        \textbf{The diameter of the plane $\mathbb{P}$, $\omega $}
        \begin{align*}
            \begin{cases}
                \omega = \text{sup}\ \mathbb{D} & \text{ if $\mathbb{D}$ has an upper bound in $\mathbb{R} $}      \\
                \omega = \infty & \text{ if $\mathbb{D}$ has no an upper bound in $\mathbb{R} $}      \\
            \end{cases}
        \end{align*}
        \bigbreak \noindent 
        Note that $\infty$ is not a real number, but we still say $r < \infty$ for all $r\in \mathbb{R} $
        \bigbreak \noindent 
        \[
            \begin{array}{|c|c|c|}
                \hline
                \mathbb{P} & \mathbb{D} & \omega \\
                \hline
                \mathbb{E} & [0, \infty) & \infty \\
                \mathbb{M} & [0, \infty) & \infty \\
                \mathbb{S}(r) & [0, \pi r] & \pi r \\
                \mathbb{H} & [0, \infty) & \infty \\
                \mathbb{G} & [0, \infty) & \infty \\
                \text{Fano} & \{0, 1, 2, 3\} & 3 \\
                \hat{\mathbb{E}} & [0, \infty) & \infty \\
                \mathbb{R}^3 & [0, \infty) & \infty \\
                \varnothing & \varnothing & \times \\
                (*) & \{0, \frac{1}{2}, 1, \frac{3}{2}, 2\} & 2 \\
                \hline
            \end{array}
        \]
        \bigbreak \noindent 
        \textbf{Note:} Whether $\omega$ is a finite number or $ \infty$, each distance $PQ$ is a nonnegative, finite real number
        \bigbreak \noindent 
        Why not assume that two points determine a unique line? That two points are together in exactly one line? The sphere $\mathbb{S}$, which we want to include as a plane, has many lines through two points, when the points are antipodes. These are the points $P,Q$ where $PQ = \pi r = \omega $.
        \bigbreak \noindent 
        Thus, our axioms will allow multiple lines through two points, but only if their distance apart is precisely $\omega$, the diameter of the plane. Note that $P,Q$, with $PQ = \omega$ \textbf{may or may not} have more than one line through them.
        \bigbreak \noindent 
        \textbf{Axioms of incidence}
        \begin{enumerate}
            \item There are at least two different lines
            \item Each line contains at least two different points
            \item Each pair of points are together in at least one line
            \item Each pair of points $P,Q$, with $PQ < \omega$ are together in at most one line
        \end{enumerate}
        \bigbreak \noindent 
        \textbf{Note:} These are true for all discussed planes except $\varnothing$. 1 and 2 are false for $\varnothing $
        \bigbreak \noindent     
    \item \textbf{So what exactly is a plane?}: Based on the provided axioms, the definition of a plane in this system is simply a structure consisting of
        \begin{itemize}
            \item A set of points $\mathbb{P}$
            \item A collection of subsets of $\mathbb{P}$ called lines $\mathbb{L}$
            \item A distance function $d:\ \mathbb{P}\times\mathbb{P}\to\mathbb{R}$.
        \end{itemize}
        \bigbreak \noindent 
        Thus, a set $\mathbb{P}$ and a set of lines $\mathbb{L}$ can be called a plane as long as they fit this definition, regardless of whether they satisfy the axioms of distance or incidence.
        \bigbreak \noindent 
        However, for a plane to behave in a meaningful way in axiomatic geometry (i.e., to be one of the discussed geometric planes like $\mathbb{E}, \mathbb{M}, \mathbb{S}(r)$, etc...) it must satisfy the axioms of distance and incidence. These axioms impose necessary geometric structure, ensuring that distances behave as expected and that lines and points interact according to the incidence rules.
        \bigbreak \noindent 
        Thus, a plane can exist without satisfying the axioms, but to be a meaningful model of geometry, it is typically expected to satisfy them.
    \item \textbf{Plane example}: Consider the plane with $\mathbb{P}:\ $ all points inside the unit circle in $\mathbb{E}$, and $\mathbb{L}$ be the set of all chords inside the circle
        \bigbreak \noindent 
        For points $P,Q$ in $\mathbb{P}$, define $d(PQ) = PQ = e(PQ)$. Ie the Euclidean distance
        \bigbreak \noindent 
        Note that the seven axioms are true statements for this example. 
        \bigbreak \noindent 
        We have $\mathbb{D} = [0,2)$, so $\omega = 2$, but $PQ < 2$ for all $P,Q\in \mathbb{P}$
    \item \textbf{Trivial discrete model (TDM)}: Let $\mathbb{P}$ be any set of at least three elements. Let $\mathbb{L}$ be the collection of all two element subsets of $\mathbb{P} $
        \bigbreak \noindent 
        Define distance as follows: For all $x\ne y \in \mathbb{P}$, 
        \begin{align*}
            \begin{cases}
                xy &= 1 \\
                xx &= 0
            \end{cases}
        \end{align*}
        The seven axioms are true for the TDM. We have $\mathbb{D} = \{0,1\}$, thus $\omega = 1 $
        \bigbreak \noindent 
        For example, if $\mathbb{P} = \{A,B,C\} $, which implies $\mathbb{L} = \{A,B\}, \{A,C\}, \{B,C\} $, which forms a triangle where all sides are of length one.
    \item \textbf{White stripes model (ws)}: Let $\ell, m$ be two parallel lines in $\mathbb{E}$
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{twolines}
            \label{fig:twolines}
        \end{figure}
        \bigbreak \noindent 
        Define $\mathbb{P} = \{\text{all points on $\ell $}\} \cup \{\text{all points on $m$}\}$, and $\mathbb{L} = \ell,m$, and all two point sets $\{P,Q\}$ where $P$ on $\ell$, $Q$ on $m$. Define distance $d = $ Euclidean distance $e(PQ)$
        \bigbreak \noindent 
        Note that the seven axioms are true statements for $ws$, and $\mathbb{D} = [0,\infty),\ \omega = \infty$
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{twolines2}
            \label{fig:twolines2}
        \end{figure}





    \end{itemize}

    \pagebreak 
    \subsection{Betweenness, segements, and rays}
    \begin{itemize}
        \item \textbf{Betweenness}: Let $\mathbb{P}$ be a plane with points, lines, distance, and satisfy the seven axioms (3 distance, 4 incidence). Define
            \bigbreak \noindent 
            \textbf{Definition.} Point $B$ lies \textbf{between} points $A$ and $C$, denoted $A-B-C$ provide that
            \begin{enumerate}
                \item $A,B$, and $C$ are different and collinear
                \item $AB + BC = AC $
            \end{enumerate}
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{between2}
                \label{fig:between2}
            \end{figure}
        \item \textbf{Betweenness example 1}: \begin{align*}
                P &= \{A, B, C, D\} \\
                L &= \{\{A, B, C\}, \{A, C, D\}, \{B, D\}\}
            \end{align*}
            \textbf{Distance:}
            \[
                \begin{array}{c|cccc}
  & A & B & C & D \\
  \hline
                    A & 0 & 1 & 2 & \frac{1}{2} \\
                    B & 1 & 0 & \frac{3}{2} & \frac{1}{2} \\
                    C & 2 & \frac{3}{2} & 0 & \frac{3}{2} \\
                    D & \frac{1}{2} & \frac{1}{2} & \frac{3}{2} & 0 \\
                \end{array}
            \]
            \textbf{On line \(\{A, C, D\}\):}
            \begin{align*}
                AC &= 2, \quad AD = \frac{1}{2}, \quad DC = \frac{3}{2} \\
            \end{align*}
            $AD + DC = AC$. Thus, $A - D - C$.
            \bigbreak \noindent 
            \textbf{On line \(\{A, B, C\}\):}
            \begin{align*}
                AB &= 1, \quad AC = 2, \quad BC = \frac{3}{2} \\
            \end{align*}
            No two of these add to the third, so there is \textbf{no betweenness relation} among \(A, B, C\).
        \item \textbf{Betweenness on the Fano plane}: We have the collinear points $A(1,0,0), B(1,1,0), D(0,1,0)$, with 
            \begin{align*}
                AB =1, \quad BD = 1, \quad AD =2
            \end{align*}
            We see $AB + BD = AD$. Thus, $A-B-D$
        \item \textbf{Betweenness on the spherical plane}: Consider points $A, C$, with $A \ne C$, and distance $AC < \omega = \pi r$. So, $A,C$ determine unique great circle (line) $\overleftrightarrow{AC}$. Let $A^{*}$ be the antipode of $A$, and $C^{*}$ be the antipode of $C$. We check all points $B$ on $\overleftrightarrow{AC}$  and see in which locations there is betweenness $A-B-C$.
            \bigbreak \noindent 
            First, consider $B$ on minor arc $\overset{\frown}{AC}$. Notice that the minor arc $\overset{\frown}{AB}$ plus the minor arc $\overset{\frown}{BC}$ equals the minor arc $\overset{\frown}{AC}$. Thus,
            \begin{align*}
                d_{\mathbb{S}}(AB) + d_{\mathbb{S}}(BC) = d_{\mathbb{S}}(AC)
            \end{align*}
            Thus, $A-B-C$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{minor1}
                \label{fig:minor1}
            \end{figure}
            \bigbreak \noindent 
            Next, let $B$ be on the minor arc $\overset{\frown}{A^{*}C}$. Observe that
            \begin{align*}
               d_{\mathbb{S}}(AC) + d_{\mathbb{S}}(CB) =  d_{\mathbb{S}}(AB)
            \end{align*}
            Thus, $A-C-B $
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{overset}
                \label{fig:overset}
            \end{figure}
            \bigbreak \noindent 
            Next, let $B$ be on the minor arc $\overset{\frown}{C^{*}A}$. Observe that
            \begin{align*}
                d_{\mathbb{S}}(BA) + d_{\mathbb{S}}(AC) = d_{\mathbb{S}}(BC)
            \end{align*}
            Thus, $B-A-C $
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{minorarc3}
                \label{fig:minorarc3}
            \end{figure}
            \bigbreak \noindent 
            Next, let $B$ be on the minor arc $\overset{\frown}{A^{*}C^{*}}$, any two of $d_{\mathbb{S}}(AB), d_{\mathbb{S}}(BC), d_{\mathbb{S}}(AC)  $ add to more than $\pi r $, hence more than any distance on $\mathbb{S} $. Therefore, no two add to the third and $A,B,C$ have no betweenness relation
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{marc1}
                \label{fig:marc1}
            \end{figure}
            \bigbreak \noindent 
            Finally, consider two points $A, A^{*}$, where $A^{*}$ is $A $'s antipode. Let $B$ be any point not equal to $A$ or $A^{*}$. Then, $B$ is collinear with $A, A^{*}$. Observe that
            \begin{align*}
                d_{\mathbb{S}}(AB) + d_{\mathbb{S}}(BA^{*}) = \pi r = d_{\mathbb{S}}(AA^{*})
            \end{align*}
            Thus, $A-B-A^{*} $
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{mior4}
                \label{fig:mior4}
            \end{figure}
            \pagebreak \bigbreak \noindent 
        \item \textbf{Betweenness theorem 1}: 
            \bigbreak \noindent 
            \textbf{Theorem 6.1 (Symmetry of betweenness)}. For a general plane $\mathbb{P}$ with points, lines, distance, and satisfy the seven axioms, $A-B-C \iff C-B-A$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose that $A-B-C$, by definition, $A,B,C$ are different and collinear. Hence, $C,B,A$ are different and collinear, and $AB + BC = AC $
            \bigbreak \noindent 
            By distance axiom three, $AB = BA$, $BC = CB$, and $AC = CA$. Thus,
            \begin{align*}
                AB + BC &= AC \\
                \implies BA + CB &= CA
            \end{align*}
            But by the commutative property of $+$ in $\mathbb{R} $
            \begin{align*}
                BA + CB &= CA \\
                \implies CB + BA &= CA 
            \end{align*}
            Therefore, by the definition of betweenness, $C-B-A$. Thus, by similar steps, if $C-B-A$, then $A-B-C$ \hspace*{\fill} $\blacksquare$
        \item \textbf{Uniqueness Middle Theorem (UMT)}:
            \bigbreak \noindent 
            \textbf{Theorem 6.2 (UMT)}: If $A-B-C$ then $B-A-C$ and $A-C-B$ are false.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A-B-C$, then $A,B,C$ are different, collinear, and $AB + BC = AC$. We know by distance axioms $1$ and $2$ that each of $AB, BC$, and $AC$ are greater than zero. Thus,
            \begin{align*}
                AC > AB \quad \text{ and } AC > BC
            \end{align*}
            Suppose for the sake of contradiction that $B-A-C$ is also true. Thus, $BC$ would be larger than both $BA=AB$ and $AC$. 
            \bigbreak \noindent 
            Since this contradicts the fact that $AC > BC$, which must be true if $A-B-C$, it must be that $B-A-C$ is false. By similar steps, $A-C-B$ is also false. \hspace*{\fill} $\blacksquare $ 
        \item \textbf{Betweennes in $\mathbb{M}$}: Suppose $A-B-C$ is true in $\mathbb{E}$. Then, we have in the Minkowski plane
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{bet}
                \label{fig:bet}
            \end{figure}
            \bigbreak \noindent 
            So we see
            \begin{align*}
                d_{\mathbb{M}}(AB) + d_{\mathbb{M}}(BC) &= \left\lvert x_{1} -x_{2} \right\rvert + \left\lvert y_{1} - y_{2} \right\rvert + \left\lvert x_{2} - x_{3} \right\rvert + \left\lvert y_{2} - y_{3} \right\rvert
            \end{align*}
            \bigbreak \noindent 
            We can then drop the absolute value bars by examining the configuration and determining which order the subtraction needs to happen to yield a positive result. We have
            \begin{align*}
                &(x_{2} - x_{1}) + (y_{2} - y_{1}) +(x_{3} -x_{2}) + (y_{3} - y_{2}) \\
                &=(x_{3}-x_{1}) + (y_{3} - y_{1}) = d_{\mathbb{M}}(AC)
            \end{align*}
            Thus, for $ A-B-C$ in $\mathbb{E}$, $A-B-C$ in $\mathbb{M}$ holds true. Similarly, $B-A-C$ in $\mathbb{E}$ implies $B-A-C$ in $\mathbb{M}$, and $A-C-B$ in $\mathbb{E}$ implies $A-C-B$ in $\mathbb{M}$
            \bigbreak \noindent 
            So for three collinear points $A,B,C$ in $\mathbb{E} $, exactly one (by the UMT) of $A-B-C$, $B-A-C$, $A-C-B$ occurs, and each relation implies the same relation happens in $\mathbb{M}$.
            \bigbreak \noindent 
            If $A-B-C$ happens in $\mathbb{M}$, then the other two do not by the UMT,  so only $A-B-C$ will then be true in $\mathbb{E}$. We state
            \begin{align*}
                A-B-C \text{ in } \mathbb{E} \iff A-B-C \text{ in } \mathbb{M}
            \end{align*}
        \item \textbf{Betweenness among the planes}: We have
            \begin{align*}
                A\text{-}B\text{-}C \text{ in } \mathbb{E} \iff A\text{-}B\text{-}C \text{ in } \mathbb{M} \\
                A\text{-}B\text{-}C \text{ in } \mathbb{E} \iff A\text{-}B\text{-}C \text{ in } \mathbb{G} \\
                A\text{-}B\text{-}C \text{ in } \mathbb{E} \iff A\text{-}B\text{-}C \text{ in } \mathbb{H} \\
            \end{align*}
        \item \textbf{Inside out}: Consider $\mathbb{P} = \{A,B,C,D,E,F\}$, $\mathbb{L}:\ \ell = \{A,B,C,D\}, m = \{A,E\}, n  = \{C,E\} , v = \{D,E\} $, and distance
            \begin{align*}
                \begin{array}{c|ccccc}
                   &A&B&C&D&E \\ 
                    A & 0 & 3 & 1 & 2 & 4\\
                    B &  3 & 0 & 2  & 1 & 4\\
                    C &  1 & 2 & 0 & 3 & 4\\
                    D & 2 &1 & 3 & 0 & 4\\
                    E & 4 & 4& 4 & 4 & 0\\
                \end{array}
            \end{align*}
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{ic}
                \label{fig:ic}
            \end{figure}
            \bigbreak \noindent 
            The seven axioms hold, $\mathbb{D} = \{0,1,2,3,4\}, \omega = 4$, and all betweenness occurs for points on $\ell$
            \begin{align*}
                A-C-B \quad A-D-B \quad C-A-D \quad C-B-D
            \end{align*}
        \item \textbf{Segments and rays}: Let $A\ne B$ be points in $ \mathbb{P}$ with $AB < \omega $. Then, there is a unique line through $A,B$, call it $ \overleftrightarrow{AB}$ 
            \begin{itemize}
                \item \textbf{The segment} $\overline\{AB\} = \{A,B\} \cup \{X: A-X-B\}$
                \item \textbf{The ray} $\overrightarrow\{AB\} = \{A,B\} \cup \{X: A-X-B\} \cup \{X: A-B-X\}$
            \end{itemize}
            \textbf{Note:} $\{X: A-X-B\} \cup \{X: A-B-X\} = \varnothing$
            \bigbreak \noindent 
            \textbf{Notation}: $\overline{AB}, \overrightarrow{AB}, \overleftrightarrow{AB}$ denote sets of points, with $\{A,B\} \subseteq \overline{AB} \subseteq \overrightarrow{AB} \subseteq \overleftrightarrow{AB}$
        \item \textbf{Carriers}: We call the line $\overleftrightarrow{AB}$ the \textbf{carrier} of $\overrightarrow{AB} $
        \item \textbf{Segments and rays on $\mathbb{S}$}
            \bigbreak \noindent 
            \fig{.5}{./figures/24.png}
            \bigbreak \noindent 
            Ray $\overrightarrow{AB}$ goes from $A$, through $B$, around to $A^{*}$. Since $A-B-A^{*}$, $\overrightarrow{AB}$ includes $A^{*} $
            \bigbreak \noindent 
            We have 
            \begin{itemize}
                \item \textbf{Segment} $\overline{AB} = \{A,B\} \cup \{X: A-X-B\}$ as usual
                \item \textbf{Ray} $\overrightarrow{AB} = \{A,B\} \cup \{X: A-X-B\} \cup \{X: B-X-A^{*}\} \cup \{A^{*}\}$, where $A^{*}$ is the antipode of $A$
            \end{itemize}

        \item \textbf{Proving results about general (abstract) planes $\mathbb{P}$}: We only use the undefined terms point, line, distance, the definitions, the assumed axioms, previously proved results, arithmetic of $\mathbb{R}$, and logic.
            \bigbreak \noindent 
            Sketches from $\mathbb{E}$, while sometimes useful, are not valid for general proofs. General planes include many examples besides $\mathbb{E}$, and Euclidean pictures may not apply to them, and may be misleading.
            \bigbreak \noindent 
            We assume plane $\mathbb{P}$, in which we have points, lines, and the first seven axioms satisfied.
            \bigbreak \noindent 
            Recall, for points $A\ne B$, $AB < \omega$,
            \begin{itemize}
                \item \textbf{Betweenness}: $A-B-C$ if $A,B,C$ are different, collinear, and $AB + BC = AC $
                \item \textbf{Segment} $\overline{AB} = \{A,B\} \cup \{X: A-X-B\}$
                \item \textbf{Ray} $\overrightarrow{AB} = \{A,B\} \cup \{X: A-X-B\} \cup \{X: A-B-X\}  $
            \end{itemize}
        \item \textbf{Proposition 6.3: Segments and lines}:
            \bigbreak \noindent 
            \textbf{Proposition.}
            \begin{enumerate}[label=(\alph*)]
                \item $\overline{AB}$ lies in one line, the line $\overleftrightarrow{AB} $
                \item $\overline{AB} = \overline{BA} $
                \item If $x\in \overline{AB}$, with $X \ne B$, then $AX < AB $
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof}} a.) Since $\overline{AB}$ exists, we have $AB < \omega$. Thus, by incidence axioms three and four, there is exactly one line containing points $A$, and $B$. Namely, $\overleftrightarrow{AB} $. If $X$ is any other point in $\overline{AB}$, then $A-X-B$ by definition of $\overline{AB}$. Thus, $X$ is collinear with $A,B$ by definition of betweenness, and hence, $x \in \overleftrightarrow{AB}$
            \bigbreak \noindent 
            b.) We have
            \begin{align*}
                \overline{AB} &= \{A,B\} \cup \{X: A-X-B\} \tag{1}\\
                \overline{BA} &= \{B,A\} \cup \{X: B-X-A\} \tag{2}\\
            \end{align*}
            But, since ordering in sets doesn't matter, $\{B,A\} = \{A,B\}$, and we have seen previously that $B-X-A = A-X-B$. Thus, (2) is precisely (1). That is, $\{B,A\} \cup \{X: B-X-A\} = \{A,B\} \cup \{X: A-X-B\}$, and therefore $\overline{AB} = \overline{BA} $
            \bigbreak \noindent 
            c.) We have
            \begin{align*}
                \overline{AB} = \{A,B\} \cup \{X: A-X-B\}
            \end{align*}
            Let $x\in \overline{AB} $, with $X\ne B$. Then, we have $A-X-B$, and $AX + XB = AB$. This implies that $AB$ greater than both $AX, XB$, which means $AB > AX$.
            \bigbreak \noindent 
            \textbf{Note}: Ray $\overrightarrow{AB}$ is also contained in exactly one line, the line $\overleftrightarrow{AB}$
            \bigbreak \noindent 
            Also, $\overrightarrow{AB} = \overrightarrow{BA}$ mostly does not hold. We have
            \begin{align*}
                \overrightarrow{AB} &= \{A,B\} \cup \{X: A-X-B\} \cup \{X: A-B-X\} \\
                \overrightarrow{BA} &= \{A,B\} \cup \{X: A-X-B\} \cup \{X: B-A-X\} \\
            \end{align*}
            Since $\{X: A-B-X\} \ne \{X: B-A-X\}$, it  is not generally the case that $\overrightarrow{AB} = \overrightarrow{BA} $ (In general). The scenario where $\overrightarrow{AB} = \overrightarrow{BA} $ is when $\overline{AB}, \overline{BA}$ are exactly the line where they are contained. This fact is true in the IO example, since $\overline{AB} = \overline{BA } = \overline{CD} = \overline{DC} = \{A,B,C,D\} = \ell  $
        \item \textbf{Proposition 6.4}
            \bigbreak \noindent 
            \textbf{Proposition}: Let $A,B,C,D$ be collinear points with $0 < AB < \omega$, $0< CD<\omega$, and $\overline{AB} = \overline{CD}$, then
            \begin{enumerate}[label=(\alph*)]
                \item Either $\{A,B\} = \{C,D\}$ or $\{A,B\} \cap \{C,D\} = \varnothing$
                \item $AB = CD$
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof (a)}} Part a says that $\{A,B\}$ and $\{C,D\}$ can have two (all) elements in common, or no elements in common. Thus, we show that it cannot be the case that they have one element in common
            \bigbreak \noindent 
            Suppose for the sake of contradiction that $\{A,B\}$ and $\{C,D\}$ have exactly one element in common. Assume it is $A=C$. Then, $A \ne B$, $B\ne C$, and $B \ne D$. 
            \bigbreak \noindent 
            By definition of a segment, $D \in \overline{CD} = \{AB\}$, which implies $A\text{-}D\text{-}B$ since $D\ne A$ and $D \ne B$. Also, $B \in  \overline{AB} = \overline{CD}$ implies $C\text{-}B\text{-} D$ (since $B \ne C$ and $B \ne D$). But, since $A = C$, we have $C\text{-}B\text{-}D  = A\text{-}B\text{-}D$ which cannot happen by the UMT since we know we have $A\text{-}D\text{-}B $. Thus, our assumption that $A = C$ must be false. A similar argument for the other equality pairs shows that the two sets must not contain exactly one common element.
            \bigbreak \noindent 
            Therefore, $\{A,B\} = \{C,D\}$ or $\{A,B\} \cap \{C,D\} = \varnothing$
            \bigbreak \noindent 
            \textbf{\textit{Proof (b)}} If $\{A,B\} = \{C,D\} $ then $AB = CD$ by substitution. So, we may assume that $\{A,B\} \cap \{C,D\} = \varnothing$. 
            \bigbreak \noindent 
            We have $C,D \in \overline{CD} = \overline{AB}$, and $C,D \ne A \text{ or } B$, which implies $A\text{-}C\text{-} B$ and $A\text{-}D\text{-}B$. Similarly, $A,B \in \overline{AB} = \overline{CD} $ yields $C\text{-}A\text{-}D$ and $C\text{-}B\text{-}D$. Hence, we have $AC + AD = CD$ and $CB +BD = CD$. Adding these two equations and making suitable substitutions  yields $2CD = 2AB$, hence, $CD = AB$
            \endpf

    \end{itemize}

    \pagebreak 
    \subsection{Three axioms for the line}
    \begin{itemize}
        \item \textbf{Proposition 7.1}
            \bigbreak \noindent 
            \textbf{Proposition}. If $A\text{-}B\text{-}C$ and $A\text{-}C\text{-}D$, then $A,B,C,D$ are distinct and collinear 
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Be the definition of betweenness, $A,C,D$ are distinct and collinear, and $AC + CD = AD$. Since $CD > 0$, $AC < AD$. But, since $AD \leq \omega$, it must be that $AC < \omega$. Thus, $A,C$ are together in a unique line  (the line $\overleftrightarrow{AC} $)
            \bigbreak \noindent 
            Also, $A,B,C$ are distinct and collinear. Thus, $B,D$ are both collinear with $A$ and $C$ which implies all four points must be in $\overleftrightarrow{AC}$, and hence they are all collinear.
            \bigbreak \noindent 
            The only way two of $A,B,C,D$ could be equal is if $B =D$. But then, substituting $B$ for $D$ in $A\text{-}C\text{-}D$, we get $A\text{-}C\text{-}B$. This contradicts $A\text{-}B\text{-}C$ and the UMT. Thus, all four points are different. \endpf

        \item \textbf{Definition:} Define $A\text{-}B\text{-}C\text{-}D$ to mean the following betweenness relations are all satisfied
            \begin{align*}
                A\text{-}B\text{-}C \quad A\text{-}B\text{-}D \quad A\text{-}C\text{-}D \quad B\text{-}C\text{-}D 
            \end{align*}
            \bigbreak \noindent 
            Also, for collinear points $A,B,C,D$
            \begin{align*}
                A\text{-}B\text{-}C\text{-}D \implies AB + BC + CD = AD
            \end{align*}
        \item \textbf{Proposition 7.2} If $A\text{-}B\text{-}C\text{-}D$, then $A,B,C,D$ are distinct and collinear, and $D\text{-}C\text{-}B\text{-}A $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} $A\text{-}B\text{-}C\text{-}D$ implies $ A\text{-}B\text{-}C$, $ A\text{-}B\text{-}D, A\text{-}C\text{-}D, B\text{-}C\text{-}D$. Since $ A\text{-}B\text{-}C$ and $ A\text{-}C\text{-}D$ are true, then $A,B,C,D$ are distinct and collinear, if we switch the order on the four betweenness relations (first point and last for each of them), we get precisely 
            \begin{align*}
                D\text{-}C\text{-}B\text{-}A
            \end{align*}
            \endpf
        \item \textbf{Betweenness of points axiom (Ax. BP)}: If $A,B,C$ are distinct, collinear points, and if $AB + BC \leq \omega$, then there exists a betweenness relation among $A,B,C$
            \bigbreak \noindent 
            What this is really saying is that if \textbf{any} of $AB + BC$, $BA + AC$, $AC + CB$ is $ \leq \omega$, then there is a betweenness relation.
            \bigbreak \noindent 
            \textbf{Note:} If Ax.BP is true for a plane $\mathbb{P}$, and if $AB + BC \leq \omega$ for distinct collinear $A,B,C$, then there is a betweenness relation, but not necessarily $ A\text{-}B\text{-}C $
            \bigbreak \noindent 
            When $\omega = \infty$, then for any distinct collinear $A,B,C$, $AB +BC  < \infty = \omega $, so there will be a betweenness relation
        \item \textbf{What would make Ax.BP false?} Three collinear points $A,B,C$ so that at least one of $AB + BC \leq \omega, AC + CB \leq \omega, BA + AC \leq \omega$, and no betweenness relation for $A,B,C$ exists
            \bigbreak \noindent 
            \textbf{Note:} If there are no lines with three points, then the axiom is vacuously true.
        \item \textbf{Planes with first 8 axioms}: Consider a general plane $\mathbb{P}$ with points, lines, distance, and all 8 axioms true. We can establish some important properties of all these planes
        \item \textbf{Triangle inequality for the line}: If $A,B,C$ are any three distinct, collinear points, then 
            \begin{align*}
                AB + BC \geq AC 
            \end{align*}
            \bigbreak \noindent 
            \textbf{Note:} Don't worry about why the word triangle is in the name. Also, the triangle inequality is not necessarily true without Ax.BP
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We examine two cases, either $ AB + BC > \omega$, or $AB + BC \leq \omega$. In this first case, $AB +BC > \omega$ implies $AB +BC > AC$, since by the definition of $\omega$, $AC \leq \omega$.
            \bigbreak \noindent 
            Next, we consider $AB + BC \leq \omega$. In this case, by Ax.BP, there must exist a betweenness relation among $A,B,C$. One of the following must be satisfied
            \begin{align*}
                A\text{-}B\text{-}C \\
                B\text{-}A\text{-}C \\
                A\text{-}C\text{-}B
            \end{align*}
            \bigbreak \noindent 
            Assume its $ A\text{-}B\text{-}C$, then by definition of $ A\text{-}B\text{-}C$, we have $AB + BC = AC$, which implies $AB + BC \geq AC$ is satisfied.
            \bigbreak \noindent 
            Next, assume its $ B\text{-}A\text{-}C$, then $BA + AC = BC$. We have
            \begin{align*}
                AC &= BC - AB \\
                AC + 2AB &= BC - AB + 2AB \\
                AC + 2AB &= BC + AB \\
                AC + 2AB &= AB + BC
            \end{align*}
            In this case, since $2AB > 0$ by distance axiom 2, we have $AC + 2AB \geq AC$. Thus, $AC + 2AB = AB + BC \geq AC $ 
            \bigbreak \noindent 
            Lastly, assume the relation we have is $ A\text{-}C\text{-}B$, then $AC + CB = AB$. We have
            \begin{align*}
                AC + CB &= AB \\
                AC &= AB - CB \\
                AC + 2CB &= AB - CB + 2CB \\
                AC + 2CB &= AB + CB \\
                AC + 2CB &= AB + BC \\
            \end{align*}
            Similar to the previous argument, since $AC + 2CB \geq AC$, we have $AC + 2CB = AB + BC \geq AC $
            \bigbreak \noindent 
            Therefore, $ AB + BC \geq AC$ \endpf
        \item \textbf{Rule of insertion}: 
            \begin{itemize}
                \item If $ A\text{-}B\text{-}C$ and $ A\text{-}X\text{-}B$, then $ A\text{-}X\text{-}B\text{-}C $
                \item If $ A\text{-}B\text{-}C$ and $ B\text{-}X\text{-}C$, then $ A\text{-}B\text{-}X\text{-}C $
            \end{itemize}
            \bigbreak \noindent 
            \textbf{\textit{Proof (a).}} Since $ A\text{-}B\text{-}C$, and $ A\text{-}X\text{-}B$, then we know that $A,X,B,C$ are distinct, collinear. 
            \bigbreak \noindent 
            By the definition of betweenness, we have
            \begin{align*}
                AB  + BC &= AC \\
                AX + XB &= AB
            \end{align*}
            Thus,
            \begin{align*}
                AX + XB + BC &= AC
            \end{align*}
            By the triangle inequality, we have $XB + BC \geq XC$. Thus,
            \begin{align*}
                AC & =AX + XB +  BC \geq AX + XC
            \end{align*}
            But the triangle inequality also implies that 
            \begin{align*}
                AX + XC \geq AC
            \end{align*}
            Thus, since $AX + XC \leq AC \leq AX + XC$. Thus, it must be that $AC = AX + XC$. Hence, $ A\text{-}X\text{-}C $. Next, plugging $AC = AX + XC$ into $AC = AX + XB + BC$ yields
            \begin{align*}
                AX + XC &= AX + XB + BC \\
                \implies XB + BC &= XC
            \end{align*}
            Thus, $ X\text{-}B\text{-}C $.
            \bigbreak \noindent 
            \textbf{\textit{Proof (b)}} If $ A\text{-}B\text{-}C$ and $ B\text{-}X\text{-}C$, then $ C\text{-}B\text{-}A$ and $ C\text{-}X\text{-}B $, so by part (a), we have
            \begin{align*}
                C\text{-}X\text{-}B\text{-}A
            \end{align*}
            Which means $ A\text{-}B\text{-}X\text{-}C$ \endpf
        \item \textbf{What does the betweenness of points axiom get us?} The triangle inequality and the insertion theorem 
        \item \textbf{Quadrichotomy Axiom for Points (Ax.QP)}: If $A,B,C,X$ are distinct, collinear points, and if $ A\text{-}B\text{-}C$. Then, at least one of the following must hold
            \begin{align*}
                X\text{-}A\text{-}B, \quad A\text{-}X\text{-}B, \quad B\text{-}X\text{-}C, \quad \text{or } \quad B\text{-}C\text{-}X
            \end{align*}
            \bigbreak \noindent 
            Thus, Ax.QP says that whenever $ A\text{-}B\text{-}C$ (say on line $\ell$), then any other point $X$ on line $\ell$ is in either $ \overrightarrow{BA} $ or $ \overrightarrow{BC} $. That is,
            \begin{align*}
                \ell = \overrightarrow{BA} \cup \overrightarrow{BC}
            \end{align*}
            \bigbreak \noindent 
            Ax.QP is true for
            \begin{itemize}
                \item $\mathbb{E}$
                \item $\mathbb{M}$
                \item $\mathbb{G}$
                \item $\mathbb{H}$
                \item $\mathbb{S}$
                \item $\mathbb{R}^{3}$
                \item $\hat{\mathbb{E}}$ (bumpy plane)
            \end{itemize}
            It is also true vacuously for the white stripes model, the TDM, and the Fano plane
            \bigbreak \noindent 
            Ax.QP is also true for the Inside Out (IO) example. It is vacuously two for the 2-point lines, but we can also check that it is satisfied for $\ell = \{A,B,C,D\} $
            \bigbreak \noindent 
            \textbf{Note:} If the first 8 axioms are true for a plane $\mathbb{P}$, and if $\omega = \infty$, then the statement of Ax.QP can be proved to hold true in $\mathbb{P}$. A key reason for this is that because $\omega = \infty$, any three collinear points must have a betweenness relation.
        \item \textbf{When is Ax.QP false?}: In a plane with at least four collinear points $A,B,C,X$ with $ A\text{-}B\text{-}C$, and none of 
            \bigbreak \noindent 
            \begin{align*}
                    X\text{-}A\text{-}B, \quad A\text{-}X\text{-}B, \quad B\text{-}X\text{-}C, \quad \text{or } \quad B\text{-}C\text{-}X
            \end{align*}
            Are true
        \item \textbf{Proposition 7.5}: If $X \ne Y$ are points distinct from $A$ on ray $\overrightarrow{AB}$, then at least one of $ A\text{-}X\text{-}Y$ or $ A\text{-}Y\text{-}X$ or $X,Y$ in $ \overline{AB}$ is true.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} If $Y = B$, then either $ A\text{-}X\text{-}Y$ or $ A\text{-}Y\text{-}X$ by definition of $ \overrightarrow{AB}$, so we may assume that $Y \ne B$, and similarly that $X \ne B$.
            \bigbreak \noindent 
            Now either $ A\text{-}X\text{-}B$ or $ A\text{-}B\text{-}X$, and either $ A\text{-}Y\text{-}B$ or $ A\text{-}B\text{-}Y$ by definition of $ \overrightarrow{AB}$, we consider each of the four possibilities. 
            \bigbreak \noindent 
            Suppose that $ A\text{-}B\text{-}X$ and $ A\text{-}Y\text{-}B$ are true. Then, the rule of insertion says that $ A\text{-}Y\text{-}B\text{-}X$, which gets us $ A\text{-}Y\text{-}X$. Similarly, if $ A\text{-}B\text{-}Y$ and $ A\text{-}X\text{-}B$ are true, then we get $ A\text{-}X\text{-}Y$ by the rule of insertion
            \bigbreak \noindent 
            Suppose that $ A\text{-}B\text{-}X$ and $ A\text{-}B\text{-}Y$ are true. $ A\text{-}B\text{-}X $ and Ax.QP says that one of 
            \begin{align*}
                Y\text{-}A\text{-}B, \quad A\text{-}Y\text{-}B, \quad B\text{-}Y\text{-}X, \quad \text{ or } \quad B\text{-}X\text{-}Y 
            \end{align*}
            Is true. But, since $ A\text{-}B\text{-}Y$ is true, then we can't have either $ Y\text{-}A\text{-}B$ or $ A\text{-}Y\text{-}B$ because this would contradict the UMT. Thus, we know we have either $ B\text{-}Y\text{-}X$  or $ B\text{-}X\text{-}Y$. If $ B\text{-}Y\text{-}X$ then by the rule of insertion we get $ A\text{-}Y\text{-}X$. If $ B\text{-}X\text{-}Y $ then the rule of insertion gets us $ A\text{-}X\text{-}Y$
            \bigbreak \noindent 
            Finally, suppose that $ A\text{-}X\text{-}B$ and $ A\text{-}Y\text{-}B$. The best we can do is assert that $X,Y$ are in $ \overline{AB}$ by the definition  of a segment.
        \item \textbf{What we have so far}: Nine axioms for a general plane, which are satisfied in the following examples that we have seen
            \begin{itemize}
                \item $\mathbb{E} $
                \item $\mathbb{M} $
                \item $\mathbb{S} $
                \item $\mathbb{H} $
                \item $\mathbb{G} $
                \item $\hat{\mathbb{E}} $
                \item $ws$
                \item $\mathbb{R}^{3} $
                \item Fano
                \item TDM
                \item IO
            \end{itemize}
            None of the axioms so far says that rays have to exist on any particular line, or even in the plane overall. We need another axiom to guarantee that rays (and segments) exist on every line.
        \item \textbf{Nontriviality Axiom (Ax.N)}: For any point $A$ on a line $\ell$ there exists a point $B$ on $\ell$ with $0 < AB < \omega$
            \bigbreak \noindent 
            This axiom is true for the planes in which $\omega = \infty$ ($\mathbb{E}$, $\mathbb{M}$, $\mathbb{H}$, $\mathbb{G}$, $\mathbb{R}^{3}$, $\hat{\mathbb{E}} $, ws)
            \bigbreak \noindent 
            This axiom is also true for $\mathbb{S}$ and Fano, where $\omega < \infty $
            \bigbreak \noindent 
            Ax.N is false for TDM, and for the two point lines in IO.
            \bigbreak \noindent 
            We now assume the IO axioms for our general plane $\mathbb{P}$
        \item \textbf{Theorem 7.6}: This next theorem is the only one in chapters 6-9 that is about points on more than a single line
            \bigbreak \noindent 
            \textbf{Theorem.} For any point $A$ on a line $\ell$ there exists a point $C$ not on $\ell$ with $0 < AC <\omega$ 
            \bigbreak \noindent 
            To prove this, we first show that there is a point $C$ not on $\ell$, then we show that this point $C$ satisfies $0 < AC < \omega$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}}
            \bigbreak \noindent 
            First, we get a point $X$ not on $\ell$. By incidence axiom 1, there is a line $m \ne \ell$, by incidence axiom 2, there is a point $X$ on $m$. By Ax.N, there is a point $y$ on $m$ with 
            \begin{align*}
                0 < XY < \omega
            \end{align*}
            Thus, $\overleftrightarrow{XY} $ is the \textbf{unique} line through $X$ and $Y$. If $X,Y$ were both on $\ell$, then $\ell = \overleftrightarrow{XY} = m$, which contradicts there being a unique line through $X,Y$. Thus, at least one of $X$ or $Y$, say $X$ is not on $\ell$.
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{fig123}
                \label{fig:fig123}
            \end{figure}
            \bigbreak \noindent 
            Second, we need to get a point $C$ not on $\ell$, with $0 < AC < \omega$
            \bigbreak \noindent 
            There is a line $t$ through $A$ and $X$, with $t\ne \ell$, since $X$ is on $t$, but not on $\ell$. Ax.N says that there is a point $C$ on $t$ with $0 < AC < \omega$. By incidence axiom 4, $t$ is the only line through $A$ and $C$. If $C$ were on $\ell$, then both $A$ and $C$ on $\ell$ would imply $\ell = t$, which is a contradiction.
            \bigbreak \noindent 
            Therefore, $C$ is not on $\ell$, and $0 < AC < \omega$.
            \bigbreak \noindent 
\begin{figure}[ht]
    \centering
    \incfig{fig12}
    \label{fig:fig12}
\end{figure}
        \item \textbf{Note about Ax.N} This axiom stops us from construction examples of planes in which all points are collinear. (See proof above)
        \item \textbf{Important fact}:  Suppose $X$ is a point on a ray $\overrightarrow{AB}$ in a general plane.
            \begin{enumerate}
                \item If $ A\text{-}X\text{-}B$ then $AX < AB $
                \item If $ A\text{-}B\text{-}X$ then $AX > AB $
                \item IF $X = B$ then $AX = AB$
            \end{enumerate}


    \end{itemize}




    \pagebreak 
    \subsection{Exam 1 Axioms definitions and theorems}
    \begin{itemize}
    \item \textbf{Euclids fifth postulate}: If a straight line intersects two straight lines such that the interior angles on one side add up to less than two right angles, then the two straight lines, if extended indefinitely, will meet on the side where the angles are less than two right angles.
    \item \textbf{Playfairs postulate}: "Through a given point not on a line, there is exactly one line parallel to the given line"
        \item \textbf{$\mathbb{E}$}
            \begin{itemize}
                \item \textbf{Points:} $(x,y)$
                \item \textbf{Lines:} Each \textit{nonvertical line} $\ell$ in $\mathbb{E}$ consists of all points $(x,y)$, where $y = mx + b$ for some fixed $m$ and $b$. Each \textit{vertical line} $\ell$ consists of all $(x,y)$, where $x=a$ for some fixed $a$
                \item \textbf{Distance}: $e(AB) = \sqrt{(x_{2} - x_{1})^{2} + (y_{2} - y_{1})^{2}} = \left\lvert x_{1}-x_{2} \right\rvert \sqrt{1+m^{2}}$
            \end{itemize}
        \item \textbf{$\mathbb{M}$}
            \begin{itemize}
                \item \textbf{Points:} $(x,y)$
                \item \textbf{Lines}: Same as in $\mathbb{E}$
                \item \textbf{Distance}: $d_{\mathbb{M}}(Ab) = \left\lvert x_{2} - x_{1} \right\rvert + \left\lvert y_{2} - y_{1} \right\rvert = \left\lvert x_{1} - x_{2} \right\rvert(1+\left\lvert m \right\rvert$) 
            \end{itemize}
        \item \textbf{$\mathbb{S}$}:
            \begin{itemize}
                \item \textbf{Points:} $(x,y)$
                \item \textbf{Lines:} Great circle through two points
                \item \textbf{Distance}:
                    \begin{align*}
                        d_{\mathbb{S}} &= r\theta = r\cos^{-1}{\left(\frac{ax+by+cz}{r^{2}}\right)}
                    \end{align*}
            \end{itemize}
        \item \textbf{$\mathbb{H}$}
            \begin{itemize}
                \item \textbf{Points}: $(x,y)$
                \item \textbf{Lines}: Chords on unit circle through two given points
                \item \textbf{Distance}: $d_{\mathbb{H}} = \ln{\left(\frac{e(AN)e(BM)}{e(AM)e(BM)}\right)}$
                    \bigbreak \noindent 
                    Use the following formulas if $M,N$ have the chance of being misplaced
                    \begin{align*}
                        \left\lvert \ln{\left(\frac{e(AN)e(BM)}{e(AM)e(BN)}\right)} \right\rvert = \left\lvert \ln{\left(\frac{e(AM)e(BN)}{e(AN)e(BM)}\right)} \right\rvert
                    \end{align*}
            \end{itemize}
        \item \textbf{$\mathbb{G}$}
            \begin{itemize}
                \item \textbf{Points:}   $(x,y)$, $x \leq 0$,or  $x > 1 $
                \item \textbf{Lines:} Lines in $\mathbb{G}$ are defined to be the same as in $\mathbb{E}$, except that for any nonvertical line $y=mx+b$, the part in the missing strip is deleted. So a typical nonvertical line $\ell$ consists of all $(x,y)$ with $y=mx+b$ ($m,b$ fixed) and with $x \leq 0$ or $x > 1$
                \item \textbf{Distance}: 
                    \begin{align*}
                        d_{\mathbb{G}}(AB) = \begin{cases}
                            e(AB) & \text{ for $A,B$ on the same side of the gap} \\     
                            e(AB) - e(CD) & \text{ for $A,B$ on the opposite sides of the gap} 
                        \end{cases}
                    \end{align*}
                \item \textbf{$\hat{\mathbb{E}}$}
                \item \textbf{Fano}
                \item \textbf{White stripes}
                \item \textbf{Trivial discrete}
                \item \textbf{Inside out}
            \end{itemize}
        \item \textbf{Interior and Exterior angles}: Interior angles are the angles inside the triangle. Each vertex of the triangle has one interior angle. The sum of the interior angles of a triangle is always $180^{\circ}$
            \bigbreak \noindent 
            Exterior angles are the angles formed outside the triangle when one side of the triangle is extended.
            At each vertex, an exterior angle is supplementary to the interior angle (they add up to $180^{\circ} $
            \bigbreak \noindent 
            If an interior angle at a vertex is $A$, the corresponding exterior angle $E$ is:
            \begin{align*}
                E = 180^{\circ} - A
            \end{align*}
            \bigbreak \noindent 
            The sum of the exterior angles of a triangle (one at each vertex) is always $360^{\circ}$ , regardless of the shape of the triangle.
        \item \textbf{Remote angles}: Remote angles refer to the interior angles of a triangle that are not adjacent to a given exterior angle
        \item \textbf{More on points}:
            \begin{itemize}
                \item \textbf{Collinear points}: Points that lie on the same straight line.
                \item \textbf{Noncollinear points}: Points that do not lie on the same straight line.
                \item \textbf{Coplanar points}: Points that lie on the same plane.
                \item \textbf{Concurrent Points}: Points where three or more lines intersect.
                \item \textbf{Equidistant Points}: Points that are all the same distance from a particular point or object.
                \item \textbf{Lattice Points}:  Points with integer coordinates.
                \item \textbf{Interior points:} Points that lie inside a given shape.
                \item \textbf{Exterior points:} Points that lie outside a given shape.
            \end{itemize}
        \item \textbf{Congruent triangles}: Congruent triangles are triangles that are exactly the same in shape and size. This means that all corresponding sides and angles of one triangle are equal to those of the other triangle.
        \item \textbf{Vertical (opposite) angles}: Vertical angles (also called opposite angles) are the angles that are formed by two intersecting lines and are opposite to each other
        \item \textbf{Theorem (\textit{Exterior angle inequality})}: An exterior angle of a triangle is greater than either remote interior angle. That is, if $\triangle ABC$ is a any triangle, and point $D$ is on the extension of segment $\overline{BC}$ through $C$, then
            \begin{align*}
                \angle ACD > \text{ both } \angle A \text{ and } \angle B
            \end{align*}
        \item \textbf{Relationship of angles}:
            \bigbreak \noindent 
            % \begin{figure}[ht]
            %     \centering
            %     \incfig{tc}
            %     \label{fig:tc}
            % \end{figure}
            \bigbreak \noindent 
            \begin{itemize}
                \item \textbf{Interior angles}: Interior angles are the angles that are inside the transversal configuration. Angles $a,b,c,d$ are interior
                \item \textbf{Exterior angles}: Exterior angles are the angles that are inside the transversal configuration. Angles $e,f,g,h$ are exterior
                \item \textbf{Consecutive interior angles}: Pairs of interior angles that are on the same side of the transversal. Angles $c,d$ are consecutive interior, and $a,b$ are consecutive interior
                \item \textbf{Consecutive exterior angles}: Pairs of exterior angles that are on the outside of the transversal configuration. Angles $e,g$ are consecutive exterior, angles $f,h$ are consecutive exterior
                \item \textbf{Alternate interior angles}: Pairs of interior angles that are on opposite sides but not complementary, angles $b,d$ and $a,c$ are alternate interior
                \item \textbf{Alternate exterior angles}: Pairs of exterior angles that are on opposite sides but not complementary, angles $e,h$, and $f,g$ are alternate exterior
                \item \textbf{Vertical angles}: Angles that are opposite each other, formed when two lines intersect. Vertical angles are of equal measure. Pairs $d,h$ - $a,g$ - $e,b$ - and $f,c$ are vertical
                \item \textbf{Supplementary angles}: Angle pairs that sum to 180, pairs $a,h$ - $d,g$ - $f,b$ - and $e,c$ are supplementary
                \item \textbf{Complementary angles}: Angle pairs that sum to 90, none in the transversal configuration
            \end{itemize}
        \item \textbf{Proposition (Equal alternate interior angles)}. Suppose $a + b = 180$, then $b = d$, and $c=a $.
        \item \textbf{Upper bounds}: Suppose $S$ is a set of real numbers, we define $b \in \mathbb{R}$ as an \textit{upper bound} for $S$ if for all $x\in S, x \leq b$
            \bigbreak \noindent 
            The negation of this definition is, there exists $x\in S$ such that $x \nleq b$, or $x > b$. Thus, to prove some $b$ is not an upper bound for $S$, we can show that some element of $S$ is greater than $b$
            \bigbreak \noindent 
            There are of course  sets that do not have any upper bounds. Consider the set $S = \{n:\ n\in \mathbb{N} \text{ and } n>0\} $. This set has no upper bound.
            \bigbreak \noindent 
            If $S = \varnothing$, then every $b \in \mathbb{R}$ is an upper bound for $S$. This statement is vacuously true.
        \item \textbf{Least upper bound (supremum)}: $c\in \mathbb{R}$ is a \textit{least upper bound} of a set $S$ of real numbers if 
            \begin{enumerate}
                \item $c$ is an upper bound for $S$
                \item $c \leq b$ for all upper bounds $b$ of $S$
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{Note:} The supremum of a set $S$ is denoted $ b = \text{sup}(S)$, where $b$ is the supremum of the set
        \item \textbf{Least upper bound property of $\mathbb{R}$}: If $S$ is a nonempty set of real numbers that has an upper bound in $\mathbb{R}$, then $S$ has a least upper bound (l.u.b) in $\mathbb{R} $
            \bigbreak \noindent 
            This justifies, among other things, that infinite decimals exist as real numbers, since an infinite decimal can be defined as the least upper bound of the set of all its finite truncations. For example, suppose $S$ is the set of all finite decimal expansions of $\pi$.
            \begin{align*}
                S = \{3,3.1,3.14,3.141, 3.1415,...\}
            \end{align*}
            Then, $S$ as an $l.u.b$ $\pi$, and $\pi\not\in S $
        \item \textbf{Least upper bound proposition}
            \bigbreak \noindent 
            \textbf{Proposition.} Let $S$ be a nonempty set of real numbers that has a least upper bound $b \in \mathbb{R}$. Let $t \in \mathbb{R}$ such that $t < b$. Then, there exists some $s \in S$ such that $t < s \leq b$.
        \item \textbf{Lower bounds}: Let $S$ be a nonempty set of real numbers. Then $g\in \mathbb{R}$ is a \textit{lower bound} for $S$ if $g \leq x$ for all $x\in S$.
        \item \textbf{Greater lower bounds (Infimum)}: $h\in \mathbb{R}$ is a \textit{greatest lower bound}, also called the \textit{infimum}, or \textit{inf} for $S$ if $ h$ is a lower bound for $S$ and $h \geq g$ for all lower bounds $g$ of $S$
        \item \textbf{Infimum proposition}
            \bigbreak \noindent 
            \textbf{Proposition}. Let $S$ be a nonempty set or real numbers that has a lower bound in $\mathbb{R}$. Then $S$ has a infimum in $\mathbb{R}$





        \item \textbf{Undefined terms}: 
            \begin{itemize}
                \item \textbf{$\mathbb{P}$:} Set of elements, called \textbf{points.}
                \item \textbf{$\mathbb{L}$:} Collection of subsets of $\mathbb{P}$, called \textbf{lines}
                \item A function $d:\ \mathbb{P}\times \mathbb{P} \to \mathbb{R} $, called a \textbf{distance function}
            \end{itemize}
        \item \textbf{Notation, terminology}
        \begin{itemize}
            \item A line is a set of points
            \item If $P$ is on the line $m$ ($P\in m$), we say that "$P$ is on $m$", or "$m$ goes through $P$"
            \item If two or more points are on the same line, we say they are \textbf{collinear}
            \item Denote distance $d(P,Q)$, or $d(PQ)$, or just $PQ$
        \end{itemize}
    \item         \textbf{Axiom of distance}: For all points $P,Q$
        \begin{enumerate}
            \item $PQ \geq 0 $
            \item $PQ = 0 \iff P=Q $
            \item $PQ = QP $
        \end{enumerate}
    \item         \textbf{Axioms of incidence}
        \begin{enumerate}
            \item There are at least two different lines
            \item Each line contains at least two different points
            \item Each pair of points are together in at least one line
            \item Each pair of points $P,Q$, with $PQ < \omega$ are together in at most one line
        \end{enumerate}
    \item \textbf{Betweenness of points axiom (Ax. BP)}: If $A,B,C$ are distinct, collinear points, and if $AB + BC \leq \omega$, then there exists a betweenness relation among $A,B,C$
        \bigbreak \noindent 
        What this is really saying is that if \textbf{any} of $AB + BC$, $BA + AC$, $AC + CB$ is $ \leq \omega$, then there is a betweenness relation.
        \bigbreak \noindent 
        \textbf{Note:} If Ax.BP is true for a plane $\mathbb{P}$, and if $AB + BC \leq \omega$ for distinct collinear $A,B,C$, then there is a betweenness relation, but not necessarily $ A\text{-}B\text{-}C $
        \bigbreak \noindent 
        When $\omega = \infty$, then for any distinct collinear $A,B,C$, $AB +BC  < \infty = \omega $, so there will be a betweenness relation
    \item \textbf{Quadrichotomy Axiom for Points (Ax.QP)}: If $A,B,C,X$ are distinct, collinear points, and if $ A\text{-}B\text{-}C$. Then, at least one of the following must hold
        \begin{align*}
            X\text{-}A\text{-}B, \quad A\text{-}X\text{-}B, \quad B\text{-}X\text{-}C, \quad \text{or } \quad B\text{-}C\text{-}X
        \end{align*}
        \bigbreak \noindent 
        Thus, Ax.QP says that whenever $ A\text{-}B\text{-}C$ (say on line $\ell$), then any other point $X$ on line $\ell$ is in either $ \overrightarrow{BA} $ or $ \overrightarrow{BC} $. That is,
        \begin{align*}
            \ell = \overrightarrow{BA} \cup \overrightarrow{BC}
        \end{align*}

    \item \textbf{Nontriviality Axiom (Ax.N)}: For any point $A$ on a line $\ell$ there exists a point $B$ on $\ell$ with $0 < AB < \omega$
        \bigbreak \noindent 
        This axiom is true for the planes in which $\omega = \infty$ ($\mathbb{E}$, $\mathbb{M}$, $\mathbb{H}$, $\mathbb{G}$, $\mathbb{R}^{3}$, $\hat{\mathbb{E}} $, ws)
        \bigbreak \noindent 
        This axiom is also true for $\mathbb{S}$ and Fano, where $\omega < \infty $
    \item \textbf{Betweenness}: Let $\mathbb{P}$ be a plane with points, lines, distance, and satisfy the seven axioms (3 distance, 4 incidence). Define
        \bigbreak \noindent 
        \textbf{Definition.} Point $B$ lies \textbf{between} points $A$ and $C$, denoted $A-B-C$ provide that
        \begin{enumerate}
            \item $A,B$, and $C$ are different and collinear
            \item $AB + BC = AC $
        \end{enumerate}
    \item \textbf{Uniqueness Middle Theorem (UMT)}:
        \bigbreak \noindent 
        \textbf{Theorem}: If $A-B-C$ then $B-A-C$ and $A-C-B$ are false.
    \item \textbf{Segments and rays}: Let $A\ne B$ be points in $ \mathbb{P}$ with $AB < \omega $. Then, there is a unique line through $A,B$, call it $ \overleftrightarrow{AB}$ 
        \begin{itemize}
            \item \textbf{The segment} $\overline\{AB\} = \{A,B\} \cup \{X: A-X-B\}$
            \item \textbf{The ray} $\overrightarrow\{AB\} = \{A,B\} \cup \{X: A-X-B\} \cup \{X: A-B-X\}$
        \end{itemize}
        \textbf{Note:} $\{X: A-X-B\} \cup \{X: A-B-X\} = \varnothing$
        \bigbreak \noindent 
        \textbf{Notation}: $\overline{AB}, \overrightarrow{AB}, \overleftrightarrow{AB}$ denote sets of points, with $\{A,B\} \subseteq \overline{AB} \subseteq \overrightarrow{AB} \subseteq \overleftrightarrow{AB}$
    \item \textbf{Segments and rays on $\mathbb{S}$}
        \begin{itemize}
            \item \textbf{Segment} $\overline{AB} = \{A,B\} \cup \{X: A-X-B\}$ as usual
            \item \textbf{Ray} $\overrightarrow{AB} = \{A,B\} \cup \{X: A-X-B\} \cup \{X: B-X-A^{*}\} \cup \{A^{*}\}$, where $A^{*}$ is the antipode of $A$
        \end{itemize}
    \item \textbf{Proposition: Segments and lines}:
        \bigbreak \noindent 
        \textbf{Proposition.}
        \begin{enumerate}[label=(\alph*)]
            \item $\overline{AB}$ lies in one line, the line $\overleftrightarrow{AB} $
            \item $\overline{AB} = \overline{BA} $
            \item If $x\in \overline{AB}$, with $X \ne B$, then $AX < AB $
        \end{enumerate}
    \item \textbf{Proposition}
        \bigbreak \noindent 
        \textbf{Proposition}: Let $A,B,C,D$ be collinear points with $0 < AB < \omega$, $0< CD<\omega$, and $\overline{AB} = \overline{CD}$, then
        \begin{enumerate}[label=(\alph*)]
            \item Either $\{A,B\} = \{C,D\}$ or $\{A,B\} \cap \{C,D\} = \varnothing$
            \item $AB = CD$
        \end{enumerate}
    \item \textbf{Proposition}
        \bigbreak \noindent 
        \textbf{Proposition}. If $A\text{-}B\text{-}C$ and $A\text{-}C\text{-}D$, then $A,B,C,D$ are distinct and collinear 
        \bigbreak \noindent 
        \textbf{\textit{Proof.}} Be the definition of betweenness, $A,C,D$ are distinct and collinear, and $AC + CD = AD$. Since $CD > 0$, $AC < AD$. But, since $AD \leq \omega$, it must be that $AC < \omega$. Thus, $A,C$ are together in a unique line  (the line $\overleftrightarrow{AC} $)
        \bigbreak \noindent 
        Also, $A,B,C$ are distinct and collinear. Thus, $B,D$ are both collinear with $A$ and $C$ which implies all four points must be in $\overleftrightarrow{AC}$, and hence they are all collinear.
        \bigbreak \noindent 
        The only way two of $A,B,C,D$ could be equal is if $B =D$. But then, substituting $B$ for $D$ in $A\text{-}C\text{-}D$, we get $A\text{-}C\text{-}B$. This contradicts $A\text{-}B\text{-}C$ and the UMT. Thus, all four points are different. \endpf

    \item \textbf{Definition:} Define $A\text{-}B\text{-}C\text{-}D$ to mean the following betweenness relations are all satisfied
        \begin{align*}
            A\text{-}B\text{-}C \quad A\text{-}B\text{-}D \quad A\text{-}C\text{-}D \quad B\text{-}C\text{-}D 
        \end{align*}
        \bigbreak \noindent 
        Also, for collinear points $A,B,C,D$
        \begin{align*}
            A\text{-}B\text{-}C\text{-}D \implies AB + BC + CD = AD
        \end{align*}
    \item \textbf{Proposition.} If $A\text{-}B\text{-}C\text{-}D$, then $A,B,C,D$ are distinct and collinear, and $D\text{-}C\text{-}B\text{-}A $
        \bigbreak \noindent 

    \item \textbf{Triangle inequality for the line}: If $A,B,C$ are any three distinct, collinear points, then 
        \begin{align*}
            AB + BC \geq AC 
        \end{align*}
        \bigbreak \noindent 
        \textbf{Note:} Don't worry about why the word triangle is in the name. Also, the triangle inequality is not necessarily true without Ax.BP
        \bigbreak \noindent 

    \item \textbf{Rule of insertion}: 
        \begin{itemize}
            \item If $ A\text{-}B\text{-}C$ and $ A\text{-}X\text{-}B$, then $ A\text{-}X\text{-}B\text{-}C $
            \item If $ A\text{-}B\text{-}C$ and $ B\text{-}X\text{-}C$, then $ A\text{-}B\text{-}X\text{-}C $
        \end{itemize}

    \item \textbf{What does the betweenness of points axiom get us?} The triangle inequality and the insertion theorem 

    \item \textbf{Proposition 7.5}: If $X \ne Y$ are points distinct from $A$ or ray $\overrightarrow{AB}$, then at least one of $ A\text{-}X\text{-}Y$ or $ A\text{-}Y\text{-}X$ or $X,Y$ in $ \overline{AB}$ is true.
    \item \textbf{Theorem 7.6}: This next theorem is the only one in chapters 6-9 that is about points on more than a single line
        \bigbreak \noindent 
        \textbf{Theorem.} For any point $A$ on a line $\ell$ there exists a point $C$ not on $\ell$ with $0 < AC <\omega$ 
        \bigbreak \noindent 
        To prove this, we first show that there is a point $C$ not on $\ell$, then we show that this point $C$ satisfies $0 < AC < \omega$

    \item \textbf{Important fact}:  Suppose $X$ is a point on a ray $\overrightarrow{AB}$ in a general plane.
        \begin{enumerate}
            \item If $ A\text{-}X\text{-}B$ then $AX < AB $
            \item If $ A\text{-}B\text{-}X$ then $AX > AB $
            \item IF $X = B$ then $AX = AB$
        \end{enumerate}









    \end{itemize}

    \pagebreak 
    \subsection{The real ray axiom, Antipodes, and opposite rays}
    \begin{itemize}
                \item \textbf{Real ray Axiom (Ax.RR)}: For any ray $ \overrightarrow{AB}$, and for any real number $s $ with $0 \leq s \leq \omega$, there is a point $X$ in $\overrightarrow{AB}$ with $AX = s$
            % \begin{align*}
            %     \{s:\ s \in \mathbb{R}, 0 \leq s \leq \omega \} = \{AX:\ X \in \overrightarrow{AB}\}
            % \end{align*}
            This axiom says that every nonnegative real number not exceeding $\omega$ produces at least one point on the ray.
            \bigbreak \noindent 
            So by $Ax.RR$, the distances $AX$, for all points $X$, $ \overrightarrow{AB}$ covers all real numbers in $[0,\infty]$ if $\omega < \infty$, and all real numbers in $[0,\infty) $ if $\omega = \infty $
        \item \textbf{Theorem 8.1}: If $\omega = \infty$, then $\mathbb{D} = [0,\infty$); if $\omega < \infty$, then $\mathbb{D} = [0,\omega] $
            \bigbreak \noindent 
            Since there are infinitely many real numbers in the interval $[0,\omega]$, for $\omega < \infty$, as well as in $[0,\infty)$, there must be infinitely many points on ray $\overrightarrow{AB}$
            \bigbreak \noindent 
            By Ax.N, any line $\ell$ in $\mathbb{P}$ contains points $A \ne B$, with $AB < \omega$ contains points $A \ne B$, with $AB < \omega$, hence $\ell$ contains ray $\overrightarrow{AB}$. Since $\overrightarrow{AB}$ has infinitely many points, so does $\ell $
            \bigbreak \noindent 
            The points in $\overline{AB}$ are exactly the points $X$ in $\overrightarrow{AB}$ with $AX = s \leq AB$. Since $[0,AB]$ contains infinitely many real numbers, there are also infinitely many on $\overline{AB}$. These remark proves the next theorem
        \item \textbf{Theorem 8.2} Each segment, ray, and line has infinitely many points.
            \bigbreak \noindent 
            Note that Ax.RR is false for WS and Fano, so this theorem does not hold. Also, Ax.RR is vacuously true for TDM, since there are no rays.
        \item \textbf{Proposition (needs proof) 8.11} Let $A,B$ be any two points on line $m$, with $0 < AB <\omega$. Then, there exists a point $C$ on $m$ with $ C\text{-}A\text{-}B$ and $ CB < \omega$.
        \item \textbf{Theorem 8.3}
            \bigbreak \noindent 
            \textbf{Proposition}. If $X \ne Y$ are points different from $A$ on ray $\overrightarrow{AB}$, then one of $ A\text{-}X\text{-}Y$ or $ A\text{-}Y\text{-}X$ is true.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose toward a contradiction that the conclusion is false. So not $ A\text{-}X\text{-}Y$ and not $ A\text{-}Y\text{-}X $
            \bigbreak \noindent 
            By prop 7.5, $X,Y$ are in $\overline{AB}$. If $Y = B$, then $X$ in $\overline{AB}$ implies $ A\text{-}X\text{-}B$, so $ A\text{-}X\text{-}Y$, which is a contradiction
            \bigbreak \noindent 
            Similarly, if $X = B$, then $Y$ in $\overline{AB}$ implies $ A\text{-}Y\text{-}B$, so $ A\text{-}Y\text{-}X$, contradiction.
            \bigbreak \noindent 
            So neither $X$ nor $Y = B$, hence $ A\text{-}X\text{-}B$, $ A\text{-}Y\text{-}B$
            \bigbreak \noindent 
            Now, we use Ax.RR just to produce one more point on $\overrightarrow{AB}$. We know $AB < \omega$ by definition of $ \overrightarrow{AB}$. So, we pick a point $E$ such that $AE = s$, with $AB < s \leq \omega$ (there are infinitely many). Since $AE > AB$, $E$ must be in the ray $\overrightarrow{AB}$ but not in the segment $\overline{AB}$. Thus, $ A\text{-}B\text{-}E$
            \bigbreak \noindent 
            We have $AB + BE = AE$. Also, $BE = EB < AE \leq \omega$. So, $EB < \omega$, and $ \overrightarrow{EB}$ is defined
            \bigbreak \noindent 
            We have $ A\text{-}X\text{-}B$ and $ A\text{-}B\text{-}E$, so by ROI, we have $ A\text{-}X\text{-}B\text{-}E$ implies $ E\text{-}B\text{-}X $ 
            \bigbreak \noindent 
            Also, $ A\text{-}Y\text{-}B$ and $ A\text{-}B\text{-}E$ by the ROI says we have $ A\text{-}Y\text{-}B\text{-}E$, which implies $ E\text{-}B\text{-}Y $
            \bigbreak \noindent 
            So, points $X,Y$ are in ray $ \overrightarrow{EB}$ but not in $ \overline{EB} $. Let's now shift our focus to the ray $ \overrightarrow{EB}$. We can apply prop 7.5 to points $X,Y$ on ray $ \overrightarrow{EB}$. Either $ E\text{-}X\text{-}Y$ or $ E\text{-}Y\text{-}X$. Equivalently, either $ Y\text{-}X\text{-}E$ or $ X\text{-}Y\text{-}E $
            \bigbreak \noindent 
            Recall that we have $ A\text{-}Y\text{-}B\text{-}E$, which gives us $ A\text{-}Y\text{-}E$, and $ A\text{-}X\text{-}B\text{-}E$ gives us $ A\text{-}X\text{-}E$
            \bigbreak \noindent 
            If $ Y\text{-}X\text{-}E$, then $ A\text{-}Y\text{-}E$ and ROI gives us $ A\text{-}Y\text{-}X\text{-}E$, which implies $ A\text{-}Y\text{-}X$
            \bigbreak \noindent 
            If $ X\text{-}Y\text{-}E$, then $ A\text{-}X\text{-}E $ and ROI gives us $ A\text{-}X\text{-}Y\text{-}E$, which implies $ A\text{-}X\text{-}Y $
            \bigbreak \noindent 
            So, $ A\text{-}Y\text{-}X$ or $ A\text{-}X\text{-}Y$ holds anyway, contradicting our initial supposition
            \bigbreak \noindent 
            Therefore, $ A\text{-}X\text{-}Y$ or $ A\text{-}Y\text{-}X$ is true \endpf
        \item \textbf{Theorem 8.4}
            \bigbreak \noindent 
            \textbf{Proposition}. If $C$ is any point on ray $ \overrightarrow{AB}$ with $ 0 < AC < \omega$, then $ \overrightarrow{AC} = \overrightarrow{AB} $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} If $C = B$, then trivially $ \overrightarrow{AC}  = \overrightarrow{AB}$. So we may assume that $ C \ne B$, and we already know that $C \ne A$ since $ AC > 0$. Since $0 < AC < \omega$, ray $ \overrightarrow{AC} $ is defined.
            \bigbreak \noindent 
            Now, $C$ on $\overrightarrow{AB}$ with $ C \ne A$ or $B$ implies $ A\text{-}C\text{-}B$ or $ A\text{-}B\text{-}C$. These betweenness relations imply $ B \in \overrightarrow{AC}$ by definition of $\overrightarrow{AC} $
            \bigbreak \noindent 
            If $X\ne A$ or $C$ is any other point on $\overrightarrow{AB}$, theorem 8.3 applied to $ \overrightarrow{AB}$ implies $ A\text{-}X\text{-}C $ or $ A\text{-}C\text{-}X$, which implies $ x \in \overrightarrow{AC}$. Therefore, $\overrightarrow{AB} \subseteq \overrightarrow{AC}$
            \bigbreak \noindent 
            If $X\ne A$ or $B$ is any other point on $\overrightarrow{AC}$, theorem 8.3 applied to $\overrightarrow{AC}$ implies $ A\text{-}X\text{-}B$ or $ A\text{-}B\text{-}X$, which implies $x\in \overrightarrow{AB} $. Therefore, $\overrightarrow{AC} \subseteq \overrightarrow{AB}$
            \bigbreak \noindent 
            Hence, $\overrightarrow{AB} = \overrightarrow{AC} $ and there is nothing sacred about the point $B$ in the ray $\overrightarrow{AB}$ \endpf
        \item \textbf{Endpoints}: 
            \bigbreak \noindent 
            \textbf{Definition}. Point $A$ is called an endpoint of ray $\overrightarrow{AB} $
        \item \textbf{Proposition}
            \bigbreak \noindent 
            \textbf{Proposition 8.5}: A ray has at most two endpoints
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose toward a contradiction that ray $h$ has three different endpoints $A,C,E$. Thus,
            \begin{align*}
                \overrightarrow{AB} = \overrightarrow{CD} = \overrightarrow{EF}
            \end{align*}
            With $A,C,E$ distinct, we apply theorem 8.3 three times
            \bigbreak \noindent 
            \begin{enumerate}
                \item Points $A,C,E$ on $\overrightarrow{AB}$ implies $ A\text{-}C\text{-}E $ or $ A\text{-}E\text{-}C$, so not $ C\text{-}A\text{-}E$ by UMT
                \item Points $A,C,E$ on $ \overrightarrow{CD}$ implies $ C\text{-}A\text{-}E$ or $ C\text{-}E\text{-}A$, by (1) it cannot be $ C\text{-}A\text{-}E$, thus it must be $ C\text{-}E\text{-}A$
                \item Points $ A\text{-}C\text{-}E$ on $\overrightarrow{EF}$ implies $ E\text{-}A\text{-}C$ or $ E\text{-}C\text{-}A$. This contradicts $ C\text{-}E\text{-}A$ by UMT
            \end{enumerate}
            \bigbreak \noindent 
            \endpf
        \item \textbf{More on Ax.RR}: Given a real number $s$ with $ 0 \leq s \leq \omega$, there is nothing explicit in $Ax.RR$ about there being only one point $X$ in $\overrightarrow{AB}$ with $AX = s$, we now prove that this is indeed the case.

        \item \textbf{Theorem 8.6 (Unique distances for Rays (UDR))}
            \bigbreak \noindent 
            \textbf{Proposition} For any ray $ \overrightarrow{AB}$ and any real number $s$ with $0 \leq s \leq \omega$, there is a \textbf{unique} point $X$ on $\overrightarrow{AB}$ with $AX = s$. $X$ is in $\overline{AB}$ if and only if $s \leq   AB $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} For $s=0$, $X = A$ is the unique point in $\overrightarrow{AB}$ with $AX = 0$, by Ax.D2
            \bigbreak \noindent 
            If $X \ne Y$ are points distinct from $A$ on $\overrightarrow{AB}$, theorem 8.3 implies either $ A\text{-}X\text{-}Y $ or $ A\text{-}Y\text{-}X$. So either $ AX < AY$ or $ AX > AY$. Either way,  $AX \ne AY$, so no two different points will be the same distance $s$ from $A$
        \item \textbf{Planes with the 11 axioms}: All theorems proved thus far hold for a plane that satisfies the 11 axioms. Major examples in which the 11 axioms are true as well as all theorems of propositions stated are $\mathbb{E}, \hat{\mathbb{E}}, \mathbb{M}, \mathbb{G}, \mathbb{S}, \mathbb{R}^{3}$, and $\mathbb{H}$
            \bigbreak \noindent 
            With these axioms and theorems stated thus far, we are soon arriving at a point in which all lines on any plane that satisfies the 11 axioms will either behave like a Euclidean  line if $\omega = \infty$, or a spherical line (great circle) if $\omega < \infty $
        \item \textbf{Proposition 8.7}: Let $\overline{AB}$ be a segment and $X,Y \in \overline{AB}$. Then, $XY \leq AB$, and if $XY = AB$, then $\{X,Y\} = \{A,B\}$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} If $X$ or $Y$ equals $A$, say $X = A$ and $Y \ne B$, then $ A\text{-}Y\text{-}B$. So, $XY = AY < AB$ by proposition 6.3. Similarly, if $X$ or $Y$ equals $B$ and the other point is not $A$, then $XY < AB$
            \bigbreak \noindent 
            So, we may assume that $ A\text{-}X\text{-}B$ and $ A\text{-}Y\text{-}B$. 
            \bigbreak \noindent 
            Since $ \overline{AB} \subseteq \overrightarrow{AB} $, we apply theorem 8.3, which yields that either $ A\text{-}X\text{-}Y$ or $ A\text{-}Y\text{-}X $
            \bigbreak \noindent 
            Thus, $XY < (AY \text{ or } AX ) < AB $ \endpf
        \item \textbf{Proposition 8.8} If $\overline{AB} = \overline{CD}$, then $\{A,B\}  = \{C,D\}$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} If $\overline{AB} = \overline{CD}$, then $ AB = CD$ by proposition 6.4.
            \bigbreak \noindent 
            Thus, by proposition 8.7, $\{C,D\} = \{A,B\} $ \endpf
        \item \textbf{More on endpoints}: We can now say that a segment uniquely determines two endpoints
        \item \textbf{Definition (Interior points and length for a segment):} Given a segment $ \overline{AB}$, $A$ and $B$ are called its endpoints. All other points of $\overline{AB}$ are called \textbf{Interior points} of $\overline{AB}$
            \bigbreak \noindent 
            Distance $AB$ is called the \textbf{length} of $\overline{AB} $
        \item \textbf{Definition}: The interior of $\overline{AB}$, denoted $\text{Int}\overline{AB}$ or $\overline{AB}^{0}$, means the set of all interior points of $\overline{AB}$. That is, $\text{Int}\overline{AB} = \overline{AB}^{0} = \{X: A\text{-}X\text{-}B\}$
        \item \textbf{Proposition 8.9}: In each segment $\overline{AB}$ there is a unique point $M$, called the \textbf{midpoint} of $\overline{AB} $, with the property that $AM = \frac{1}{2}AB$. Further, $AM = MB $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Let $s = \frac{1}{2}AB$. By UDR, there is a unique point $M$ in $\overrightarrow{AB}$ with $AM = s = \frac{1}{2}AB$. Since $s < AB$, $M$ is in $\overline{AB} $. Since $AM \ne 0$ and $AM \ne AB$, $M \ne A$ or $B$. Thus, $ A\text{-}M\text{-}B$, and
            \begin{align*}
                AM + MB &= AB \implies \frac{1}{2}AB + MB = AB \\
                \therefore MB &= \frac{1}{2}AB
            \end{align*}
            \endpf
        \item \textbf{Theorem 9.1 (Antipode on line theorem)}: Let $A$ be a point on a line $m$ (in a plane with the 11 axioms). Assume that $\omega < \infty$. Then, there exists a unique point $A^{*}_{m}$ on $m$ such that $AA_{m}^{*} = \omega$. Further, if $X$ is any other point on $m$, then $ A\text{-}X\text{-}A^{*}_{m} $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}}
            Let \( X \) be any point on \( m \) with \( 0 < AX < \omega \).
            (Such points exist by Ax.~N). So ray \( \overrightarrow{AX} \) is defined.
            \bigbreak \noindent 
            Thm 8.6 (uDR) for \( A = \omega \) implies There is a unique point \( A_m^* \) on \( \overrightarrow{AX} \) with \( AA_m^* = \omega \).
            \( AA_m^* > AX \) and the Important Fact \(\Rightarrow A - X - A_m^* \).
            \bigbreak \noindent 
            Now, we show that there is no other point $P$ anywhere on $m$ with $AP = \omega$
            \bigbreak \noindent 
            Suppose toward a contradiction that $P$ is another point on $m$ with $AP = \omega$. Then, $P$ is not in $\overrightarrow{AX}$.
            \bigbreak \noindent 
            Ax.QP applied to $ A\text{-}X\text{-}A^{*}_{m}$ and point $P$ implies one of 
            \begin{align*}
                P\text{-}A\text{-}X, \quad A\text{-}P\text{-}X, \quad X\text{-}P\text{-}A_{m}^{*}, \quad X\text{-}A^{*}_{m}\text{-}P
            \end{align*}
            If $ P\text{-}A\text{-}X$, then $PX > PA = \omega$, a contradiction.
            \bigbreak \noindent 
            If $ A\text{-}P\text{-}X$, then $ AX > AP = \omega$, another contradiction
            \bigbreak \noindent 
            If $ X\text{-}P\text{-}A_{m}^{*} $, then $ A\text{-}X\text{-}A_{m}^{*}$ and ROI yields $ A\text{-}X\text{-}P\text{-}A_{m}^{*}$ yields $ A\text{-}X\text{-}P$, which implies $P \in \overrightarrow{AX}$, contradiction.
            \bigbreak \noindent 
            Thus, $ X\text{-}A_{m}^{*}\text{-}P$. Consequently, $A_{m}^{*}P < XP \leq \omega$, so $\overline{A_{m}^{*}P} $ is defined
            \bigbreak \noindent 
            UDR says there's a point $U$ with $A_{m}^{*}\text{-}U\text{-}P$. So, $UP < A_{m}^{*}P < \omega$, which implies $U \ne A$ as $AP = \omega$
            \bigbreak \noindent 
            Ax.QP applied to $ A_{m}^{*}\text{-}U\text{-}P$ and point $A$ yields one of 
            \begin{align*}
                A\text{-}A_{m}^{*}\text{-}U, \quad A_{m}^{*}\text{-}A\text{-}U, \quad U\text{-}A\text{-}P, \quad U\text{-}P\text{-}A
            \end{align*}
            Which implies one of 
            \begin{align*}
                AU>AA_{m}^{*} = \omega ,\quad A_{m}^{*}U > A_{m}^{*}A = \omega, \quad UP > AP = \omega, \quad UA > PA = \omega
            \end{align*}
            All contradictions. Thus, $A_{m}^{*}$ is the only point on $m$ with $AA_{m}^{*} = \omega$
            \bigbreak \noindent 
            So, if $X$ is any point on $m$ other than $A$ or $A_{m}^{*}$, then $0 < AX < \omega$. Hence, ray $\overrightarrow{AX} $ is defined.
            \bigbreak \noindent 
            Now the first part of this proof applies to $ \overrightarrow{AX}$, and so $ A\text{-}X\text{-}A_{m}^{*}$
            \bigbreak \noindent 
            \endpf
        \item \textbf{Definition}. Assume $\omega < \infty$. Let $A$ be a point on a line $m$. The unique point $A_{m}^{*}$ on $m$ such that $AA_{m}^{*} = \omega$ is called the \textbf{antipode} of $A$ on $m$. Thus,
            \begin{align*}
                \begin{cases}
                    A,A_{m}^{*} \text{ are on m, }  AA_{m}^{*} = \omega \\
                    \text{and } A\text{-}X\text{-}A_{m}^{*} \text{ for all other points $X$ on $m$}
                \end{cases}
            \end{align*}
        \item \textbf{Theorem 9.2 (Almost-uniqueness for Quadrichotomy)}:  
            Suppose that \( A, B, C, X \) are distinct points on a line \( m \),  
            and that \( A - B - C \). Then \textbf{\textit{exactly one}} of the following holds:  
            \[
                X - A - B, \quad A - X - B, \quad B - X - C, \quad B - C - X
            \]
            with the \textbf{\textit{only exception}} that both \( X - A - B \) and \( B - C - X \) are true  
            when \( \omega < \infty \) and \( X = B_m^* \).
            \bigbreak \noindent 
            (Note that \( B_m^* - A - B \) and \( B - C - B_m^* \) \textbf{\textit{are both true}} by Thm. 9.1)
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} 
            By Axiom QP, at least one of \( X - A - B \), \( A - X - B \), \( B - X - C \), \( B - C - X \) holds.
            \bigbreak \noindent 
            \textbf{Suppose \( A - X - B \).} Then \( A - B - C \) and the Rule of I. \( \Rightarrow A - X - B - C \).  
            \bigbreak \noindent 
            So \( A - X - B \) and \( X - B - C \) are true (by definition of \( A - X - B - C \)),  
            hence \( X - A - B \), \( B - X - C \), \( B - C - X \) are false by the UMT (Thm. 6.2).  
            Thus, \( A - X - B \Rightarrow \) none of the other three relations hold.
            \bigbreak \noindent 
            \textbf{Suppose \( B - X - C \).} Then \( A - B - C \) and the Rule of I. \( \Rightarrow A - B - X - C \).  
            \bigbreak \noindent 
            So \( A - B - X \) and \( B - X - C \) are true, hence the UMT \( \Rightarrow \)  
            \( X - A - B \), \( A - X - B \), \( B - C - X \) are false.  
            \bigbreak \noindent 
            Thus, \( B - X - C \Rightarrow \) none of the other three relations hold.
            \bigbreak \noindent 
            So if more than one of \( X - A - B \), \( A - X - B \), \( B - X - C \), \( B - C - X \) holds,  
            they must be exactly \( X - A - B \) and \( B - C - X \).
            \bigbreak \noindent 
            Now assume that \( X - A - B \) and \( B - C - X \) are true.
            \bigbreak \noindent 
            \textbf{Suppose (toward a contradiction)} that \( BX < \omega \).  
            \bigbreak \noindent 
            Then ray \( \overrightarrow{BX} \) is defined,  
            and \( X - A - B \), \( B - C - X \Rightarrow A, C \) are in \( \overrightarrow{BX} \).  
            \bigbreak \noindent 
            So Thm. 8.3 \( \Rightarrow \) one of \( B - A - C \) or \( B - C - A \) is true.  
            \bigbreak \noindent 
            This contradicts \( A - B - C \) and the UMT (Thm. 6.2).  
            \bigbreak \noindent 
            Therefore, \( BX = \omega \), hence \( X = B_m^* \).
            \bigbreak \noindent 
            Corollary 8.5 showed that any ray has at most two endpoints.  
            Prop. 9.3 will show that when \( \omega < \infty \), any ray \( \overrightarrow{AB} \) with carrier \( m \)  
            (\( m = \overleftrightarrow{AB} \)) has a second endpoint, namely \( A_m^* \).  
            This generalizes what happens on \( \mathbb{S} \), where \( \overrightarrow{AB} = A^*B \).
        \item \textbf{Proposition 9.3 (needs proof)}: Assume \( \omega < \infty \). Let \( A, B \) be points on line \( m \)  
            with \( 0 < AB < \omega \). Then  
            \begin{enumerate}
                \item[(a)] \( \overrightarrow{AB} = \overline{AB} \cup \overline{BA_m^*} \) and \( \overline{AB}^{\circ} \cap \overline{BA_m^*}^{\circ} = \varnothing \).
                \item[(b)] \( \overrightarrow{AB} = \overrightarrow{A_m^* B} \), so that if \( A \) is an endpoint of a ray  
                    with carrier \( m \), then so is \( A_m^* \).
            \end{enumerate}
        \item \textbf{Theorem 9.4}.
            If \( h \) is a ray with two endpoints \( A \) and \( P \),  
            then \( \omega < \infty \) and \( P = A_m^* \), where \( m \) is the carrier of \( h \) (\( h \subseteq m \)).
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose (toward a contradiction) that \( AP < \omega \).  
            \bigbreak \noindent 
            Since \( P \) is an endpoint of \( h \), and \( A \) is on \( h \) with \( 0 < AP < \omega \),  
            Thm. 8.4 \( \Rightarrow h = \overrightarrow{PA} \).  
            \bigbreak \noindent 
            But \( A \) is also an endpoint of \( h \), so Thm. 8.4 \( \Rightarrow h = \overrightarrow{AP} \).
            \bigbreak \noindent 
            Let \( a \) be any number with \( AP < a \leq \omega \).
            \bigbreak \noindent 
            Axiom RR or Thm. 8.6 \( \Rightarrow \) there is a point \( X \) on \( \overrightarrow{AP} \) with  
            \( AX > a > AP \). So the Important Fact \( \Rightarrow A - P - X \).
            \bigbreak \noindent 
            Since \( h = \overrightarrow{PA} \) and \( X \) is on \( h \),  
            one of \( X = A \), \( X = P \), \( P - X - A \), or \( P - A - X \) is true, by definition of \( \overrightarrow{PA} \).  
            This contradicts \( A - P - X \), by the UMT.
            \bigbreak \noindent 
            Therefore, \( AP = \omega \), which implies that  
            \( \omega < \infty \) and \( P = A_m^* \).
        \item \textbf{Definition (interior points of a ray)}: Let \( h = \overrightarrow{AB} \) be a ray.  
            All points of \( h \) that are not endpoints of \( h \) are called \textit{interior points} of \( h \).  
            \bigbreak \noindent 
            The \textit{interior} of \( h \) is the set of all interior points of \( h \),  
            and is denoted by \( h^\circ \), \( \overline{AB}^\circ \), or \( \text{Int } \overrightarrow{AB} \).
        \item \textbf{Definition (Opposite rays)}: Two rays with the same endpoint whose union is a line are called \textbf{opposite rays}
        \item \textbf{Theorem 9.6 (Opposite ray theorem)}: If $ B\text{-}A\text{-}C$, then $\overrightarrow{AB}$ and $\overrightarrow{AC}$ are opposite rays
            \bigbreak \noindent 
            Also, for $m = \overleftrightarrow{AB}$
            \begin{align*}
                \overrightarrow{AB} \cap \overrightarrow{AC} = 
                \begin{cases}
                    \{A\}     & \text{ if } \omega = \infty \\
                    \{A, A_{m}^{*}\}     & \text{ if } \omega<\infty
                \end{cases}
            \end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} $ B\text{-}A\text{-}C$ implies both $AB,AC  < BC \leq \omega$. So, rays $\overrightarrow{AB}, \overrightarrow{AC}$ are defined, and $\overleftrightarrow{AB}$ is the unique line through $A,B$, and $\overleftrightarrow{AC}$ is the unique line through $A,C$
            \bigbreak \noindent 
            $ B\text{-}A\text{-}C$ implies $B,A,C$ collinear which implies $ \overleftrightarrow{AB} = \overleftrightarrow{AC}$. Call this line $m$.
            \bigbreak \noindent 
            We have $\overrightarrow{AB}, \overrightarrow{AC} \subseteq m$
            \bigbreak \noindent 
            If $X \ne A,B,C$ is on $m$, then Ax.QP say one of 
            \begin{align*}
                X\text{-}B\text{-}A \quad B\text{-}X\text{-}A \quad A\text{-}X\text{-}C \quad A\text{-}C\text{-}X
            \end{align*}
            Must be satisfied. In other words, $X$ is in $\overrightarrow{AB}$ or $\overrightarrow{AC}$. So, $m \subseteq \overrightarrow{AB}  \cup \overrightarrow{AC}$, hence $ m = \overrightarrow{AB} \cup \overrightarrow{AC} $
            \bigbreak \noindent 
            Since $\overrightarrow{AB}$ and $\overrightarrow{AC}$ have the same endpoint, and $\overrightarrow{AB} \cup \overrightarrow{AC}  = m $, $\overrightarrow{AB}$ and $\overrightarrow{AC} $ are opposite rays
            \bigbreak \noindent 
            What about $\overrightarrow{AB} \cap \overrightarrow{AC}$? $ B\text{-}A\text{-}C$ implies not $ A\text{-}B\text{-}C$ or $ A\text{-}C\text{-}B$, so $B \not\in \overrightarrow{AC}$, and $C \not\in \overrightarrow{AB}$
            \bigbreak \noindent 
            So neither $B$ nor $C$ is in $\overrightarrow{AB} \cap \overrightarrow{AC}$
            \bigbreak \noindent 
            Let $X$ be any point $\ne A,B,C$ in $m$. Suppose $X \in \overrightarrow{AB} \cap \overrightarrow{AC}$
            \begin{align*}
                &X \in \overrightarrow{AB} \implies X\text{-}B\text{-}A \text{ or } B\text{-}X\text{-}A \\
                &X \in \overrightarrow{AC} \implies A\text{-}X\text{-}C \text{ or } A\text{-}C\text{-}X
            \end{align*}
            So two of $ X\text{-}B\text{-}A, B\text{-}X\text{-}A, A\text{-}X\text{-}C, A\text{-}C\text{-}X$ are true
            \bigbreak \noindent 
            Theorem 9.2 applied to $ B\text{-}A\text{-}C$ and point $X$ implies it must be $ X\text{-}B\text{-}A$ and $ A\text{-}C\text{-}X$, with $\omega < \infty$ and $ X = A_{m}^{*}$
            \bigbreak \noindent 
            Therefore, $ \overrightarrow{AB} \cap \overrightarrow{AC} \subseteq \{A, A_{m}^{*}\} $
            \bigbreak \noindent 
            A is on both rays, by definition of a ray, and $ A\text{-}B\text{-} A_{m}^{*}, A\text{-}C\text{-}A_{m}^{*}$ with theorem 9.1 implies $A_{m}^{*}$ is on $\overrightarrow{AB}$ and $\overrightarrow{AC}$, so $\overrightarrow{AB} \cap \overrightarrow{AC} = \{A,A_{m}^{*}\}$ when $\omega < \infty $, and $\{A\}$ when $\omega = \infty $
        \item \textbf{Corollary 9.7}: Each ray has a unique opposite ray.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Let $\overrightarrow{AB}$ be a ray. Proposition 8.11 says there's a point $C$ on $\overrightarrow{AB}$ with $ C\text{-}A\text{-}B$. Then, $AC<BC \leq \omega$, and the opposite ray theorem implies $\overrightarrow{AC}$ is an opposite ray to $\overrightarrow{AB} $
            \bigbreak \noindent 
            Let $h$ be any ray opposite to $\overrightarrow{AB}$, so that $h$ has endpoint $A$, and $h \cup \overrightarrow{AB} = \overleftrightarrow{AB}$
            \bigbreak \noindent 
            C is not in $\overrightarrow{AB}$ (from $ C\text{-}A\text{-}B$ or from $\overrightarrow{AB} \cap \overrightarrow{AC} = \{A,A_{m}^{*}\}$), hence $C \in h $
            \bigbreak \noindent 
            $h$ has endpoint $A$, $C$ in $h$ with $0 < AC < \omega$ implies $h = \overrightarrow{AC} $ by theorem 8.4

        \item \textbf{Notation:} Denote the ray opposite to ray $h$ by $h^{\prime}$. So, $\overrightarrow{AB}^{\prime}$ means the ray opposite $\overrightarrow{AB} $
        \item \textbf{Corollary 9.8}: Let $A,B$ be points on line $m$ with $0 <AB<\omega <\infty$. Then $\overrightarrow{AB}^{\prime} = \overrightarrow{AB_{m}^{*}} $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Theorem 9.1 implies $ B\text{-}A\text{-}B_{m}^{*}$. Then, theorem 9.6 implies $\overrightarrow{AB_{m}^{*}}  = \overrightarrow{AB}^{\prime}$
        \item \textbf{Corollary 9.9 (needs proof)}: Let $A,B$ be points on line $m$ with $ 0 < AB < \omega < \infty$. Then, $ m = \overline{AB} \cup \overline{BA_{m}^{*}} \cup \overline{A_{m}^{*}B_{m}^{*}} \cup \overline{B_{m}^{*}A}$, with the interiors of these segments being disjoint.
        \item \textbf{Theorem 9.10 (Needs proof)}: Let $A,B$ be points on line $m$ with $0 < AB < \omega < \infty$ . Let $C \ne A,B,A_{m}^{*}, B_{m}^{*} $ be another point on $m$. Then there is no betweenness relation for $A,B,C$ if and only if $C \in \overline{A_{m}^{*}B_{m}^{*}}^{0}$
        \item \textbf{When $\omega < \infty$, any line $m$ is "like a circle"}: Suppose $ B\text{-}A\text{-}C$ on $m$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{lineah}
                \label{fig:lineah}
            \end{figure}
            \bigbreak \noindent 
            $\overrightarrow{AB}, \overrightarrow{AC}$ are opposite rays by theorem 9.6. $A_{m}^{*}$ is on both $ \overrightarrow{AB} = \overrightarrow{A_{m}^{*}B}$ and $\overrightarrow{AC} = \overrightarrow{A_{m}^{*}C} $ by prop 9.3
            \bigbreak \noindent 
            So is it really like a circle? Take point $X$ on $\overrightarrow{AB}$ near $A_{m}^{*}$, and point $Y$ on $\overrightarrow{AC}$ near $A_{m}^{*} $
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{lineah2}
                \label{fig:lineah2}
            \end{figure}
            \bigbreak \noindent 
            Say distances $XA_{m}^{*}, YA_{m}^{*}$ are small enough so that $XA_{m}^{*} + YA_{m}^{*} \leq \omega$. To show that this line should be a circle, we need 
            \begin{align*}
                X\text{-}A_{m}^{*}\text{-}Y
            \end{align*}
            Because $XA_{m}^{*} + YA_{m}^{*} \leq \omega$, Ax.BP says there is a B.R among $X,Y,A_{m}^{*} $
            \bigbreak \noindent 
            Suppose $ A_{m}^{*}\text{-}X\text{-}Y$, can we get a contradiction?
            \bigbreak \noindent 
            $A_{m}^{*}X < \omega$, $X$ on $\overrightarrow{AB} = \overrightarrow{A_{m}^{*}B}$ implies $\overrightarrow{A_{m}^{*}B} = \overrightarrow{A_{m}^{*}X} $ (Thm 8.4)
            \bigbreak \noindent 
            So if $ A_{m}^{*}\text{-}X\text{-}Y$, then $Y$ is in $\overrightarrow{A_{m}^{*}X} = \overrightarrow{AB}$. But, $Y \in \overrightarrow{AC}$, and $\overrightarrow{AC}, \overrightarrow{AB}$ have only points $A,A_{m}^{*}$ in common. A similar argument reveals why it also cannot be  $A_{m}^{*}\text{-}Y\text{-}X$
            \bigbreak \noindent 
            Thus, it must be $ X\text{-}A_{m}^{*}\text{-}Y$, and the line is "like a circle"






    \end{itemize}

    \pagebreak 
    \subsection{Separation}
    \begin{itemize}
        \item \textbf{Proposition between} Let $\overrightarrow{AB}$ and $\overrightarrow{AC}$ be opposite rays, and points $X \in \text{Int}\overrightarrow{AB}$, $Y \in \text{Int}\overrightarrow{AC} $ with $AX + AY \leq \omega$, then $ X\text{-}A\text{-}Y$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} $X$ in $\text{Int}\overrightarrow{AB}$ implies $0 < AX < \omega$. So, by theorem 8.4, $\overrightarrow{AB} = \overrightarrow{AX}$. Similarly, $\overrightarrow{AC} = \overrightarrow{AY}$. 
            \bigbreak \noindent 
            Ax.BP and $AX + AY \leq \omega$ implies there is B.R among $A,X,Y$
            \bigbreak \noindent 
            If $ A\text{-}X\text{-}Y$ then the definition of a ray implies $ Y \in \overrightarrow{AX} = \overrightarrow{AB}$. But, $Y \in \text{Int}\overrightarrow{AC}$, and $\overrightarrow{AB} \cap \text{Int}\overrightarrow{AC}  = \varnothing$, which by the opposite ray theorem (9.6) is a contradiction. So, not $ A\text{-}X\text{-}Y$, and similarly not $ A\text{-}Y\text{-}X $. Thus, we have $ X\text{-}A\text{-}Y $
        \item \textbf{Definition}. A subset $S$ of $\mathbb{P}$ is \textbf{convex} if for each pair of points $X \ne Y$ in $S$ with $XY < \omega$, $\overline{XY} \subseteq S$ holds.
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{conex1}
                \label{fig:conex1}
            \end{figure}
            \bigbreak \noindent 
            Each of these are convex sets in $\mathbb{E}$, with or without the boundary
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{nonconvex2}
                \label{fig:nonconvex2}
            \end{figure}
            \bigbreak \noindent 
            Each of these are non-convex in $\mathbb{E}$, with or without the boundary
        \item \textbf{Theorem 10.1}: If $S_{1}$ and $S_{2}$ are convex sets in $\mathbb{P}$, then so is $S_{1} \cap S_{2}$
        \item \textbf{Theorem 10.2}: Segments, rays, and lines are convex.
        \item \textbf{Definition}: A pair of sets $H,K$ in $\mathbb{P}$ is called \textbf{opposed around a line $m$} if 
            \begin{itemize}
                \item $H,K \ne \varnothing $
                \item $H,K$ are convex
                \item $H \cap K = \varnothing $
                \item $H \cup K = \mathbb{P} - m$
            \end{itemize}
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{opposed}
                \label{fig:opposed}
            \end{figure}
            \bigbreak \noindent 
            So we can imagine this line $m$ that extends indefinitely, everything above the line is in $H$, below the line is in $K$, and the sets $H,K$ are said to be \textbf{opposed around the line $m$}
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{ing}
                \label{fig:ing}
            \end{figure}
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{insh}
                \label{fig:insh}
            \end{figure}
        \item \textbf{H and K in $\mathbb{R}^{3}$}: Imagine the wall in front of you as part of a plane in $3$-dim space that extends to infinity in every direction.
            \bigbreak \noindent 
            Picture $m$ as vertical line on the wall. Let $H$ be all the points on your side of the wall (plane), together with all points on the wall (plane) to the right of $m$. In particular, you are in $H$
            \bigbreak \noindent 
            Let $K$ be all the points on the other side of the wall (plane), together with all points on the wall (plane) to the left of $m$
        \item \textbf{Theorem 10.3} Let $H,K$ be sets opposed around a line $m$ in $\mathbb{P}$. Suppose that $A,C$ are points so that $C \in m$, $A \in H$, $AC < \omega$. Then, $\text{Int}\overrightarrow{CA} \subseteq H$, and $\text{Int}\overrightarrow{CA}^{\prime} \subseteq K $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Let $\ell = \overleftrightarrow{AC}$. $\ell \ne m$, since $A \not\in m$. $\ell, m$ meet only at $C$ (or also at $C_{m}^{*} = C_{\ell}^{*} $ if $\omega < \infty $ and if $C_{m}^{*} = C_{\ell}^{*} $). So, $\text{Int}\overrightarrow{CA} \subseteq H \cup K $
            \bigbreak \noindent 
            Let $CA = a < \omega$. Pick a number $b$ with $0 < b < \omega - a$. Ax.RR implies there is a point $B$ on $\overrightarrow{CA}^{\prime}$ with $CB = b$, so $\overrightarrow{CA}^{\prime} = \overrightarrow{CB} $.
            \bigbreak \noindent 
            For all points $Y$ with $ C\text{-}Y\text{-}B$ or $Y = B$, $CY \leq b < \omega - a$
            \bigbreak \noindent 
            Let $ y = CY$. Then, $y < \omega - a$, which implies $a+y < \omega$, which implies $CA + CY < \omega $
            \bigbreak \noindent 
            Proposition between implies $ A\text{-}C\text{-}Y$, so $ AY = AC + CY < \omega$. Thus, $\overline{AY}$ is defined, and $C \in \overline{AY} $
            \bigbreak \noindent 
            If $Y \in H$, then $A \in H$ and $H$ is convex (by the definition of opposed sets). This implies $\overline{AY} \subseteq H$, which implies $ C \in H $
            \bigbreak \noindent 
            But, $C \in m$, and $H \subseteq\mathbb{P}-m$, contradiction. Therefore, $Y \in K$ for all $Y \ne C$ in $\overline{CB} $
            \bigbreak \noindent 
            Now, let $X$ be any point in $\text{Int}\overrightarrow{CA}$, let $x = CX$, so $0 < x < \omega$. Pick a number $y$ with $0 < y < \begin{cases} b \\ w-x\end{cases} $
            \bigbreak \noindent 
            Ax.RR implies there is a point $Y$ on $\overrightarrow{CA}^{\prime} = \overrightarrow{CB}$ with $CY = y  < b$. So, $Y \in \overline{CB}$, hence $Y \in K $
            \bigbreak \noindent 
            Also, $XC  + CY = x + y  < x + \omega - x = \omega $
            \bigbreak \noindent 
            Prop between implies $ X\text{-}C\text{-}Y$, so $XY = XC  + CY < \omega $. Thus, $\overline{XY}$ is defined, and $C \in \overline{XY}$. 
            \bigbreak \noindent 
            If $X \in K$, then $Y \in K$ and $K$ is convex (defn of opposed sets). This implies $\overline{XY} \subseteq K$, which implies $C \in K$. But, $C \in m$, and $K \subseteq\mathbb{P} - m$ (defn. opposed sets). A contradiction.
            \bigbreak \noindent 
            Therefore, $X \in H$ \textbf{for all} $X \in \text{Int} \overrightarrow{CA} $, and $\text{Int}\overrightarrow{CA} \subseteq H$
            \bigbreak \noindent 
            A similar argument, starting with $B \in K$ reveals $\text{Int}\overrightarrow{CB}\subseteq K$; that is $\text{Int}\overrightarrow{CA}^{\prime} \subseteq K$
        \item \textbf{Corollary 10.4}: let $H,K$ be sets opposed around a line $m$, let $A,B$ be points not on $m$, with $ A\text{-}X\text{-}B$ for some point $X \in m$. Then, $A,B$ lie one in each of $H$ and $K$, in some order.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} $A,B$ are in $\mathbb{P} - m = H \cup K$. We may assume $A \in H$. Thm 9.6 implies $ \overrightarrow{XB} = \overrightarrow{XA}^{\prime}$. So, Thm 10.3 implies $\text{Int}\overrightarrow{XA} \subseteq H$, $\text{Int}\overrightarrow{XB} \subseteq K$, hence $B \in K$
        \item \textbf{Definition}: Let $m$ be a line. Sets $H,K$ are called \textbf{opposite halfplanes with edge $m$} if:
            \bigbreak \noindent 
            \begin{align*}
                &H,K \text{ are opposed around $m$, and whenever } X \in H, Y \in K \text{ and } XY < \omega, \\ &\text{ then, } \overline{XY} \cap m \ne \varnothing
            \end{align*}
            Planes that satisfy this are
            \begin{align*}
                \mathbb{E}, \hat{\mathbb{E}}, \mathbb{M}, \mathbb{H}, \mathbb{S}
            \end{align*}
            This definition is not true for $\mathbb{G}$, or $\mathbb{R}^{3} $
            \bigbreak \noindent 
\begin{figure}[ht]
    \centering
    \incfig{somefig2}
    \label{fig:somefig2}
\end{figure}
            \bigbreak \noindent 
            The existence of opposite halfplanes yields a number of important properties. When $\omega < \infty$, they guarantee the uniqueness of an antipode throughout the plane, not just line-by-line
        \item \textbf{Theorem 10.5}: Suppose that $m$ is a line  so that there exists a pair $H,K$ of opposite half planes with edge $m$. Suppose also that $\omega < \infty$ and $A$ is a point on $m$. If $B$ is any point in $\mathbb{P}$ with $AB = \omega$, then $B \in m$ (so $B = A_{m}^{*}$, and there is only one point $B$ in all of $\mathbb{P}$ with $AB = \omega$)
            \bigbreak \noindent 
            This is what happens on $\mathbb{S}$, where we see that every line $m$ does have a pair of opposite halfplanes with edge $m$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose toward a contradiction that $B \not\in m$. Axioms I3 and N imply there is a line $n$ through $A$ and $B$, and a point $P$ on $n$ with $0 < AP < \omega$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{stac}
                \label{fig:stac}
            \end{figure}
            \bigbreak \noindent 
            Antipode on line thm (9.1) implies $B = A_{m}^{*}$, and $ A\text{-}P\text{-}B$, so $BP < \omega$.
            \bigbreak \noindent 
            $B \not\in m$ and Ax.I4 implies $m\cap n = \{A\} $
            \bigbreak \noindent 
            Prop 9.3 implies $\overrightarrow{AP} = \overrightarrow{A_{m}^{*}P} = \overrightarrow{BP}$. Note that $n = \overleftrightarrow{BP} $
            \bigbreak \noindent 
            Prop 8.11 implies there's a point $Q$ with $ Q\text{-}B\text{-}P$ and $PQ < \omega$.
            \bigbreak \noindent 
            Thm 9.6 (opp. ray thm) implies $\overrightarrow{BQ} = \overrightarrow{BP}^{\prime} = \overrightarrow{AP^{\prime}}$, so $Q \in \text{Int}\overrightarrow{AP}^{\prime}$. We may assume that $P \in H$, so Thm 10.3 implies $Q \in K$. Then, $H,K$ are opposite halfplanes, and $PQ < \omega$, which implies $\overline{PQ} \cap m  = \varnothing $
            \bigbreak \noindent 
            But, $P,Q \in  n$ implies  $\overline{PQ} \subseteq n$, which implies $\overline{PQ} \cap m \subseteq n \cap m = \{A\} $. So, $A \in \overline{PQ}$, and $ Q\text{-}B\text{-}P$, which implies $ B \in \overline{PQ}$
            \bigbreak \noindent 
            Prop 8.7 implies $AB \leq PQ$, but $AB = \omega$, and $PQ < \omega$, a contradiction.
            \endpf
        \item \textbf{Theorem 10.6}: Suppose that there is a pair $H,K$ of opposite halfplanes with edge $m$. Let $A \ne B$ be points not on $m$. Then, 
            \begin{align*}
                A,B \text{ lie one in each of $H,K$ } \iff \text{ there is a point $X$ on $m$ such that $ A\text{-}X\text{-}B $}
            \end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} If $ A\text{-}X\text{-}B$ for some point $X$ on $m$, then coroll. 10.4 (which only required that $H,K$ be opposed around $m$) implies $A,B$ lie one in each of $H,K$.
            \bigbreak \noindent 
            Suppose that $A,B$ lie one in each of $H,K$. If $AB < \omega$, then $\overline{AB} \cap m \ne \varnothing $ by the definition of opposite halfplanes, so $ A\text{-}X\text{-} B$ for some $X$ in $m$
            \bigbreak \noindent 
            If $AB = \omega$, then Ax.I3 and the antipode on line thm (9.1) implies $B$ is the antipode $P$ on $n$, and $ A\text{-}P\text{-}B$ for all other points $P$  on $n$. If some  such point $P$ is also on $m$, then we are done. Otherwise, since $A,B$ lie one in each of $H,K$, and $P$ is in $H$ or $K$. We may assume that $A,P$ are in $H$ and $B$ is not in $K$.
            \bigbreak \noindent 
            Now, $ A\text{-}P\text{-}B$ implies $PQ < \omega$. So the defn of opposite halfplanes implies $ P\text{-}X\text{-}B$ for some point $X \in m$. $ A\text{-}P\text{-}B$, $ P\text{-}X\text{-}B$, and the rule of insertion implies
            \begin{align*}
                A\text{-}P\text{-}X\text{-}B \implies A\text{-}X\text{-}B
            \end{align*}
        \item \textbf{Corollary 10.7 (Needs proof)}: Suppose that there is a pair $H,K$ of opposite halfplanes with edge a line $m$. Then, $H,K$ is the only pair of sets opposed around $m$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}}
            \bigbreak \noindent 
            \textbf{Note:} It follows from coroll 10.7 that since lines $m$ in $\mathbb{G}$ and in $\mathbb{R}^{3}$ have sets opposed around them that are not opposite halfplanes, then there are no other pairs of sets that are opposite halfplanes with edge $m$
        \item \textbf{A difference between $\mathbb{R}^{3}$ and $\mathbb{G}$}: No line $m$ in $\mathbb{R}^{3}$ has a pair of opposite halfplanes with edge $m$. Some lines $m$ in $\mathbb{G}$ have a pair of opposite halfplanes with edge $m$
        \item \textbf{Separation Axiom Ax.S}: for each line $m$, there exists a pair of opposite halfplanes with edge $m$. 
            \bigbreak \noindent 
            Ax.S is true for $\mathbb{E}, \hat{\mathbb{E}}, \mathbb{M},\mathbb{H}, \mathbb{S}$. But, is false for $\mathbb{G}, \mathbb{R}^{3}$
        \item \textbf{Definition}: Let $H,K$ be opposite halfplanes with edge $m$. Two points in the same halfplane are said to be on the \textbf{same side} of $m$. 
            \bigbreak \noindent 
            Two points in opposite halfplanes are said to be \textbf{opposite sides} of $m$
        \item \textbf{Theorem 10.8}: Suppose that $\omega < \infty$. For each point $ A$, there is exactly one point $A^{*}$ in $\mathbb{P}$ with $AA^{*} = \omega$. Also, every line through $A$ goes through $A^{*}$ as well.
        \item \textbf{Definition}: $A^{*} $ is called the \textbf{antipode} of $A$
            \bigbreak \noindent 
            Note that the antipode property of the sphere $\mathbb{S}$ is now true for every plane $\mathbb{P}$ with 12 axioms, when $\omega < \infty$
            \bigbreak \noindent 
            Whats also true when $\omega < \infty$ is that for all points $A\in \mathbb{P}$ and all points $X \in \mathbb{P}$ with $X \ne A$ or $A^{*}$, then
            \begin{align*}
                A\text{-}X\text{-}A^{*}
            \end{align*}
            \bigbreak \noindent 
            This is because there is a line $m$ through $A$ and $X$ (Ax.I3). In fact, it is the unique line $\overleftrightarrow{AX}$, since $X \ne A^{*}$ implies $AX < \omega $
            \bigbreak \noindent 
            Thm 10.8 implies $A^{*}$ is on $m$, and then the antipode on line theorem (9.1) implies $ A\text{-}X\text{-}A^{*} $
        \item \textbf{Corollary 10.9}: Suppose that $\omega < \infty$. For any line $m$ and point $P$, there are just two possibilities:
            \begin{align*}
               \begin{cases}
                   P,P^{*} &\text{ both on $m$}     \\
                   P, P^{*} &\text{on opposite sides of $m$}
               \end{cases}
            \end{align*}
            \bigbreak \noindent 
            \textbf{Proof.} If either $P$ or $P^{*}$ is on $m$, then so is the other, by Thm 10.8, so we need to only consider when neither $P$ nor $P^{*}$ is on $m$. Let $X$ be any point on $m$. By what we showed above, $ P\text{-}X\text{-}P^{*}$. Then, thm 10.6 implies $P,P^{*}$ are in opposite halfplanes with edge $m$
        \item \textbf{Proposition Noncollinear}: If $A,B,C$ are three noncollinear points (not all on the same line), then $AB, AC,BC$ all less than $\omega$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose (toward a contradiction) that $AB = \omega$. Then, $B = A^{*}$, so $ A\text{-}C\text{-}B$. In particular, $A,C,B$ are collinear, a contradiction.
            \bigbreak \noindent 
            The following theorem was given as an axiom, in place of axioms, by Moritz pasch in 1882. It is equivalent to the separation Axiom: We prove here that it holds as a consequence of Ax.S (along with the other axioms); and also one can assume the statement of the theorem, and prove that the statement of Ax.S must be true.
        \item \textbf{Theorem 10.10 (Pasch's Axioms) (needs proof)}: 
            Let $A,B,C$ be three noncollinear points. Let $X$ be a point with $ B\text{-}X\text{-}C $, and $m$ a line through $X$ but not through $A,B,$ or $C$. Then, exactly one of
            \begin{enumerate}
                \item $m$ contains a point $Y$ with $ A\text{-}Y\text{-}C$
                \item $m$ contains a point $Z$ with $ A\text{-}Z\text{-}B $
            \end{enumerate}
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{pasch}
                \label{fig:pasch}
            \end{figure}
            \bigbreak \noindent 
            Note that there are two things to prove.
            \begin{itemize}
                \item $a$ or $b$ happens, and not both at once, for line $m$
            \end{itemize}
            Hint: Opposite halfplanes.
        \item \textbf{Theorem 10.11}: Assume that $\omega < \infty$. Then, any two distinct lines must have a point (in fact, a pair of antipodes) in common.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose toward a contradiction that there are lines $m,n$ with $m \cap n = \varnothing $. Let $H,K$ be the opposite halfplanes with edge $m$, and let $P$ be a point on $n$. Since $P \not\in m$, we may assume that $P \in H $
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{lines}
                \label{fig:lines}
            \end{figure}
            \bigbreak \noindent 
            Coroll. 10.9 implies $P^{*} \in K$. $P^{*} \in n$ by thm 10.8. Let $Q$ be any other point on $n$. Then, $QP$, $QP^{*} < \omega$. So, $\overline{QP}, \overline{QP^{*}}$ are defined, and are contained in $n$. 
            \bigbreak \noindent 
            If $Q \in H$, then Ax.S implies $\overline{QP^{*}} \cap m \ne \varnothing$, which implies $n\cap m \ne \varnothing $
            \bigbreak \noindent 
            If $ Q\in K$, then Ax.S implies $\overline{QP} \cap m \ne \varnothing$, which implies $n \cap m \ne \varnothing $,
            \bigbreak \noindent 
            Both of these a contradiction.



    \end{itemize}

    \pagebreak 
    \subsection{Pencils and Angles}
    \begin{itemize}
        \item \textbf{Definition: \textit{Coterminal rays}}: Rays with the same endpoint
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{coterm}
                \label{fig:coterm}
            \end{figure}
            \bigbreak \noindent 
        \item \textbf{Definition: \textit{Angle}}: $\underline{ab} = a \cup b $, where $a,b$ are coterminal rays
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{ang}
                \label{fig:ang}
            \end{figure}
            \bigbreak \noindent 
        \item \textbf{duality}: To develop properties of coterminal rays, our steps will be closely analogous to those we took to study collinear points. The analogy is called \textbf{duality}
            \bigbreak \noindent 
            The theory of coterminal rays is dual to the theory of collinear points when $\omega < \infty$
            \bigbreak \noindent 
            But, the theory of rays will be good whether $\omega < \infty$ or $\omega = \infty$
        \item \textbf{Definition: \textit{Pencil of rays at point $A$}}: The set of all rays with endpoint $A$: denote by $P_{A}$ or just $P$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{pencil}
                \label{fig:pencil}
            \end{figure}
            \bigbreak \noindent 
            When $\omega < \infty$, each ray $h = \overrightarrow{AB} = \overrightarrow{A^{*}B}$, so $P_{A} = P_{A^{*}} $. $h^{\prime} $ is the opposite ray to $h$, as before
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{circ}
                \label{fig:circ}
            \end{figure}
            \bigbreak \noindent 

        \item \textbf{Undefined Term \textit{Angle distance function, or angle measure}}: A function $\mu$ from all pairs $(p,q) $ of coterminal rays to $\mathbb{R}$
            \bigbreak \noindent 
            We abbreviate the angular distance between rays $p,q$, or the angle measure of the angle $pq$, $\mu(p,q)$ as $pq$ 
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{undef}
                \label{fig:undef}
            \end{figure}
            \bigbreak \noindent 
        \item \textbf{Angular distance in each of $\mathbb{E}$, $\hat{\mathbb{E}}$, $\mathbb{M}$, $\mathbb{S}$, $\mathbb{H}$}
            \begin{itemize}
                \item \textbf{$\mathbb{E}$, $\hat{\mathbb{E}}$, $\mathbb{M} $}: The usual measure in degrees (0 to 180)
                    \bigbreak \noindent 
                    \begin{figure}[ht]
                        \centering
                        \incfig{eangle}
                        \label{fig:eangle}
                    \end{figure}
                    \bigbreak \noindent 
                    \begin{align*}
                        pq = \cos^{-1}{\left(\frac{1+mn}{\sqrt{1+m^{2}}\sqrt{1+n^{2}}}\right)}
                    \end{align*}
                    From the law of cosines
                \item \textbf{$\mathbb{S}$}: 
                    \bigbreak \noindent 
                    \fig{.7}{./figures/s1.png}
                    \bigbreak \noindent 
                    Rays $\hat{p}, \hat{q}$ in plane tangent to $\mathbb{S}$ at $A$. $pq$ is defined as $\hat{p}\hat{q}$ in the tangent plane 
            \end{itemize}
                \item \textbf{Definition \textit{(Ordinary angle)}}: An ordinary angle is any angle that is less than 180 degrees.
                \item $\mathbb{H}$: Consider $\mathbb{H}$ in a horizontal plane, cover $\mathbb{H}$ with a hemispherical dome. Rays $p,q$ in $ \mathbb{H}$, coterminal at point $A$. Project vertically up to dome: $p,q$ project to circular arcs on the dome, $A$ to $\hat{A}$
                    \bigbreak \noindent 
                    $\mu_{\mathbb{H}}(p,q)$ is the measure of ordinary angle between the two lines in the tangent plane at $\hat{A} $
                    \bigbreak \noindent 
                    \fig{.7}{./figures/h1.png}
                    \bigbreak \noindent 
                    \begin{figure}[ht]
                        \centering
                        \incfig{diag2}
                        \label{fig:diag2}
                    \end{figure}
                    \bigbreak \noindent 
                    \begin{align*}
                       \mu_{\mathbb{H}}(p,q) = \cos^{-1}{\left(\frac{1+mn-bc}{\sqrt{1+m^{2}-b^{2}}\sqrt{1+n^{2}-c^{2}}}\right)} 
                    \end{align*}
                \item \textbf{Measure axioms}
                    \begin{enumerate}
                        \item [M1]: For all coterminal rays $p,q$, $0 \leq pq \leq 180$
                        \item [M2]: $pq = 0 \iff p=q$
                        \item [M3]: $pq = qp$
                        \item [M4]: $pq = 180 \iff q=p^{\prime} $
                    \end{enumerate}
                    \bigbreak \noindent 
                    Note that $M4$ implies that $180$ is the suppremum (and the max) for angular distance. Observe that this fact is analogous to distances (when $\omega < \infty$), and $PQ = \omega \iff Q = P^{*} $
                    \bigbreak \noindent 
                    Thus,
                    \begin{align*}
                        180 \leftrightarrow \omega \\
                        p^{\prime} \leftrightarrow P^{*}
                    \end{align*}
                \item \textbf{Definition \textit{(betweenness for rays)}}: Ray $b$ lies \textbf{between} rays $a$ and $c$ ($ a\text{-}b\text{-}c $) provided that
                    \begin{enumerate}[label=(\alph*)]
                        \item $a,b,c$ are different, coterminal
                        \item $ab + bc = ac $
                    \end{enumerate}
                \item \textbf{Theorem 11.1 \textit{(symmetry of betweenness)}}: $ a\text{-}b\text{-}c \iff c\text{-}b\text{-}a$
                \item \textbf{Theorem 11.3 \textit{UMT}}: If $ a\text{-}b\text{-}c$, then $ b\text{-}a\text{-}c$ and $ a\text{-}c\text{-}b$ are false.
                    \bigbreak \noindent 
                    \textbf{\textit{Proof.}} The definition of $ a\text{-}b\text{-}c$ implies $ a\text{-}b\text{-}c$ are different, coterminal, and $ab + bc = ac$. 
                    \bigbreak \noindent 
                    Observe that each of $ab,bc,ac >0$ by axioms M1,M2. Thus, $ab + bc =ac$ implies $ac$ is larger than each of $ab,bc$
                    \bigbreak \noindent 
                    Suppose toward a contradiction that $ b\text{-}a\text{-}c$ is also true. Then, $ bc$ larger than each of $ba = ab$, and $ac$. This contradicts $ac$ larger than $ab, bc $
                    \bigbreak \noindent 
                    Therefore, $ b\text{-}a\text{-}c$ is false. Similarly, $ a\text{-}c\text{-}b$ is also false \endpf
                \item \textbf{Note about Incidence axioms}: There are no duals for the four incidence axioms we studied previously for points
                    \bigbreak \noindent 
                    We needed those axioms to begin developing how the undefined terms point and line are related. For instance, to guarantee points $A,B$ are in a \textbf{unique} line together, we require $AB < \omega$ (Ax.I4). Point $A$ can be in many different lines
                    \bigbreak \noindent 
                    But, rays and pencils are defined concepts, and by the definitions, and by what we have proved about rays, ray $a = \overrightarrow{AB}$ is in \textbf{just one pencil $P_{A} $}
                    \bigbreak \noindent 
                    Coterminal rays $a = \overrightarrow{AB}, b = \overrightarrow{AC}$ are automatically in the unique pencil $P_{A}$, no proof needed.
                    \bigbreak \noindent 
                    The dual of axiom N is a true statement for rays, but we don't need to assume it; we can prove it.
                \item \textbf{Theorem 11.2 (non-triviality)}: For any ray $p$ there is a coterminal ray $q$ so that $0 < pq < 180$
                    \bigbreak \noindent 
                    \textbf{\textit{Proof.}} Let $p = \overrightarrow{AB}$ be on line $\ell$. Thm 7.6 implies there is a point $C$ not on $\ell$ with $0 < AC < \omega$. Then, ray $\overrightarrow{AC}$ is defined, and is not contained in $\ell$, since $C \not\in \ell$. So, $\overrightarrow{AC} \ne p$, and $\ne p^{\prime}$. 
                    \bigbreak \noindent 
                    Let $q = \overrightarrow{AC}$. Then, 
                    \begin{align*}
                        180 \geq &pq \geq 0 \quad (\text{Ax.M1})\\
                                 &pq \ne 0 \quad (\text{Ax.M2},\ q\ne p) \\
                                 &pq \ne 180 \quad (\text{Ax.m4},\ q \ne p^{\prime}) 
                    \end{align*}
                    Therefore, $0 < pq < 180$
                \item \textbf{Definition \textit{(Wedge, fan)}}: Let $p,q$ be coterminal rays with $0<pq<180$.
                    \begin{itemize}
                        \item \textbf{Wedge $\overline{pq} = \{p,q\} \cup \{r: p\text{-}r\text{-}q\}$}
                        \item \textbf{Fan $\overrightarrow{pq} = \{p,q\} \cup \{r: p\text{-}r\text{-}q\} \cup \{r: p\text{-}q\text{-}r\}$}
                    \end{itemize}
                    (The duals of segment and ray)
                \item \textbf{Betweenness of rays axiom (Ax.BR)}: If $a,b,c$ are distinct, coterminal rays, and if $ab+bc \leq 180$, then there exists a betweenness relation among $a,b,c$
                    \bigbreak \noindent 
                    Thus, if no betweenness relation exists, then
                    \begin{align*}
                        ab + bc > 180 \\
                        ac + cb > 180 \\
                        ba + ac > 180
                    \end{align*}
                \item \textbf{Definition \textit{(quad betweenness)}}: $ a\text{-}b\text{-}c\text{-}d $ means that all four of 
                    \begin{align*}
                        a\text{-}b\text{-}c \quad a\text{-}b\text{-}d \quad a\text{-}c\text{-}d \quad b\text{-}c\text{-}d
                    \end{align*}
                    are true
                \item \textbf{Theorem \textit{(Triangle inequality for rays)}}: If $a,b,c$ are three distinct, coterminal rays, then $ab + bc \geq ac$
                \item \textbf{Theorem 11.5 \textit{(Rule of insertion for rays)}}:
                    \begin{enumerate}[label=(\alph*)]
                        \item If $ a\text{-}b\text{-}c$ and $ a\text{-}r\text{-}b$, then $ a\text{-}r\text{-}b\text{-}c $
                        \item If $ a\text{-}b\text{-}c $ and $ b\text{-}r\text{-}c $, then $ a\text{-}b\text{-}r\text{-}c $
                    \end{enumerate}
                \item \textbf{Quadrichotomy of Rays Axiom (Ax.QR)}: If $a,b,c,x$ are distinct, coterminal rays, and if $ a\text{-}b\text{-}c$, then at least one of the following must hold
                    \begin{align*}
                        x\text{-}a\text{-}b \quad a\text{-}x\text{-}b \quad b\text{-}x\text{-}c \quad b\text{-}c\text{-}x
                    \end{align*}
                    \bigbreak \noindent 
                    So, Ax.QR says that whenever $ a\text{-}b\text{-}c$ (say in pencil $P$), then any other ray in $P$ is in either fan $\overrightarrow{ba}$ or fan $\overrightarrow{bc} $ (so $P = \overrightarrow{ba} \cup \overrightarrow{bc} $)
                \item \textbf{Real fan axiom (Ax.RF)}: For any fan $\overrightarrow{ab} $ and for any real number $t$ with $ 0 \leq t \leq 180$, there is a ray $r$ in $\overrightarrow{ab} $ with $ar = t $
                    \bigbreak \noindent 
                    Ax.RF says every real number from 0 to 180 produces at least one ray in the fan
                    \bigbreak \noindent 
                    \textbf{Note:} Ax.RF is one version of what is sometimes called the \textbf{Protractor Axiom}
                \item \textbf{Notes}: Axioms $M1-M4$, $BR,QR,RF$ are true for $\mathbb{E}, \hat{\mathbb{E}}, \mathbb{M}, \mathbb{H}, \mathbb{S}$
                    \bigbreak \noindent 
                    All the results of chapters 8,9 have dual results for rays in a pencil. We do not state them all. But some that we do not state are needed for the proofs of some that we do.
                \item \textbf{Theorem 11.6 (Unique angular distance for fans)}: For any fan $\overrightarrow{pq}$ and any real number $t$ with $0 \leq t \leq 180$, there is a unique ray $r$ in $\overrightarrow{pq}$ with $pr = t$. $r$ is in $\overline{pq} $ if and only if $t \leq  pq$
                \item \textbf{Theorem 11.8}: If ray $a$ lies in pencil $P$, then $ a\text{-}r\text{-}a^{\prime} $ for every other ray $r$ in $P$
                    \bigbreak \noindent 
                    \textbf{Note:} We assumed in Ax.M4 that $a^{\prime} $ is the unique ray in $P$ with angular distance 1800 from a, so most of the proof of thm 9.1 does not need to be dualized. Alternatively, we could omit the assumption that $pq =180 \implies q = p^{\prime} $ and prove that this must be so by writing the dual of the full proof of thm 9.1.
                \item \textbf{Theorem 11.9 (Almost uniqueness of quadrichotomy for rays)}: Suppose that $a,b,c,r$ are distinct rays in a pencil $P$, and that $ a\text{-}b\text{-}c$. Then, \textbf{exactly} one of 
                    \begin{align*}
                        r\text{-}a\text{-}b \quad a\text{-}r\text{-}b \quad b\text{-}r\text{-}c \quad b\text{-}c\text{-}r
                    \end{align*}
                    With the exception that both $ r\text{-}a\text{-}b $ and $ b\text{-}c\text{-}r$ are true when $r = b^{\prime} $
                    \bigbreak \noindent 
                    \textbf{\textit{Proof}}: We proceed by dualizing the proof of theorem 9.2.
                    \bigbreak \noindent 
                    By Axiom.QR, at least one of 
                    \begin{align*}
                        r\text{-}a\text{-}b \quad a\text{-}r\text{-}b \quad b\text{-}r\text{-}c \quad b\text{-}c\text{-}r
                    .\end{align*}
                    Suppose we have $ a\text{-}r\text{-}b$. Then, $ a\text{-}b\text{-}c$ and the rule of insertion yields $ a\text{-}r\text{-}b\text{-}c $
                    \bigbreak \noindent 
                    So, $ a\text{-}r\text{-}b $ and $ r\text{-}b\text{-}c$ are true. Which, by the UMT guarantees that both $ b\text{-}r\text{-}c $ and $ b\text{-}c\text{-}r$ are false. 
                    \bigbreak \noindent 
                    Next, suppose that $ b\text{-}r\text{-}c$ is true. Then, $ a\text{-}b\text{-}c$ and the rule of insertion yields $ a\text{-}b\text{-}r\text{-}c$. So, $ a\text{-}b\text{-}r$ and $ b\text{-}r\text{-}c$ are true, and by the UMT, all three of  $ r\text{-}a\text{-}b$, $ a\text{-}r\text{-}b$, $ b\text{-}c\text{-}r$ are false. Thus, none of the other three relations hold.
                    \bigbreak \noindent 
                    So, if more than one of $ r\text{-}a\text{-}b, a\text{-}r\text{-}b, b\text{-}r\text{-}c, b\text{-}c\text{-}r$ holds, they must be exactly $ r\text{-}a\text{-}b$ and $ b\text{-}c\text{-}r$
                    \bigbreak \noindent 
                    Assume that $ r\text{-}a\text{-}b$ and $ b\text{-}c\text{-}r$ are true. Suppose toward a contradiction that $br < 180$. Then, fan $\overrightarrow{br}$ is defined, and $ r\text{-}a\text{-}b, b\text{-}c\text{-}r$ implies $a,c$ are in $ \overrightarrow{br}$. By the dual of theorem 8.3 (stated above), one of 
                    \begin{align*}
                        b\text{-}a\text{-}c \quad \text{or} \quad b\text{-}c\text{-}a
                    \end{align*}
                    is true. But, this contradicts $ a\text{-}b\text{-}c$ by the UMT. 
                    \bigbreak \noindent 
                    Therefore, $br = 180$, hence $ r = b^{\prime}$. \endpf

                \item \textbf{Theorem 11.10 (Opposite fan theorem)}: Let $p,q,r$ be rays in pencil $P$ such that $ q\text{-}p\text{-}r$. Then, $ \overrightarrow{pq} \cup \overrightarrow{pr} = P$, and $ \overrightarrow{pq} \cap \overrightarrow{pr} = \{p,p^{\prime}\} $
                \item \textbf{Corollary 11.11}: If $p,q$ are rays in pencil $P$ with $0 < pq < 180$, then $P = \overrightarrow{pq} \cup \overrightarrow{pq^{\prime}} $ and $\overrightarrow{pq} \cap \overrightarrow{pq^{\prime}} = \{p,p^{\prime}\}$
                \item \textbf{Compatibility Axiom (Ax.C)}: Let $A,B,C$ be points on line $m$, and $X$ a point not on $m$. If $ A\text{-}B\text{-}C$, then $ \overrightarrow{XA}\text{-}\overrightarrow{XB}\text{-}\overrightarrow{XC} $
                    \bigbreak \noindent 
                    \begin{figure}[ht]
                        \centering
                        \incfig{compat}
                        \label{fig:compat}
                    \end{figure}
                    \bigbreak \noindent 
                    Notice $AB + BC = AC \implies ab + bc = ac $
                \item \textbf{Notation and terminology}: Recall that $\hcancel{pq}$ means $p \cup q$, then union of the rays. Measure of $\hcancel{pq} $ means the angular distance $pq$
                \bigbreak \noindent 
                Suppose $p = \overrightarrow{BA}$, $ q = \overrightarrow{BC}$. Then, write
                \begin{align*}
                    \hcancel{pq} = \underline{\angle ABC} = \underline{\angle CBA}
                \end{align*}
                Or just $\underline{\angle B}$ when clear, and
                \begin{align*}
                    pq = \angle ABC = \angle CBA
                \end{align*}
                or just $\angle B$.
                \bigbreak \noindent 
                \begin{figure}[ht]
                    \centering
                    \incfig{im}
                    \label{fig:im}
                \end{figure}
            \item \textbf{Definition}: 
                \begin{itemize}
                    \item \textbf{Zero angle:} $\underline{pq}$ is a \textbf{zero angle} if $pq = 0 $ ($\iff p = q$)
                    \item \textbf{Straight angle}: If $pq = 180 (\iff p = q^{\prime}) $
                    \item \textbf{Proper angle:} if $0 < pq < 180 $
                    \item \textbf{acute angle}: if $ 0 < pq < 90$
                    \item \textbf{right angle}: if $ pq = 90$
                    \item \textbf{obtuse angle}: if $ 90 < pq < 180$
                \end{itemize}
            \item \textbf{Proposition 11.14}
                \begin{enumerate}[label=(\alph*)]
                    \item If $\omega < \infty$, then $\angle ABC = \angle AB^{*}C$
                    \item If $P \in \overrightarrow{BA}^{0} $ and $Q \in \overrightarrow{BC}^{0} $, then $\angle ABC = \angle PBQ$
                        \bigbreak \noindent 
                \end{enumerate}
                \bigbreak \noindent 
                \textbf{\textit{Proof}} (a) If $\omega < \infty$, then thm 10.8 and prop 9.3 implies $\overrightarrow{BA} = \overrightarrow{B^{*}A} $, $\overrightarrow{BC} = \overrightarrow{B^{*}C} $. So, $\underline{\angle ABC} = \overrightarrow{BA} \cup \overrightarrow{BC} = \overrightarrow{B^{*}A} \cup \overrightarrow{B^{*}C} = \angle AB^{*}C$ 
                \bigbreak \noindent 
                (b) If $P \in \overrightarrow{BA}^{0}$ and $Q \in \overrightarrow{BC}^{0}$, then $0 < BP < \omega$ and $0 < BQ < \omega$ by thm 9.4. Then, $ \overrightarrow{BA} = \overrightarrow{BP} $ and $\overrightarrow{BC} = \overrightarrow{BQ} $ by thm 8.4, so $\angle ABC = \overrightarrow{BA} \cup \overrightarrow{BC}  = \overrightarrow{BP} \cup \overrightarrow{BQ} = \angle PBQ$
            \item \textbf{Proposition 11.15 (Midpoint)}: If $\underline{pq}$ is a proper angle, then there is exactly one ray $b$ in the wedge $\overline{pq}$ so that $pb  = \frac{1}{2}pq $
            \item \textbf{Definition}: The ray $b$ is called the \textbf{bisector} of angle $\underline{pq}$ 
            \item \textbf{Theorem 12.2 (Fan: halfplane)}: Let $H,K$ be opposite halfplanes with edge line $\ell$, point $B \in H$. Let $X,A$ be points on $\ell$ with $0 < AX < \omega$. Let $h = \overrightarrow{XA}$, $k = \overrightarrow{XB}$. Then, $H $ consists of all points on all rays of the fan $\overrightarrow{hk}$, except for the points of $\ell$
                \bigbreak \noindent 
                That is, $P \in H \iff P \in j^{0}$, where $j^{0}$ is the interior of some ray $j \in \overrightarrow{hk}$, $j \ne h$ or $h^{\prime}$
                \bigbreak \noindent 
                \begin{figure}[ht]
                    \centering
                    \incfig{figher}
                    \label{fig:figher}
                \end{figure}
                \bigbreak \noindent 
                \textbf{\textit{Proof.}} Since $B \in H$ and $k = \overrightarrow{XB}$, by theorem 10.3 $k^{0} \subseteq H$. Suppose that $j$ is a ray in $\overrightarrow{hk}$ with $j\ne k,h,h^{\prime}$. So, either $ h\text{-}j\text{-}k$ or $ h\text{-}k\text{-}j$ by the definition of Fan.
                \bigbreak \noindent 
                Suppose toward a contradiction that for some point $C \in j^{0}$, then $C \in K$. Theorem 8.4 implies $j = \overrightarrow{XC}$, and theorem 10.3 implies $j^{0} \in K$
                \bigbreak \noindent 
                \begin{figure}[ht]
                    \centering
                    \incfig{ok}
                    \label{fig:ok}
                \end{figure}
                \bigbreak \noindent 
                $B \in H$, $C \in K$, so by Theorem 10.6, $ B\text{-}P\text{-}C$ for some $p \in \ell$. If $P =X$, then $ B\text{-}X\text{-}C$, which implies $ \overrightarrow{XC} = \overrightarrow{XB}^{\prime}$ by the opposite ray theorem (9.6)
                \bigbreak \noindent 
                If $P=X^{*}$ then $ B\text{-}X^{*}\text{-}C$, which implies $ \overrightarrow{X^{*}C} = \overrightarrow{X^{*}B^{\prime}}$ by Theorem 9.6
                \bigbreak \noindent 
                Then, $ B,X,C,X^{*}$ collinear (theorem 10.8), so proposition 9.3 implies $ \overrightarrow{X^{*}C} = \overrightarrow{XC} = j$, $ \overrightarrow{X^{*}B} = \overrightarrow{XB} = k$
                \bigbreak \noindent 
                So, if $P = X$ or $X^{*} $, then $j=k^{\prime}$. Then,  theorem 11.8 implies $ k\text{-}h\text{-}j$. But, this contradicts $ h\text{-}j\text{-}k$ or $ h\text{-}k\text{-}j $ by Theorem 11.3 (UMT for rays). Therefore, $P \ne X$ or $X^{*}$, so $X$ is not collinear with $B,P,C$. Also, $P \in \ell$ so either $P \in h^{0}$ or $P \in \text{Int}h^{\prime}$. By theorem 8.4, $ \overrightarrow{XP} = h$ or $h^{\prime}$
                \bigbreak \noindent 
                By Ax.C and $ B\text{-}P\text{-}C$, $ \overrightarrow{XB}\text{-}\overrightarrow{XP}\text{-}\overrightarrow{XC}$, which implies either $ k\text{-}h\text{-}j$ or $ k\text{-}h^{\prime}\text{-}j$
                \bigbreak \noindent 
                Again, $j \in \overrightarrow{hk}$, which implies $ h\text{-}j\text{-}k$ or $ h\text{-}k\text{-}j$, so by UMT, $ k\text{-}h\text{-}j$ is false. Thus, $ k\text{-}h^{\prime}\text{-}j = j\text{-}h^{\prime}\text{-}k$
                \bigbreak \noindent 
                If $ h\text{-}j\text{-}k$ then ROI yields $ h\text{-}j\text{-}h^{\prime}\text{-}k$, which gives $ h\text{-}h^{\prime}\text{-}j$, contradicting $ h\text{-}j\text{-}h^{\prime}$.
                \bigbreak \noindent 
                So, for all rays $j \in \overrightarrow{hk}$ with $j\ne h$ or $h^{\prime}$, then $ j^{0} \subseteq H$. 
                \bigbreak \noindent 
                Now, $\text{Int}k^{\prime} \subseteq K$ by thm 10.3, and the proof thus far shows: for all $j \in \overrightarrow{hk^{\prime}} $ with $j \ne h$ or $h^{\prime}$, then $j^{0}  \subseteq K$
                \bigbreak \noindent 
                For any point $D \in H$, $ \overrightarrow{XD} \in P_{X}$, but $\overrightarrow{XD}\not\in \overrightarrow{hk^{\prime}} $ since $D \not\in K$. 
                \bigbreak \noindent 
                By coroll. 11.11, $\overrightarrow{XD} \in \overrightarrow{hk}$. So, points of $H$ equals points on all $j^{0}, j\in \overrightarrow{hk}, j\ne h,h^{\prime}$
                \endpf


            \item \textbf{Corollary 12.3}: Let $z$ by any number with $0 < z < 180$. For any ray $\overrightarrow{AB}$ there are exactly two rays $h,k$ in $P_{A}$ such that $\overrightarrow{AB}h = z = \overrightarrow{AB}k$. Furthermore, $h^{0}$ and $k^{0}$ lie in opposite halfplanes with edge $\overleftrightarrow{AB} $
                \bigbreak \noindent 
                \textbf{\textit{Proof.}} There is a ray $q$ with $0 < \overrightarrow{AB}q < 180 $ (Thm. 11.2). Thus, fan $\overrightarrow{\overrightarrow{AB}q} $ is defined.
                \bigbreak \noindent 
                Coroll 11.11 implies $P_{A}  = \overrightarrow{\overrightarrow{AB}q} \cup \overrightarrow{\overrightarrow{AB}q^{\prime}}$, the union of two fans that have only $\overrightarrow{AB}, \overrightarrow{AB}^{\prime}$ in common.
                \bigbreak \noindent 
                \begin{figure}[ht]
                    \centering
                    \incfig{threefans}
                    \label{fig:threefans}
                \end{figure}
                \bigbreak \noindent 
                Thm 11.6 implies there's a unique ray $h$ in $\overrightarrow{\overrightarrow{AB}q}$ with $\overrightarrow{AB}h = z$, and a unique ray $k$ in $\overrightarrow{\overrightarrow{AB}q^{\prime}}$ with $\overrightarrow{AB}k  = z$. So, there are only two such rays in $P_{A} = \overrightarrow{\overrightarrow{AB}q} \cup \overrightarrow{\overrightarrow{AB}q^{\prime}}$
                \bigbreak \noindent 
                \begin{figure}[ht]
                    \centering
                    \incfig{fourfans}
                    \label{fig:fourfans}
                \end{figure}
                \bigbreak \noindent 
                Thm 12.2 implies $h^{0}, k^{0}$ lie in opposite halfplanes with edge $\overleftrightarrow{AB}$

    \end{itemize}

    \pagebreak 
    \subsection{The Crossbar Theorem}
    \begin{itemize}
        \item \textbf{Intro:} This gives us a sufficient condition (a guarantee) that a ray will meet a line (in fact, a line segment)
            \bigbreak \noindent 
            Axiom C does not do this. It deals with rays that are already assumed to meet a line.
            \bigbreak \noindent 
            The context for the crossbar theorem is any general plane with the 20 axioms.
        \item \textbf{Theorem 12.4 (The Crossbar Theorem)}: If $\underline{hk}$ is a proper angle with vertex (common endpoint) $X$, if $A \in h^{0}$ (so $h = \overrightarrow{XA}$), $C \in k^{0}$ (so $k = \overrightarrow{XC}$), and $ h\text{-}j\text{-}k$, then there is an interior point $B$ of $j$ with $ A\text{-}B\text{-}C$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{cbt}
                \label{fig:cbt}
            \end{figure}
            \bigbreak \noindent 
            \textbf{Note:} $\underline{hk}$ proper means that $h \ne k$ or $k^{\prime}$, $ k \ne h$ or $h^{\prime}$. Hence, $C \not\in h \cup h^{\prime} = \overleftrightarrow{XA}$, $A \not\in k\cup k^{\prime} = \overleftrightarrow{XC} $. Then, $X,A,C$ noncollinear, so $AC<\omega$. 
            \bigbreak \noindent 
            Thus, segment $\overline{AC}$ is defined, and the crossbar theorem says that $j^{0}$ meets $\overline{AC}^{0} $. Note that
            \begin{align*}
                j^{0} \cap \overline{AC}^{0} \ne \varnothing
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $h = \overrightarrow{XA}, k = \overrightarrow{XC}$, with $\underline{hk}$ a proper angle. Assume $ h\text{-}j\text{-}k$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{cbt2}
                \label{fig:cbt2}
            \end{figure}
            \bigbreak \noindent 
            $ h\text{-}j\text{-}k$ implies $h,j,k$ distinct, which implies $0 < hj < hk < jk $
            \bigbreak \noindent 
            $ h\text{-}j\text{-}k $ implies $hj + jk = hk < 180$, so $0 < hj < 180, 0 < jk < 180 $, which implies fans $\overrightarrow{jh}, \overrightarrow{jk}$ defined. $ h\text{-}j\text{-}k$ also implies $P_{X} = \overrightarrow{jh} \cup \overrightarrow{jk}$, with $\overrightarrow{jh} \cap \overrightarrow{jk} = \{j,j^{\prime}\} $ (thm 11.10)
            \bigbreak \noindent 
            Let $m =$ line $j \cup j^{\prime}$; we have $H,K$ opposite halfplanes with edge $m$ (Ax.S), we may assume that $A \in H$
            \bigbreak \noindent 
            Theorem 12.2 implies $H$ is the set of all points of all $r^{0}$, for $r \in \overrightarrow{jh}$, $r \ne j$ or $j^{\prime} $
            \bigbreak \noindent 
            $\overrightarrow{jk}$ is the "opposite fan" to $\overrightarrow{jh}$, so theorem 12.2 implies $k^{0} \subseteq K$, so $C \in K$
            \bigbreak \noindent 
            Now, theorem 10.6 implies there is a point $Y$ on $m$ with $ A\text{-}Y\text{-}C$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{ict23}
                \label{fig:ict23}
            \end{figure}
            \bigbreak \noindent 
            If $Y = X$ or $X^{*}$, then $ A\text{-}X\text{-}C$ or $ A\text{-}X^{*}\text{-}C$, which implies $A,X,C$ collinear. By theorem 10.8, if $ A,X^{*}, C$ collinear, then $A,X^{*}, C,X$ collinear, which contradicts $\underline{\angle AXC} = \underline{hk}$ proper.
            \bigbreak \noindent 
            So, $Y$ on $m$ with $Y \ne X, X^{*}$, which implies $Y \in j^{0}$ or $\text{Int}j^{\prime}$, which implies $\overrightarrow{XY} = j$ or $j^{\prime} $
            \bigbreak \noindent 
            $A,Y,C$ on line $\overleftrightarrow{AY}$, and $X$ not on $\overleftrightarrow{AY}$, so by Ax.C and $ A\text{-}Y\text{-}C$, $ \overrightarrow{XA}\text{-}\overrightarrow{XY}\text{-}\overrightarrow{XC} $, which implies $ h\text{-}\overrightarrow{XY}\text{-}k$
            \bigbreak \noindent 
            Suppose $ \overrightarrow{XY} = j^{\prime}$, then $ h\text{-}j^{\prime}\text{-}k$. By hypothesis, $ h\text{-}j\text{-}k$. So, $k$ in fans $\overrightarrow{hj^{\prime}} $ and $ \overrightarrow{hj} $. But, coroll 11.11 implies $ \overrightarrow{hj^{\prime}} \cap \overrightarrow{hj} = \{h, h^{\prime}\}$, and $ k \ne h$ or $h^{\prime}$ ($\underline{hk} $ proper). This is a contradiction, which implies $ \overrightarrow{XY} = j$, hence $Y \in j^{0}$, and $ A\text{-}Y\text{-}C$ \endpf



        \item \textbf{Definition}: Let $A,B,C$ be three noncollinear points (So $AB$, $BC$, $AC$ all $< \omega$ by prop noncollinear). 
            \bigbreak \noindent 
            \begin{itemize}
                \item The \textbf{triangle} $\triangle ABC$ is $\overline{AB} \cup \overline{BC} \cup \overline{CA}$
                \item The \textbf{sides} of $\triangle ABC$ are $\overline{AB}, \overline{BC}, \overline{CA}$
                \item The \textbf{vertices} of $\triangle ABC$ are $A,B,C$
                \item The \textbf{angles} of $\triangle ABC$ are
                    \begin{align*}
                        \underline{\angle CAB} &= \underline{\overrightarrow{AC}\overrightarrow{AB}} = \angle A = \angle A \\
                        \underline{\angle ABC} &= \underline{\overrightarrow{BA}\overrightarrow{BC}} = \angle B \\
                        \underline{\angle BCA} &= \underline{\overrightarrow{CB}\overrightarrow{CA}} = \angle C
                    .\end{align*}
                \item $\angle CAB$ are vertex $A$ are called \textbf{opposite} $\overline{BC}$, etc...
                \item The \textbf{angle sum} $\sigma(ABC) = \angle A + \angle B + \angle C$ (This is not necessarily 180)
            \end{itemize}
        \item \textbf{Note:} Say we have $\triangle ABC$ and ray $j$ with $ \overrightarrow{BA}\text{-}j\text{-}\overrightarrow{BC} $
            \begin{figure}[ht]
                \centering
                \incfig{mytri}
                \label{fig:mytri}
            \end{figure}
            $\angle ABC$ is proper, since $A,B,C$ are noncollinear. So, the crossbar theorem implies  $j^{0}$ meets $\overline{AC}^{0}$. Thus, there is a point $D$ on $j^{0}$ with $ A\text{-}D\text{-}C$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{mytri2}
                \label{fig:mytri2}
            \end{figure}
            \bigbreak \noindent 
            \textbf{Note:} Euclid does this a lot, with no explicit justification.
        \item \textbf{Note about the crossbar theorem}: The proof of the crossbar theorem depends on the fan: halfplane theorem (12.2), which in turn depends on the separation axiom (Ax.S)
            \bigbreak \noindent 
            In $\mathbb{G}$, where $Ax.S$ is false, the crossbar theorem is also false.




    \end{itemize}

    \pagebreak 
    \subsection{Duals of results from chapters 8 and 9}
    \bigbreak \noindent 
    \subsubsection{Theorems (14)}
    \begin{itemize}
        \item \textbf{Theorem 8.1D}: The set of angle measures $\mathbb{D} = [0,180]$
        \item \textbf{Theorem 8.2D}: All wedges, fans, pencils have infinitely many rays
        \item \textbf{Theorem 8.3D}: Let $x\ne y$ be distinct from $a$ on fan $\overrightarrow{ab}$. Then, exactly one of 
            \begin{align*}
                a\text{-}x\text{-}y \quad \text{ or } \quad a\text{-}y\text{-}x
            .\end{align*}
        \item \textbf{Theorem 8.4D}: Let $\overrightarrow{ab}$ be a fan. If $c \in \overrightarrow{ab}$, $0 < c < 180$, then $\overrightarrow{ab} = \overrightarrow{ac}$
        \item \textbf{Theorem 8.6D}: Stated in theorem 11.6
        \item \textbf{Theorem 9.1D}: Let ray $a$ be in pencil $P$, there exists a unique fan $a^{\prime} \in P$ such that $aa^{\prime} = 180$. For all other rays $x\in P$, $ a\text{-}x\text{-}a^{\prime} $
        \item \textbf{Theorem 9.2D}: Stated in theorem 11.8
        \item \textbf{Theorem 9.4D}: If $ap = 180$ in some fan $h$, then $p = a^{\prime}$.
        \item \textbf{Theorem 9.6D}: Stated in theorem 11.9
        \item \textbf{Theorem 9.7D}: Each fan has a unique opposite fan.
        \item \textbf{Theorem 9.8D}: Let rays $a,b \in P$, if $0 < ab < 180$, then fan $\overrightarrow{ab}^{\prime} = \overrightarrow{ab^{\prime}} $
        \item \textbf{Theorem 9.9D}: Let rays $a,b \in P$, if $0 < ab < 180$, then $P = \overline{ab} \cup \overline{ab^{\prime}} \cup \overline{ba^{\prime}} \cup \overline{b^{\prime}a^{\prime}}$, where the interiors of these wedges are disjoint.
        \item \textbf{Theorem 9.10D}: Let rays $a,b \in P$, if $0 < ab < 180$, and $c$ is some other ray in $P$, then there exists no betweenness relation among $a,b,c$ if and only if $c \in \overline{a^{\prime}b^{\prime}} $
    \end{itemize}

    \bigbreak \noindent 
    \subsubsection{Propositions}
    \begin{itemize}
        \item \textbf{Proposition 8.11D}: Let $a,b \in P$, $0 < ab < 180$, there exists $c\in P$ such that $ c\text{-}a\text{-}b$, $cb < 180$
        \item \textbf{Proposition 8.5D}: A fan has at most two terminal rays 
        \item \textbf{Proposition 8.7D}: Let $\overline{ab}$ be a wedge, for all $x,y \in \overline{ab}$, $xy \leq ab$, if $xy = ab$, then $\{x,y\} = \{a,b\}$
        \item \textbf{Proposition 8.8D}: If $\overline{ab}  = \overline{cd}$, then $\{a,b\} = \{c,d\}$
        \item \textbf{Proposition 8.9D}: Stated in proposition 11.15
        \item \textbf{Proposition 9.3D}: Let $a,b \in P$ such that $0 < ab < 180$. Then,
            \begin{itemize}
                \item Fan $\overrightarrow{ab} = \overline{ab} \cup \overline{ba^{\prime}}$, with $\overline{ab} \cap \overline{ba^{\prime}}  = \varnothing$
                \item Fan $\overrightarrow{ab} = \overrightarrow{a^{\prime}b} $
            \end{itemize}
    \end{itemize}

    \pagebreak 
    \subsection{Side angle side congruence}
    \begin{itemize}
        \item \textbf{Intro}: We know present the 21 axiom for a general plane, in fact the last axiom that will be covered here. Euclid called it a theorem, but we'll show that it is not a consequence of the first 20 axioms, and so cannot be proved from them.
            \bigbreak \noindent 
            Our context is a general plane with the 20 axioms. These include $\mathbb{E}, \hat{\mathbb{E}}, \mathbb{M}, \mathbb{H}, \mathbb{S} $
        \item \textbf{Definition: Congruence}: Two segments $\overline{AB}$ and $ \overline{XY}$ are \textbf{congruent} $(\cong)$ if they have the same length: $\overline{AB} \cong \overline{XY} $ means $AB = XY$
            \bigbreak \noindent 
            Two angles $\angle CAB$ and $\angle ZXY$ are congruent if they have the same angle measure
            \bigbreak \noindent 
            Two triangles $\triangle ABC$ and $\triangle ZXY$ are congruent under the correspondence $A\leftrightarrow X$, $B \leftrightarrow Y, C\leftrightarrow Z$ (Write as $ABC \leftrightarrow XYZ $) if 
            \begin{align*}
                \overline{AB} \cong \overline{XY},\quad \overline{BC} \cong\overline{YZ} ,\quad \overline{AC} \cong \overline{XZ}
            .\end{align*}
            and 
            \begin{align*}
                \angle ABC \cong \angle XYZ, \quad \angle CAB \cong \angle ZXY,\quad \angle BCA \cong \angle YZX
            .\end{align*}
            denote this by $\triangle ABC \cong \triangle XYZ $
            \bigbreak \noindent 
            \textbf{Note:} The correspondence of vertices is an essential part of the congruence of triangles.
        \item \textbf{Side-angle-side axiom (Ax.SAS)}: If under the correspondence $ABC \leftrightarrow XYZ$ between the vertices of $ \triangle ABC$ and those of $ \triangle XYZ$, two sides of $ \triangle ABC$ are congruent to the corresponding two sides of $\triangle XYZ$, and the angle included between these two sides of $ \triangle ABC$ is congruent to the corresponding angle of $\triangle XYZ$, then $\triangle ABC \cong \triangle XYZ$
        \item \textbf{The bumpy plane $\hat{\mathbb{E}}$}: Observe that Ax.SAS is false for the bumpy plane
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{bp}
                \label{fig:bp}
            \end{figure}
        \item \textbf{The taxicab plane}: Observe that Ax.SAS is false for the taxicab plane
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{taxi}
                \label{fig:taxi}
            \end{figure}
            \bigbreak \noindent 
            \textbf{Note}: Since the first 20 axioms are true for $\hat{\mathbb{E}}, \mathbb{M} $, but the 21st is false, is is therefore not possible that the 21st is a consequence of the first 20.
            \bigbreak \noindent 
            Ax.SAS is true for $\mathbb{E}, \mathbb{S}, \mathbb{H}$
        \item \textbf{Definition: Absolute plane}: An \textbf{absolute plane} $\mathbb{P}$ is a set of points $\mathbb{P}$ with lines, distance, and angular distance (all undefined terms), such that all 21 axioms are true. The three planes above are absolute planes
        \item \textbf{Theorem 13.1 (ASA)}: If under the correspondence $ABC \leftrightarrow XYZ$, two angles and the included side of $\triangle ABC$ are congruent, respectively, to the corresponding two angles and included side of $\triangle XYZ$, then $\triangle ABC \cong \triangle XYZ $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} If we can show that $BC = YZ$, then we can apply Ax.SAS: $ \overline{BA} \cong \overline{YX}$, $\overline{BC} \cong \overline{YZ}, \angle ABC \cong \angle XYZ$ implies $\triangle ABC \cong \triangle XYZ$
            \bigbreak \noindent 
            Suppose toward a contradiction that $ BC \ne YZ$. Since we are given exactly the same information about the two triangles, we may choose notation so that $BC > YZ$
            \bigbreak \noindent 
            Thm 8.6 implies there is a point $W$ on $\overrightarrow{BC}$ with $BW = YZ$, then $BW < BC$, which implies $ B\text{-}W\text{-}C$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{thefig}
                \label{fig:thefig}
            \end{figure}
            \bigbreak \noindent 
            $\overrightarrow{BC} = \overrightarrow{BW}$ (Thm 8.4), and Thm 10.3 implies $C,W$ are in the same halfplane with edge $\overleftrightarrow{AB}$. IN particular, $A,B,W$ are noncollinear, and we have $\triangle ABW$ with
            \begin{align*}
                \overline{BA} \cong \overline{YX},\ \overline{BW} \cong \overline{YZ},\ \angle ABW = \angle ABC \cong \angle XYZ
            .\end{align*}
            Note that $\angle ABW = \angle ABC$ by prop 11.14. With these facts, and by Ax.SAS, $ \triangle ABW \cong \triangle XYZ$, which implies $ \angle BAW \cong \angle YXZ$.
            \bigbreak \noindent 
            $\angle YXZ = \angle X \cong \angle A = \angle BAC$, so $\angle BAW = \angle BAC$
            \bigbreak \noindent 
            $ B\text{-}W\text{-}C$ and Ax.C implies $ \overrightarrow{AB}\text{-}\overrightarrow{AW}\text{-}\overrightarrow{AC} $, which implies $ \overrightarrow{AB}\overrightarrow{AW}  + \overrightarrow{AW}\overrightarrow{AC} = \overrightarrow{AB}\overrightarrow{AC}$, which implies $ \angle BAW + \angle WAC = \angle BAC $
            \bigbreak \noindent 
            Thm 10.3 implies $W,B$ in a halfplane with edge $\overleftrightarrow{AC}$, which implies $W,A,C$ noncollinear, which implies $ \angle WAC$ is proper. Thus, $ \angle WAC > 0$, and $ \angle BAW < \angle BAC$, which is a contradiction \endpf
        \item \textbf{Definition: types of triangles}
            \begin{itemize}
                \item A triangle is \textbf{isosceles} if two sides have the same length
                \item \textbf{Equilateral} if all three sides have the same length
                \item \textbf{Equiangular} if all three angles have the same measure  
            \end{itemize}
            \textbf{Note:} A triangle can be called \textbf{scalene} if all all three sides have different lengths and all three angles have different measures
        \item \textbf{Theorem 13.2 (pons asinorum ("Bride of asses"))} In any $\triangle ABC$, 
            $$ AB = AC \iff \angle ACB = \angle ABC $$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{assse}
                \label{fig:assse}
            \end{figure}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Consider the correspondence $ABC \leftrightarrow ACB$ between the vertices of $\triangle ABC$ and itself
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{mig}
                \label{fig:mig}
            \end{figure}
            \bigbreak \noindent 
            Suppose that $AB = AC$, then 
            \begin{align*}
                \overline{AB} \cong \overline{AC},\quad \overline{AC} \cong \overline{AB}, \quad \angle BAC \cong \angle CAB
            .\end{align*}
            So, Ax.SAS implies $\triangle ABC \cong \triangle ACB $, which implies $ \angle ACB = \angle ABC $
            \bigbreak \noindent 
            Suppose that $\angle ACB = \angle ABC$. Then, $\angle ACB \cong \angle ABC$, $\angle ABC \cong \angle ACB$, $\overline{CB} = \overline{BC} $
            \bigbreak \noindent 
            So, Thm 13.1 (ASA) implies $ \triangle ABC \cong \triangle ACB $, which implies $ AB = AC$ by congruence
        \item \textbf{Corollary 13.3}: A triangle is equilateral if and only if it is equiangular
        \item \textbf{Theorem 13.4 (SSS)}: If in $\triangle ABC$ and $\triangle XYZ$, $\overline{AB} \cong \overline{XY}$, $ \overline{BC} \cong \overline{YZ}$ and $\overline{CA} \cong \overline{ZX}$, then 
            \begin{align*}
                \triangle ABC \cong \triangle XYZ
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We'll show that $\angle BAC = \angle YXZ$. Then, $Ax.SAS$ will imply $\triangle ABC \cong \triangle XYZ$.
            \bigbreak \noindent 
            So, assume for the sake of contradiction that $ \angle A \ne \angle X$. We may assume that $\angle A > \angle X$ (otherwise, just switch the notation for vertices from one triangle to the other). So, $\angle BAC > \angle YXZ$, which means that $\overrightarrow{AB}\overrightarrow{AC} > \angle X$. We apply Ax.RF (or thm 11.6) to the fan $ \overrightarrow{\overrightarrow{AB}\overrightarrow{AC}} $. Thus, there is a ray $h$ in $\overrightarrow{\overrightarrow{AB}\overrightarrow{AC}} $ with $\overrightarrow{AB}h  = \angle X$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{anglex}
                \label{fig:anglex}
            \end{figure}
            \bigbreak \noindent 
            Because $\overrightarrow{AB}h = \angle X < \overrightarrow{AB}\overrightarrow{AC}$, we have $ \overrightarrow{AB}\text{-}h\text{-}\overrightarrow{AC} $. $\underline{\overrightarrow{AB}\overrightarrow{AC}}$ is a proper angle, since $A,B,C$ noncollinear. So, we may apply the Crossbar Theorem
            \bigbreak \noindent 
            Therefore, there is a point $D \in h^{0}$ with $ B\text{-}D\text{-}C$. So, $ h = \overrightarrow{AD} $ (thm 8.4)
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{helloworld}
                \label{fig:helloworld}
            \end{figure}
            \bigbreak \noindent 
            Ax.RR implies there is a point $P$ on $h$ with $AP = XZ$. So, $h = \overrightarrow{AP}$. $\overline{AB} \cong \overline{XY}$, $\overline{AP} \cong \overline{XZ}, \underline{\angle BAP} = \underline{\overrightarrow{AB}h} \cong \underline{\angle YXZ}$
            \bigbreak \noindent 
            Ax.SAS implies $ \triangle ABP \cong \triangle XYZ $, which implies $BP = YZ = BC$ (So $P \ne D$, since $BD< BC$), and $AP = XZ = AC $
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{newtri}
                \label{fig:newtri}
            \end{figure}
            \bigbreak \noindent 
            Pons Asinorum (13.2) for $ \triangle BCP$ implies $ \angle BCP  = \angle BPC$, and for $ \triangle ACP $, $\angle ACP = \angle APC $
            \bigbreak \noindent 
            $ B\text{-}D\text{-}C$ and Ax.C implies $ \overrightarrow{PB}\text{-}\overrightarrow{PD}\text{-}\overrightarrow{PC} $, which implies $\angle BPD + \angle DPC = \angle BPC $, implies $ \angle BPC > \angle DPC $
            \bigbreak \noindent 
            Now, we consider separately two cases for $P$ on $\overrightarrow{AD}$
            \bigbreak \noindent 
            1.) $ A\text{-}P\text{-}D$. Then, $ \overrightarrow{PD} = \overrightarrow{PA}^{\prime}$ (Thm 9.6), so Thm 11.8 implies $ \overrightarrow{PA}\text{-}\overrightarrow{PC}\text{-}\overrightarrow{PD}$
            \bigbreak \noindent 
            Thus, $ \angle APC + \angle DPC = \angle APD = 180 $ (Ax.M4)
            \bigbreak \noindent 
            $ A\text{-}P\text{-}D $ and Ax.C implies $ \overrightarrow{CA}\text{-}\overrightarrow{CP}\text{-}\left(\overrightarrow{CD} =  \overrightarrow{CB}\right)$, which implies $ \angle ACP + \angle BCP = \angle ACB$. 
            \bigbreak \noindent 
            Since $\angle ACP = \angle APC$ and $\angle BCP = \angle BPC > \angle DPC$, $ \angle ACB = \angle ACP + \angle BCP = \angle APC + \angle BPC > \angle APC + \angle DPC = 180 $, which contradicts Ax.M1
            \bigbreak \noindent 
            2.) $ A\text{-}D\text{-}P$ (needs proof)







    \end{itemize}

    \pagebreak 
    \subsection{Perpendiculars}
    \begin{itemize}
        \item \textbf{Intro:} We've introduced 21 axioms, and defined an \textbf{absolute plane}, which hase
            \begin{itemize}
                \item \textbf{Undefined terms}: Point, line, distance, angle measure
                \item \textbf{21 Axioms}
            \end{itemize}
            Examples are $\mathbb{E}, \mathbb{H},\mathbb{S} $
            \bigbreak \noindent 
            Next, we introduce and study \textbf{perpendicular lines}.
        \item \textbf{Definition: Supplementary angles}: Two angles are \textbf{supplementary} if their measures sum to 180.
        \item \textbf{Theorem 14.1 (Supplementary angles theorem)}: If $h,j$ are coterminal rays, then $\underline{hj}$ and $\underline{jh^{\prime}} $ are supplementary
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} If $j = h$, then $hj = 0$ by Ax.M2, and $jh^{\prime} = 180$ by Ax.M4. So, $hj + jh^{\prime} = 180$.
            \bigbreak \noindent 
            If $j \ne h$ or $h^{\prime}$, thm 11.8 implies $ h\text{-}j\text{-}h^{\prime}$, which means $hj + jh^{\prime} = hh^{\prime}$, and $hh^{\prime} =180$ by Ax.M4
        \item \textbf{Definition}: Angles $\underline{hk}, \underline{rs}$ are \textbf{vertical} if $\{r,s\}  = \{h^{\prime}, k^{\prime}\}$
        \item \textbf{Theorem 14.2 (Vertical angles theorem)}: Vertical angles are congruent
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Given vertical angles $\underline{hk}, \underline{h^{\prime}k^{\prime}}$, Thm 14.1 implies $\underline{hk}$ and $\underline{kh^{\prime} }$ are supplementary, and $ \underline{kh^{\prime}}$ and $h^{\prime}k^{\prime} $ are supplementary, which implies $kh + kh^{\prime} = 180 = kh^{\prime} + h^{\prime}k^{\prime}$, which implies $hk = h^{\prime}k^{\prime} $
            \bigbreak \noindent 
            \textbf{Note:} When two lines intersect, four angles are formed, angles $\underline{hk}, \underline{kh^{\prime}}, \underline{h^{\prime}k^{\prime}},$ and $\underline{k^{\prime}h} $, the measure of any one determines the measure of the others, by thms 14.1, 14.2. In particular, if $hk = 90$, then all four angle measures are $90$
        \item \textbf{Definition: Perpendicular}: Two intersecting lines $m,n$ are \textbf{perpendicular} (at point of intersection $B$) if the four angles they determine at $B$ are right angles, we write $m\perp n$ (at $B$)
            \bigbreak \noindent 
            \textbf{Note:} Prop 11.14 implies if $m \perp n$ at $B$, then $m \perp n$ at $B^{*} $ (when $\omega < \infty $)
        \item \textbf{Theorem 14.3}: Through any point $A$ on a line $m$, there is exactly one line $n$ perpendicular to $m$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Let $h$ be a ray on $m$ with endpoint $A$ (so $m = h \cup h^{\prime} $)
            \bigbreak \noindent 
            Since $0 < 90 < 180$, coroll 12.3 implies there are exactly two rays $k,j$ in $P_{A}$ with $hk = hj = 90 $
            \bigbreak \noindent 
            Let $n = k \cup k^{\prime}$. $hk = 90$ implies $ hk^{\prime} = 90$ by thm 14.1, so $j = k^{\prime}$. That is, $k, k^{\prime}$ are the only rays in $P_{A}$ that form a right angle with $h$. So, $n$ is the only line through $A$ with $m \perp n$
        \item \textbf{Definition: The perpendicular bisector}: The \textbf{perpendicular bisector} of a segment $\overline{AB}$ is the line perpendicular to $\overleftrightarrow{AB}$ at the midpoint $M$ of $\overline{AB}$
        \item \textbf{Theorem 14.9 (needs proof)}: Every point of the perpendicular bisector of a segment is equidistant from the endpoints of the segment: $AX = BX$ for all $X$ on the perpendicular bisector
        \item \textbf{Theorem 14.10 (converse of 14.9)}: Let $m = \overleftrightarrow{AB}$, suppose that line $n\ne m$ meets $m$ at the midpoint $M$ of $\overline{AB}$. Suppose that there is some point $X$ on $n$, not on $m$, so that $AX = BX$. Then, $n \perp n$ at $M$
        \item \textbf{Note about 14.9 and 14.10}: Theorems 14.9 and 14.10 say that the perpendicular bisector of $\overline{AB}$ consists exactly of the points $X$ in $\mathbb{P}$ such that $AX = BX $
        \item \textbf{Theorem 14.4}: Through a point $A$ not on a given line $m$ there is at least one line $n$ perpendicular to $m$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Choose any point $B$ on $m$. Since $A$ is not on $m$, $AB < \omega$. So, there is a unique line $\overleftrightarrow{AB}$ through $A$ and $B$, and ray $\overrightarrow{BA}$ is defined. Let $h$ be a ray in $m$ with endpoint $B$, so that $m = h \cup h^{\prime}$. Let $\theta  = \overrightarrow{BA}h $
            \bigbreak \noindent 
            \fig{.6}{./figures/g1.png}
            \bigbreak \noindent 
            $A$ is in a halfplane $H$ with edge $m$. Coroll. 12.3 implies there is a second ray $k$ with endpoint $B$ so that $k^{0}$ is in the opposite halfplane $K$ and $hk= \theta$
            \bigbreak \noindent 
            \fig{.5}{./figures/g2.png}
            \bigbreak \noindent 
            Ax.RR implies there's a point $C$ on $k$ with $BC = BA$. Thm 10.6 implies there's a point $X$ on $m$ with $ A\text{-}X\text{-}C$. Then, $ \overrightarrow{XC} =  \overrightarrow{XA}^{\prime}$
            \bigbreak \noindent 
            We consider some cases
            \bigbreak \noindent 
            1.) If $X = B,$ then $\overrightarrow{BC} = \overrightarrow{BA}^{\prime}$, so $ \overrightarrow{BA}h + \overrightarrow{BC}h = 180$ (Thm 14.1), this implies $ \theta  + \theta  = 180$, thus $\theta  = 90$. So, $\overleftrightarrow{AB} \perp m$. Note that this is the lucky case. Our random choice of $B$ gave us a perpendicular line.
            \bigbreak \noindent 
            2.) If $X = B^{*}$, then $\overrightarrow{B^{*}C} = \overrightarrow{B^{*}A}^{\prime}$. Thus, $h$ has endpoint $B^{*}$ (Prop 9.3). So, Thm 14.1 implies $ \overrightarrow{B^{*}A}h + \overrightarrow{B^{*}C}h = 180$
            \bigbreak \noindent 
            In this case, prop 11.14 implies $\overrightarrow{B^{*}A}h = \overrightarrow{BA}h$, and $\overrightarrow{B^{*}C}h = \overrightarrow{BC}h$ $\overrightarrow{BA}h  + \overrightarrow{BC}h$, and thus $\theta  + \theta  = 180$, so $\theta  = 90$. Thus, we have $\overleftrightarrow{AB} \perp m$
            \bigbreak \noindent 
            3.) If $X$ is in $h^{0}$, then $ h = \overrightarrow{BX}$.
            \bigbreak \noindent 
            \fig{.6}{./figures/g3.png}
            \bigbreak \noindent 
            $\theta  = \angle ABX = \angle CBX$, so $\underline{\angle ABX} \cong \underline{\angle CBX} $, $ \overline{BA} \cong \overline{BC}, \overline{BX} \cong \overline{BX}$, and thus Ax.SAS implies $\triangle ABX \cong \triangle CBX $, which implies $\angle AXB = \angle CXB$ by definition of congruent triangles
            \bigbreak \noindent 
            From here, thm 14.1 implies $180 = \overrightarrow{XA}\overrightarrow{XB} + \overrightarrow{XC}\overrightarrow{XB} = \angle AXB + \angle CXB$. 
            \bigbreak \noindent 
            Therefore, $\angle AXB = \angle CXB = 90$. So, $\overleftrightarrow{AX} \perp m$ at $X$, $\overleftrightarrow{AX}$ goes through $A$.
            \bigbreak \noindent 
            If $X$ is on $\text{Int}h^{\prime}$, thm 14.1 implies $\angle ABX = 180 - \theta = \angle CBX$. So again, $\overline{BA} \cong \overline{BC}$, $ \overline{BX} \cong \overline{BX}, \underline{\angle ABX} \cong \underline{\angle CBX}$ and Ax.SAS implies $ \triangle ABX  \cong \triangle CBX$, which implies $\angle AXB = \angle CXB$.
            \bigbreak \noindent 
            \fig{.6}{./figures/g4.png}
            \bigbreak \noindent 
            By thm 14.1, $180 = \overrightarrow{XA}\overrightarrow{XB} + \overrightarrow{XC}\overrightarrow{XB} = \angle AXB + \angle CXB$, so $\angle AXB = \angle CXB = 90$, hence $\overleftrightarrow{AX} \perp m$, and $\overleftrightarrow{AX}$ goes through $A$. \endpf
        \item \textbf{Definition: Pole}: Point $A$ is a \textbf{Pole} of line $m$ if there exists a point $X$ on $m$ such that 
            \begin{align*}
                \overleftrightarrow{AX} \perp m \text{ and } AX = \frac{\omega}{2}
            .\end{align*}
            \bigbreak \noindent 
            \fig{.6}{./figures/g5.png}
            \bigbreak \noindent 
            So, poles will exist only when $\omega < \infty$. Think $m=$ equator, $A=$ north pole.
            \bigbreak \noindent 
            \fig{.6}{./figures/g6.png}
        \item \textbf{Theorem 14.5}: If there are two different lines through a point $A$ and perpendicular to a line $m$, then $A$ is a pole of $m$.
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{picture}
                \label{fig:picture}
            \end{figure}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}}  We'll show that $AX_{1} = \frac{\omega}{2}$. Note that $X_{1}X_{2} < \omega$, since $n_{1} \ne n_{2}$
            \bigbreak \noindent 
            $AX_{1} < \omega$ (Since $A$ is not on $m$), so $\overrightarrow{X_{1}A}$, and $ \overrightarrow{X_{1}A}^{\prime} $ exist. Ax.RR implies there is a point $B$ on $\overrightarrow{X_{1}A}^{\prime}$ with $X_{1}B = X_{1}A$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{pic2}
                \label{fig:pic2}
            \end{figure}
            \bigbreak \noindent 
            $\overline{X_{1}A} \cong \overline{X_{1}B}, \overline{X_{1}X_{2}} \cong X_{1}X_{2}, \angle AX_{1}X_{2} = 90 = \angle BX_{1}X_{2}$, thus $\underline{\angle AX_{1}X_{2}} \cong\underline{\angle BX_{1}X_{2}}$. So, by Ax.SAS, $\triangle AX_{1}X_{2} \cong \triangle BX_{1}X_{2}$, which implies $ \angle BX_{2}X_{1} = \angle AX_{2}X_{1} = 90$
            \bigbreak \noindent 
            Thus, $\overrightarrow{X_{2}X_{1}}\overrightarrow{X_{2}B} = \overrightarrow{X_{2}X_{1}}\overrightarrow{X_{2}A}^{\prime}$ with $ \overrightarrow{X_{2}B}^{0}, \overrightarrow{X_{2}A^{\prime}}$ in same halfplane with edge $m$, which implies $\overrightarrow{X_{2}B} = \overrightarrow{X_{2}A}^{\prime} $ (Coroll. 12.3)
            \bigbreak \noindent 
            This implies $\overrightarrow{X_{2}B} \subseteq n_{2}$, $n_{1}, n_{2}$ meet in $A$ and $B $
            \bigbreak \noindent 
            Ax.I4 implies $AB = \omega$. Then, $ A\text{-}X_{1}\text{-}B$ and $AX_{1} = BX_{1}$, which implies $ AX_{1} = BX_{1} = \frac{\omega}{2} $ \endpf
        \item \textbf{Theorem 14.6}: If $A$ is a pole of line $m$, then every line through $A$ is perpendicular to $m$, and meets $m$ at a point distance $\frac{\omega}{2} $ from $A$. Also, every line perpendicular to $m$ goes through $A$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Let $X$ be a point on $m$ given by the definition of pole: $\overleftrightarrow{AX} \perp m$ (at $X$), and $AX =\frac{\omega}{2}$
            \bigbreak \noindent 
            Then, $\overleftrightarrow{AX^{*}} \perp m$ at $X^{*}$ by prop 11.14, and $AX^{*} = \omega - AX = \omega - \frac{\omega}{2} = \frac{\omega}{2}$
            \bigbreak \noindent 
            Let $Y$ be any point on $m$, $Y \ne X$ or $X^{*}$. Then, $X,Y,A$ are noncollinear, so $\triangle AXY$ is defined.
            \bigbreak \noindent 
            \fig{.6}{./figures/g7.png}
            \bigbreak \noindent 
            $A^{*}$ is on the opposite side of $m$ from $A$ (Coroll 10.9) and $ A\text{-}X\text{-}A^{*}$ (thm 10.8, 9.1), which implies $\frac{\omega}{2} + XA^{*} = AX + XA^{*} = AA^{*} = \omega$, implies $XA^{*} = \frac{\omega}{2} = XA$; along with $XY = XY$, $ \angle AXY = 90 = \angle A^{*}XY $
            \bigbreak \noindent 
            So, Ax.SAS implies $\triangle AXY \cong  \triangle A^{*}XY$, which implies $\angle AYX = \angle A^{*}YX $
            \bigbreak \noindent 
            Since $\overrightarrow{YA^{*}}  = \overrightarrow{YA}^{\prime}$ (coroll 9.8).
            \bigbreak \noindent 
            Thm 14.1 implies $\overrightarrow{YA}\overrightarrow{YX}$ and $\overrightarrow{YA^{*}YX} $ are supplementary, which implies $\angle AYX + \angle A^{*}YX = 180 $
            \bigbreak \noindent 
            Therefore, $\angle AYX = \angle A^{*}YX = 90$, hence $\overleftrightarrow{AY} \perp m$ at $Y$
            \bigbreak \noindent 
            Also, $ A\text{-}Y\text{-}A^{*}$ implies $ AY + YA^{*} = AA^{*} = \omega$. $\triangle AXY \cong \triangle A^{*}XY$ implies $AY = A^{*}Y$, which implies $AY = A^{*}Y = \frac{\omega}{2} $
            \bigbreak \noindent 
            If $\ell$ is any line perpendicular to $m$, say at point $Z$, we just proved that $ \overleftrightarrow{AZ} \perp m$. By Thm 14.3, $\overleftrightarrow{AZ} = \ell$, so $\ell$ goes through $A$ \endpf
        \item \textbf{Corollary 14.7}: Suppose $\omega < \infty$, each line $m$ has exactly two poles, $A$ and $A^{*}$
        \item \textbf{Definition: \textit{Right triangle}}: A \textbf{right triangle} is a triangle with exactly \textbf{one} right angle.
        \item \textbf{Definition: \textit{Hypotenuse}}: In a right triangle, the \textbf{hypotenuse} is the side opposite the right angle. The \textbf{legs} are the other two sides
        \item \textbf{Definition: \textit{Birectangular triangle}}: A triangle with exactly \textbf{two} right angles is a \textbf{birectangular} (e.g $\triangle ABC$ on $\mathbb{S}$ with $B,C$ on equator, $A = $ north pole). 
        \item \textbf{Definition: \textit{Trirectangular triangle}}: A triangle with three right angles is \textbf{trirectangular}
        \item \textbf{Definition: \textit{small triangle}}: A triangle is \textbf{small} if all sides have length $< \frac{\omega}{2}$. (So when $\omega = \infty$, every triangle is small).
            \bigbreak \noindent 
            If $\triangle ABC$ has more than one right angle (say $\angle B = \angle C = 90$), then $ \overleftrightarrow{AB}, \overleftrightarrow{AC}$ both perpendicular to $ \overleftrightarrow{BC}$, so thm 14.5 implies $A$ is a pole for $\overleftrightarrow{BC}$. Then, Thm 14.6 implies $AB = AC = \frac{\omega}{2}$, which implies $\triangle ABC$ is \textbf{not} small.
    \end{itemize}

    \pagebreak 
    \subsection{The Exterior Angle Inequality and the Triangle Inequality}
    \begin{itemize}
        \item \textbf{Definition: \textit{Cevian}:} A \textbf{Cevian} is a segment from a vertex of a triangle to a point on the opposite side.
            \bigbreak \noindent 
            \fig{.6}{./figures/g8.png}
        \item \textbf{Theorem 15.1 (Cevian theorem)}: Suppose $\omega < \infty$, if $AB < \frac{\omega}{2}$, and $AC \leq \frac{\omega}{2}$ in $\triangle ABC$, and if $ B\text{-}D\text{-}C $ (so $\overline{AD} $ is a cevian of $\triangle ABC$), then $AD < \frac{\omega}{2}$
            \bigbreak \noindent 
            \fig{.6}{./figures/g9.png}
            \bigbreak \noindent 
            \fig{.6}{./figures/g10.png}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Ax.RR implies there's a point $X$ on $\overrightarrow{AB}$ with $AX  = \frac{\omega}{2}$. $AX = \frac{\omega}{2} > AB$ implies $ A\text{-}B\text{-}X$. So, $ \overleftrightarrow{AB} = \overleftrightarrow{AX} , \overrightarrow{AB} = \overrightarrow{AX}$
            \bigbreak \noindent 
            Thm. 14.3 implies there's a line $ n \perp \overleftrightarrow{AB} $ at $X$
            \bigbreak \noindent 
            \fig{.6}{./figures/g11.png}
            \bigbreak \noindent 
            $AX =\frac{\omega}{2}$ and $ \overleftrightarrow{AX} \perp n$ implies $A$ is a pole of $n$. $\overleftrightarrow{AC}$ meets $n$ twice, at a pair of antipodes (Thm. 10.11), one of which will be on $\overleftrightarrow{AC}$, the other on $ \overrightarrow{AC}^{\prime}$. So, $\overrightarrow{AC}$ meets $n$ at a point $E$. 
            \bigbreak \noindent 
            Thm 14.6 implies $AE = \frac{\omega}{2}$, so either $ A\text{-}C\text{-}E $ (if $AC < \frac{\omega}{2}$), or $C = E$ (if $AC = \frac{\omega}{2}$).
            \bigbreak \noindent 
            Let $H$ be the halfplane with edge $n$ that contains $A$. Thm 10.3 and $ X\text{-}B\text{-}A $ implies $ B \in H$
            \bigbreak \noindent 
            If $ A\text{-}C\text{-}E $
            \bigbreak \noindent 
            \fig{.6}{./figures/g12.png}
            \bigbreak \noindent 
            Then Thm 10.3 implies $ C \in H$. $H$ convex implies $ \overline{BC} \subseteq H $, so $ B\text{-}D\text{-}C$ implies $ D \in H$.
            \bigbreak \noindent 
            If $C = E$, 
            \bigbreak \noindent 
            \fig{.6}{./figures/g13.png}
            \bigbreak \noindent 
            Then $ B\text{-}D\text{-}E$ and Thm 10.3 implies $ D \in H$ in this case also
            \bigbreak \noindent 
            $ \overleftrightarrow{AD}$ meets $n$ in a pair of antipodes, so $\overleftrightarrow{AD}$ meets $n$ in a point $Y$, and $AY = \frac{\omega}{2}$ by Thm 14.6
            \bigbreak \noindent 
            $D \in H$, $Y \in n$ implies $D \ne Y$. If $ A\text{-}Y\text{-}D$ then Thm 10.6 implies $A,D$ are in opposite halfplanes, which is false.
            \bigbreak \noindent 
            So, $Y \in \overrightarrow{AD}$, which implies we must have $ A\text{-}D\text{-}Y$. Therefore $AD < AY = \frac{\omega}{2} $
            \bigbreak \noindent 
            \fig{.6}{./figures/g14.png}
            \bigbreak \noindent 
            \endpf
        \item \textbf{Definition: \textit{exterior and remote interior angles}:} Given $ \triangle ABC$, and $D$ a point with $ B\text{-}C\text{-}D$, then $ \underline{\angle ACD} $ is called an \textbf{exterior angle} of $\triangle ABC$, and $ \underline{ \angle A}, \underline{ \angle B}$ are called the \textbf{remote interior angles} (relative to $ \underline{\angle ACD} $)
            \bigbreak \noindent 
            \fig{.6}{./figures/g15.png}
        \item \textbf{Theorem 15.3 (EAI)}: An exterior angle of a small triangle has larger measure than either remote interior angle
            \bigbreak \noindent 
            \fig{.6}{./figures/g15.png}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We aim to show $ \angle ACD > \angle A,\ \angle ACD > \angle B $
            \bigbreak \noindent 
            $ \overline{AC}$ has midpoint $M$, Ceviain Thm and $BA,BC < \frac{\omega}{2}$ (definition of small triangle) implies $ BM < \frac{\omega}{2} $
            \bigbreak \noindent 
            Then, $2BM < \omega$, so Ax.RR implies there is a point $E$ on ray $\overrightarrow{BM}$ with $BE =  2BM > BM$. So, defn of ray implies $ B\text{-}M\text{-}E$, hence $ME = BM $
            \bigbreak \noindent 
            \fig{.6}{./figures/g16.png}
            \bigbreak \noindent 
            \fig{.6}{./figures/g17.png}
            \bigbreak \noindent 
            $ A\text{-}M\text{-}C, B\text{-}M\text{-}E$ and thm 9.6 implies $ \overrightarrow{MC} = \overrightarrow{MA}^{\prime}, \overrightarrow{ME} = \overrightarrow{MB}^{\prime}$, so $ \underline{\angle AMB}, \underline{\angle CME}$ are vertical. Then, Thm 14.2 implies $ \underline{\angle AMB} \cong \underline{\angle CME} $
            \bigbreak \noindent 
            So, $\overline{MA} \cong \overline{MC}, \ \overline{MB} \cong \overline{ME}$, and AX.SAS implies $ \triangle AMB  \cong \triangle CME$.
            \bigbreak \noindent 
            Hence, $\angle MCE  = \angle MAB = \angle CAB$. Ax.C and $ B\text{-}M\text{-}E$ implies $ \overrightarrow{CB}\text{-}\overrightarrow{CM}\text{-}\overrightarrow{CE} $. $ B\text{-}C\text{-}D $ implies $ \overrightarrow{CD} = \overrightarrow{CB}^{\prime} $, which implies $ \overrightarrow{CB}\text{-}\overrightarrow{CE}\text{-}\overrightarrow{CD} $ (Thm 11.8)
            \bigbreak \noindent 
            Then, Thm 11.5 (ROI for rays) implies $ \overrightarrow{CB}\text{-}\overrightarrow{CM}\text{-}\overrightarrow{CE}\text{-}\overrightarrow{CD}$, which implies $ \overrightarrow{CM}\text{-}\overrightarrow{CE}\text{-} \overrightarrow{CD}$. So, $ \angle ACD = \angle MCD = \angle MCE + \angle ECD > \angle MCE = \angle CAB = \angle A$
            \bigbreak \noindent 
            From point $F$ with $ A\text{-}C\text{-}F$, exterior angle $ \underline{\angle BCF}$ vertical to $ \underline{\angle ACD} $. $N = $ midpoint of $\overline{BC}$, $G \in \overrightarrow{AN}$, $NA = NG $ implies $ \triangle BNA \cong\triangle CNG$, which implies $\angle NCG = \angle NBA = \angle B$. Then, $\angle ACD = \angle BCF = \angle NCG + \angle GCF > \angle NCG = \angle B $
            \bigbreak \noindent 
            \fig{.6}{./figures/g18.png}
        \item \textbf{Corollary 15.4 (needs proof)}: The nonright angles of a small right triangle are accute
        \item \textbf{Corollary 15.5 (needs proof)}: The base angles of an isosceles triangle whose congruent sides are $< \frac{\omega}{2}$ are acute.
        \item \textbf{Triangle inequality informal proof sketch}: In any $ \triangle ABC$ (in any absolute plane),
            \begin{align*}
                AB + BC > AC
            .\end{align*}
            Suppose toward a contradiction that in $ \triangle ABC $, $ AB + BC < AC$ (we'll worry later about contradicting $ AB + BC = AC $)
            \bigbreak \noindent 
            Then, there's a point $X$ in $ \overline{AC}$ with $AX = AB$, and a point $ Y$ in $ \overline{XC}$ with $YC = BC$
            \bigbreak \noindent 
            \fig{.6}{./figures/g19.png}
            \bigbreak \noindent 
            Pons asinorum for $ \triangle ABX$ implies $ \angle ABX = \angle BXA (\alpha)$, and $ \triangle BYC$ implies $ \angle CBY = \angle CYB (\beta) $
            \bigbreak \noindent 
            \fig{.6}{./figures/g20.png}
            \bigbreak \noindent 
            If the EAI applies to $ \triangle BXY$, then 
            \begin{align*}
                \beta = \angle BYC > \angle BXY = 180 - \alpha
            .\end{align*}
            Which, implies $ \alpha + \beta > 180$. But, at $B$, $ \alpha + \beta < \angle ABC < 180$, a contradiction
        \item \textbf{Proposition 15.6}: If $AB < \frac{\omega}{2}$, and $ BC \leq \frac{\omega}{2}$ in $ \triangle ABC$, then $AB + BC > AC$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose toward a contradiction that $AB + BC \leq AC$. Then, $0 < BC \leq AC - AB$. So, $AB < AC$
            \bigbreak \noindent 
            By Ax.RR, there is a point $X$ on $\overrightarrow{AC}$ with $AX = AB$, hence $ A\text{-}X\text{-}C $
            \bigbreak \noindent 
            \fig{.6}{./figures/g21.png}
            \bigbreak \noindent 
            Pons asinorum for $ \triangle ABX $ implies $ \angle ABX = \angle BXA$ ($\alpha $).
            \bigbreak \noindent 
            $AX + BC = AC$ implies $ XC = AC - AX = AC - AB \geq BC$ 
            \bigbreak \noindent 
            \textbf{Case 1)} Suppose that $XC = BC$. Pons asinorum for $ \triangle BCX$ implies $ \angle XBC  = \angle BXC$ ($\beta$)
            \bigbreak \noindent 
            \fig{.6}{./figures/g22.png}
            \bigbreak \noindent 
            $ A\text{-}X\text{-}C$ and Ax.C implies $ \overrightarrow{BA}\text{-}\overrightarrow{BX}\text{-}\overrightarrow{BC} $, which implies $ \angle ABC = \alpha + \beta = \angle AXB + \angle BXC = 180$ (Thm 14.1)
            \bigbreak \noindent 
            But, $A,B,C$ not collinear, implies $ \underline{\angle ABC}$ is proper, which implies $ \angle ABC \ne 180$ by Ax. M4, a contradiction.
            \bigbreak \noindent 
            \textbf{Case 2)} Suppose that $ XC > BC$. Ax.RR for $\overrightarrow{CX}$ implies there is a point $Y$ on $\overrightarrow{CX}$ with $CY = BC$. Then, $CY < CX$ implies $ C\text{-}Y\text{-} X$ by definition of $\overrightarrow{CX}$, which implies $  X\text{-}Y\text{-}C$. 
            \bigbreak \noindent 
            Let $M$ be the midpoint of $\overline{XY}$. $BA < \frac{\omega}{2}, BC \leq \frac{\omega}{2}$ (by hypothesis) so Theorem 15.1 implies $ BX,BM,BY < \frac{\omega}{2}$
            \bigbreak \noindent 
            \fig{.6}{./figures/g23.png}
            \bigbreak \noindent 
            $XM = MY = \frac{1}{2}XY < \frac{\omega}{2}$, so $ \triangle BMX, \triangle BMY$ are small.
            \bigbreak \noindent 
            Pons asinorum for $\triangle BYC$ implies $ \angle CBY  = \angle CYB$ ($\beta$). EAI for $\triangle BMY$ implies $ \beta = \angle BYC > \angle BMY$. EAI for $ \triangle BMX \implies \alpha = \angle BXA > \angle BMX $
            \bigbreak \noindent 
            So, $ \alpha + \beta > \angle BMX + \angle BMY = 180 $ (Thm 14.1), but $180 > \angle ABC$ (Ax.M1, M4). We have
            \begin{align*}
                180 &> \angle ABC \\
                    &= \angle ABX + \angle XBC \\
                    &= \angle ABX + \angle XBY + \angle YBC \\
                    &= \alpha + \angle XBY + \beta > \alpha +\beta
            .\end{align*}
            A contradiction, so $ AB  + BC \leq AC$ is false, therefore $AB + BC > AC $
        \item \textbf{Theorem 15.7 (The triangle inequality)}: In any $\triangle ABC$, 
            \begin{align*}
                AB + BC > AC
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} If $AB \geq \frac{\omega}{2}$ and $ BC   \geq \frac{\omega}{2}$, then $AB + BC \geq \omega > AC$. So, we may assume that one of $AB,BC$, say $AB$ is less than $\frac{\omega}{2}$.
            \bigbreak \noindent 
            If $ BC \leq \frac{\omega}{2}$, then $ AB < \frac{omega}{2} $ and prop 15.6 implies $ AB + BC  > AC $. So, we may assume that $BC > \frac{\omega}{2}$and $ AB < \frac{\omega}{2}$. In particular, $\omega < \infty$
            \bigbreak \noindent 
            If $AC \leq \frac{\omega}{2}$, then $AB + BC > BC > \frac{omega}{2} \geq AC$ and we're done. So, we may also assume that $AC > \frac{\omega}{2}$. We now have $AB < \frac{omega}{2} $, $BC > \frac{omega}{2}, AC > \frac{\omega}{2}$
            \bigbreak \noindent 
            $A,B,C^{*}$ are not collinear, since if $ C^{*}$ is on line $ \overleftrightarrow{AB} $, then so is $C$ by Thm. 10.8, a contradiction. So, $\triangle ABC^{*} $ is defined
            \bigbreak \noindent 
            Now, $BC^{*} = \omega - BC$ and $AC^{*} = \omega - AC$. $AC > \frac{\omega}{2} $ implies $AC^{*} < \omega - \frac{\omega}{2} = \frac{\omega}{2} $
            \bigbreak \noindent 
            So, in $\triangle ABC^{*}$, we have $BA < \frac{\omega}{2}$, and $AC^{*} < \frac{\omega}{2}$. Then, prop 15.6 implies that $BA + AC^{*} > BC^{*}$
            \bigbreak \noindent 
            \fig{.6}{./figures/g24.png}
            \bigbreak \noindent 
            So, $BA + (\omega - AC) > (\omega -BC) $ implies $AB + BC > AC$ \endpf
        \item \textbf{Corollary 15.8}: For any points $A,B,C$, $AB + BC \geq AC$. 
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} If $A,B,C $ are not collinear, Thm 15.7 implies $AB + BC > AC$. If $A,B,C$ are collinear and distinct, Thm 7.3 implies $AB + BC \geq AC$
            \bigbreak \noindent 
            If $B = A$ or $C$, then $ AB + BC = AC$. If $A = C$, then $AB + BC \geq 0 = AC$. So, the inequality holds in every case.
        \item \textbf{Theorem 16.1 (Comparison theorem)}: If one angle of a triangle is larger than a second, then the side opposite the lager angle is longer than the side opposite the smaller angle; and conversely. 
            \bigbreak \noindent 
            That is, in $\triangle ABC$, 
            \begin{align*}
                \angle B > \angle C \iff AC > AB
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $\angle B > \angle C$. Ax.RF implies there is a ray $j$ in Fan $\overrightarrow{\overrightarrow{BC}\overrightarrow{BA}} $ so that $\overrightarrow{BC}j = \angle C$. Then, $\overrightarrow{BC}j < \angle B = \angle CBA = \overrightarrow{BC}\overrightarrow{BA}$, which implies $ \overrightarrow{BC}\text{-}j\text{-}\overrightarrow{BA}$
            \bigbreak \noindent 
            $\underline{\overrightarrow{BC}\overrightarrow{BA}}$ is proper, since $A,B,C$ are noncollinear, so the crossbar theorem may be applied.
            \bigbreak \noindent 
            $j^{0}$ meets $\overline{AC}^{0}$ at a point $D$, so $ A\text{-}D\text{-}C$ and $ j = \overrightarrow{BD} $
            \bigbreak \noindent 
            Now, $\angle CBD = \overrightarrow{BC}j = \angle ACB = \angle DCB$ (prop 11.14), so pons asinorum for $ \triangle DBC $ implies $ CD = BD$. Triangle inequality for $ \triangle ADB $ implies 
            \begin{align*}
                AB &< AD + BD \\
                   &= AD + CD = AC
            .\end{align*}
            Therefore, $ AC > AB$
            \bigbreak \noindent 
            If $ \angle C  > \angle B$, then the same argument, reversing the notation $ B \leftrightarrow C$ implies $ AB > AC$.
            \bigbreak \noindent 
            If $ \angle B = \angle C$, then pons asinorum implies $ AC = AB $. Thus,
            \begin{align*}
                \angle B > \angle C \iff AC > AB
            .\end{align*}
        \item \textbf{Corollary 16.2 (Needs proof)}: The hypotenuse of a small right triangle is its longest side
        \item \textbf{Theorem 16.3}: Suppose that in $\triangle ABC$, $ \angle C = 90$ and $AC  < \frac{\omega}{2} $. Then, $\underline{\angle B}$ is acute and $AB  > AC$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} If we can show that $ AB > AC$, then the Comparison Theorem will imply that $\angle C > \angle B$, so $90 = \angle C > \angle B$, hence $\underline{\angle B} $ will be acute. Thus, we aim to show that $ AB > AC $
            \bigbreak \noindent 
            By hypothesis, $ AC < \frac{\omega}{2}$. So, if $ AB \geq \frac{\omega}{2}$, then $ AB > AC$ and we're done. So, we may assume that $AB < \frac{\omega}{2} $
            \bigbreak \noindent 
            Let $M$ be the midpoint of $\overline{BC}$. Then, $BM = CM = \frac{1}{2}BC < \frac{\omega}{2} $. $AM < \frac{\omega}{2}$ by the Cevian Theorem (15.1), so $\triangle ABM$ and $ \triangle ACM$ are both small.
            \bigbreak \noindent 
            In particular, $ \triangle ACM$ is a small right triangle. Coroll. 16.2 implies $AM > AC$ and $ 90 = \angle ACM > \angle AMC$
            \bigbreak \noindent 
            EAI (15.3) for $\triangle AMB$ implies $ \angle AMC > \angle ABM$, so 
            \begin{align*}
                \angle ACM &> \angle ABM \\
                \implies \angle ACB &> \angle ABC
            .\end{align*}
            So, the Comparison theorem 16.1 implies $AB > AC $
        \item \textbf{Definition:} for any line $m$ and point $A$, the \textbf{distance between $A$ and $m$}, denoted $d(A,m)$, is the minimum distance $AX$ for all points $X$ on $m$.
            \bigbreak \noindent 
            \textbf{Note:} If $A$ is on $m$, then $d(A,m) = AA = 0$
        \item \textbf{Theorem 16.8}: Let $m$ be a line, $C \in m$, $A \not\in m$, $\overleftrightarrow{AC} \perp m$
            \begin{enumerate}[label=(\alph*)]
                \item If $AC < \frac{\omega}{2}$ then $d(A,m) = AC$; and $AC < AX$, all $X \ne C$ on $m$
                \item If $AC = \frac{\omega}{2}$ (so $\omega<\infty$), then $d(A,m) = \frac{\omega}{2} = AX$, all $X \in m$
                \item If $AC > \frac{\omega}{2}$ (so $\omega<\infty$), then $d(A,m)  = \omega - AC = AC^{*}$; and $AC^{*} < AX$, all $X \ne C^{*}$ on $m$
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} 
            \bigbreak \noindent 
            (a) Suppose $\overleftrightarrow{AC} \perp m$ and $AC < \frac{\omega}{2}$. If $ X \in m$ with $X \ne C$ or $C^{*}$, then $A,C,X$ are not collinear, so $\triangle ACX$ exists. Then, Thm. 16.3 implies $AC < AX$. If $X = C^{*}$, then $AX = AC^{*} = \omega - AC > \frac{\omega}{2} $ , since $AC < \frac{\omega}{2} $ so again $AC < AX$
            \bigbreak \noindent 
            (b) Suppose $\overleftrightarrow{AC} \perp m$ and $ AC = \frac{\omega}{2} $. Then $A$ is a pole of $m$, so Thm 14.6 implies $AX = \frac{\omega}{2}$ for all $X$ on $m$
            \bigbreak \noindent 
            (c) Suppose $\overleftrightarrow{AC} \perp m$ and $AC > \frac{\omega}{2}$. Then, $AC^{*} = \omega - AC < \frac{\omega}{2}$. $C^{*}$ is on $m$ (Thm 10.8), and $\overleftrightarrow{AC^{*}} \perp m$ at $C^{*}$ (prop 11.14), so part (a) implies $AC^{*} < AX$ for all $X \ne C^{*}$ on $m$
    \end{itemize}

    \pagebreak 
    \subsection{Extra}
    \begin{itemize}
        \item \textbf{Definition: \textit{parallel lines}}: Two lines $m\ne n$ are called \textbf{parallel} if $m \cap n = \varnothing$. If so, we write $m \parallel n $
            \bigbreak \noindent 
            Suppose a point $P$ is not on a line $m$. There are exactly three mutually exclusive possibilities
            \begin{enumerate}[label=(\roman*)]
                \item There is no line through $P$ parallel to $m$ 
                \item There is exactly one line through $P$ parallel to $m$
                \item There are at least two lines through $P$ parallel to $m$
            \end{enumerate}
        \item \textbf{Definition} An absolute plane in which $(i)$ holds for every line $m$ and point $P$ not on $m$ (ie no parallel lines) is called \textbf{spherical}
            \bigbreak \noindent 
            An absolute plane in which (ii) holds for every line $m$ and point $P$ not on $m$ is called \textbf{Euclidean}
            \bigbreak \noindent 
            An absolute plane in which (iii) holds for every line $m$ and point $P$ not on $m$ is called \textbf{Hyperbolic}
            \bigbreak \noindent 
            These properties do not mix, only one must hold per absolute plane. 
        \item \textbf{Theorem}: In any absolute plane $\mathbb{P}$, exactly one of the following must occur.
            \begin{enumerate}[label=(\roman*)]
                \item $\mathbb{P}$ is Spherical; $\sigma(ABC) = \angle A + \angle B + \angle C > 180$ for all $\triangle ABC$, and $\omega < \infty $ 
                \item $\mathbb{P}$ is Euclidean; $\sigma(ABC) = \angle A + \angle B + \angle C = 180$ for all $\triangle ABC$, and $\omega = \infty $ 
                \item $\mathbb{P}$ is Hyperbolic; $\sigma(ABC) = \angle A + \angle B + \angle C < 180$ for all $\triangle ABC$, and $\omega = \infty $ 
            \end{enumerate}
            \bigbreak \noindent 
            $\mathbb{S},\ \mathbb{E}$, and $\mathbb{H} $ are essentially the only examples, up to isometry.
        \item \textbf{Theorem (\textit{AAA})}: Suppose that $\triangle ABC$ and $\triangle XYZ$ are triangles in a non-Euclidean absolute plane with $\angle A = \angle X$, $ \angle B = \angle Y$, and $ \angle C = \angle Z$. Then, $\triangle ABC \cong \triangle XYZ$
    \end{itemize}

    \pagebreak 
    \unsect{Set-theoretic asides}
    \subsection{Sets and structure}
    \begin{itemize}
        \item \textbf{Binary relation}: Consider a set $X$, a binary relation $ \leq_{X}$ on $X$ is defined to be any subset of $X \times X $, so
            \begin{align*}
               \leq_{X} \subseteq X\times X 
            .\end{align*}
            Thus, $ \leq_{X}$ is a set of ordered pairs $(x,y)$, with $x,y \in X $. If $(x,y) \in \leq_{X}$ for $x,y \in X$, then
            \begin{align*}
                x \leq_{X} y    
            .\end{align*}
            So, $(x,y) \in \leq_{X} \iff x \leq_{X} y$
        \item \textbf{Ordered sets}: An ordered set is a set equipped with a relation that allows you to compare elements in a consistent way.
            \bigbreak \noindent 
            An ordered set is a pair
            \begin{align*}
                (X, \leq_{X})
            ,\end{align*}
            where $X$ is a set and $\leq_{X}$ is a binary relation on $X$ satisfying certain axioms. The exact axioms depend on the type of order. This notation is shorthand for "the ordered set $X$ with order $ \leq_{X} $"
            \bigbreak \noindent 
            When we write
            \begin{align*}
                (X, \leq_{X})
            ,\end{align*}
            we are saying For any two elements $x,y\in X$, the relation $ \leq_{X} $ specifies whether $x$ is below $y$, equal to $y$, or incomparable with $y$. Without the relation, $X$ is just an unordered set.
            \bigbreak \noindent 
            so, $(X, \leq_{X}) $ means we are taking the unordered set $X$, and giving it the structure $ \leq_{X}$ so that we can order the elements in $X$. If $(x,y) \in \leq_{X}$, then
            \begin{align*}
                x \leq_{X} y
            ,\end{align*}
            and we can say that $x$ is below $y$ in the order of $X$. If $(x,y) \not\in \leq_{X} $, these elements are still in $X$, but we cannot say anything about their ordering relative to each other in $X$.
            \bigbreak \noindent 
            So, $(X, \leq_{X}) $ is not a subset of $X$, it is a set equipped with structure, a pair than consists of a set, and a binary relation that uses that set for elements.
       \item \textbf{Partial order}: A relation $ \leq_{X} $ on $X$ is a \textbf{partial order} if, for all $x,y,z \in X $
            \begin{enumerate}
                \item \textbf{Reflexive}: $x \leq_{X} x $
                \item \textbf{Antisymmetric}: If $x \leq_{X} y $ and $y \leq_{X} x $, then $x = y $
                \item \textbf{Transitive}: If $x \leq_{X} y $, and $y \leq_{X} z $, then $x \leq_{X} z  $
            \end{enumerate}
            A set equipped with a partial order is called a partially ordered set, or poset.
        \item \textbf{Total (linear) orders}: A partial order $ \leq_{X}$ is a \textbf{total order} if for all $x,y \in X $, 
            \begin{align*}
                x \leq_{X} y \quad \text{ or } y \leq_{X} x
            .\end{align*}
        \item \textbf{Strict orders}: Sometimes the strict relation $<_{X} $ is used instead of $ \leq_{X} $. A strict order satisfies
            \begin{enumerate}
                \item \textbf{Irreflexivity}: $x \not<_{X} x $
                \item \textbf{Transitivity}: $x <_{X} y$ and $y <_{X} z  $ implies $x <_{X} z  $
            \end{enumerate}
            Strict and non-strict orders are interdefinable:
            \begin{align*}
                x <_{X} y \iff x \leq_{X} y \text{ and } x \ne y
            .\end{align*}
        \item \textbf{Number sets}: When we use the number sets $\mathbb{N}, \mathbb{Z}, \mathbb{Q}, \mathbb{\bar{Q}}, \mathbb{R}$, or $\mathbb{C} $ we are talking about that set equipped with the usual numerical order $ \leq$. This is the standard total (linear) order.
        \item \textbf{Natural numbers partially ordered by divisibility}: Consider
            \begin{align*}
                (\mathbb{N}, \mid)
            .\end{align*}
            So,
            \begin{align*}
                \mid \subseteq \mathbb{N} \times \mathbb{N}
            .\end{align*}
            If $(x,y) \in \mid$, for $x,y \in \mathbb{N}$, then
            \begin{align*}
                x \mid y
            ,\end{align*}
            or $x$ "divides" $y$, so there exists $k \in \mathbb{N} $ such that
            \begin{align*}
                y = kx
            .\end{align*}
            $x \mid x $ if there exits $k \in \mathbb{N} $ such that $x = kx$. Fortunately, $1 \in \mathbb{N} $, so $x = 1x = x $. Thus, divisibility on $\mathbb{N} $ is reflexive.
            \bigbreak \noindent 
            Suppose that $x \mid y $, and $y \mid x$, then there exists $k,\ell \in \mathbb{N} $ such that
            \begin{align*}
                y = kx, \quad \text{ and } x = \ell y
            .\end{align*}
            So 
            \begin{align*}
              y = k \left(\ell y\right)  
            ,\end{align*}
            which implies $k = \frac{1}{\ell}$, and $\ell = \frac{1}{k}$. But, $k,\ell \in  \mathbb{N}$, so $k = \ell = 1 $. Thus,
            \begin{align*}
                x = 1y = y
            .\end{align*}
            So, divisibility on $\mathbb{N}$ is antisymmetric. Next, suppose $x \mid y $, and $y \mid z $. So, there exists $k,\ell \in \mathbb{N} $ such that
            \begin{align*}
                y = kx, \quad \text{ and } z = \ell y
            .\end{align*}
            We can say that $x \mid z $ if there exists $s \in \mathbb{N} $ such that $z = sx $. Since $y=kx $ and $z = \ell y $, 
            \begin{align*}
               z = \ell (kx) 
            .\end{align*}
            By commutativity of multiplication, 
            \begin{align*}
                z = (\ell k)x
            .\end{align*}
            And, since $\ell k \in \mathbb{N}$, $x \mid Z $. So, divisibility on $\mathbb{N} $ is transitive.
            \bigbreak \noindent 
            Therefore, $(\mathbb{N}, \mid) $ is partially ordered. But, consider $x,y \in \mathbb{N} $, where $x = 2\ell $, and $y = 2k+1 $ for $k,\ell \in \mathbb{N} $. Then, $x \mid y $  implies that
            \begin{align*}
                2\ell \mid 2k+1
            .\end{align*}
            Assume for the sake of contradiction that $2\ell \mid 2k+1$. Then, there exist $m \in \mathbb{N} $ such that
            \begin{align*}
                2k+1 = m(2\ell) = 2(m\ell)
            .\end{align*}
            But, notice that the $2k+1$ is odd, while $2(m\ell)$ is even. Since an odd number cannot equal an even number, a contradiction. So, we found two numbers, $x,y \in \mathbb{N} $ that is not a member of the binary relation $ \mid$. So, divisibility on $\mathbb{N} $ is not a total ordering.

        \item \textbf{Disjoint unions}: Let $\{A_{i}\}_{i\in I} $ be a family of sets, the notation
            \begin{align*}
                \bigsqcup A_{i}
            \end{align*}
            means the union of the sets of $A_{i} $, with the additional information that they are considered pairwise disjoint. Formally, even if the sets overlap, the disjoint union treats them as distinct by tagging elements with their index.
            \bigbreak \noindent 
            The disjoint union is defined as
            \begin{align*}
               \bigsqcup_{i\in I}A_{i} := \bigcup_{i\in I} \left(A_{i} \times \{i\}\right) 
            .\end{align*}
            So, an element is not just a set $a\in A_{i}$, but a pair $(a,i) $. Formally, even if the sets overlap, the disjoint union treats them as distinct by tagging elements with their index.
            \bigbreak \noindent 
            For example, suppose $A_{1} = \{1,2\} $, and $A_{2} = \{2,3\} $. The ordinary union is 
            \begin{align*}
                \bigcup_{i=1}^{2} A_{i} =  A_{1} \cup A_{2} = \{1,2,3,\}
            ,\end{align*}
            whereas the disjoint union is 
            \begin{align*}
                \bigsqcup_{i=1}^{2} = A_{1} \sqcup A_{2} = \{(1,1),(2,1),(2,2), (3,2)\}
            .\end{align*}




    \end{itemize}

    \pagebreak 
    \subsection{Spaces}
    \begin{itemize}
        \item \textbf{The product space}: The product space is the natural mathematical construction that allows us to treat pairs of elements as single objects, while retaining the structure of each component space.
            \bigbreak \noindent 
            Let $A$ and $B$ be sets. The \textbf{product space} (or Cartesian product) is
            \begin{align*}
                A \times B = \{(a,b):\; a \in A,\; b\in B\}
            .\end{align*}
        \item \textbf{Product spaces and vector spaces}: If $V$ and $W$ are vector spaces over the same field $\mathbb{F}$, then 
            \begin{align*}
                V \times W
            \end{align*}
            is again a vector space, with operations defined componentwise, for $(v_{1}, w_{1}), (v_{2}, w_{2}) \in V\times W$, 
            \begin{align*}
                (v_{1}, w_{1}) + (v_{2}, w_{2}) = (v_{1} + v_{2}, w_{1} + w_{2}) \in V \times W
            .\end{align*}
            For $(v, w) \in V\times W $, and $\alpha \in \mathbb{F} $, 
            \begin{align*}
                \alpha(v,w) = (\alpha v, \alpha w) \in V\times W
            .\end{align*}
            Also, its dimension satisfies 
            \begin{align*}
                \text{dim}\left(V\times W\right) = \text{dim}\left(V\right) + \text{dim}\left(W\right)
            .\end{align*}
            For example, 
            \begin{align*}
                \mathbb{R}^{2} \times \mathbb{R} \cong \mathbb{R}^{3}
            .\end{align*}
            Thus, there exists a linear structure preserving bijection 
            \begin{align*}
                \Phi:\; \mathbb{R}^{2} \times \mathbb{R} \to \mathbb{R}^{3}, \quad \Phi((x,y),z) = (x,y,z)
            .\end{align*}
            With inverse,
            \begin{align*}
                \Phi^{-1}(x,y,z) = ((x,y),z)
            .\end{align*}
        \item \textbf{Ambient spaces}: The ambient space is the larger space in which the objects under study naturally live. It provides the surrounding structure—coordinates, topology, metric, algebraic operations—needed to define and analyze those objects.
            \bigbreak \noindent 
            An ambient space is not the object of primary interest; it is the context that makes the object meaningful. The object is typically a subset, subspace, or embedded structure inside the ambient space.
            \bigbreak \noindent 
            Formally, if $X \subseteq A $, then $A$ is the ambient space for $X$.
            \bigbreak \noindent 
            A circle defined by $x^{2} + y^{2} = 1 $ has ambient space $\mathbb{R}^{2}$. The circle itself is one-dimensional, but distances, angles, and curvature are defined using the surrounding plane.
            \bigbreak \noindent 
            For a function $f:\; \mathbb{R}^{n} \to \mathbb{R} $, the graph
            \begin{align*}
                \mathcal{G}(f) = \{(x,f(x)):\; x\in \mathbb{R}^{n}\}
            \end{align*}
            has ambient space $\mathbb{R}^{n+1} $. Although the graph is $n$-dimensional, it lives inside a higher-dimensional space
            \bigbreak \noindent 
            A plane through the origin in $\mathbb{R}^{3} $ is a 2-dimensional subspace. Its ambient space is $\mathbb{R}^{3}$, which determines dot products, orthogonality, and projections.
        \item \textbf{Higher dimensional ambient spaces}: If an object is $n$-dimensional, then any space that can contain an embedding of it may serve as an ambient space.
            \bigbreak \noindent 
            Formally, if 
            \begin{align*}
                X \hookrightarrow \mathbb{R}^{n+k}
            ,\end{align*}
            then $\mathbb{R}^{n+k} $ is a valid ambient space for $X$, for any $k \geq 1 $. There is no rule forcing $k=1$.  However, the ambient space $\mathbb{R}^{n+1}$ is common because it is often the minimal convenient choice. A graph of a function $f:\; \mathbb{R}^{n} \to \mathbb{R} $ naturally lives in $\mathbb{R}^{n+1}$.
        \item \textbf{Codimension}: The number
            \begin{align*}
                k = (\text{dimension of ambient space}) - (\text{dimension of object})
            \end{align*}
            is called the \textbf{codimension}. There is no upper bound on codimension in principle.
        \item \textbf{Morphism spaces}:  Given two sets (or spaces) $A$ and $B$, there are two fundamentally different kinds of objects you can consider:
            \begin{itemize}
                \item \textbf{Points} in $A$ or $B$
                \item \textbf{Maps} from $A$ to $B$
            \end{itemize}
            A morphism space is the collection of all maps of a specified type between two objects.
            \bigbreak \noindent 
            For two objects $A$ and $B$, 
            \begin{align*}
                \text{Hom}(A,B)
            \end{align*}
            denotes the set (or space) of all structure-preserving maps from $A$ to $B$. 
            \bigbreak \noindent 
            \textbf{Note:} Hom means homomorphism, because a homomorphism is a map that preserves the relevant algebraic structure.


    \end{itemize}

    \pagebreak 
    \subsection{Functions}
    \begin{itemize}
        \item \textbf{Image under a function}: Suppose $A$ and $B$ are sets, and 
            \begin{align*}
                f:\; A \to B
            \end{align*}
            is a function. For an element $a\in A$, the \textbf{image} of $a$ under $f$ is the element
            \begin{align*}
                f(a) \in B
            .\end{align*}
            For a subset $S \subseteq A$,  the \textbf{image} of $S$ under $f$ is
            \begin{align*}
                f(S) := \{f(a)\in B:\; a \in S\}
            .\end{align*}
            So, the set of all outputs obtained by applying $f$ to elements of $S$.
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{image}
                \label{fig:image}
            \end{figure}
            \bigbreak \noindent 
            \textbf{Note:} The red inputs may exist if $f$ is not injective.
        \item \textbf{Preimage under a function}: For a subset $T \subseteq B $, the \textbf{preimage} of $T$ under $f$ is
            \begin{align*}
                f^{-1}(T) := \{a \in A:\; f(a) \in T\}
            .\end{align*}
            For an element $b \in B$, the preimage is the set
            \begin{align*}
                f^{-1}(\{b\}) := \{a \in A:\; f(a) = b\}
            .\end{align*}
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{preimage2}
                \label{fig:preimage2}
            \end{figure}
            \bigbreak \noindent 
            \textbf{Note:} The red outputs may exist if $f$ is not surjective. If $f$ is not surjective, then it could be the case that some elements of $T$ are not hit by $f$. In this case, not all elements of $T$ have a preimage in $A$.
        \item \textbf{The image of the preimage, encoding surjectivity}: Suppose $A$ and $B$ are sets, and
            \begin{align*}
                f:\; A \to B
            \end{align*}
            is a function from $A$ to $B$. Let $T \subseteq B$. Then, the preimage of $T$ under $f$ is the set
            \begin{align*}
                f^{-1}(T) := \{a \in A:\; f(a) \in T\}
            .\end{align*}
            Then, the image of the preimage of $T$, $f^{-1}(T)$, is the set
            \begin{align*}
                f(f^{-1}(T)) = \{f(a):\; a\in f^{-1}(T)\} = \{f(a):\; f(a) \in T\} \subseteq T
            .\end{align*}
            If $f$ is not surjective, and some elements of $T$ do not have a preimage in $A$, then $f(f^{-1}(T)) \subset T$. Otherwise, $f$ is surjective and $f(f^{-1}(T)) = T$.
            \bigbreak \noindent 
            So, $f(f^{-1}(T)) $ removes the elements of $T$ that are not hit by $f$. Thus, we can say that $f$ is surjective if and only if for any subset $T \subseteq B$,
            \begin{align*}
                f(f^{-1}(T)) = T
            .\end{align*}
            Otherwise, if $f(f^{-1}(T)) \subset T$, then $f$ is not surjective. So, we say that $f(f^{-1}(T)) $ encodes surjectivity.
        \item \textbf{The preimage of the image, encoding injectivity}: Suppose $A$ and $B$ are sets, and 
            \begin{align*}
                f:\; A \to B
            \end{align*}
            is a function from $A$ to $B$. Let $S \subseteq A$. Then, the image of $S$ under $f$ is the set
            \begin{align*}
               f(S) = \{f(a) \in B:\; a \in S\} 
            .\end{align*}
            So, the preimage of $f(S)$ is the set
            \begin{align*}
                f^{-1}(f(S)) = \{a \in A:\; f(a) \in f(S)\} = \{a\in A:\; \exists s \in S \text{ with } f(a) = f(s)\}
            .\end{align*}
            Now, notice that if $f$ is injective, then all elements in $f(S)$ must have their preimage in $S$. So, if we take the preimage of the entirety of $f(S)$, then we get back $S$. Therefore, if $f$ is injective, 
            \begin{align*}
                f^{-1}(f(S)) = S
            .\end{align*}
            However, suppose $f$ is not injective. Consider some element $s \in S$ with image $f(s) \in f(S)$. It could be the case that there exists some $a \in A$,  $a \not\in S$ with $f(a) = f(s) $. Notice that this element $a\in A \setminus S$ then belongs to the preimage of $f(S)$, $f^{-1}(f(S))$.
            \bigbreak \noindent 
            Hence, if $f$ is not injective, then
            \begin{align*}
                S \subseteq f^{-1}(f(S))
            .\end{align*}
            So, $f^{-1}(f(S)) $ encodes injectivity. $f^{-1}(f(S))$ is the set $S$, along with any additional points in $A$ that have images in $f(S) $. These additional points only appear if $f$ is not injective.
            \bigbreak \noindent 
            Therefore, for any subset $S \subseteq A$, $f$ is injective if and only if 
            \begin{align*}
                f^{-1}(f(S)) = S
            .\end{align*}
            If $f^{-1}(f(S)) \supset S$ for any subset $S$ of $A$, then $f$ is not injective.
        \item \textbf{Properties of image and preimage}: For sets $A, B$, and a function $f:\ A \to B$, the following properties hold for any subset $S \subseteq A$ and $T \subseteq B$:
            \begin{enumerate}
                \item $f(f^{-1}(T)) \subseteq T$
                \item $f^{-1}(f(S)) \supseteq S$
            \end{enumerate}
            Also, preimages preserve set operations, 
            \begin{align*}
                &f^{-1}(T_1 \cup T_2) = f^{-1}(T_1) \cup f^{-1}(T_2), \\ 
                &f^{-1}(T_1 \cap T_2) = f^{-1}(T_1) \cap f^{-1}(T_2)
            .\end{align*}
        \item \textbf{Endofunction}: If $X$ is a set, a function
            \begin{align*}
                f:\; X \to X
            \end{align*}
            is called an \textbf{endofunction on $X$} 
            \bigbreak \noindent 
            \textbf{Note:} If $f$ is a bijection, then we can say $f$ is a \textbf{bijection on $X$}, whereas if the codomain is some other set $Y$, we would say that $f$ is a bijection from $X$ to $Y$.
        \item \textbf{Bijective endofunction}: If $X$ is a set, a function
            \begin{align*}
                f:\; X \to X
            \end{align*}
            that is bijective is called a permutation of $X$. The set of all permutations of $X$ forms the symmetric group on $X$, denoted $\text{Sym}(X) $. If $X = \{1,\dots, n\} $, then this group is $S_{n}$.
            \bigbreak \noindent 
            If $f$ is a bijection on $X$, then $f$ is a member of $\text{Sym}(X) $.
        \item \textbf{Bijection}: A function
            \begin{align*}
                f:\; X \to Y
            \end{align*}
            that is both surjective and injective (bijective) is called a \textbf{bijection} from $X$ to $Y$.
        \item \textbf{Surjection}: A function
            \begin{align*}
                f:\; X \to Y
            \end{align*}
            that is surjective is called a \textbf{surjection} from $X$ to $Y$.
        \item \textbf{Injection}: A function
            \begin{align*}
                f:\; X \to Y
            \end{align*}
            that is injective is called an \textbf{injection} from $X$ to $Y$.
        \item \textbf{Structure preserving}: "Structure-preserving" means that the map respects the operations and axioms that define the object you are working with. The phrase is intentionally generic; its precise meaning depends on what structure the set carries.
            \bigbreak \noindent 
            A structure on a set is:
            \begin{itemize}
                \item A collection of operations (e.g., addition, scalar multiplication),
                \item Possibly distinguished elements (e.g., zero),
                \item And axioms relating them.
            \end{itemize}
            For a vector space $V$, this structure is 
            \begin{itemize}
                \item Vector addition 
                \item Scalar multiplication by elements of a field  $\mathbb{F} $
                \item The vector space axioms.
            \end{itemize}
            A map preserves structure if doing the operation before or after applying the map gives the same result
            \begin{center}
                Apply operation $\; \leftrightarrow \; $ apply map
            \end{center}
            The map "commutes" with the operations.
        \item \textbf{Morphisms}: A morphism is a structure-preserving map between objects of the same type.
            \bigbreak \noindent 
            A morphism
            \begin{align*}
                f:\; X \to Y
            \end{align*}
            must preserve the structure of $X$ as expressed inside $Y$. So, $f$ is a morphism if it preserves the structure \textbf{carried by} $X$ in a way that is compatible with the \textbf{structure on} $Y$.
            \bigbreak \noindent 
            Performing an operation in $X$, then applying $f$, gives the same result as first applying $f$ and then performing the corresponding operation in $Y$.
            \bigbreak \noindent 
            The structure being preserved is the type of structure common to both $X$ and $Y$.
            \bigbreak \noindent 
            A morphism is defined relative to a specified structure. If a map preserves some operations but not all of the operations that define a structure, then the map is \textbf{not} a morphism of that structure. However, it may still be a morphism of a reduced structure obtained by forgetting some operations.
        \item \textbf{Homomorphism}: A homomorphism is a structure-preserving map between algebraic objects of the same type.
        \item \textbf{Linear maps over vector spaces}:  
            Let
            \begin{align*}
                T : V \to W
            \end{align*}
            be a linear map, where $V$ and $W$ are vector spaces over a field $\mathbb{F}$.  
            The structure of a vector space consists of vector addition and scalar multiplication.  
            A map preserves structure if applying a vector space operation before the map yields the same result as applying the map after the operation.
            \bigbreak \noindent
            Let $v_1, v_2 \in V$. Since
            \begin{align*}
                T(v_1 + v_2) = T(v_1) + T(v_2),
            \end{align*}
            the map $T$ preserves vector addition. Moreover, for $\alpha \in \mathbb{F}$ and $v \in V$,
            \begin{align*}
                T(\alpha v) = \alpha T(v),
            \end{align*}
            so $T$ also preserves scalar multiplication.  
            Therefore, linear maps are morphisms of vector spaces.

        \item \textbf{Endomorphism}: If $X$ is a set equipped with some structure, for example a vector space, then a map
            \begin{align*}
                f:\; X \to X
            \end{align*}
            that preserves the structure of $X$ is called an endomorphism. A linear operator $T:\; V \to V $ is an endomorphism of $X $
        \item \textbf{Isomorphism}: If $X$ and $Y$ sets with some structure, and
            \begin{align*}
                f:\; X \to Y
            \end{align*}
            is a bijective morphism whose inverse is also a morphism, then $f$ is called an \textbf{isomorphism}, or \textbf{isomorphic}.
            \bigbreak \noindent 
            This means that $X$ and $Y$ have the same structure
            \bigbreak \noindent 
            \textbf{Note:} If two spaces $V$, and $W$ are isomorphic, then we can use the symbol $\cong $,
            \begin{align*}
                V \cong W
            \end{align*}
            to signify that there exists an isomorphism between the two spaces.

        \item \textbf{Automorphism}: If
            \begin{align*}
                f:\; X \to X
            \end{align*}
            is a bijective endomorphism, the $f$ is an \textbf{automorphism}. For example, an invertible linear operator.
        \item \textbf{Summary, self maps (endofunctions)}: If $X$ is a set, and
            \begin{align*}
                f:\; X \to X
            \end{align*}
            is an \textbf{endofunction} of $X$, then $f$ is an \textbf{endomorphism} of $X$ if $f$ preserves the structure of $X$, and an \textbf{automorphism} of $X$ if $f$ is bijective and structure preserving (endomorphism).
            \bigbreak \noindent 
            So,
            \begin{align*}
                \text{automorphisms } \subset \text{ endomorphisms } \subset \text{ endofunctions}
            .\end{align*}
        \item \textbf{Non-self maps}: Suppose $X$ and $Y$ are sets, and 
            \begin{align*}
                f:\; X \to Y
            \end{align*}
            is a function from $X$ to $Y$. If $f$ preserves 
        \item \textbf{Homogeneous function}: A homogeneous function is a function whose value scales in a predictable way when its input is scaled.
            \bigbreak \noindent 
            Let $V$ and $W$ be vector spaces over a field $\mathbb{F}$, a function
            \begin{align*}
                f:\; V \to W
            \end{align*}
            is called \textbf{homogeneous of degree $k$}, or \textbf{degree-$k$ homogeneous} if, for all $v \in V $, and $\alpha \in \mathbb{F} $, 
            \begin{align*}
                f(\alpha v) = \alpha^{k}f(v)
            .\end{align*}
            For example, 
            \begin{align*}
                f(\alpha v) = \alpha f(v)
            \end{align*}
            is a function homogeneous of degree $1$. This is often called positively homogeneous or 1-homogeneous. If 
            \begin{align*}
                f(\alpha v ) = f(v)
            ,\end{align*}
            this function is degree-0 homogeneous. The function is invariant under scaling.
            \bigbreak \noindent 
            Every linear map $T:\; V \to W$ is degree-1 homogeneous. The determinant is degree-$n$ homogeneous, for $A \in \mathbb{R}^{n\times n}$, since
            \begin{align*}
                \det(\alpha A) = \alpha^{n} \det(A)
            .\end{align*}
        \item \textbf{Monotone (order-preserving) functions}: Let $(X, \leq_{X}) $ and $(Y, \leq_{Y}) $ be ordered sets. A function
            \begin{align*}
                f:\ X \to Y
            \end{align*}
            is order-preserving (or monotone increasing) if
            \begin{align*}
                x_{1} \leq_{X} x_{2} \implies f(x_{1}) \leq_{Y} f(x_{2})
            .\end{align*}
            Monotone increasing functions respect the ordering. Larger inputs do not map to smaller outputs.
            \bigbreak \noindent 
            For example, suppose $(X, \leq)$, $(Y, \leq)$, and 
            \begin{align*}
                f:\; X \to Y \quad f(x) = ax
            \end{align*}
            for $a \ne 0$. Let $x_{1}, x_{2} \in X $, with $x_{1} \leq x_{2} $. Then, $f(x_{1}) =ax_{1}$, and $f(x_{2}) = ax_{2}$. So,
            \begin{align*}
                ax_{1} \leq ax_{2} \iff x_{1} \leq x_{2}
            .\end{align*}
            So, $f$ is monotone increasing. 
        \item \textbf{Antitone (Order reversing) functions}: A function
            \begin{align*}
                f:\; X \to X
            \end{align*}
            is order-reversing (antitone) if 
            \begin{align*}
                x_{1} \leq_{X} x_{2} \implies f(x_{1}) \geq_{Y} f(x_{2})
            .\end{align*}
            The function flips the order, larger inputs map to smaller outputs. For example, $f(x) = -x$ on $\mathbb{R} $.
        \item \textbf{Idempotent}: A function
            \begin{align*}
                f:\; X \to X
            \end{align*}
            is idempotent if
            \begin{align*}
                f \circ f = f \quad \text{ i.e. } \quad f(f(x)) = f(x) \; \text{for all $x \in X $}
            .\end{align*}
            Applying the function \textbf{more than once has no additional effect}. For example, projection onto a subspace $P^{2} = P $. Idempotent maps often encode \textbf{projection or stabilization}.
        \item \textbf{Identity map}: Let $M$ be a map, 
            \begin{align*}
                M:\; X \to X
            .\end{align*}
            The \textbf{identity map} id for the underlying set ($X$) is the map
            \begin{align*}
                \text{id}\; X \to X,\quad \text{id}(x) = x
            \end{align*}
            for all $x \in X $.
        \item \textbf{Zero map}: Let $X$ be a set and $Y$ be a set equipped with a distinguished element $0 \in Y $. The zero map
            \begin{align*}
                Z:\; X \to Y
            \end{align*}
            is defined by
            \begin{align*}
                Z(x) = 0 \quad \text{for all } x \in X
            .\end{align*}
        \item \textbf{Involution}: A function
            \begin{align*}
                f:\; X \to X
            \end{align*}
            is an \textbf{involution} if 
            \begin{align*}
                f \circ f = \text{id}_{X}
            .\end{align*}
            The function is its own inverse. Matrix transposition is an involution. Recall the transpose map
            \begin{align*}
                T:\; M_{n\times n}(\mathbb{F}) \to M_{n\times n}(\mathbb{F}),\quad T(A) = A^{T}
            .\end{align*}
            Consider $T(T(A)) $,
            \begin{align*}
                T(T(A)) = T(A^{T}) = (A^{T})^{T} = A
            .\end{align*}
            Thus, $T \circ T = \text{id} $, so $T$ is an involution.
        \item \textbf{Nilpotent}: A function
            \begin{align*}
                f:\; X \to X
            \end{align*}
            is nilpotent if there exists $k \geq 1 $ such that
            \begin{align*}
                f^{k} = 0
            ,\end{align*}
            where  0 is the zero map. Repeated application of the map \textbf{kills everything}.
        \item \textbf{A function and its graph}: A function is a triple
            \begin{align*}
                f:\; A \to B
            \end{align*}
            consisting of
            \begin{itemize}
                \item A domain $A $
                \item A codomain $B$
                \item A rule assigning to each $a\in A$ a \textbf{single element} $f(a) \in B $
            \end{itemize}
            A function is not a set of points in space, it lives in a morphism space, not in the ambient space.
            \bigbreak \noindent 
            For example, 
            \begin{align*}
                f(x,y) = x^{2} + y^{2}
            \end{align*}
            is a rule from $\mathbb{R}^{2}$ to $\mathbb{R}$. The \textbf{graph} of $f$ is a \textbf{subset} of the product space $A \times B $
            \begin{align*}
                \text{Graph}(f) = \{(a,b) \in A \times B:\; b = f(a)\}
            .\end{align*}
            For $f:\; \mathbb{R}^{2} \to \mathbb{R}$,
            \begin{align*}
                \text{Graph}(f) = \{(x,y,z) \in \mathbb{R}^{3}:\; z = f(x,y)\} 
            .\end{align*}
            \textbf{This} is the geometric object. A function by itself has no geometry until you embed it into a set of points. The graph is such an embedding, the embedding into the product space.
            \bigbreak \noindent 
            So, a function lives in a space of maps, the graph lives in the product space.



    \end{itemize}

    \pagebreak 
    \subsection{Sums and products}
    \begin{itemize}
        \item \textbf{Bijective reindexing}: Let $A$ be a finite set, and
            \begin{align*}
                f:\; A \to \mathbb{R}
            \end{align*}
            be any function. If 
            \begin{align*}
                \phi:\; A \to A
            \end{align*}
            is a bijection, then
            \begin{align*}
                \sum_{a \in A}f(a) = \sum_{a\in A}f(\phi(a))
            .\end{align*}
            Since a bijective endofunction over $A$ permutes the elements of $A$, and the outputs of $f$ are commutative, the sums are equal.



    \end{itemize}

    \pagebreak 
    \unsect{Numerical Linear Algebra}
    \bigbreak \noindent 
    \subsection{Introduction}
    \bigbreak \noindent 
    \begin{itemize}

        \item \textbf{Matrix Notation}: For a matrix $A \in \mathbb{R}^{m\times n} $, we say
            \begin{align*}
                A = (a_{ij}) = \begin{bmatrix}
                    a_{11} & a_{12} & \cdots & a_{1n} \\
                    a_{21} & a_{22} & \cdots & a_{2n} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    a_{m1} & a_{m2} & \cdots & a_{mn}
                \end{bmatrix}
            \end{align*}
            with $a_{ij} \in \mathbb{R} $.
        \item \textbf{Vector notation}: For a vector $x \in \mathbb{R}^{n} $ (or $\mathbb{R}^{n\times 1} $), we have
            \begin{align*}
                x = \begin{bmatrix}
                    x_{1} \\ x_{2} \\ \vdots \\ x_{n}
                \end{bmatrix}
            \end{align*}
            for $x_{i} \in \mathbb{R} $.

        \item \textbf{Submatrix notation (rows)}: 
            \[
                A(i,:) \in \mathbb{R}^{1 \times n} \;\;\Longleftrightarrow\;\;
                A(i,:) = \bigl[\, a_{i1} \; a_{i2} \; \cdots \; a_{in} \,\bigr].
            \]
        \item \textbf{Submatrix notation (columns)}: 
            \[
                A(:,j) \in \mathbb{R}^{m \times 1} \;\;\Longleftrightarrow\;\;
                A(:,j) =
                \begin{bmatrix}
                    a_{1j} \\
                    a_{2j} \\
                    \vdots \\
                    a_{mj}
                \end{bmatrix}.
            \]
        \item \textbf{Sparse Matrix}: A sparse matrix or sparse array is a matrix in which most of the elements are zero. There is no strict definition regarding the proportion of zero-value elements for a matrix to qualify as sparse but a common criterion is that the number of non-zero elements is roughly equal to the number of rows or columns.
        \item \textbf{Dense Matrix}: if most of the elements are non-zero, the matrix is considered dense
        \item \textbf{Sparsity}: The number of zero-valued elements divided by the total number of elements is sometimes referred to as the sparsity of the matrix.
        \item \textbf{Band Matrix}: a band matrix or banded matrix is a sparse matrix whose non-zero entries are confined to a diagonal band, comprising the main diagonal and zero or more diagonals on either side.
            \bigbreak \noindent 
            \[
                A(i_{1}:i_{2},:) \in \mathbb{R}^{(i_{2}-i_{1}+1) \times n}
                \;\;\Longleftrightarrow\;\;
                A(i_{1}:i_{2},:) =
                \begin{bmatrix}
                    a_{i_{1}1} & a_{i_{1}2} & \cdots & a_{i_{1}n} \\
                    a_{i_{1}+1,1} & a_{i_{1}+1,2} & \cdots & a_{i_{1}+1,n} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    a_{i_{2}1} & a_{i_{2}2} & \cdots & a_{i_{2}n}
                \end{bmatrix}.
            \]

            \[
                A(:,j_{1}:j_{2}) \in \mathbb{R}^{m \times (j_{2}-j_{1}+1)}
                \;\;\Longleftrightarrow\;\;
                A(:,j_{1}:j_{2}) =
                \begin{bmatrix}
                    a_{1j_{1}} & a_{1,j_{1}+1} & \cdots & a_{1j_{2}} \\
                    a_{2j_{1}} & a_{2,j_{1}+1} & \cdots & a_{2j_{2}} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    a_{mj_{1}} & a_{m,j_{1}+1} & \cdots & a_{mj_{2}}
                \end{bmatrix}.
            \]
            Where
            \[
                \begin{aligned}
                    A(i_{1}:i_{2},:) &:\;\; \text{all rows between } i_{1} \text{ and } i_{2}, \;\text{across all columns}, \\[6pt]
                    A(:,j_{1}:j_{2}) &:\;\; \text{all columns between } j_{1} \text{ and } j_{2}, \;\text{across all rows}.
                \end{aligned}
            \]
        \item \textbf{Transposition}: $\mathbb{R}^{m\times n} \to \mathbb{R}^{n\times m} $
            \begin{align*}
                C = A^{\top} \iff c_{ij} = a_{ji}
            .\end{align*}
        \item \textbf{Transpose map}: The map
            \begin{align*}
                T:\; M_{n\times n}(\mathbb{F}) \to M_{n\times n}(\mathbb{F}), \quad T(A) = A^{T}
            .\end{align*}
        \item \textbf{Addition} $\quad (\mathbb{R}^{m \times n} \times \mathbb{R}^{m \times n} \;\to\; \mathbb{R}^{m \times n})$
            \[
                C = A + B 
                \;\;\Longrightarrow\;\; 
                c_{ij} = a_{ij} + b_{ij}.
            \]

        \item \textbf{Scalar-matrix Multiplication: } $\quad (\mathbb{R} \times \mathbb{R}^{m \times n} \;\to\; \mathbb{R}^{m \times n})$
            \[
                C = \alpha A 
                \;\;\Longrightarrow\;\; 
                c_{ij} = \alpha a_{ij}.
            \]

        \item \textbf{Matrix-matrix Multiplication: } $\quad (\mathbb{R}^{m \times p} \times \mathbb{R}^{p \times n} \;\to\; \mathbb{R}^{m \times n})$
            \[
                C = AB 
                \;\;\Longrightarrow\;\; 
                c_{ij} = \sum_{k=1}^{p} a_{ik} b_{kj}.
            \]
        \item \textbf{Matrix-vector Multiplication: } $\quad (\mathbb{R}^{m \times n} \times \mathbb{R}^n \;\to\; \mathbb{R}^m)$
            \[
                y = Ax 
                \;\;\Longrightarrow\;\; 
                y_i = \sum_{j=1}^{n} a_{ij} x_j.
            \]

        \item \textbf{Inner product (or dot product): } $\quad (\mathbb{R}^n \times \mathbb{R}^n \;\to\; \mathbb{R})$
            \[
                c = x^T y 
                \;\;\Longrightarrow\;\; 
                c = \sum_{i=1}^{n} x_i y_i.
            \]

            \item \textbf{Outer product: } $\quad (\mathbb{R}^m \times \mathbb{R}^n \;\to\; \mathbb{R}^{m \times n})$
            \[
                C = x y^T 
                \;\;\Longrightarrow\;\; 
                c_{ij} = x_i y_j.
            \]
        \item \textbf{Flops}: A flop is a floating-point operation between numbers stored in a floating-point format on a computer.
            \bigbreak \noindent 
            If $x$ and $y$ are numbers stored in a floating point format, then the following operations are each one flop
            \begin{align*}
                x + y \quad x - y \quad xy \quad x / y
            .\end{align*}

        \item \textbf{Empty sum}: In standard mathematical convention, if the lower bound exceeds the upper bound, the sum is defined to be zero
            \begin{align*}
                \sum_{i=k}^{j} f(k) = 0 \quad \text{if } i > j
            \end{align*}

        \item \textbf{Conformable matrix}: Simply a matrix that has the right dimensions to partcipate
        \item \textbf{Relationship between the sign of a 2-degree polynomial and its discriminant}: Recall that for a degree two polynomial, $p(x) \in P_{2}$, $p(x) = ax^{2} + bx +c$, the discriminant is given by
            \begin{align*}
                D &= b^{2} - 4ac
            .\end{align*}
            \begin{itemize}
                \item $p(x) \geq 0$ for all $x$ if and only if $a > 0 $ $D \leq 0$
                \item $p(x) \leq 0$ for all $x$ if and only if $a < 0 $ $D \leq 0$
            \end{itemize}
        \item \textbf{Useful fact I}: Let $a,b \in \mathbb{R} \setminus \{0\}$, if $a \geq b$, then
            \begin{align*}
                \frac{1}{a} \leq \frac{1}{b}
            .\end{align*}
        \item \textbf{Useful fact II}: Let $a,b,c,d \in \mathbb{R}$, if $0 \leq a \leq b$, and $ 0 < d \leq c$, then 
            \begin{align*}
                \frac{a}{c} \leq \frac{b}{d}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $a,b,c,d \in \mathbb{R}$, with $0 \leq a \leq b$, and $0 < d \leq c$. We have
            \begin{align*}
                a \leq b \implies \frac{a}{c} \leq \frac{a}{c}
            .\end{align*}
            Since $c \geq d$, $\frac{1}{c} \leq \frac{1}{d}$, which implies that
            \begin{align*}
                \frac{b}{c} \leq \frac{b}{d}
            .\end{align*}
            Combining these two facts gives
            \begin{align*}
                \frac{a}{c} \leq \frac{b}{c} \leq \frac{b}{d}
            .\end{align*}
            Therefore, $\frac{a}{c} \leq \frac{b}{d} $ $\endpf$
        \item \textbf{Transposition of the product of $n$ matrices}: Let $A_{1}, A_{2}, ..., A_{n-2},A_{n-1},A_{n} \in \mathbb{R}^{n\times n}$, then
            \begin{align*}
                \left(A_{1}A_{2} \cdots A_{n-2}A_{n-1}A_{n}\right)^{T} = A_{n}^{T}A_{n-1}^{T}A_{n-2}^{T} \cdots A_{2}^{T}A_{1}^{T}
            .\end{align*}
            \textbf{\textit{Proof.}}
            \begin{align*}
                \left(A_{1}A_{2} \cdots A_{n-2}A_{n-1}A_{n}\right)^{T} &= A_{n}^{T}\left(A_{1}A_{2} \cdots A_{n-2}A_{n-1}\right)^{T} \\
                                                                       &= A_{n}^{T}A_{n-1}^{T}\left(A_{1}A_{2} \cdots A_{n-2}A_{n-1}\right)^{T} \\
                                                                       &=A_{n}^{T}A_{n-1}^{T}A_{n-2}^{T}\left(A_{1}A_{2} \cdots\right)^{T} \\
                                                                       &=\ldots \\
                                                                       &= A_{n}^{T}A_{n-1}^{T}A_{n-2}^{T} \cdots A_{2}^{T}A_{1}^{T}
            .\end{align*}
            $\endpf $

        \item \textbf{What does it mean to multiply by $\cos{\left(\theta \right)}$ or $\sin{\left(\theta \right)}$}:
            From Euclidean geometry, if a vector 
            \[
                v = \begin{pmatrix} x \\ y \end{pmatrix}
            \]
            is measured from the origin $(0,0)$, then
            \begin{align*}
                \cos{\left(\theta \right)} &= \frac{x}{\|v\|_{2}}, \\
                \sin{\left(\theta \right)} &= \frac{y}{\|v\|_{2}}.
            \end{align*}
            Thus, $\|v\|\cos(\theta) = x$ gives the \textbf{component of $v$ in the direction of} 
            $e_{1} = \begin{pmatrix} 1 \\ 0 \end{pmatrix}$ (the $x$-axis), 
            and $\|v\|\sin(\theta) = y$ gives the \textbf{component of $v$ in the direction of} 
            $e_{2} = \begin{pmatrix} 0 \\ 1 \end{pmatrix}$ (the $y$-axis).
        \item \textbf{The dot product}: For $v,u \in \mathbb{R}^{n}$, the dot product $v^{T}u$ measures how much of $u$ lies in the direction of $v$.  Recall the projection formula,
            \begin{align*}
                \text{proj}_{v}(u) = \left(\frac{v^{T}u}{v^{T}v}\right)v = \left(\frac{v^{T}u}{\norm{v}^{2}_{2}}\right)v = \frac{v^{T}u}{\norm{v}_{2}} \cdot \frac{v}{\norm{v}_{2}}
            .\end{align*}
            The scalar $(v^{T}u)/\norm{v}_{2} \in \mathbb{R}$ measures the length of $u$'s projection onto $v$, and the vector $v / \norm{v}_{2}$ is a vector with length one that points in the direction of $v$. 
            \bigbreak \noindent 
            Thus, $v^{T}u$ measures how much of $u$ aligns with $v$, scaled by the length of $v$ ($\norm{v}_{2}$).
            \bigbreak \noindent 
            We also have that
            \begin{align*}
                v^{T}u = \norm{v}\norm{u}\cos{\left(\theta \right)}
            ,\end{align*}
            where $\theta$ is the angle between $u$ and $v$. Notice that above we have that 
            \begin{align*}
                \frac{v^{T}u}{\norm{v}_{2}}
            \end{align*}
            is the length of the projection of $u$ onto $v$. So,
            \begin{align*}
                \frac{v^{T}u}{\norm{v}_{2}} = \norm{u}_{2}\cos{\left(\theta \right)}
            .\end{align*}
            This tells us that the length of the projection of $u$ onto $v$ is the length of $\norm{u}$ multiplied by the cosine of the angle between $u$ and $v$.
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{projlen}
                \label{fig:projlen}
            \end{figure}
            \bigbreak \noindent 
            As you can see we dropped a perpendicular from $u$ down to $v$. Using the definition of cosine in right triangles,
            \begin{align*}
                \cos{\left(\theta \right)} = \frac{\text{projection length}}{\norm{u}_{2}} \\
                \implies \text{ projection length } = \norm{u}_{2}\cos{\left(\theta \right)}
            .\end{align*}

            \bigbreak \noindent 
            Using the fact that $v^{T}u = u^{T}v = \norm{v}\norm{u}\cos{\left(\theta \right)}$, we see that the dot product depends on three things 
            \begin{enumerate}
                \item The length of $v$
                \item The length of $u$
                \item The cosine of the angle between them.
            \end{enumerate}
            Let $v \ne 0$ be fixed, and let $u=t\hat{u}$, where $\hat{u}$ is in the direction of $u$ with $\norm{\hat{u}} =1$. Let $\phi$ be the fixed angle between $v$ and $\hat{u}$. So,
            \begin{align*}
                v^{T}u = \norm{v}t\cos{\left(\phi\right)}
            .\end{align*}
            \begin{enumerate}
                \item As $t \to \infty$, $\norm{u}_{2} \to \infty$, and $v^{T}u \to +\infty$ if $\cos{\left(\phi\right)} > 0$, $\to -\infty$ if $\cos{\left(\phi\right)} < 0 $, and stays zero if $\cos{\left(\phi\right)} = 0 $
                \item As $t \to -\infty$, $\norm{u}_{2} \to \infty$, and $v^{T}u \to -\infty$ if $\cos{\left(\phi\right)} > 0$, $\to +\infty$ if $\cos{\left(\phi\right)} < 0 $, and stays zero if $\cos{\left(\phi\right)} = 0 $
                \item As $\norm{u}_{2} = \left\lvert t \right\rvert \to 0$, $v^{T}u \to 0$
            \end{enumerate}
            Now, fix the length of $u$, but let the direction vary,
            \begin{enumerate}
                \item If $\theta \in \{0,2\pi\}$, $v^{T}u = \norm{v}_{2}\norm{u}_{2} $
                \item As $\theta$ goes from zero to $\pi$, $v^{T}u$ goes from $+\norm{v}_{2}\norm{u}_{2} $ to $-\norm{v}_{2}\norm{u}_{2}$, crossing $0$ at $\theta  = \frac{\pi}{2}$
                \item As $\theta $ goes from $\pi$ to $2\pi$, $v^{T}u$ goes from $-\norm{v}_{2}\norm{u}_{2}$ to $+\norm{v}_{2}\norm{u}_{2} $, crossing $0$ at $\theta  = \frac{3\pi}{2} $
            \end{enumerate}
            \textbf{Note:} 
            If $v^{T}u<0$, then $\cos{\left(\theta \right)}<0$, meaning the angle between $v$ and $u$ is obtuse; greater than $90^{\circ}$
            \bigbreak \noindent 
            That tells you that the projection of one vector onto the other points opposite to the other’s direction. In other words, moving along $u$ decreases your progress in the direction of $v$.
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{negativestuff}
                \label{fig:negativestuff}
            \end{figure}
            \bigbreak \noindent 
            First, we notice that $\phi = 180 - \theta$, so
            \begin{align*}
                \cos{\left(180-\theta \right)} = \cos{\left(\phi\right)} = \cos{\left(180\right)}\cos{\left(\theta \right)} + \sin{\left(180\right)}\sin{\left(\theta \right)} = -\cos{\left(\theta \right)}
            .\end{align*}
            \bigbreak \noindent 
            We will look at $\text{proj}_{u}(v)$, $\text{proj}_{-u}(v)$, and $\text{proj}_{u}(-v)$. First,
            \begin{align*}
                \text{proj}_{u}(v) = \frac{v^{T}u}{\norm{u}_{2}}\frac{u}{\norm{u}_{2}} = \norm{v}_{2}\cos{\left(\theta \right)} \frac{u}{\norm{u}_{2}}
            .\end{align*}
            Next,
            \begin{align*}
                \text{proj}_{-u}(v) &= \frac{v^{T}(-u)}{\norm{-u}_{2}}\frac{-u}{\norm{-u}_{2}} = \frac{v^{T}u}{\norm{u}_{2}}\frac{u}{\norm{u}_{2}} = \norm{v}_{2}\cos{\left(\phi \right)}\frac{-u}{\norm{u}_{2}}  \\
                &=-\norm{v}_{2}\cos{\left(\theta \right)}\frac{-u}{\norm{u}_{2}} =\text{proj}_{u}(v)
            .\end{align*}
             Last, we have that
            \begin{align*}
                \text{proj}_{u}(-v) &= \frac{-v^{T}u}{\norm{u}_{2}} \frac{u}{\norm{u}_{2}} = \norm{-v}_{2}\cos{\left(\phi\right)} \frac{u}{\norm{u}_{2}} \\
                &= -\norm{v}_{2}\cos{\left(\theta \right)} \frac{u}{\norm{u}_{2}} = -\text{proj}_{u}(v)
            .\end{align*}
            So,
            \begin{align*}
                \text{proj}_{u}(v) = \text{proj}_{-u}(v) = -\text{proj}_{-u}(v)
            .\end{align*}
            \bigbreak \noindent 
            Suppose that 
            \[
                v = \begin{pmatrix} x \\ y \end{pmatrix}, \quad 
                e_{1} = \begin{pmatrix} 1 \\ 0 \end{pmatrix} \; (\text{$x$-axis}).
            \]
            Then
            \[
                v^{T}e_{1} = e_{1}^{T}v = x.
            \]
            Thus, $v^{T}e_{1}$ gives the \textbf{component of $v$ in the direction of $e_{1}$}, i.e., the amount of $v$ that lies along the $x$-axis.
            Similarly, if 
            \[
                e_{2} = \begin{pmatrix} 0 \\ 1 \end{pmatrix} \; (\text{$y$-axis}),
            \]
            then
            \[
                v^{T}e_{2} = e_{2}^{T}v = y.
            \]
            Hence, $v^{T}e_{2}$ gives the \textbf{component of $v$ in the direction of $e_{2}$}, i.e., the amount of $v$ that lies along the $y$-axis.


        \item \textbf{Dot product and projection of vectors on the same line}: Suppose $a,x \in \mathbb{R}^{n}$ are on the same line. Then, $x = ka$, and
            \begin{align*}
                \frac{x}{\norm{x}_{2}} = \frac{ka}{\norm{ka}_{2}} = \frac{k}{\left\lvert k \right\rvert}\frac{a}{\norm{a}_{2}} = \text{sgn}(k)\frac{a}{\norm{a}_{2}}
            .\end{align*}
            If $x,a$ point in opposite directions, then $\text{sgn}(k) = -1$, and 
            \begin{align*}
                a^{T}x = \norm{a}_{2}\norm{x}_{2}(-1) = -\norm{a}_{2}\norm{x}_{2},\quad \frac{x}{\norm{x}_{2}} = -\frac{a}{\norm{a}_{2}}
            .\end{align*}
            So, the projection is
            \begin{align*}
                \text{proj}_{a}(x) = \frac{a^{T}x}{\norm{a}_{2}} \frac{a}{\norm{a}_{2}} = \frac{-\norm{a}_{2}\norm{x}_{2}}{\norm{a}_{2}}\left(- \frac{x}{\norm{x}_{2}}\right) = x
            .\end{align*}
            If $x,a$ point  in the same direction, $\text{sgn}(k) = 1$, and
            \begin{align*}
                a^{T}x = \norm{a}_{2}\norm{x}_{2}(1) = \norm{a}_{2}\norm{x}_{2},\quad \frac{x}{\norm{x}_{2}} = \frac{a}{\norm{a}_{2}}
            .\end{align*}
            The projection in this case is
            \begin{align*}
               \text{proj}_{a}(x) = \frac{a^{T}x}{\norm{a}_{2}} \frac{a}{\norm{a}_{2}}  = \frac{\norm{a}_{2}\norm{x}_{2}}{\norm{a}_{2}} \frac{x}{\norm{x}_{2}} = x
            .\end{align*}
            Hence, the projection is the same in both cases. In the raw dot product, notice that 
            \begin{align*}
                a^{T}x = \norm{a}_{2}\norm{x}_{2}\cos{\left(\theta \right)} = \pm \norm{a}_{2}\norm{x}_{2}
            .\end{align*}
            So, if $a$ and $x$ lie on the same line, then the projection of $x$ onto $a$ has length $\norm{x}_{2}$. If they are in opposite directions, $a^{T}x < 0$, and if they point in the same direction, $a^{T}x > 0$.

            % \item \textbf{Describing dot product in words}: Suppose that $a,x\in \mathbb{R}^{n}$. If $a^{T}x = b$, then we say that the projection of $x$ onto $a$ has length $\frac{b}{\norm{a}} $.
        \item \textbf{Describing dot product in words}: 
            Suppose that $a, x \in \mathbb{R}^n$. 
            The quantity $a^T x$ measures how much of $x$ lies in the direction of $a$. 
            If $a^T x = b$, then the projection of $x$ onto $a$ has length $\dfrac{b}{\|a\|}$.

            \begin{itemize}
                \item If $x$ is \emph{orthogonal} to $a$, then $a^T x = 0$, so the projection of $x$ onto $a$ is the zero vector.
                \item If $a^T x > 0$, then $x$ has a component in the same direction as $a$.
                \item If $a^T x < 0$, then $x$ has a component in the direction opposite to $a$.
            \end{itemize}





    \end{itemize}



    \pagebreak \bigbreak \noindent 
    \subsection{Gaussian Elimination and its variants (1)}
    \bigbreak \noindent 
    \subsubsection{Matrix Multiplication}
    \bigbreak \noindent 
    \begin{itemize}
        \item \textbf{Matrix Multiplication}:        
            In general, if $A$ is a real matrix with $m$ rows and $n$ columns, and $x$ is a real vector with $n$ entries, then
            \[
                A = 
                \begin{bmatrix}
                    a_{11} & \cdots & a_{1n} \\
                    \vdots & \ddots & \vdots \\
                    a_{m1} & \cdots & a_{mn}
                \end{bmatrix}
                \in \mathbb{R}^{m \times n}
                \quad \text{and} \quad
                x =
                \begin{bmatrix}
                    x_{1} \\
                    \vdots \\
                    x_{n}
                \end{bmatrix}
                \in \mathbb{R}^n.
            \]
            If $b = Ax$, then $b \in \mathbb{R}^m$ and
            \[
                b_i = \sum_{j=1}^n a_{ij} x_j
                = a_{i1}x_1 + \cdots + a_{in}x_n, 
                \quad i = 1, \ldots, m.
            \]
            Thus, $b_i$ is the \textbf{inner-product} between the $i$-row of $A$, 
            \[
                A(i,:) = [a_{i1} \;\; \cdots \;\; a_{in}], \quad (i = 1, \ldots, m)
            \]
            and the vector $x$.
            \bigbreak \noindent 
            Also,
            \[
                b = A(:,1) x_1 + \cdots + A(:,n)x_n,
            \]
            so $b$ is a \textbf{linear combination} of the columns of $A$, i.e.,
            \[
                A(:,j) = 
                \begin{bmatrix}
                    a_{1j} \\
                    a_{2j} \\
                    \vdots \\
                    a_{mj}
                \end{bmatrix},
                \quad j = 1, \ldots, n.
            \]
        \item \textbf{Matrix-Matrix Multiplication}:
            Let $A \in \mathbb{R}^{m \times n}$ and $X \in \mathbb{R}^{n \times p}$.
            \bigbreak \noindent 
            If $B = AX$ then $B \in \mathbb{R}^{m \times p}$ and
            \[
                b_{ij} = \sum_{k=1}^n a_{ik} x_{kj}, \quad i = 1, \ldots, m, \;\; j = 1, \ldots, p.
            \]
            That is, $b_{ij}$ is the inner-product between row $i$ of $A$ and column $j$ of $X$.
            \bigbreak \noindent 
            Also, each column of $B$ is a linear combination of the columns of $A$.
            \bigbreak \noindent 
            Total flops required for matrix multiplication is
            \[
                \sum_{i=1}^m \sum_{j=1}^p \sum_{k=1}^n 2 = 2mnp.
            \]
            If $A, X \in \mathbb{R}^{n \times n}$, then computing $B = AX$ requires $2n^3 = O(n^3)$ flops.
            \bigbreak \noindent 
            We can see this by describing the algorithm for Matrix-Matrix multiplication
            \bigbreak \noindent 
            \begin{jlcode}
            for i = 1:m
                for j = 1:n
                    for k = 1:p
                        C[i,j] += A[i,k]B[k,j]
                    end
                end
            end
            \end{jlcode}
            \bigbreak \noindent 
            The multiplication $A[i,j]B[k,j]$ is one flop, followed by the addition. Therefore, two flops per iteration of the innermost loop.
        \item \textbf{Block Matrices}:
            Partition $A \in \mathbb{R}^{m \times n}$ and $X \in \mathbb{R}^{n \times p}$ into blocks:
            \[
                A =
                \begin{blockarray}{ccc}
   & n_1 & n_2 \\
   \begin{block}{c[cc]}
       m_1 & A_{11} & A_{12} \\
       m_2 & A_{21} & A_{22} \\
   \end{block}
                \end{blockarray}
                \quad,\qquad
                X =
                \begin{blockarray}{ccc}
   & p_1 & p_2 \\
   \begin{block}{c[cc]}
       n_1 & X_{11} & X_{12} \\
       n_2 & X_{21} & X_{22} \\
   \end{block}
                \end{blockarray}
            \]
                    where $n = n_1 + n_2$, $m = m_1 + m_2$, and $p = p_1 + p_2$.
                    \bigbreak \noindent 
                    If $B = AX$, and 
                    \begin{align*}
                        B = 
                        \begin{blockarray}{ccc}
                            & p_{1} & p_{2} \\
                            \begin{block}{c[cc]}
                                m_{1} & B_{11} & B_{12} \\
                                m_{2} & B_{21} & B_{22} \\
                            \end{block}
                        \end{blockarray}
                    ,\end{align*}
                    then
                    \[
                        \begin{blockarray}{cc}
  &  \\
  \begin{block}{[cc]}
      B_{11} & B_{12} \\
      B_{21} & B_{22} \\
  \end{block}
                        \end{blockarray}
                        =
                        B = AX =
                        \begin{blockarray}{cc}
  &  \\
  \begin{block}{[cc]}
      A_{11} & A_{12} \\
      A_{21} & A_{22} \\
  \end{block}
                        \end{blockarray}
                        \begin{blockarray}{cc}
  &  \\
  \begin{block}{[cc]}
      X_{11} & X_{12} \\
      X_{21} & X_{22} \\
  \end{block}
                        \end{blockarray}
                    \]

                    \[
                        =
                        \begin{blockarray}{cc}
  &  \\
  \begin{block}{[cc]}
      A_{11}X_{11} + A_{12}X_{21} & A_{11}X_{12} + A_{12}X_{22} \\
      A_{21}X_{11} + A_{22}X_{21} & A_{21}X_{12} + A_{22}X_{22} \\
  \end{block}
                        \end{blockarray}
                    \]

                    That is,
                    \[
                        B_{ij} = \sum_{k=1}^2 A_{ik} X_{kj}, 
                        \qquad i,j = 1,2.
                    \]

                \item \textbf{Transpose of block matrices}: Let $A \in \mathbb{R}^{n\times n}$, with
                    \begin{align*}
                        A  = \begin{bmatrix} A_{11} & a_{12} \\ A_{21} & a_{22} \end{bmatrix}
                    .\end{align*}
                    Then, 
                    \begin{align*}
                        A^{\top} = \begin{bmatrix}
                            A_{11}^{\top} & A_{21}^{\top} \\ A_{12}^{\top} & A_{22}^{\top}
                        \end{bmatrix}
                    \end{align*}
                \item \textbf{Transpose of a block vector}: Similarly, if $ x \in \mathbb{R}^{n}$ is decomposed into blocks
                    \begin{align*}
                        \begin{pmatrix} x_{1} \\ x_{2} \end{pmatrix}
                    ,\end{align*}
                    with $x_{1} \in \mathbb{R}^{n_{1}} ,\; x_{2} \in \mathbb{R}^{n_{2}},\; n = n_{1} + n_{2}$, then
                    \begin{align*}
                        x^{\top} = \begin{pmatrix} x_{1}^{\top} & x_{2}^{\top} \end{pmatrix}
                    \end{align*}



    \end{itemize}

    \pagebreak 
    \subsubsection{Systems of Linear Equations}
    \begin{itemize}
        \item \textbf{Systems of linear equations}: Let $A \in \mathbb{R}^{n\times n},\ b \in \mathbb{R}^{m}$, our goal is to find $x \in \mathbb{R}^{m}$ such that $Ax = b$
        \item \textbf{Singularity}: A \textbf{singular matrix} is a square matrix that does not have an inverse.
            \bigbreak \noindent 
            A \textbf{nonsingular} matrix is a square matrix that does have an inverse.
            \bigbreak \noindent 
            The following are equivalent, if any one holds, they all hold
            \begin{itemize}
                \item $Ax = b$ has a unique solution
                \item $\det(A)\ne 0$
                \item $A^{-1}$ exists
                \item There is no nonzero vector $y \in \mathbb{R}^{m}$ such that $Ay=0 $
                \item The columns of $A$ are linearly independent
                \item The rows of $A$ are linearly independent
                \item Given any vector $b$, there is exactly one vector $x$ such that $Ax=b$
            \end{itemize}
            If any one of the following are true, they all are true, and $A$ is nonsingular
        \item \textbf{Solution to $Ax = b$}: If $A$ is nonsingular, then $A^{-1}$ exists, and
            \begin{align*}
                x = A^{-1}b
            .\end{align*}
            Which is the unique solution to $Ax=b$
            \bigbreak \noindent 
            \textbf{Note:} Practically, it is not wise to compute $A^{-1}$, as this can be expensive.
    \end{itemize}

    \pagebreak 
    \subsubsection{Triangular systems}
    \begin{itemize}
        \item \textbf{Upper triangular}: A square matrix $A = U$ of the form 
            \begin{align*}
                A = U = \begin{bmatrix}
                    u_{11} & u_{12} & \cdots & u_{1n} \\
                    0 & u_{22} & \cdots & u_{2n} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    0 & 0 & \cdots & u_{nn}
                \end{bmatrix}
            \end{align*}
            is called \textbf{upper triangular}.
            \bigbreak \noindent 
            Formally, a matrix $A$ is upper triangular if $a_{ij} = 0 $ whenever $i > j $
        \item \textbf{Lower triangular}: A square matrix $A = L$
            \begin{align*}
                A = L = \begin{bmatrix}
                    \ell_{11} & 0 & \cdots & 0 \\
                    \ell_{21} & \ell_{22} & \cdots & 0 \\
                    \vdots & \vdots & \ddots & \vdots \\
                    \ell_{n1} & \ell_{n2} & \cdots & \ell_{nn}
                \end{bmatrix}
            \end{align*}
            is called \textbf{lower triangular}
            \bigbreak \noindent 
            Formally, a matrix $A$ is lower triangular if $a_{ij} = 0 $ whenever $i < j $
        \item \textbf{Theorem 1.3.1}: Let $A$ be a triangular matrix. Then, $A$ is nonsingular if and only if $g_{ii} \ne 0$ for $i=1,2,...,n $
        \item \textbf{Solutions to triangular systems}: 
            Consider the system
            \begin{align*}
               \begin{bmatrix}
                    \ell_{11} & 0 & \cdots & 0 \\
                    \ell_{21} & \ell_{22} & \cdots & 0 \\
                    \vdots & \vdots & \ddots & \vdots \\
                    \ell_{n1} & \ell_{n2} & \cdots & \ell_{nn}
                \end{bmatrix} \begin{bmatrix}
                    x_{1} \\ x_{2} \\ \vdots \\ x_{n}
                \end{bmatrix}
                =
                \begin{bmatrix}
                    b_{1} \\ b_{2} \\ \vdots \\ b_{n}
                \end{bmatrix}
            .\end{align*}
            So,
            \begin{align*}
                \ell_{11}x_{1} &= b_{1} \\
                \ell_{21}x_{1} + \ell_{22}x_{2} &= b_{2} \\
                \vdots \\
                \ell_{n1}x_{1} + \ell_{n2}x_{2} + \cdots + \ell_{nn}x_{n} &= b_{n}
            .\end{align*}
            Then,
            \begin{align*}
                x_{1} &= \frac{b_{1}}{\ell_{11}}
            \end{align*}
            and,
            \begin{align*}
                \ell_{22}x_{2} &= b_{2} - \ell_{21}x_{1} \\
                \implies x_{2} &= \frac{b_{2}-\ell_{21}x_{1}}{\ell_{22}}
            .\end{align*}
            In general, we have
            \begin{align*}
                x_{i} = \frac{b_{i} - \sum_{j=1}^{i-1}\ell_{ij}x_{j}}{\ell_{ii}}
            \end{align*}
            for $i =1,2,...,n $. This method is called \textbf{Forward Substitution}.
            \bigbreak \noindent 
            A similar process is used on upper triangular matrices and is called \textbf{Backward Substitution}.
        \item \textbf{Counting flops for the forward substitution method}: We have 
                \begin{jlcode}
                for i = 1:n
                    for j=1:i-1
                        b[i] = b[i] - ell[i,j]b[j]
                    end
                    b[i] = b[i] / ell[i,i]
                end
                \end{jlcode}
            Thus, the count of flops is
            \begin{align*}
                n+\sum_{i=1}^{n}2(i-1) &= n+2 \sum_{i=1}^{n}(i-1) = n+2 \left( \sum_{i=1}^{n}i - \sum_{i=1}^{n} 1\right)  \\
                   &= n + 2 \left(\sum_{i=1}^{n}i - n\right) = n+ 2 \left(\frac{n(n+1)}{2}-n\right) \\
                   &=n + n^{2} - n = n^{2}
            \end{align*}
            So, forward substitution is $\mathcal{O}(n^{2})$
        \item \textbf{Column oriented forward substitution}: Suppose we have $Lx = b$ when $L$ is lower triangular, we split the matrix into the following blocks
            \begin{align*}
                \begin{bmatrix}
                    \ell_{11} & 0 \\
                    \hat{\ell} & \hat{L}
                \end{bmatrix}
                \begin{bmatrix}
                    x_{1} \\ \hat{x} 
                \end{bmatrix}
                = \begin{bmatrix}
                    b_{1} \\ \hat{b}
                \end{bmatrix}
            .\end{align*}
            With $\hat{\ell} \in \mathbb{R}^{n-1}$, $\hat{L} \in \mathbb{R}^{n-1 \times n-1} $, $\hat{x} \in \mathbb{R}^{n-1}$, $\ell_{11}, x_{1}, b_{1} \in \mathbb{R}$. Note that $\hat{L}$ is also lower triangular.
            \bigbreak \noindent 
            We have
            \begin{align*}
                \ell_{11}x_{1} &= b_{1} \implies x_{1} = \frac{b_{1}}{\ell_{11}} \\
                \hat{\ell}x_{1} + \hat{L}\hat{x} &= \hat{b} \implies \hat{L}\hat{x} = \hat{b} - \hat{\ell}x_{1}
            \end{align*}
            Thus, we reduced the dimension by one. We repeat this process for the remaining $x_{i}$. The process is 
            \begin{enumerate}
                \item Compute $x_{1} = \frac{b_{1}}{\ell_{11}} $
                \item Compute $\hat{b} - \hat{\ell}x_{1} = \tilde{b} \in \mathbb{R}^{n-1} $
                \item Find $\hat{L}x = \tilde{b} $
            \end{enumerate}
        \item \textbf{Counting flops for column oriented forward substitution}: Let $f_{n}$ be the flop count, we have
            \begin{align*}
                f_{n} = 1 + 2(n-1) + f_{n-1}
            .\end{align*}
            With
            \begin{align*}
                f_{n-1} = 1 + 2(n-2) + f_{n-2}, \\
                f_{n-2} = 1 + 2(n-3) + f_{n-3}, \\
            .\end{align*}
            Until
            \begin{align*}
                f_{n-(n-1)} = f_{1} = 1 + 2((n-(n-1))-1) + f_{0}  = 1 + 2(0) + f_{0} = 1
            \end{align*}
            with $f_{0} = 0 $
            \bigbreak \noindent 
            So, 
            \begin{align*}
                f_{n} &= 1 + 2(n-1) + 1 + 2(n-2) + ... + 1 + 2((n-(n-1))-1) \\
                &= \sum_{i=1}^{n} 1 + 2(n-1) = n + 2n^{2} - 2\sum_{i=1}^{n}i \\
                &=...=n^{2}
            .\end{align*}
            Thus, column oriented forward substitution is also $\mathcal{O}(n^{2})$
        \item \textbf{Solutions of an upper triangular system (Backward substitution)}: 
            Let $A \in \mathbb{R}^{n\times n},\ x \in \mathbb{R}^{n},\ b \in \mathbb{R}^{n}$, with
            \begin{align*}
                A = \begin{bmatrix}
                    a_{11} & a_{12} & \cdots & a_{1n} \\
                    0 & a_{22} & \cdots & a_{2n} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    0 & 0 & \cdots & a_{nn}
                \end{bmatrix},  \quad \;
                x = \begin{bmatrix}
                    x_{1} \\ x_{2} \\ \vdots \\ x_{n}
                \end{bmatrix}, \quad \;
                b = \begin{bmatrix}
                    b_{1} \\ b_{2} \\ \vdots \\ b_{n}
                \end{bmatrix}
            .\end{align*}
            Then, 
            \begin{align*}
                 \begin{bmatrix}
                    a_{11} & a_{12} & \cdots & a_{1n} \\
                    0 & a_{22} & \cdots & a_{2n} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    0 & 0 & \cdots & a_{nn}
                \end{bmatrix}
                \begin{bmatrix}
                    x_{1} \\ x_{2} \\ \vdots \\ x_{n}
                \end{bmatrix} 
                = \begin{bmatrix}
                    b_{1} \\ b_{2} \\ \vdots \\ b_{n}
                \end{bmatrix}
            \end{align*}
            implies
            \begin{align*}
                a_{11}x_{1} + a_{12}x_{2} + \cdots + a_{1n}x_{n} &= b_{1} \\
                a_{22}x_{2} + a_{23}x_{3} + \cdots + a_{2n}x_{n} &= b_{2} \\
                                                                 &\vdots \\
                a_{nn} x_{n} &= b_{n}
            .\end{align*}
            So, 
            \begin{align*}
                x_{1} &= \frac{b_{1} - (a_{12}x_{2} + a_{13}x_{3} + \cdots + a_{1n}x_{n})}{a_{11}} ,\\
                x_{2} &= \frac{b_{2} - (a_{23}x_{3} + a_{24}x_{4} + \cdots + a_{2n}x_{n})}{a_{22}} ,\\
                x_{n} &= \frac{b_{n}}{a_{nn}}
            .\end{align*}
            In general, we have that
            \begin{align*}
                x_{i} &= \frac{b_{i} - \sum_{j=i+1}^{n}a_{ij}x_{j}}{a_{ii}}, \quad i=n,n-1,...,1
            \end{align*}
        \item \textbf{Column-oriented backward substitution}:
            Let $U \in \mathbb{R}^{n\times n}$ be upper triangular, $x \in \mathbb{R}^{n}$, and $ b \in \mathbb{R}^{n}$ which gives the system
            \begin{align*}
                \begin{bmatrix}
                    u_{11} & u_{12} & \cdots & u_{1n} \\
                    0 & u_{22} & \cdots & u_{2n} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    0 & 0 & \cdots & u_{nn}
                \end{bmatrix} 
                \begin{bmatrix}
                    x_{1} \\ x_{2} \\ \vdots \\ x_{n}
                \end{bmatrix}
                = 
                \begin{bmatrix}
                    b_{1} \\ b_{2} \\ \vdots \\ b_{n}
                \end{bmatrix}
            \end{align*}
            Split the system into the following block decomposition
            \begin{align*}
                \begin{bmatrix}
                    \hat{U} & u \\
                    0^{\top} & u_{nn}
                \end{bmatrix}
                \begin{bmatrix}
                    \hat{x} \\ x_{n}
                \end{bmatrix}
                = 
                \begin{bmatrix}
                    \hat{b} \\ b_{n}
                \end{bmatrix}
            \end{align*}
            Then,
            \begin{align*}
                \hat{U}\hat{x} + ux_{n} &= \hat{b} \implies \hat{U}\hat{x} = \hat{b} - ux_{n} = \tilde{b}, \\
                u_{nn}x_{n} &= b_{n} \implies x_{n} = \frac{b_{n}}{u_{nn}}
            \end{align*}
            Thus, the column-oriented backward substitution algorithm is defined by the following steps
            \begin{enumerate}
                \item Compute $x_{n} = \frac{b_{n}}{u_{nn}} $
                \item Compute $\tilde{b} = \hat{b} - ux_{n} $
                \item Run the algorithm on $\hat{U}, \tilde{b}$. That is, $\text{Alg}(\hat{U}, \tilde{b})$
            \end{enumerate}
            \bigbreak \noindent 
            The non-recursive pseudocode in the spirit of 1.3.5 and 1.3.13 is
            \bigbreak \noindent 
            \begin{jlcode}
                for |$i=n,...,1$|
                if |$U[i,i] = 0$|, set error flag, exit

                |$b[i] = b[i] / U[i,i]$|

                for |$j = i-1,...,1$|
                |$b[j] = b[j] - U[j,i] \cdot b[i]$|
                end
                end
            \end{jlcode}

        \item \textbf{Counting flops for the above backward substitution algorithm}: The general expression for $x_{i}$ can be expressed as
            \bigbreak \noindent 
            \begin{jlcode}
            for i = n:-1:1
                for j = i+1:n
                    B[i] = B[i] - A[i,j] * B[j]
                end
                B[i] = B[i]/A[i,i]
            end
            \end{jlcode}
            \bigbreak \noindent 
            So, the flop count is
            \begin{align*}
                f(n) &= n+\sum_{i=1}^{n}2(n-(i+1) + 1) \\
                     &=n+\sum_{i=1}^{n}2(n-i) \\
                     &=n+2\sum_{i=1}^{n}n - 2\sum_{i=1}^{n}i \\
                     &= n + 2n^{2} - 2 \cdot \frac{n(n+1)}{2} \\
                     &= n + 2n^{2} - (n^{2} +n) \\
                     &= n + 2n^{2} -n^{2}-n \\
                     &=n^{2}
            \end{align*}
            So, the backward substitution algorithm is $\mathcal{O}(n^{2}) $
        \item \textbf{Triangular matrices after multiplication}:
            triangular matrices stay triangular after multiplication, provided you multiply matrices of the same triangular type:
            \begin{itemize}
                \item Upper triangular $\times$ upper triangular = upper triangular
                \item Lower triangular $\times$ lower triangular = lower triangular
            \end{itemize}
        \item \textbf{Triangular matrices after transpose}
            \begin{itemize}
                \item The transpose of an upper triangular matrix is a lower triangular matrix
                \item The transpose of an lower triangular matrix is a upper triangular matrix
            \end{itemize}
        \item \textbf{Triangular matrices after inversion}: The inverse of a lower triangular matrix is lower triangular, and the inverse of an upper triangular matrix is upper triangular
        \item \textbf{Diagonal matrices}: Are both upper triangular and lower triangular (at the same time).

            
    \end{itemize}

    \pagebreak 
    \subsubsection{Positive Definite Systems}
    \begin{itemize}
            \item \textbf{Positive definite matrix}: A matrix $A$ is \textbf{positive definite} provided that the following two conditions are satisfied
            \begin{enumerate}
                \item $A$ is symmetric. That is, $A = A^{\top} $
                \item $x^{\top}Ax > 0 $ for all $x\ne 0$
            \end{enumerate}
        \item \textbf{Positive Definiteness Characterizations}:  
            Let $A \in \mathbb{R}^{n \times n}$ be a symmetric matrix. Then the following are equivalent:  
            \begin{enumerate}
                \item $A$ is positive definite.  
                \item All eigenvalues of $A$ are positive.  
                \item All \emph{leading principal minors} of $A$ are positive (Sylvester’s criterion).  
            \end{enumerate}  
            Moreover:  
            \begin{itemize}
                \item (1) $\implies$ $a_{ii} > 0$ for all $i=1,2,\dots,n$.  
                \item (1) $\implies$ every principal submatrix of $A$ is positive definite.  
            \end{itemize}

        \item \textbf{Properties of positive definite (p.d) matrices}:
            \begin{enumerate}
                \item If $A$ is p.d then $A$ is \textit{nonsingular}
                    \bigbreak \noindent 
                    \textbf{Note:} Since $A$ is nonsingular there is no $y \in \mathbb{R}^{n}$, $y\ne 0$ such that $Ay = 0$
                \item If $A = M^{\top}M$ for some $M$ nonsingular than $A$ is p.d
                \item $A$ is p.d if and only if all eigenvalues of $A$ are positive
                    \bigbreak \noindent 
                    Recall that $\lambda$ is an eigenvalue of $A$ if there exists $x_{\lambda} \ne 0$ such that $Ax_{\lambda}  = \lambda x_{\lambda}$
                \item If $A$ is p.d then all principal submatrices are p.d
                \item $A$ is p.d if and only if all leading principal minors are positive
                \item If $A$ is p.d than $\det(A) > 0$
                \item $A$ is p.d if and only if there exists a unique upper triangular matrix $R$ such that $A = R^{\top}R$ (Cholesky factorization described below)
            \end{enumerate}
            \textbf{Note:} Property two is a key property.
            \bigbreak \noindent 
            \textbf{\textit{Proof of (1)}}: Assume $A$ is a p.d matrix. Further assume (for the sake of contradiction) that $A$ is singular. Then, there exits $y \in \mathbb{R}^{n},\; y \ne 0 $ with $Ay=0$
            \bigbreak \noindent 
            Since $Ay = 0$, $y\ne 0$, then $y^{\top}Ay=0$ when $y\ne 0$, so $A$ is not p.d.
            \bigbreak \noindent 
            Therefore if $A$ is p.d, then $A$ is nonsingular $\endpf$
            \bigbreak \noindent 
            \textbf{\textit{Proof of (2)}}: Assume that $A  = M^{\top}M$ for some $M$ nonsingular. Then,
            \begin{align*}
                A^{\top} = (M^{\top}M)^{\top} = M^{\top}(M^{\top})^{\top} = M^{\top}M = A
            \end{align*}
            So $A$ is symmetric ($A = A^{\top}$)
            \bigbreak \noindent 
            Next, let $x \ne 0$
            \begin{align*}
                x^{\top}Ax &= x^{\top}(M^{\top}M)x \\
               &=(x^{\top}M^{\top})(Mx) \\
               &=(Mx)^{\top}(Mx)
            \end{align*}
            let $y = Mx $, then
            \begin{align*}
                y^{\top}y &= \begin{pmatrix} y_{1} & y_{2} & \cdots&y_{n} \end{pmatrix} \begin{pmatrix} y_{1} \\ y_{2} \\ \vdots & y_{n} \end{pmatrix} \\
                          &=y_{1}^{2} + y_{2}^{2} + ... + y_{n}^{2} > 0
            \end{align*}
            So, $A$ is p.d $\endpf$
            \bigbreak \noindent 
            Note that since $x \ne 0$, $y\ne 0$. 
            \bigbreak \noindent 
            Recall that $y^{\top}y = \norm{y}^{2}$
            \bigbreak \noindent 
            \textbf{\textit{Proof of (3)}}: Assume that $A$ is p.d. Let $\lambda$ be an eigenvalue for $A$. Then,
            \begin{align*}
                Ax_{\lambda} &= \lambda x_{\lambda} \\
                \implies x^{\top}_{\lambda}Ax_{\lambda} &= x^{\top}_{\lambda}\lambda x \\
                                                        &= \lambda x^{\top}_{\lambda} x_{\lambda}
            \end{align*}
            First, observe that $x^{\top}Ax >0$ since $A$ p.d. Thus,
            \begin{align*}
               \lambda x_{\lambda}^{\top} x > 0 
            \end{align*}
            and since $x_{\lambda}^{\top} x = \norm{x_{\lambda}}^{2} $, we have
            \begin{align*}
                \lambda \norm{x_{\lambda}}^{2} > 0 
            \end{align*}
            since $ \norm{x_{\lambda}}^{2} > 0$, and $ \lambda \norm{x_{\lambda}} > 0 $, it follows that $\lambda > 0$

        
        \item \textbf{Principal submatrices}: 
            A \textbf{principal submatrix} of a square matrix 
            $A \in \mathbb{R}^{n \times n}$ is obtained by selecting a subset of indices 
            $I \subseteq \{1, \ldots, n\}$, and then keeping only the rows and the columns of $A$ with those same indices.
            \bigbreak \noindent 
            \textbf{Examples}
            \[
                A =
                \begin{bmatrix}
                    a_{11} & a_{12} & a_{13} \\
                    a_{21} & a_{22} & a_{23} \\
                    a_{31} & a_{32} & a_{33}
                \end{bmatrix},
            \]
            \begin{itemize}
                \item Choosing $I = \{1,2\}$ gives the principal submatrix
                    \[
                        \begin{bmatrix}
                            a_{11} & a_{12} \\
                            a_{21} & a_{22}
                        \end{bmatrix}.
                    \]

                \item Choosing $I = \{2,3\}$ gives
                    \[
                        \begin{bmatrix}
                            a_{22} & a_{23} \\
                            a_{32} & a_{33}
                        \end{bmatrix}.
                    \]
                \item Choosing $I = \{1,3\} $ gives
                    \begin{align*}
                        \begin{bmatrix}
                            a_{11} & a_{13} \\
                            a_{31} & a_{33}
                        \end{bmatrix}
                    \end{align*}
                \item Choosing $I = \varnothing$ gives the empty matrix, usually denoted $0_{M_{0,0}}$. This empty matrix is in fact a principal submatrix of $A$
            \end{itemize}
            \bigbreak \noindent 
            Note that if $I$ is the subset of indices, then the submatrix is denoted $A[I]$, or $A[I,I]$
            \bigbreak \noindent 
            If $A\in\mathbb{R}^{n\times n} $
            \begin{align*}
                A = \begin{bmatrix}
                    a_{11} & a_{12} & \cdots &a_{1n} \\
                    a_{21} & a_{22} & \cdots &a_{2n} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    a_{n1} & a_{n2} & \cdots &a_{nn}
                \end{bmatrix}
            \end{align*}
            Then the principal submatrices are
            \begin{align*}
                A_{1} &= \begin{bmatrix}
                    a_{11}
                \end{bmatrix} \\
                    A_{2} &= \begin{bmatrix}
                    a_{11} & a_{12} \\
                    a_{21} & a_{22}
                \end{bmatrix} \\
                        A_{3} &= \begin{bmatrix}
                    a_{11} & a_{12} & \cdots &a_{1n} \\
                    a_{21} & a_{22} & \cdots &a_{2n} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    a_{n1} & a_{n2} & \cdots &a_{nn}
                \end{bmatrix}
            \end{align*}
        \item \textbf{Leading principal minors}: Let $A\in \mathbb{R}^{n\times n}$, with
            \begin{align*}
                A = \begin{bmatrix}
                    a_{11} & a_{12} & \cdots & a_{1n} \\
                    a_{21} & a_{22} & \cdots & a_{2n} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    a_{n1} & a_{n2} & \cdots & a_{nn} 
                \end{bmatrix}
            \end{align*}
            \begin{itemize}
                \item Take $I_{1} = \{1\} $
                    \begin{align*}
                       A_{I_{1}} = \begin{bmatrix} a_{11} \end{bmatrix}
                    \end{align*}
                \item Take $I_{2} = \{1,2\} $
                    \begin{align*}
                        A_{I_{2}} = \begin{bmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \end{bmatrix}
                    \end{align*}
                \item Take $I_{k} = \{1,2,...,k\} $ for $k < n$
                    \begin{align*}
                        A_{I_{k}} = \begin{bmatrix}
                            a_{11} & a_{12} & \cdots & a_{1k} \\
                            a_{21} & a_{22} & \cdots & a_{2k} \\
                            \vdots & \vdots & \ddots & \vdots \\
                            a_{k1} & a_{k2} & \cdots & a_{kk} \\
                        \end{bmatrix}
                    \end{align*}
                \item Take $I_{n} = \{1,2,...,n\} $ (The whole matrix)
                    \begin{align*}
                        A = \begin{bmatrix}
                            a_{11} & a_{12} & \cdots & a_{1n} \\
                            a_{21} & a_{22} & \cdots & a_{2n} \\
                            \vdots & \vdots & \ddots & \vdots \\
                            a_{n1} & a_{n2} & \cdots & a_{nn} 
                        \end{bmatrix}
                    \end{align*}
            \end{itemize}
            \bigbreak \noindent 
            These matrices are a special chain of principal submatrices called \textit{leading principal submatrices}
            \bigbreak \noindent 
            This family of principal submatrices are the ones most often used in certain matrix theory results.
        \item \textbf{Determinant of the empty matrix}: We define
            \begin{align*}
                \det(\varnothing) = 1
            \end{align*}
        \item \textbf{Principal minors}: A principal minor is simply the determinant of a principal submatrix.
        \item \textbf{Cholesky decomposition and the Cholesky Factor}: Let $A \in \mathbb{R}^{n\times n}$ be p.d, then $A = R^{\top}R$ where $R$ is upper triangular with $r_{ii} > 0$. The matrix $R$ is called the \textbf{Cholesky factor}.
            \bigbreak \noindent 
            If $A = R^{\top}R$, then $Ax = b$ can be written as 
            \begin{align*}
                R^{\top}Rx = b
            \end{align*}
            where
            \begin{align*}
                \begin{cases}
                        Rx &= y \quad \text{(Lower triangular)}              \\
                        R^{\top}y &= b \quad \text{(Upper triangular)}
                \end{cases}
            \end{align*}
            and since these new systems are triangular, they can be solved quickly with forward or backward substitution.
        \item \textbf{Inner product formulas to compute $R$ (Cholesky factor)}: We have the formulas
            \begin{align*}
                r_{ii} &= \sqrt{a_{ii} - \sum_{k=1}^{i-1}r_{ki}^{2}} \quad i = 1,2,...,n \\
                r_{ij} &= \frac{a_{ij} - \sum_{k=1}^{i-1}r_{ki}r_{kj}}{r_{ii}} \quad j = i+1,...,n
            \end{align*}
        \item \textbf{Recursive column oriented method to find the Cholesky factor $R$ (Outer product method)}: Let $A \in \mathbb{R}^{n\times n}$. Assume that $A$ is positive definite, so $A = A^{\top}$, and $A = R^{\top}R$ for a unique upper triangular matrix $R$. We have,
            \begin{align*}
                A &= \begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \cdots & a_{nn} \end{bmatrix} = 
                \begin{bmatrix}
                    r_{11} & 0  & \cdots & 0\\
                    r_{12} & r_{22}  &  \cdots & 0 \\
                    \vdots & \vdots & \ddots & \vdots\\
                    r_{1n} & r_{2n} & \cdots & r_{nn}
                \end{bmatrix}
                \begin{bmatrix}
                    r_{11} & r_{12} & \cdots & r_{1n} \\
                    0 & r_{22} & \cdots & r_{2n} \\
                    0 & 0 & \ddots & \vdots \\
                    0 & 0  & \cdots & r_{nn}
                \end{bmatrix}
            \end{align*}
            We then perform a matrix decomposition 
            \begin{align*}
                \begin{bmatrix}
                    a_{11} & a^{\top} \\
                    a & \hat{A}
                \end{bmatrix}
                =
                \begin{bmatrix}
                    r_{11} & 0^{\top} \\
                    r & \hat{R}^{\top}
                \end{bmatrix}
                \begin{bmatrix}
                    r_{11} & r^{\top} \\
                    0 & \hat{R}
                \end{bmatrix}
            .\end{align*}
            Where $\hat{A} = \hat{A}^{\top} \in \mathbb{R}^{n-1 \times n-1}$, $a \in \mathbb{R}^{n-1}$, $\hat{R}^{\top} \in \mathbb{R}^{n-1\times n-1}$ lower triangular, and $\hat{R} \in \mathbb{R}^{n-1\times n-1}$ upper triangular. Further,
            \begin{align*}
                \hat{A} &= \begin{bmatrix} a_{22} & \cdots & a_{2n} \\ \vdots & \ddots & \vdots \\ a_{n2} & \cdots & a_{nn} \end{bmatrix},\; a = \begin{pmatrix} a_{21} \\ a_{31} \\ \vdots \\ a_{n1} \end{pmatrix}, \\
                \hat{R} &= \begin{bmatrix} r_{22} &  \cdots & r_{2n} \\ 0 & \ddots & \vdots \\ 0  & \cdots & r_{nn} \end{bmatrix},\; r = \begin{pmatrix} r_{12} \\ r_{13} \\ \vdots \\ r_{1n} \end{pmatrix} 
            .\end{align*}
            So, given this decomposition, we see that 
            \begin{align*}
                a_{11} &= r_{11}^{2} \implies r_{11} = \sqrt{a_{11}}
            .\end{align*}
            Recall that in the definition of the Cholesky factor $R$, $r_{ii} > 0$ for $i = 1,2,...,n  $
            \bigbreak \noindent 
            Continuing the matrix multiplication, we have that
            \begin{align*}
                a &= r_{11}r \implies r = \frac{a}{r_{11}}
            \end{align*}
            and, 
            \begin{align*}
                \hat{A} &=rr^{\top} + \hat{R}\hat{R}^{\top} \implies \hat{R}^{\top}\hat{R} = \hat{A} - rr^{\top} = \tilde{A}
            \end{align*}
            \bigbreak \noindent 
            Thus, 
            the recursive column oriented algorithm to compute the Cholesky factor $R$ is given by the following steps
            \begin{enumerate}
                \item $r_{11} = \sqrt{a_{11}}$
                \item $r = \frac{a}{r_{11}} $
                \item $\tilde{A} = \hat{A} - rr^{\top} $
                \item $\text{Alg}(\tilde{A}) = \hat{R} $
            \end{enumerate}
        \item \textbf{Counting flops for the recursive algorithm above}:
            \begin{enumerate}
                \item (Step 1): One flop
                \item (Step 2): $n-1$ flops
                \item (Step 3): $(n-1)^{2}$ flops. Notice that $r \in \mathbb{R}^{n-1},\; r^{\top} \in \mathbb{R}^{n-1}$, and the outer product
                    \begin{align*}
                        rr^{\top} \in \mathbb{R}^{n-1\times n-1}
                    \end{align*}
                    and requires $(n-1)^{2}$ flops.
                    \bigbreak \noindent 
                    Since $\hat{A} \in \mathbb{R}^{n-1\times n-1}$, $ \hat{A} - rr^{\top}$ requires an addition $(n-1)^{2}$ flops. So, step 3 requires $2(n-1)^{2}$ flops
            \end{enumerate}
            \bigbreak \noindent 
            Thus, 
            \begin{align*}
                f_{n} &= 1 + (n-1) + 2(n-1)^{2} + f_{n-1} \\
                &=n + 2(n-1)^{2} + f_{n-1}
            .\end{align*}
            Where
            \begin{align*}
                f_{n-1} &= 1 + (n-2) + 2(n-2)^{2} + f_{n-2} = n-1 + 2(n-2)^{2} + f_{n-2} \\
                        &\vdots \\
                f_{n-(n-1)}  &= f_{1} = 1 + 0 + 0 + f_{0} 
            .\end{align*}
            Note that $f_{0} = 0$. So, $f_{1} = 1$. In total, we have
            \begin{align*}
                f_{n} &= n + 2(n-1)^{2} + n-1 + 2(n-2)^{2} + n-2 + 2(n-3)^{2} + ... + 1 \\
                      &= \sum_{k=1}^{n} k + 2(k-1)^{2} \\
                      &= \sum_{k=1}^{n}k + 2\sum_{k=1}^{n} k^{2} -2k + 1 \\
                      &= \sum_{k=1}^{n}k + 2\sum_{k=1}^{n}k^{2} - 4\sum_{k=1}^{n}k + 2\sum_{k=1}^{n}1 \\
                      &= 2 \sum_{k=1}^{n}k^{2} - 3\sum_{k=1}^{n}k + 2k \\
                      &= 2 \left(\frac{n(n+1)(2n+1)}{6}\right) - 3 \left(\frac{n(n+1)}{2}\right) + 2k = \mathcal{O}(n^{3})
            \end{align*}
            \bigbreak \noindent 
            So, the recursive algorithm is $\mathcal{O}(n^{3})$
        \item \textbf{Consequence of proof n.1.2:} If $A$ has any $a_{ii} \leq 0$, $A$ is not positive definite.
        \item \textbf{Bordered form of Choleskys method}: Suppose $A \in \mathbb{R}^{n\times n}$ is positive definite. Then, $A$ admits a decomposition $A = R^{\top}R$, for a unique upper triangular matrix $R$ called the Cholesky factor, with $r_{ii} > 0$ for $i =1,2,...,n$. So,
            \begin{align*}
                        A &= \begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \cdots & a_{nn} \end{bmatrix} = 
                \begin{bmatrix}
                    r_{11} & 0  & \cdots & 0\\
                    r_{12} & r_{22}  &  \cdots & 0 \\
                    \vdots & \vdots & \ddots & \vdots\\
                    r_{1n} & r_{2n} & \cdots & r_{nn}
                \end{bmatrix}
                \begin{bmatrix}
                    r_{11} & r_{12} & \cdots & r_{1n} \\
                    0 & r_{22} & \cdots & r_{2n} \\
                    0 & 0 & \ddots & \vdots \\
                    0 & 0  & \cdots & r_{nn}
                \end{bmatrix}
            \end{align*}
        We then perform a matrix decomposition 
        \begin{align*}
            \begin{bmatrix}
                \hat{A} & a \\
                a^{\top} & a_{nn}
            \end{bmatrix}
             =
             \begin{bmatrix}
                 \hat{R}^{\top} & 0 \\
                 r^{\top} & r_{nn}
             \end{bmatrix}
             \begin{bmatrix}
                 \hat{R} & r \\
                 0 & r_{nn}
             \end{bmatrix}
        .\end{align*}
        So, 
        \begin{align*}
            \hat{A} &= \hat{R}^{\top}\hat{R}, \\
            a &= \hat{R}^{\top}r, \\
            a_{nn} &= r^{\top}r + r_{nn}^{2} \implies r_{nn} = \sqrt{a_{nn} - r^{\top}r}
        .\end{align*}
        So, the steps for the algorithm are 
        \begin{enumerate}
            \item Recurse $\hat{A}$ until $A \in \mathbb{R}^{1\times 1}$
            \item Solve the lower triangular system $\hat{R}^{\top}r = a$ by forward substitution
            \item Compute $r_{nn} = \sqrt{a_{nn} - r^{\top}r} $
            \item Return the step two on the previous call
        \end{enumerate}
        The above algorithm is postorder recursion and requires $\mathcal{O}(n^{3})$ flops.



    \end{itemize}

    \pagebreak 
    \subsubsection{Banded Matrices}
    \begin{itemize}
        \item \textbf{Cholesky factor $R$ in a diagonal matrix}: If $A = D = \begin{bmatrix}
                a_{11} & 0 & \cdots & 0 \\
                0 & a_{22} & \cdots & 0 \\
                \vdots & \vdots & \ddots & \vdots \\
                0 & 0 & \cdots & a_{nn} 
        \end{bmatrix}$ then
        \begin{align*}
            R = \begin{bmatrix}
                \sqrt{a_{11}} & 0 & \cdots & 0 \\
                0 & \sqrt{a_{22}} & \cdots & 0 \\
                \vdots & \vdots & \ddots & \vdots \\
                0 & 0 & \cdots & \sqrt{a_{nn}}
            \end{bmatrix}
        \end{align*}
        \item \textbf{Banded matrix}: A banded matrix is a sparse matrix whose nonzero entries are confined to a diagonal band, consisting of the main diagonal and a fixed number of diagonals on either side of it.
            \bigbreak \noindent 
                Let $A \in \mathbb{R}^{m \times n}$.  
                Then $A$ is called a \textbf{banded matrix} if there exist nonnegative integers $p, q$ (called the \emph{lower} and \emph{upper bandwidths}) such that
                \[
                    a_{ij} = 0 \quad \text{whenever } i - j > p \text{ or } j - i > q.
                \]
                \begin{itemize}
                    \item The \emph{lower bandwidth} $p$ is the number of subdiagonals (below the main diagonal) that may contain nonzero entries.
                    \item The \emph{upper bandwidth} $q$ is the number of superdiagonals (above the main diagonal) that may contain nonzero entries.
                \end{itemize}
                The \emph{total bandwidth} is sometimes defined as $p + q + 1$, counting the main diagonal as well.
                \bigbreak \noindent 
                A tridiagonal matrix has lower bandwidth $p=1$ and upper bandwidth $q=1$:
                \[
                    A =
                    \begin{bmatrix}
                        a_{11} & a_{12} & 0      & 0      \\
                        a_{21} & a_{22} & a_{23} & 0      \\
                        0      & a_{32} & a_{33} & a_{34} \\
                        0      & 0      & a_{43} & a_{44}
                    \end{bmatrix}.
                \]
                The total bandwidth here is $1 + 1 + 1 = 3$.

            % \item \textbf{Column envelope}:  
            %     The \emph{column envelope} of a matrix $A = [a_{ij}] \in \mathbb{R}^{n \times n}$ is the set of index pairs $(i,j)$ lying in the upper triangular part of $A$ (including the diagonal) such that at least one nonzero entry occurs in column $j$ at or above row $i$. Formally,
            %     \begin{align*}
            %         \operatorname{colenv}(A) 
            %         = \{\, (i,j) \mid 1 \le i \le j \le n,\; 
            %         \exists\, k \le i \text{ with } a_{kj} \ne 0 \,\}.
            %     \end{align*}
        \item \textbf{Column envelope}: The column envelope of $A $ is the set of indices $(i,j)$ in the upper triangular part of $A$ (including the main diagonal). Define
            \begin{align*}
            \text{colenv}\{A\} = \{(i,j)\} :\; i \leq j \text{ and } a_{kj} \ne 0 \text{ for } k \leq i\}
            \end{align*}
        \item \textbf{Theorem}: Let $A$ be p.d, if $R$ is the Cholesky factor of $A$, then
            \begin{align*}
                \operatorname{colenv}\{R\}  = \operatorname{colenv}\{A\}
            \end{align*}
    \end{itemize}

    \pagebreak 
    \subsubsection{Gaussian Elimination and LU Decompositions}
    \begin{itemize}
        \item \textbf{Intro to $LU$ decomposition}: Consider a matrix $A \in \mathbb{R}^{n\times n} $. If we can factor $A$ as $A = LU$, for $L$ lower triangular, $U$ upper triangular, then the system $Ax = b$, for vectors $x,b \in \mathbb{R}^{n}$ turns into
            \begin{align*}
                LUx = b
            .\end{align*}
            We can then split this system as follows
            \begin{align*}
                \begin{cases}
                    Ly &= b \\
                    Ux &= y
                \end{cases}
            \end{align*}
            First, we solve $Ly = b$ with forward substitution to find $y$. We can then solve $Ux = y$ with backward substitution to find the target $x$.
            \bigbreak \noindent 
            Recall that the forward and backward substitution methods for solving linear systems requires $\mathcal{O}(n^{2})$ flops.
        \item \textbf{Elementary operations on systems that do not change the solution set}. We have the operations
            \begin{enumerate}
                \item Interchange rows.
                \item Multiply an equation by a nonzero constant.
                \item Add a multiple of one equation to another equation.
            \end{enumerate}
            We show that these elementary operations (E.O) leave the solution set unchanged. Let the original system be $S$ and the modified system be $S^{\prime}$. To show that the solution set is unchanged is to show that if a vector $x$ is a solution to $S$ then it is also a solution to $S^{\prime}$, and vice versa.
            \bigbreak \noindent 
            Consider the system $S$, $Ax = b$ for $A \in \mathbb{R}^{n\times n}$, $x,b \in \mathbb{R}^{n}$. So, the system is
            \begin{align*}
                a_{11}x_{1} + a_{12}x_{2} + ... + a_{1n}x_{n} &= b_{1},\\
                a_{21}x_{1} + a_{22}x_{2} + ... + a_{2n}x_{n} &= b_{2},\\
                                                              &\vdots\\
                a_{n1}x_{1} + a_{n2}x_{2} +  ... + a_{nn}x_{n} &= b_{n}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof (2).}} Multiply an arbitrary equation by a nonzero scalar $k$, suppose we choose the second equation. $S^{\prime}$ is then
             \begin{align*}
                a_{11}x_{1} + a_{12}x_{2} + ... + a_{1n}x_{n} &= b_{1},\\
                k(a_{21}x_{1} + a_{22}x_{2} + ... + a_{2n}x_{n}) &= k(b_{2}),\\
                                                              &\vdots\\
                a_{n1}x_{1} + a_{n2}x_{2} +  ... + a_{nn}x_{n} &= b_{n}
            .\end{align*}
            Let $(c_{1}, c_{2},...,c_{n})$ be a solution to the original system $S$. That is, it satisfies all equations. Let's look at the second equation
            \begin{align*}
                a_{21}c_{1} + a_{22}c_{2} + ... + a_{2n}c_{n} &= b_{2}\\
            \end{align*}
            If we multiply by $k$, we get
            \begin{align*}
                k(a_{21}c_{1} + a_{22}c_{2} + ... + a_{2n}c_{n}) &= k(b_{2})
            .\end{align*}
            Which means $(c_{1}, c_{2}, ..., c_{n}) $ also satisfies the second equation in $S^{\prime}$. Since all other equations were left unchanged, $(c_{1}, c_{2},...,c_{n}) $ satisfies those equations as well. So, the solution set is the same for both systems.
            \bigbreak \noindent 
            \textbf{Note}: If $k=0$, the second equation would collapse to $0=0$, which would enlarge the solution set. In this case, a constraint would be removed from the  system $S^{\prime}$. The second equation is now tautological, it imposes no restriction. The solution set would be
            \begin{align*}
                \{x\in \mathbb{R}^{n}:\ Ax = b \text{ for all rows except row two}\}
            \end{align*}
            \bigbreak \noindent 
            Every solution of $S$ is also a solution of $S^{\prime}$, but the converse need not hold: $S^{\prime}$ could have solutions that don’t satisfy the second original equation. 
            \bigbreak \noindent 
            So $S^{\prime}$ has at least as many solutions, and possibly more. If the second equation was independent of the others, then yes - you've enlarged the solution set.
            \bigbreak \noindent 
            \textbf{\textit{Proof (3).}} Add an arbitrary equation to a different equation. Suppose we add the first equation to the second equation. Note that we leave the first unchanged. $S^{\prime}$ is then
             \begin{align*}
                a_{11}x_{1} + a_{12}x_{2} + ... + a_{1n}x_{n} &= b_{1},\\
                (a_{21}+a_{11})x_{1} + (a_{22}+a_{12})x_{2} + ... + (a_{2n} + a_{1n})x_{n}) &= b_{2} + b_{1},\\
                                                                                            &\vdots\\
                a_{n1}x_{1} + a_{n2}x_{2} +  ... + a_{nn}x_{n} &= b_{n}
            .\end{align*}
            Let $c = (c_{1}, c_{2}, ..., c_{n}) $ be a solution to $S$, so $c$ is a solution to the first, second, and the remaining equations. That is, 
            \begin{align*}
                a_{11}c_{1} + a_{12}c_{2} + ... + a_{1n}c_{n} &= b_{1},\\
                a_{21}c_{1} + a_{22}c_{2} + ... + a_{2n}c_{n} &= b_{2},\\
                                                              &\vdots\\
                a_{n1}c_{1} + a_{n2}c_{2} +  ... + a_{nn}c_{n} &= b_{n}
            .\end{align*}
            Add the first equation to the second, we get
             \begin{align*}
                a_{11}c_{1} + a_{12}c_{2} + ... + a_{1n}c_{n} &= b_{1},\\
                (a_{21}+a_{11})c_{1} + (a_{22}+a_{12})c_{2} + ... + (a_{2n} + a_{1n})c_{n}) &= b_{2} + b_{1},\\
                                                                                            &\vdots\\
                a_{n1}c_{1} + a_{n2}c_{2} +  ... + a_{nn}c_{n} &= b_{n}
            \end{align*}
            which is precisely $S^{\prime}$, so $c$ satisfies $ S^{\prime}$. Next, let $c = (c_{1}, c_{2}, ..., c_{n}) $ be a solution to $S^{\prime}$. So,
             \begin{align*}
                a_{11}c_{1} + a_{12}c_{2} + ... + a_{1n}c_{n} &= b_{1},\\
                (a_{21}+a_{11})c_{1} + (a_{22}+a_{12})c_{2} + ... + (a_{2n} + a_{1n})c_{n}) &= b_{2} + b_{1},\\
                                                                                            &\vdots\\
                a_{n1}c_{1} + a_{n2}c_{2} +  ... + a_{nn}c_{n} &= b_{n}
            \end{align*}
            Subtract the first equation from the second, and we get back $S$. So, the solution set remains unchanged.
        \item \textbf{Elimination matrix $E$}: An elimination matrix is just a special matrix that performs a single step of Gaussian elimination when you multiply it by another matrix.
            \bigbreak \noindent 
            Suppose you want to eliminate the entry in row $i$, column $j$ of $A$. In elimination, you would replace row $i$ by
            \[
                \text{row}_{i} - m \cdot \text{row}_{j},
            \]
            where $m = \tfrac{a_{ij}}{a_{jj}}$.
            \bigbreak \noindent 
            The \textbf{elimination matrix} $E$ is the identity matrix, except in position $(i,j)$, where it has $-m$. So,
            \[
                E = I - m e_i e_j^{\top} = I - mE_{ij},
            \]
            where $e_i$ and $e_j$ are standard basis vectors (all zeros except a one at the $i^{\text{th}}$ or $j^{\text{th}} $ position), and $E_{ij} = e_{i}e_{j}^{T} $
            \bigbreak \noindent 
            Multiplying $E$ by $A$ from the left actually performs that row operation:
            \[
                EA = A \quad \text{with entry $(i,j)$ zeroed out.}
            \]
            Let
            \[
                A = \begin{bmatrix}
                    2 & 1 \\
                    4 & 3
                \end{bmatrix}.
            \]
            We want to eliminate the entry in the bottom-left,  the multiplier is
            \[
                m = \frac{4}{2} = 2.
            \]
            The elimination matrix is
            \[
                E = \begin{bmatrix}
                    1 & 0 \\
                    -2 & 1
                \end{bmatrix}.
            \]
            Now check
            \[
                EA =
                \begin{bmatrix}
                    1 & 0 \\
                    -2 & 1
                \end{bmatrix}
                \begin{bmatrix}
                    2 & 1 \\
                    4 & 3
                \end{bmatrix}
                =
                \begin{bmatrix}
                    2 & 1 \\
                    0 & 1
                \end{bmatrix},
            \]
        \item \textbf{Type three elementary operations using left matrix multiplication}: Suppose we have $A \in \mathbb{R}^{n\times n}$, and we want to add a multiple of the $j^{\text{th}}$ row to the $i^{\text{th}}$ row, call $\tilde{A}$ the matrix obtained after this elementary operation
            \begin{align*}
                &\text{If } k \ne i,\; \text{row}_{k}(\tilde{A}) = \text{ row}_{k}(A), \\ 
                &\text{If } k = i,\; \text{row}_{k}(\tilde{A}) = \text{ row}_{k}(A) + m\cdot \text{row}_{j}(A)
            .\end{align*}
            We assert that $\tilde{A} = MA$, where $M \in \mathbb{R}^{n\times n}$ is the identity matrix, except for $m$ at position $i,j$. If $i > j$, $M$ is lower triangular, and if $i < j $, $M$ is upper triangular. If we use this fact during Gaussian elimination, $M$ will always be lower triangular, since we only care about zeroing out the lower triangular part of $A$.
            \bigbreak \noindent 
            Let $E_{ij}$ be the zero matrix except for a one at $e_{ij}$. Thus, 
            \begin{align*}
                M &= I + mE_{ij}
            .\end{align*}
            Observe that $E_{ij} = e_{i}e_{j}^{T}$, so
            \begin{align*}
                M &= I + me_{i}e_{j}^{T}
            .\end{align*}
            From this fact, we have
            \begin{align*}
                MA &= (I + me_{i}e_{j}^{T})A = A + me_{i}(e_{j}^{T}A)
            .\end{align*}
            Recall that $e_{j}^{T}A$ is the $j^{\text{th}} $ row of $A$, so
            \begin{align*}
                MA &= A + me_{i} \cdot  \text{row}_{j}(A)
            .\end{align*}
            Further observe that $e_{i} \cdot \text{row}_{j}(A)$ is a matrix of size $n\times n$, where the $i^{\text{th}} $ row is $\text{row}_{j}(A)$, and all other rows are zero.
            \bigbreak \noindent 
            So, we see that 
            \begin{align*}
                &\text{If } k \ne i,\; \text{row}_{k}(E_{ij}A) = 0, \; \text{ so } \text{row}_{k}(MA) = \text{ row}_{k}(A), \\
                &\text{If } k = i,\; \text{row}_{k}(E_{ij}A) = \text{row}_{j}(A), \; \text{ so } \text{row}_{k}(MA) = \text{row}_{i}(A) + m \cdot  \text{row}_{j}(A)
            .\end{align*}
            Thus, $\tilde{A} = MA$ $\endpf$
        \item \textbf{Type two elementary operations using left matrix multiplication}: Suppose $\tilde{A}$ is obtained from $A$ by multiplying the $i$th row by the nonzero constant $c$. We wish to find a matrix $M$ such that $MA = \tilde{A}$
        \bigbreak \noindent 
        Suppose we have $A \in \mathbb{R}^{2\times 2}$, where 
        \begin{align*}
            A = \begin{bmatrix}
                \alpha & \beta \\
                \gamma & \varphi
            \end{bmatrix}
        .\end{align*}
        Now, suppose we want to scale the second row by $c$, where $c \in \mathbb{R}$, then
        \begin{align*}
            \tilde{A} = \begin{bmatrix}
                \alpha & \beta \\ 
                c\gamma & c\varphi
            \end{bmatrix}
            &= 
            \begin{bmatrix}
                \alpha & \beta \\
                \gamma & \varphi 
            \end{bmatrix}
             + 
             \begin{bmatrix}
                 \alpha & \beta \\
                 (c-1)\gamma & (c-1)\varphi
             \end{bmatrix}
             \\
            &= A + (c-1)\begin{bmatrix}
                0 & 0 \\
                0 & 1
            \end{bmatrix}
            A
            \\
            &= A + (c-1)E_{22}A
        .\end{align*}
        So, suppose we wish to scale the $i^{\text{th}}$ row of $A$ by a constant $c$, then
        \begin{align*}
            \tilde{A}= A + (c-1)E_{ii}A = (I + (c-1)E_{ii})A = MA
        .\end{align*} 
        Thus, $M = I + (c-1)E_{ii}$.
        \bigbreak \noindent 
        It seems that the inverse operation is multiplying row $i$ by $\frac{1}{c}$. Thus, we propose that the inverse of $M$ is
        \begin{align*}
            M^{-1} = I + \left(\frac{1}{c} - 1\right)E_{ii}
        .\end{align*}
        We have
        \begin{align*}
            MM^{-1} &= \left(I + (c-1)E_{ii}\right)\left(I + \left(\frac{1}{c}-1\right)E_{ii}\right) \\
                    &= I + \left(\frac{1}{c}-1\right)E_{ii} + (c-1)E_{ii} + (c-1)\left(\frac{1}{c}-1\right)E_{ii}^{2}
        .\end{align*}
        But,
        \begin{align*}
            E_{ii}^{2} &= (e_{i}e_{i}^{T})(e_{i}e_{i}^{T}) = e_{i}(e_{i}^{T}e_{i})e_{i}^{T} \\
                       &= (e_{i}^{T}e_{i})e_{i}e_{i}^{T} = (e_{i}^{T}e_{i})E_{ii} \\
                       &= \norm{e_{i}}^{2}E_{ii} = E_{ii}
        .\end{align*}
        So, $E_{ii}^{2} = E_{ii}$, and 
        \begin{align*}
            MM^{-1} &= II + \left(\frac{1}{c}-1\right)E_{ii} + (c-1)E_{ii} + (c-1)\left(\frac{1}{c}-1\right)E_{ii}^{2} \\
            &= I + \left(\frac{1}{c}-1 + c-1\right)E_{ii} + (c-1)\left(\frac{1}{c}-1\right)E_{ii} \\
            &= I + \left(\frac{1}{c}-1 + c-1 + (c-1)\left(\frac{1}{c}-1\right)\right)E_{ii} \\
            &= I + \left(\frac{1}{c}-1+c-1 + 1 -c - \frac{1}{c} + 1\right)E_{ii} \\
            &= I + 0 E_{ii} = I
        .\end{align*}
        Thus, $M^{-1} = I + \left(\frac{1}{c}-1\right) E_{ii}$
        \bigbreak \noindent 
        Observe that the determinant of $M$ is   
        \begin{align*}
            \det(M) = \det(I + (c-1)E_{ii}) = \prod_{k=1}^{n} m_{kk}
        .\end{align*}
        But, notice that $m_{kk} =1$, except at $k=i$, where we have $m_{ii}=  1 + (c-1) = c$. Thus, $\det(M) = c $, and 
        \begin{align*}
            \det(\tilde{A}) = \det(MA) =  \det(M)\det(A) = c\det(A)
        .\end{align*}
        Since $c\ne 0$, $\det(\tilde{A}) = 0 \iff \det(A) = 0$. Hence, $\tilde{A}$ is nonsingular if and only if $A$ is. $\endpf$

        \item \textbf{LU Factorization without E.O (1)}: We perform Gaussian Elimination on the augmented system $[A|b] $ to yield a new system $[U|y]$.
            \bigbreak \noindent 
        We move down the main diagonal selecting $a_{ii}$ as the \textbf{pivot element}, and row $i$ as the \textbf{pivot row}. We do this for $i = 1,2,...,n$. For each pivot element, we get the elements $a_{ki} = 0$ for $k=i+1,i+2,...,n$ we can accomplish this without interchanging rows so long as the pivot elements are nonzero.
        \bigbreak \noindent 
        We perform elementary operations of the form
        \begin{align*}
            -m_{ki}r_{i} + r_{k} \to r_{k}^{\prime} \quad \text{ for } k = i+1,i+2,...,n
        \end{align*}
        where $r_{i}$ is the $i^{\text{th}}$ row, $r_{k}$ is the $k^{\text{th}}$ row, and $m_{ki}$ is the \textbf{multiplier} $m_{ki} = \frac{a_{ki}}{a_{ii}} $
        \bigbreak \noindent 
        Upon completion of the Gaussian elimination, the collected multipliers together with ones in the main diagonal and zeros in the entries above the main diagonal form the matrix $L$.
        \bigbreak \noindent 
        \textbf{Additional information:} We perform Gaussian elimination on the augmented matrix $[A|b] \to [U|y]$. Note that after we achieve $U$, we have the system $Ux = y$ with the same solution set as $Ax = b$. 
        \bigbreak \noindent 
        Notice that each step has its own elimination matrix $E_{1},E_{2},... $. If we apply them in sequence,
        \begin{align*}
            E_{k} \cdots E_{2}E_{1}A = U
        \end{align*}
        Where $U$ is the final upper triangular matrix. It follows that 
        \begin{align*}
            A = (E_{k} \cdots E_{2}E_{1})^{-1}U
        \end{align*}
        Define 
        \begin{align*}
            (E_{k} \cdots E_{2}E_{1})^{-1} = L
        \end{align*}
        It’s lower triangular because each elimination matrix is lower triangular, and the inverse of a lower triangular matrix is also lower triangular.
        \bigbreak \noindent 

        \bigbreak \noindent 
        For example, consider the system
        \begin{align*}
            \begin{bmatrix}
                \begin{array}{ccc|c}
                    2 & 1 & 1 & 7 \\
                    2 & 2 & -1 & 3 \\
                    4 & -1 & 6 & 20
               \end{array}
            \end{bmatrix}
        \end{align*}
        We start with $a_{11} = 2$ as the pivot element, and row one as the pivot row. We perform elementary operations of the form above to get $a_{21} = a_{31} = 0$. To get $a_{21} = 0$, we have the operation
        \begin{align*}
            -1r_{1} + r_{2} \to r_{2}^{\prime}, \quad m_{21} = 1
        \end{align*}
        To get $a_{31} = 0$, we perform the operation
        \begin{align*}
            -2r_{1} + r_{3} \to r_{3}^{\prime}, \quad m_{31} = 2
        \end{align*}
        After the two operations, we have
        \begin{align*}
            \begin{bmatrix}
                \begin{array}{ccc|c}
                    2 & 1 & 1 & 7 \\
                    0 & 1 & -2 & -4 \\
                    0 & -3 & 4 & 6
                \end{array}
            \end{bmatrix}
        \end{align*}
        We move to the next pivot element $a_{22} = 1$. To get $a_{32} = 0$, we perform the operation
        \begin{align*}
            -(-3)r_{2} + r_{3} \to r_{3}^{\prime},\quad m_{32} = -3
        \end{align*}
        So after the last operation we have
        \begin{align*}
            \begin{bmatrix}
                \begin{array}{ccc|c}
                    2 & 1 & 1 & 7 \\
                    0 & 1 & -2 & -4 \\
                    0 & 0 & -2 & -6
                \end{array}
            \end{bmatrix}
        \end{align*}
        % \item \textbf{Theorem}: Let $A \in \mathbb{R}^{n\times n}$, $A$ can be factored as $A = LU$, for $L \in \mathbb{R}^{n\times n}$ unit lower triangular, $U \in \mathbb{R}^{n\times n}$ upper triangular if and only if all leading principal submatrices of $A$ are nonsingular.
    \item \textbf{Theorem}: Let $A \in \mathbb{R}^{n\times n}$ be nonsingular. Then, we can solve the system $Ax = b$, $b \in \mathbb{R}^{n}$ using Gaussian Elimination without row interchanges if and only if all landing principal sub-matrices of $A$ are nonsingular.
    \item \textbf{Theorem}: Let $A \in \mathbb{R}^{n \times n}$. Then $A$ admits an LU factorization
            \[
                A = LU,
            \]
            where $L \in \mathbb{R}^{n \times n}$ is unit lower triangular and 
            $U \in \mathbb{R}^{n \times n}$ is upper triangular, 
            \textbf{without row interchanges}, if and only if all leading principal 
            submatrices of $A$ are nonsingular.

    \item \textbf{Row oriented algorithm to find $LU$ factorization}: 
        Let $A \in \mathbb{R}^{n\times n}$. If $A$ can be factored into products $LU$, for $U \in \mathbb{R}^{n\times n}$ upper triangular, $L \in \mathbb{R}^{n\times n}$ unit lower triangular, then
        \begin{align*}
            A &= LU  
        \end{align*}
        implies
        \begin{align*}
              \begin{bmatrix}
                a_{11} & a_{12} & a_{13} & \cdots & a_{1n} \\
                a_{21} & a_{22} & a_{23} & \cdots & a_{2n} \\
                a_{31} & a_{32} & a_{33} & \cdots & a_{3n} \\
                \vdots & \vdots & \vdots & \ddots & \vdots \\
                a_{n1} & a_{n2} & a_{n3} & \cdots & a_{nn} \\
            \end{bmatrix}
             = \begin{bmatrix}
                 1 & 0 & 0 & \cdots & 0 \\
                 \ell_{21} & 1 & 0 & \cdots & 0 \\
                 \ell_{31} & \ell_{32} & 1 & \cdots & 0 \\
                 \vdots & \vdots & \vdots & \ddots & \vdots \\
                 \ell_{n1} & \ell_{n2} & \ell_{n3} & \cdots & 1
             \end{bmatrix}
             \begin{bmatrix}
                 u_{11} & u_{12} & u_{13} & \cdots & u_{1n} \\
                 0  & u_{22} & u_{23} & \cdots & u_{1n} \\
                 0& 0& u_{33} & \cdots & u_{3n} \\
                 \vdots & \vdots & \vdots & \ddots & \vdots \\
                 0 & 0 & 0 & \cdots & u_{nn}
             \end{bmatrix}
        .\end{align*}
        Let's first examine the formula for $u_{ij}$ by solving for each row in $U$
        \begin{enumerate}
            \item \textbf{Row 1}: for $j=1,\dots,n$
                \[
                    u_{1j} = a_{1j}.
                \]

            \item \textbf{Row 2}: for $j=2,\dots,n$
                \[
                    u_{2j} = a_{2j} - \ell_{21}\,u_{1j}.
                \]

            \item \textbf{Row 3}: for $j=3,\dots,n$
                \[
                    u_{3j} = a_{3j} - \ell_{31}\,u_{1j} - \ell_{32}\,u_{2j}.
                \]

            \item \textbf{Row $i$}: for $j=i,\dots,n$
                \[
                    u_{ij} = a_{ij} - \sum_{k=1}^{i-1} \ell_{ik}\,u_{kj}.
                \]

            \item \textbf{Row $n$}: (just the diagonal entry)
                \[
                    u_{nn} = a_{nn} - \sum_{k=1}^{n-1} \ell_{nk}\,u_{kn}.
                \]
        \end{enumerate}
        Next, we look at the formula for $\ell_{ij}$ by solving for each column in $L$
        \begin{enumerate}
            \item \textbf{Column 1}: for $i=2,\dots,n$
                \[
                    \ell_{i1} \;=\; \frac{a_{i1}}{u_{11}}.
                \]
            \item \textbf{Column 2}: for $i=3,\dots,n$
                \[
                    \ell_{i2} \;=\; \frac{a_{i2} - \ell_{i1}u_{12}}{u_{22}}.
                \]
            \item \textbf{Column 3}: for $i=4,\dots,n$
                \[
                    \ell_{i3} \;=\; \frac{a_{i3} - \ell_{i1}u_{13} - \ell_{i2}u_{23}}{u_{33}}.
                \]
            \item \textbf{Column $j$}: for $i=j+1,\dots,n$
                \[
                    \ell_{ij} \;=\; \frac{a_{ij} - \sum_{k=1}^{j-1}\ell_{ik}u_{kj}}{u_{jj}}.
                \]
            \item \textbf{Column $n$}: (no entries below the diagonal to compute if $j=n$)
                \[
                    \text{Only } \ell_{nn}=1 \text{ (by unit lower convention).}
                \]
        \end{enumerate}
        So, we see that
        \begin{align*}
            u_{ij} &= a_{ij} - \sum_{k=1}^{i-1}\ell_{ik}u_{kj} \quad j=i,i+1,...,n \tag{1} \\
            \ell_{ij} &= \frac{a_{ij} - \sum_{k=1}^{j-1}\ell_{ik}u_{kj}}{u_{jj}} \quad i=j+1,j+2,...,n \tag{2}
        \end{align*}
        \bigbreak \noindent 
        To use these formulas to find each $u_{ij}$ we first need to plug $i=1$ into $(1)$, then after we get the first row of $U$, we can plug in $j=1$ into $(2)$ to get the first column of $L$, and so on.

        \item \textbf{Column oriented recursive algorithm to find the $LU$ factorization}: 
            Assume $A \in \mathbb{R}^{n\times n }$ admits an $LU$ factorization for $L\in \mathbb{R}^{n\times n}$ unit lower triangular, $U$ upper triangular. Then,
            \begin{align*}
                A = LU
            \end{align*}
            implies
            \begin{align*}
                \begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \cdots & a_{nn} \end{bmatrix} = 
                \begin{bmatrix} 1 & 0 & \cdots & 0 \\ \ell_{21} & \ell_{22} & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ \ell_{n1} & \ell_{n2} & \cdots & 1 \end{bmatrix}
                \begin{bmatrix} u_{11} & u_{12} & \cdots & u_{1n} \\ 0 & u_{22} & \cdots & u_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & u_{nn} \end{bmatrix}
            .\end{align*}
            Decompose $A = LU$ into the blocks
            \begin{align*}
                \begin{bmatrix}
                    a_{11} & b^{\top} \\
                    a & \hat{A}
                \end{bmatrix}
                =
                \begin{bmatrix}
                    1 & 0^{\top} \\
                    \ell & \hat{L}
                \end{bmatrix}
                \begin{bmatrix}
                    u_{11} & u^{\top} \\
                    0 & \hat{U}
                \end{bmatrix}
            .\end{align*}
            We see that
            \begin{align*}
                a_{11} &= u_{11}, \\
                b^{\top} &= u^{\top}, \\
                \ell u_{11} &= a \implies \ell = \frac{a}{u_{11}}, \\
                \hat{A} &= \ell u^{\top} + \hat{L}\hat{U} \implies \hat{L}\hat{U} = \hat{A} - \ell u^{\top}
            .\end{align*}
            Define $\tilde{A} = \hat{A} - \ell u^{\top}$. 
            The recursive algorithm is then defined by the following steps.
            \begin{enumerate}
                \item $u_{11} = a_{11} $ (zero flops)
                \item $u^{\top} = b^{\top} $ (zero flops)
                \item $\ell = \frac{a}{u_{11}} $ ($n-1$ flops) 
                \item $\tilde{A} = \hat{L}\hat{U} = \hat{A} - \ell u^{\top} $ ($2(n-1)^{2}$ flops)
                \item $\text{Alg}(\tilde{A})$
            \end{enumerate}
            Let $f(n)$ be the flop count for the above algorithm. We have
            \begin{align*}
                f(n) &= 0 + 0  + (n-1) + 2(n-1)^{2} + f_{n-1} = (n-1) + 2(n-1)^{2} + f_{n-1}\\
                f(n-1) &= ((n-1) - 1) + 2((n-1)-1)^{2} + f_{n-2} \\
                       &\vdots \\
                f(n-(n-2)) &= f_{2} = ((n-(n-2))-1) + 2((n-(n-2))-1)^{2} + f_{n-(n-1)} \\
                f_{n-(n-1)} &= f_{1} = 0 
            \end{align*}
            So, the total number of flops is given by the sum
            \begin{align*}
                \sum_{k=2}^{n} (k-1) + 2(k-1)^{2}
            .\end{align*}
            Let $ i = k-1 $. When  $k=2$, $i = 1$. When $k=n$, $i = n-1$. So, the sum becomes
            \begin{align*}
                \sum_{i=1}^{n-1} 2i^{2} + i
            \end{align*}
            \begin{remark}
                We have the summation rules
                \begin{align*}
                    \sum_{i=1}^{n} i = \frac{n(n+1)}{2}, \quad \sum_{i=1}^{n} i^{2} = \frac{n(n+1)(2n+1)}{6}
                \end{align*}
                Plug in $n-1$ for each,
                \begin{align*}
                   \sum_{i=1}^{n} i = \frac{(n-1)n}{2}, \quad \sum_{i=1}^{n} i^{2} = \frac{(n-1)n(2n-1)}{6} 
                \end{align*}
            \end{remark}
            So,
            \begin{align*}
                \sum_{i=1}^{n-1} 2i^{2} + i &= 2\left(\frac{(n-1)n(2n-1)}{6}\right) + \frac{(n-1)n}{2} \\
                                            &= \frac{2}{3}n^{2} -\frac{1}{2}n^{2} - \frac{1}{6}n = \frac{2}{3}n^{3} + \mathcal{O}(n^{2})
            \end{align*}
            Therefore, the number of flops required for the recursive outer product method to find the $LU$ factorization is $\frac{2}{3}n^{3} + \mathcal{O}(n^{2}) $
        \item \textbf{Bordered form $LU$ decomposition algorithm}:
            Assume $A \in \mathbb{R}^{n\times n }$ admits an $LU$ factorization for $L\in \mathbb{R}^{n\times n}$ unit lower triangular, $U$ upper triangular. Then,
            \begin{align*}
                A = LU
            \end{align*}
            implies
            \begin{align*}
                \begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \cdots & a_{nn} \end{bmatrix} = 
                \begin{bmatrix} 1 & 0 & \cdots & 0 \\ \ell_{21} & \ell_{22} & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ \ell_{n1} & \ell_{n2} & \cdots & 1 \end{bmatrix}
                \begin{bmatrix} u_{11} & u_{12} & \cdots & u_{1n} \\ 0 & u_{22} & \cdots & u_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & u_{nn} \end{bmatrix}
            .\end{align*}
            Decompose $A = LU$ into the blocks
            \begin{align*}
                \begin{bmatrix}
                    \hat{A} & b \\
                    a^{\top} & a_{nn}
                \end{bmatrix}
                = 
                \begin{bmatrix}
                    \hat{L} & 0 \\
                    \ell^{\top} & 1
                \end{bmatrix}
                \begin{bmatrix}
                    \hat{U} & u \\
                    0^{\top} & u_{nn}
                \end{bmatrix}
            \end{align*}
            Where $\hat{A}, \hat{L}, \hat{U}$ are the $(n-1)^{\text{th}}$ leading principal submatrices of $A,L,U$.
            \bigbreak \noindent 
            Then, 
            \begin{align*}
                \hat{A} &= \hat{L}\hat{U} \\
                \hat{L}U &= b  \\
                \ell^{\top} \hat{U} &= a^{\top} \implies \hat{U}^{\top}\ell = a \\
                u_{nn} &= a_{nn} - \ell^{\top}u^{\top}
            \end{align*}
        % \item \textbf{$LU $ factorization of symmetric, non positive definite systems}: Let $A \in \mathbb{R}^{n\times n}$ be symmetric, but not positive definite. So, $A = A^{\top}$. Assume that $A$ admits an $LU$ factorization $A = LU$.  
        %     \bigbreak \noindent 
        %     In this case, we require $L$ to not be unit lower triangular, just lower triangular.
        %     \begin{align*}
        %         A^{\top} &= A = LU = (LU)^{\top} = U^{\top}L^{\top}
        %     \end{align*}
        %     So,
        %     \begin{align*}
        %         U^{\top} &= L, \\
        %         L^{\top} &= U
        %     \end{align*}
        %     Thus,
        %     \begin{align*}
        %         A &= LL^{\top} \quad \text{ or } \quad A = U^{\top}U
        %     \end{align*}
        %     Which would halve the flops of the normal $A = LU$ factorization. 
        %     \bigbreak \noindent 
        %     If $L$ were unit lower triangular, then
        %     \begin{align*}
        %         A &= LDL^{\top}
        %     \end{align*}
        %
        \item \textbf{Intro to row interchanges (pivoting)}: Without pivoting, Gaussian elimination can behave as if the problem were ill-conditioned even when it is not, because tiny pivots can amplify rounding errors. This is why we use partial pivoting.
            \bigbreak \noindent 
            Consider the system
            \begin{align*}
                \begin{bmatrix}
                    0.0003 & 1.566 \\
                    0.3454 & -2.436
                \end{bmatrix}
                \begin{bmatrix}
                    x_{1} \\ x_{2}
                \end{bmatrix}
                =
                \begin{bmatrix}
                    1.569 \\ 1.018
                \end{bmatrix}
            .\end{align*}
            Solving the system by Gaussian Elimination without pivoting, we get $m_{21} = \frac{0.3454}{0.0003} = 1151.3333$. After Gaussian Elimination, we get
            \begin{align*}
                x_{1} = 3.333, \quad x_{2} = 1.001
            .\end{align*}
            We note that the exact solution to the system is $x_{1} = 10, x_{2} = 1$. So what happened? We see that $x_{2}$ is far from the true solution.
            \bigbreak \noindent 
            If we instead swap the rows to use the second row as the pivot row, we get
            \begin{align*}
                m_{21} = \frac{0.0003}{0.3454} = 0.0008686
            .\end{align*}
            Then, $x_{1} = 10.01,\; x_{2} = 1$.
            \bigbreak \noindent 
            We we round off a number $\alpha$, we get $\alpha \to \bar{\alpha}$, where $\alpha = \bar{\alpha} + \epsilon $, for some small $\epsilon$. If this number is then multiplied by a scalar $m$, we get
            \begin{align*}
                m\alpha = m\bar{\alpha} + m\epsilon     
            .\end{align*}
            So, the error grows as $m$ grows. Our goal is to select the pivot such that $m$ is minimized.
            \bigbreak \noindent 
            If we select the largest element in the $k^{\text{th}}$ column (at step $k$), then we can guarantee $m \leq 1$.
        \item \textbf{Partial pivoting}: At iteration $k$ of Gaussian Elimination, we swap row $k$ with some row below so that the new $a_{kk}$ has the largest absolute value compared to all entries below in column $k$.
        \item \textbf{Permutation matrix}: A permutation matrix is a special kind of square matrix that represents a permutation of elements. Formally:
            It is obtained from the identity matrix by rearranging its rows (or equivalently, its columns).
            \bigbreak \noindent 
            Each row and each column has exactly one entry equal to 1, and all other entries are 0.
            \bigbreak \noindent 
            Multiplying a vector (or another matrix) by a permutation matrix reorders its entries.
            \bigbreak \noindent 
            Suppose $P$ is formed by taking $I$ and interchanging rows one and two. Then,
            \begin{align*}
                P = \begin{pmatrix} 0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1 \end{pmatrix}
            .\end{align*}
            Then, 
            \begin{align*}
                P\begin{pmatrix} a \\ b \\ c \end{pmatrix} = \begin{pmatrix} b \\ a \\ c \end{pmatrix}
            .\end{align*}
            So, it swaps the first two entries.
        \item \textbf{Permutation matrix left multiplication vs right multiplication}: If $P$ is a permutation matrix, and $A \in \mathbb{R}^{n\times n}$, then $AP$ permutes the columns of $A$. Recall that $\text{col}_{j}(AP) = A\text{col}_{j}(P)$, so
            \begin{align*}
                \text{col}_{j}(AP) = A\text{col}_{j}(P)
            .\end{align*}
            But, $\text{col}_{j}(P) = e_{k}$, where $e_{k}$ is the $k^{\text{th}} $ standard basis vector in $\mathbb{R}^{n}$, so
            \begin{align*}
                \text{col}_{j}(AP) = Ae_{k}
            .\end{align*}
            Notice that $Ae_{k} = \text{col}_{k}(A)$. Suppose column one is swapped with column two in $P$, then $\text{col}_{1}(P) = e_{2}$, so $\text{col}_{1}(AP) = Ae_{2} = \text{col}_{2}(A) $.
            \bigbreak \noindent 
            Similarly, $PA$ permutes the rows of $A$. Recall that $\text{row}_{i}(AB) = \text{row}_{i}(A)B$, so 
            \begin{align*}
                \text{row}_{i}(PA) = \text{row}_{i}(P)A = e_{k}^{T}A = \text{row}_{k}(A)
            .\end{align*}
            Suppose that row one is swapped with row two in $P$, then $\text{row}_{1}(P) = e_{2}^{T}$, and $\text{row}_{1}(PA) = e_{2}^{T}A = \text{row}_{2}(A) $
    \item \textbf{Gaussian elimination with partial pivoting}:
        Eliminates entries below the pivots to produce an upper triangular system.
        \bigbreak \noindent 
        At each step, you swap the current row with one below it to bring the largest (by absolute value) element in the pivot column into the pivot position. This improves numerical stability.
    \item \textbf{$LU$ factorization with partial pivoting}: We we partial pivot rows in Gaussian Elimination (while building $L,U$), we make the same swap in $P$. If $L$ is not being stored in $A$ during the process, then we also need to swap the rows of $L$, but keep the main diagonal the same. The main diagonal of $L$ is always remains ones, and the upper triangular part is always zero. 
        \bigbreak \noindent 
        At the end, we get
        \begin{align*}
            PA = LU
        .\end{align*}
        Then, we also see that
        \begin{align*}
            A = P^{-1}LU = P^{T}LU
        .\end{align*}
        We can use this fact to solve systems $Ax = b$. We have
        \begin{align*}
            Ax &= b \\
            \implies PAx &= Pb \\
            \implies LUx &= Pb
        .\end{align*}
        Just like in standard $LU$ decomposition, we split the system in two triangular systems that can both be solved by substitution in $n^{2}$ flops. We have
        \begin{align*}
            \begin{cases}
                Ly &= Pb  \quad \text{(Lower triangular)}\\
                Ux &= y \quad \text{(Upper triangular)}
            \end{cases}
        .\end{align*}
    \end{itemize}

    \pagebreak 
    \subsection{Outer Products, inner products, and transposition tricks}
    \begin{itemize}
        \item \textbf{Build an $m\times n$ matrix from $n$ vectors in $\mathbb{R}^{m}$}: Suppose we have vectors $x_{1}, x_{2}, x_{3}, ..., x_{n} \in \mathbb{R}^{m}$, and we wish to construct the matrix formed by combining each vector $x_{k}$ for $k=1,2,3,...,n$. Algebraically, we have
            \begin{align*}
                X &= \begin{bmatrix} x_{1} & x_{2} & x_{3} & \cdots & x_{n} \end{bmatrix} = x_{1}e_{1}^{\top} + x_{2}e_{2}^{\top} + x_{3}e_{3}^{\top} + ... + x_{n}e_{n}^{\top} \\
                  &= \sum_{k=1}^{n}x_{k}e_{k}^{\top}
            \end{align*}
            where $e_{\ell}$ for $\ell = 1,2,3,...,n$ are the standard basis vectors in $\mathbb{R}^{n} $.
            \bigbreak \noindent 
            For example, if $x = \begin{pmatrix} x_{1} \\ x_{2} \end{pmatrix} \in \mathbb{R}^{2}$, and $y = \begin{pmatrix} y_{1} \\ y_{2} \end{pmatrix} \in \mathbb{R}^{2}$ then
            \begin{align*}
                X &= xe_{1}^{\top} + ye_{2}^{\top} = \begin{pmatrix} x_{1} \\ x_{2} \end{pmatrix} \begin{pmatrix} 1  & 0 \end{pmatrix} + \begin{pmatrix} y_{1} \\ y_{2} \end{pmatrix} \begin{pmatrix} 0 & 1 \end{pmatrix} \\
                  &= \begin{pmatrix} x_{1} & 0 \\ x_{2} & 0 \end{pmatrix} + \begin{pmatrix} 0& y_{1} \\ 0 & y_{2} \end{pmatrix} = \begin{pmatrix} x_{1} & y_{1} \\ x_{2} & y_{2} \end{pmatrix}
            \end{align*}
        \item \textbf{Construct a $m\times n$ matrix with a single element in some position}: Suppose we want an $m\times n$ matrix with $k$ in position $a_{ij}$ We take the outer product
            \begin{align*}
               A = me_{i}e_{j}^{\top}
            \end{align*}
            Where $e_{i}$ is the $i^{\text{th}} $ standard basis vector in $\mathbb{R}^{m}$, and $e_{j}$ is the $j^{\text{th}}$ standard basis vector in $\mathbb{R}^{n}$.
        \item \textbf{Matrix multiplication in terms of column}: For $A,B \in \mathbb{R}^{n\times n}$, and $C = AB \in \mathbb{R}^{n\times n}$, we have that
            \begin{align*}
                \text{col}_{j}(C) = A\text{col}_{j}(B)
            .\end{align*}
            Thus, $C=AB$, where $A,B \in \mathbb{R}^{n\times n}$ requires solving $n$ linear systems.
        \item \textbf{Matrix multiplication in terms of rows}: Let $A,B\in \mathbb{R}^{n\times n} $, and $C = AB$. Since $C = AB$, $C^{T} = B^{T}A^{T}$, and using the fact above, we see
            \begin{align*}
                \text{col}_{j}(C^{T}) = B^{T}\text{col}_{j}(A^{T})        
            .\end{align*}
            But, $\text{col}_{j}(C^{T}) = (\text{ row}_{j}(C))^{T}$, and $\text{col}_{j}(A^{T}) = (\text{ row}_{j}(A))^{T} $. So,
            \begin{align*}
                \text{col}_{j}(C^{T}) &= B^{T}\text{col}_{j}(A^{T})         \\
                \implies \left(\text{row}_{j}(C)\right)^{T} &= B^{T}\left(\text{row}_{j}(A)\right)^{T}
            .\end{align*}
            Taking the transposition of both sides gives
            \begin{align*}
                \text{row}_{j}(C) &= \text{ row}_{j}(A)B
            .\end{align*}
            Therefore, changing the name of index, we get the result
            \begin{align*}
                \text{row}_{i}(C) &= \text{ row}_{i}(A)B
            .\end{align*}
        \item \textbf{Getting the rows and columns of a matrix algebraically}: Let $A \in \mathbb{R}^{n\times n}$, let $e_{i}$ be the $i^{\text{th}}$ standard basis vector in $\mathbb{R}^{n}$. That is, a vector of size $n$ with a one in the $i^{\text{th}}$ position, and zeros everywhere else. Then,
            \begin{align*}
                \text{col}_{j}(A) = Ae_{j}
            .\end{align*}
            This comes directly from how matrix–vector multiplication works in linear algebra.
            Multiplying a matrix $A$ by a standard basis vector $e_{j} $ picks out the $j$-th column of $A$, because the 1 in position $j$ selects that column while all other zeros eliminate the rest.
            \bigbreak \noindent 
            If we take the transpose of both sides,
            \begin{align*}
                \left(\text{col}_{j}(A)\right)^{T} = e_{j}^{T}A^{T},
            \end{align*}
            which implies that
            \begin{align*}
                \left(\text{col}_{j}(A^{T})\right)^{T} = e_{j}^{T}A,
            .\end{align*}
            But, we know that $\text{row}_{j}(A) = (\text{ col}_{j}(A^{T}))^{T} $, and $\text{col}_{j}(A) = (\text{row}_{j}(A^{T}))^{T} $. Thus,
            \begin{align*}
                \left(\text{col}_{j}(A^{T})\right)^{T} = e_{j}^{T}A \\
                \implies \text{row}_{j}(A) = e_{j}^{T}A
            .\end{align*}
        \item \textbf{Retrieving an element of a matrix algebraically}: Let $A \in \mathbb{R}^{n\times n}$, and $e_{i} \in \mathbb{R}^{n}$ be the $i^{\text{th}} $ standard basis vector, then
            \begin{align*}
                e_{i}^{T}Ae_{j} = a_{ij},
            \end{align*}
            since $Ae_{j} = \text{col}_{j}(A)$, and $e_{i}^{T}\text{col}_{j}(A) = 1(\text{col}_{j})_{i} = a_{ij}$

            
            

                

    \end{itemize}

    \pagebreak 
    \subsection{Sensitivity of linear systems (2)}
    \bigbreak \noindent 
    \subsubsection{Vector and matrix norms}
    \begin{itemize}
        \item \textbf{Norm:} A norm is an operation $\norm{\cdot }:\; \mathbb{R}^{n} \to \mathbb{R}_{+}:\; x \to \norm{x} \geq 0$  that satisfies
            \begin{enumerate}
                \item $\norm{x} = 0 \iff x = 0$
                \item $\norm{\alpha x} = \left\lvert \alpha \right\rvert \norm{x} $
                \item $\norm{x+y} \leq \norm{x} + \norm{y} $ (triangle inequality)
            \end{enumerate}
        \item \textbf{Euclidean norm (2-norm)}: The standard Euclidean distance. For $x \in \mathbb{R}^{n}$,
            \begin{align*}
                \norm{x}_{2} = \sqrt{x_{1}^{2} + x_{2}^{2} + ... + x_{n}^{2}}
            .\end{align*}
        \item \textbf{Manhattan norm (1-norm)}: Denoted $L^{1} $, and also called \textbf{Taxicab norm}. For $x \in \mathbb{R}^{n} $,
            \begin{align*}
                \norm{x}_{1} = \left\lvert x_{1} \right\rvert + \left\lvert x_{2} \right\rvert + ... + \left\lvert x_{n} \right\rvert
            .\end{align*}
        \item \textbf{$L$-Infinity (max) norm ($\infty$-norm)}: Denoted $L^{\infty}$. for $x\in \mathbb{R}^{n}$,
            \begin{align*}
                \norm{x}_{\infty} = \max_{1 \leq i \leq n} \left\lvert x_{i} \right\rvert = \max\{\left\lvert x_{1} \right\rvert, \left\lvert x_{2} \right\rvert, ..., \left\lvert x_{n} \right\rvert\} 
            .\end{align*}
        \item \textbf{Unit balls of norms in $\mathbb{R}^{2}$}:
                \begin{figure}[h]
                    \centering
                    \incfig{2norm}
                    \label{fig:2norm}
                \end{figure}
            \begin{itemize}
                \item \textbf{2-norm}: $B_{\norm{x}_{2}}(0,1) = \{x\in \mathbb{R}^{n}:\; x_{1}^{2} + x_{2}^{2} \leq 1\}$
                \item \textbf{1-norm}: $B_{\norm{x}_{1}}(0,1) = \{x\in \mathbb{R}^{n}:\; \left\lvert x_{1} \right\rvert + \left\lvert x_{2} \right\rvert \leq 1\}$
                \item \textbf{$\infty$-norm}: $B_{\norm{x}_{\infty}}(0,1) = \{x\in \mathbb{R}^{n}:\; \max_{1 \leq i \leq 2}\left\lvert x_{i} \right\rvert \leq 1\}$
            \end{itemize}
        \item \textbf{$p$-norm}: In $\mathbb{R}^{n}$, A more general norm is
            \begin{align*}
                \norm{x}_{p} = \left(\sum_{i=1}^{n} \left\lvert x_{i} \right\rvert^{p}\right)^{\frac{1}{p}} = \left(\left\lvert x_{1}^{p} \right\rvert + \left\lvert x_{2} \right\rvert^{p} + ... + \left\lvert x_{n} \right\rvert^{p}\right)^{\frac{1}{p}}
            \end{align*}
            for $1 \leq p < \infty $. The general $p$-norm satisfies all three properties of a norm only when $p \geq 1$. For smaller $p$, the triangle inequality does not hold.
        \item \textbf{Entrywise (Bad) Matrix-norms}: Consider the isomorphism $\phi:\; \mathbb{R}^{n\times n} \to \mathbb{R}^{n\cdot n} $. For example, 
            \begin{align*}
                \begin{pmatrix} a & b \\ c & d \end{pmatrix} \mapsto \begin{pmatrix} a \\ b \\c \\d \end{pmatrix}
            .\end{align*}
            This way, we can use our vector norms defined above on matrices. The norms we have seen so far would be
            \begin{align*}
                \norm{A}_{p} &= \left(\sum_{i=1}^{n}\sum_{j=1}^{n}\left\lvert a_{ij} \right\rvert^{p}\right)^{\frac{1}{p}}, \\
                \norm{A}_{1} &= \sum_{i=1}^{n}\sum_{j=1}^{n} \left\lvert a_{ij} \right\rvert, \\
                \norm{A}_{2} &= \left(\sum_{i=1}^{n}\sum_{j=1}^{n}a_{ij}^{2}\right)^{\frac{1}{2}}
            .\end{align*}
            \textbf{Note:} The matrix 2-norm $\norm{A}_{2}$ is also called the \textit{Frobenius} norm, denoted $\norm{A}_{F}$.
            \bigbreak \noindent 
            We see that in the Frobenius norm, $\norm{I}_{F} = \sqrt{n} \ne 1$. In general, we would like our matrix norms to have $\norm{I} = 1$ for all dimensions, and to not grow as the dimension increases.
            \bigbreak \noindent 
            These entrywise norms treat the matrix as a big vector and ignore its action on other vectors.
        \item \textbf{Properties of matrix norms}: Matrix norms satisfy the three required properties of norms.
            \begin{enumerate}
                \item $\norm{A} = 0 \iff A = 0 $
                \item $\norm{\alpha A} = \left\lvert \alpha \right\rvert \norm{A} $
                \item $\norm{A + B} \leq \norm{A} + \norm{B} $ (Triangle inequality)
            \end{enumerate}
        \item \textbf{Induced (operator) matrix norms}: For all $A\in \mathbb{R}^{n\times m}$, we define
            \begin{align*}
                \norm{A}_{p} := \max_{x\in\mathbb{R}^{n} \setminus \{0\}} \frac{\norm{Ax}_{p}}{\norm{x}_{p}} = \max_{\norm{y}_{p} = 1} \norm{Ay}_{p}
            .\end{align*}

        \item \textbf{Properties of induced matrix norms}
            \begin{itemize}
                \item \textbf{Sub-multiplicativity}: $\norm{AB}_{p} \leq \norm{A}_{p}\norm{B}_{p} $
                \item \textbf{Consistency}: $\norm{Ax}_{p} \leq \norm{A}_{p}\norm{x}_{p} $
                \item \textbf{Normalization}: $\norm{I}_{p} = 1 $
            \end{itemize}
            These are what entrywise ("flattened") norms lack.
        \item \textbf{Induced matrix norms special cases}:
            \begin{center}
                \begin{tabular}{p{1cm}|p{5cm}|p{5cm}}
                    \toprule
                    $p$ & \textbf{Name} & \textbf{Explicit formula} \\
                    \midrule
                    $1$ & Maximum column sum &
                    $\displaystyle \|A\|_{1} = \max_{1 \leq j \leq n} \sum_{i=1}^{m} |a_{ij}|$ \\[3ex]
                    $2$ & Spectral norm &
                    $\displaystyle \|A\|_{2} = \sqrt{\lambda_{\max}(A^{T}A)}$ \\[3ex]
                    $\infty$ & Maximum row sum &
                    $\displaystyle \|A\|_{\infty} = \max_{1 \leq i \leq m} \sum_{j=1}^{n} |a_{ij}|$ \\
                    \bottomrule
                \end{tabular}
            \end{center}
        \item \textbf{Singular values}: For $A \in \mathbb{R}^{m\times n}$, its \textbf{singular values} are the numbers
            \begin{align*}
                \sigma_{1} \geq \sigma_{2} \geq \cdots \geq \sigma_{r} > 0 
            ,\end{align*}
            defined as the square roots of the eigenvalues of $A^{T}A$
            \begin{align*}
                \sigma_{i}(A) = \sqrt{\lambda_{i}(A^{T}A)}
            .\end{align*}
            If $A$ has rank $r$, then there are $r$ positive singular values. The rest are zero.
            \bigbreak \noindent 
            Singular values measure how much $A$ stretches vectors
            \begin{align*}
                \sigma_{1} &= \max_{\norm{x}_{2} = 1} \norm{Ax}_{2} \\
                \sigma_{r} &= \min_{\norm{x}_{2} = 1} \norm{Ax}_{2}
            .\end{align*}
            \begin{itemize}
                \item $\sigma_{1}$ is the maximum expansion factor of $A$
                \item $\sigma_{r}$ is the minimum expansion factor
            \end{itemize}
        \item \textbf{Singular values of $A^{-1}$}: The singular values of $A^{-1}$ are the reciprocals of the singular values of $A$.
            \begin{align*}
                \sigma_{1}(A^{-1}) = \frac{1}{\sigma_{1}(A)}, \sigma_{2}(A^{-1}) = \frac{1}{\sigma_{2}(A)}, \cdots , \sigma_{n}(A^{-1}) = \frac{1}{\sigma_{n}(A)}
            .\end{align*}
        \item \textbf{Eigenvalues of $A^{T}A$}: Consider the singular values of $A$,
            \begin{align*}
                \sigma_{i} = \sqrt{\lambda_{i}(A^{T}A)}
            .\end{align*}
            Thus, 
            \begin{align*}
                \lambda_{i}(A^{T}A) = \sigma_{i}(A)^{2}
            .\end{align*}
        \item \textbf{Singular values of $A^{T}A $}:
            \begin{align*}
                \sigma_{i}(A^{T}A) = \sqrt{\lambda_{i}((A^{T}A)^{T}(A^{T}A))} = \sqrt{\lambda_{i}(A^{T}A)^{2}}
            .\end{align*}
            But, to get the eigenvalues for the square of a matrix you square the eigenvalues for the matrix. So, $\lambda_{i}(A^{T}A)^{2} = (\lambda_{i}(A^{T}A))^{2} $. Thus,
            \begin{align*}
                \sigma_{i}(A^{T}A) = \sqrt{(\lambda_{i}(A^{T}A))^{2}} = \lambda_{i}(A^{T}A) = \sigma_{i}(A)^{2}
            .\end{align*}
            So, the singular values for $A^{T}A$ are the squares of the singular values of $A$. Thus, the set of eigenvalues for $A^{T}A$ is the same as the set of singular values for $A^{T}A$
        \item \textbf{Spectral norm}: We have
            \begin{align*}
                \norm{A}_{2} = \max_{\norm{x}_{2} = 1} \norm{Ax}_{2} = \sigma_{1} = \sqrt{\lambda_{\text{max}}(A^{T}A)}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{Note:} Since $\frac{1}{\sigma_{n}}$ is the largest singular value for $A^{-1}$,
            \begin{align*}
               \norm{A^{-1}}_{2} = \frac{1}{\sigma_{n}} = \frac{1}{\sqrt{\lambda_{\text{min}}}(A^{T}A)}
            .\end{align*}
        \item \textbf{Derived property of matrix norm}: For $A \in \mathbb{R}^{n\times n}$, we have
            \begin{align*}
                \norm{A} &= \max_{x\ne 0} \frac{\norm{Ax}}{\norm{x}} \geq \frac{\norm{Ax}}{\norm{x}} \\
                         &\implies \norm{Ax} \leq \norm{A}\norm{x}
            .\end{align*}
        \item \textbf{Cauchy Schwarz inequality for 2-norm (vector norm)}: states
            \begin{align*}
                \left\lvert x^{T}y \right\rvert \leq \norm{x}_{2}\norm{y}_{2} 
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Let $t \in \mathbb{R}$. We know that $0 \leq \norm{x + ty}_{2}^{2} $. Recall that $x^{T}x = \norm{x}_{2}^{2} = \norm{x}_{2}\norm{x}_{2}$.
            \bigbreak \noindent 
            We have
            \begin{align*}
                0 \leq (x + ty)^{T}(x+ty) &= x^{T}x + x^{T}ty + ty^{T}x + t^{2}y^{t}y \\
                                          &= \norm{x}_{2}^{2} + 2t(x^{T}y) + t^{2}\norm{y}_{2}^{2}
            .\end{align*}
            Observe that this is a 2-degree polynomial in $t$, call it $p_{2}(t)$.
            \begin{align*}
                p_{2}(t) &= \norm{y}_{2}^{2} t^{2} + 2(x^{t}y)t + \norm{x}_{2}^{2} \geq 0 
            .\end{align*}
            Since $p_{2}(t)$ is greater than or equal to zero, we know that the discriminant is less than or equal to zero. That is, $p_{2} (t) \geq 0 $ implies $D \leq 0$, where $D = (2(x^{T}y))^{2} -4(\norm{y}_{2}^{2})(\norm{x}_{2}^{2})$. Thus,
            \begin{align*}
                (2(x^{T}y))^{2} -4(\norm{y}_{2}^{2})(\norm{x}_{2}^{2}) &\leq 0 \\
                \implies 4(x^{T}y)^{2} -4(\norm{y}_{2}^{2})(\norm{x}_{2}^{2}) &\leq 0  \\
                \implies (x^{T}y)^{2} -(\norm{y}_{2}^{2})(\norm{x}_{2}^{2}) &\leq 0  \\
                \implies (x^{T}y)^{2}  &\leq \norm{y}_{2}^{2}\norm{x}_{2}^{2} \\
                \implies \left\lvert x^{T}y \right\rvert &\leq \norm{x}_{2}\norm{y}_{2}
            .\end{align*}
            \bigbreak \noindent 
            This property of vector norms also holds for norms induced by an inner product. In an inner product space with norm $\norm{\cdot }_{P}$ is induced by an inner product $\left\langle x,y \right\rangle $ if $\left\langle x,x \right\rangle = \norm{x}_{P}^{2}$

    \end{itemize}

    \pagebreak 
    \subsubsection{Condition number}
    \begin{itemize}
        \item \textbf{Numerical error when solving systems, residual vector}: 
            Suppose we want to solve a linear system $Ax = b$. 
            In practice, due to floating-point roundoff and the large number of flops required for a big system, 
            the computed solution $\bar{x}$ will generally not satisfy $Ax = b$ exactly. 
            \bigbreak \noindent 
            We define the \textbf{residual} as
            \[
                r = b - A\bar{x},
            \]
            which measures how far $\bar{x}$ is from being an exact solution. 
            If $\bar{x}$ is a good approximation, then $r \approx 0$. 
            \bigbreak \noindent 
            % If $\bar{x}$ is not sufficiently accurate, we can attempt to improve it. 
            % Notice that
            % \[
            %     A\bar{x} + r = b,
            % \]
            % so the residual can be used to correct the solution. 
            % If $\bar{\bar{x}}$ denotes an improved approximation, then we want
            % \[
            %     A\bar{\bar{x}} = b = A\bar{x} + r.
            % \]
            % \bigbreak \noindent 
            % This motivates the following iterative refinement process:
            % \begin{enumerate}
            %     \item Compute an approximate solution $\bar{x}$ to $Ax = b$.
            %     \item Compute the residual $r = b - A\bar{x}$.
            %     \item Solve the \emph{correction system} $A\delta \bar{x} = r$ for $\delta \bar{x}$.
            %     \item Update the solution: $\bar{x} \leftarrow \bar{x} + \delta \bar{x}$.
            %     \item Repeat until the residual is sufficiently small.
            % \end{enumerate}
            % \bigbreak \noindent 
            % If we define a better solution $\bar{\bar{x}}$ as our computed solution plus $\delta \bar{x}$,
            % \begin{align*}
            %     \bar{\bar{x}} = \bar{x} + \delta \bar{x}
            % .\end{align*}
            % We want
            % \begin{align*}
            %     A\bar{\bar{x}} &= b, \\
            %     \implies A(\bar{x} + \delta \bar{x} ) &= b, \\
            %     \implies A\bar{x} + A\delta \bar{x} &= b
            % .\end{align*}
            % But, the residual is defined as $r = b - A\bar{x}$, so $A\bar{x} + r =b$. Thus, we have
            % \begin{align*}
            %     A\bar{x} + A\delta \bar{x} &= A\bar{x} + r
            % .\end{align*}
            % Which we see implies that $A\delta \bar{x} = r $. So, we solve the new system $A\delta \bar{x} = r$ for delta \bar{x}, then update
            % \begin{align*}
            %     \bar{x} \leftarrow \bar{x}  + \delta \bar{x}
            % \end{align*}
            % and repeat if necessary. 
            % \bigbreak \noindent 
            % \textbf{Note}: If we instead solve
            % \begin{align*}
            %     A\bar{\bar{x}} = A\bar{x} + r
            % \end{align*}
            % directly, we will find that our computed $\bar{\bar{x}}$ is equal to $\bar{x} + \delta \bar{x}$.
        \item \textbf{Iterative approach to improve $\hat{x}$}: Suppose for a system $Ax = b$ numerical techniques yields an approximation $\hat{x}_{1}$. Then, the residual vector $\hat{r}_{1} = b - A\hat{x}_{1}$, which implies that $b = \hat{r}_{1} + A\hat{x}_{1}$. If $\hat{x}_{2}$ is a different approximation, where $\hat{x}_{2} = \hat{x}_{1} + \delta \hat{x}_{1}$, then
            \begin{align*}
                A\hat{x}_{2} &= b = \hat{r}_{1} + A\hat{x}_{1} \\
                \implies A(\hat{x}_{1} + \delta \hat{x}_{1}) &= \hat{r}_{1} + A\hat{x}_{1} \\
                \implies A\hat{x}_{1} + A\delta\hat{x}_{1} &= \hat{r}_{1} + A\hat{x}_{1} \\
                \implies A\delta\hat{x}_{1} &= \hat{r}_{1}  
            .\end{align*}
            So, we solve the system for $\delta \hat{x}_{1}$. Then, since $\hat{x}_{2} = \hat{x}_{1} + \delta \hat{x}_{1}$, we see that we need to update the first solution by adding the computed $\delta \hat{x}_{1} $.
            \bigbreak \noindent 
            In general, if $\hat{x}_{i}$ is the $i^{\text{th}}$ numerical solution to $Ax = b$, and $\hat{r}_{i}$ is the residual vector to the $i^{\text{th}}$ solution, then 
            \begin{align*}
                \hat{x}_{i+1} = \hat{x}_{i} + A^{-1}\hat{r}_{i}
            .\end{align*}
            In practice, we don't compute $A^{-1}\hat{r}_{i}$, as we know that this is an expensive task. Instead, we solve the system correction system
            \begin{align*}
                A\delta\hat{x}_{i} = \hat{r}_{i} 
            .\end{align*}
            In exact arithmetic, 
            \begin{align*}
                A\delta \hat{x} &= b - A\hat{x} \\
                \implies \delta \hat{x} &= A^{-1}\left(b - A\hat{x}\right) \\
                                        &= A^{-1}b - A^{-1}A\hat{x} \\
                                        &= x - \hat{x}
            .\end{align*}
            So, 
            \begin{align*}
                \hat{x}_{\text{new}} &= \hat{x} + \delta \hat{x} = \hat{x} + x - \hat{x} = x
            .\end{align*}
            Thus, in exact arithmetic, we converge to the true solution in one step.
            \bigbreak \noindent 
            In practice, computations are done in floating-point arithmetic, so both the residual and the correction are computed approximately. 
            Let 
            \[
                A\,\delta\hat{x} = r + \delta r,
            \]
            where $\delta r$ represents rounding or truncation errors. When we update
            \[
                \hat{x}_{\text{new}} = \hat{x} + \delta\hat{x},
            \]
            we hope that the new residual
            \[
                r_{\text{new}} = b - A\hat{x}_{\text{new}}
            \]
            is smaller than the previous residual. Each iteration ideally improves the approximation because
            \begin{align*}
                \delta \hat{x} \approx A^{-1}(b - A\hat{x}) = x - \hat{x}
            .\end{align*}
            When floating-point errors are small enough relative to the conditioning of $A$, this correction moves $\hat{x} $ closer to $x$. But, if $A$ is ill-conditioned, the corrections may no longer reduce the error — in fact, they can make it worse.

        \item \textbf{Intro to measuring solutions}: Consider a problem $(P)$, where
            \begin{align*}
                (P):\; Ax = b
            .\end{align*}
            Numerical techniques yields a solution $\hat{x}$, which may or may not be the true solution to $(P)$. Let $x$ be the true solution to the system. So, $x$ solves $Ax = b$. 
            \bigbreak \noindent 
            We want to measure the distance between the numerical solution $\hat{x} $ and the true solution $x$, we hope that the numerical solution $\hat{x}$ is close to $x$. If the distance is small, then $\hat{x}$ is a good solution.
        \item \textbf{Relative error}: The relative error in $\hat{x}$ is given by
            \begin{align*}
                \frac{\norm{\hat{x} - x}}{\norm{x}} = \frac{\norm{\delta x}}{\norm{x}}
            \end{align*}
            where $\hat{x} = x + \delta  x $, which implies $x = \hat{x} - \delta  x $.
        \item \textbf{Perturbation}: If numerical methods to solve a linear system $Ax = b$ yields $\hat{x}$, then $\hat{x}$ solves $\hat{A}\hat{x} = \hat{b}$. Note that it is possible for $\hat{A} = A$ or $\hat{b} = b $. If both $\hat{A} = A$ and $\hat{b} = b$, then $\hat{x} = x$.
            \bigbreak \noindent 
            $\hat{A}$ and $\hat{b}$ are called perturbed if they are modified versions of the original. If $\hat{A}$ is a perturbed matrix $A$, and $\hat{b}$ is a perturbed vector $b$, then
            \begin{align*}
                \hat{A} &= A + \delta A, \\
                \hat{b} &= b + \delta  b
            .\end{align*}
        \item \textbf{Perturbing $b$}: We can perturb $b$, but not $A$ such that $\hat{x}$ solves $A\hat{x} = \hat{b}$.
            \bigbreak \noindent 
            Recall that the residual vector is $\hat{r} = b - A\hat{x} $. If $\hat{b} = A\hat{x}$, then
            \begin{align*}
                \hat{b} = A\hat{x} = A\hat{x} - b + b = b - b + A\hat{x} = b - (b - A\hat{x}) = b - \hat{r}
            .\end{align*}
            Note that in this case, $\hat{A} = A$. We can quantify the change in $b$ by observing that since $\hat{b} = b + \delta b$, and $\hat{b} = b - \hat{r}$, we have
            \begin{align*}
                b - \hat{r} &= b + \delta b\\
                \implies -\hat{r} &= \delta b 
            .\end{align*}
        \item \textbf{Condition number}: We wish to find an upper bound for the relative error in $x$, $\frac{\norm{\delta  x}}{\norm{ x}} $. 
            We have the two systems,
            \begin{align*}
                Ax = b, \quad A\hat{x} = \hat{b}
            .\end{align*}
            Thus, we have
            \begin{align*}
                Ax &= b\; \tag{1}, \\
                A(x + \delta  x) &= b + \delta  b \; \tag{2}
            .\end{align*}
            Looking at $(1)$, we see
            \begin{align*}
                Ax &= b \implies \norm{b} = \norm{Ax}
            .\end{align*}
            But, by the Cauchy Schwarz inequality, $\norm{b} \leq \norm{A}\norm{x}$. So,
            \begin{align*}
                \norm{b} \leq \norm{A}\norm{x} \tag{1}
            .\end{align*}
            Looking at $(2) $, we see
            \begin{align*}
                A(x + \delta  x) &= b + \delta  b \\
                \implies Ax + A \delta x &= b + \delta  b \\
                \implies A \delta  x &= \delta  b  \\
                \implies \delta x &= A^{-1} \delta  b  \\
                \implies \norm{\delta  x} &= \norm{A^{-1} \delta  b} \\
                \implies \norm{ \delta  x} &\leq \norm{A^{-1}} \norm{\delta  b} \tag{2}
            .\end{align*}
            Notice that we can setup $(1)$ so that dividing $(2)$ by $(1)$ gives the relative error in $x$ on the left, and relative error of $b$ on the right. So,
            \begin{align*}
                \frac{1}{\norm{x}} \leq \frac{\norm{A}}{\norm{b}}
            .\end{align*}
            Now, we divide $(2)$ by $(1)$, we have
            \begin{align*}
                \frac{\norm{\delta x}}{\norm{x}} \leq \norm{A^{-1}}\norm{A} \frac{\norm{ \delta  b}}{\norm{b}}
            .\end{align*}
            We now have the relative error in the numerical solution bounded above by the relative error of $b$ times some constant $\norm{A^{-1}}\norm{A}$, we call this constant the condition number $\kappa(A)$. That is,
            \begin{align*}
                \kappa(A) = \norm{A^{-1}}\norm{A}
            .\end{align*}
            The condition number of a matrix $A$ measures how sensitive the solution of a linear system $A x = b$ is to small changes in $b$ (or in $A$).
            \bigbreak \noindent 
            We see that as $\kappa(A) \to \infty$, the relative error in $x$ grows without bound.
        \item \textbf{Condition number ($\kappa_{2}(A)$) in terms of singular values}: Recall that
            \begin{align*}
                \norm{A}_{2} &= \sigma_{1} = \sigma_{\text{max}},\\ 
                \norm{A^{-1}}_{2} &= \frac{1}{\sigma_{n}} = \frac{1}{\sigma_{\text{min}}}
            .\end{align*}
            So,
            \begin{align*}
                \kappa_{2}(A) = \norm{A^{-1}}_{2}\norm{A}_{2} = \sigma_{\text{max}} \cdot \frac{1}{\sigma_{\text{min}}} = \frac{\sigma_{\text{max}}}{\sigma_{\text{min}}}
            .\end{align*}
        \item \textbf{Properties of the condition number}: Let $A$ be a matrix, and $\kappa(A)$ be the condition number that measures the system $Ax = b$. The following two properties hold
            \begin{enumerate}
                \item $\kappa(A) \geq 1$
                \item $\kappa(I) = 1$
                \item $\kappa(A) = \kappa(A^{-1}) $
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof (1)}}: $\kappa(A) = \norm{A^{-1}}\norm{A}$. By Cauchy Schwarz,
            \begin{align*}
                \norm{A^{-1}A} \leq \norm{A^{-1}} \norm{A} \\
                \implies \norm{I} \leq \norm{A^{-1}}\norm{A} \\
                \implies 1 \leq \norm{A^{-1}}\norm{A} = \kappa(A) 
            .\end{align*}
            $\endpf $
            \bigbreak \noindent 
            \textbf{\textit{Proof (2)}}:
            \begin{align*}
                \kappa(I) = \norm{I^{-1}}\norm{I} = \norm{I} \norm{I} = 1 \cdot  1 = 1
            .\end{align*}
            $\endpf$
            \bigbreak \noindent 
            \textbf{\textit{Proof (3)}}:
            \begin{align*}
                \kappa(A^{-1}) = \norm{\left(A^{-1}\right)^{-1}}\norm{A^{-1}} = \norm{A^{-1}} \norm{A} = \kappa(A)
            .\end{align*}
            $\endpf$
        \item \textbf{Theorem \textit{(Relative Error Bound I)}}: Let $A$ be nonsingular, $b \ne 0$, and $Ax = b$. If $A(x + \delta  x) = b + \delta  b$, then
            \begin{align*}
                \frac{\norm{ \delta  x}}{\norm{ x}} \leq \kappa(A) \frac{\norm{\delta  b }}{\norm{ b}}
            \end{align*}
            where $\kappa(A) = \norm{A^{-1}}\norm{A}$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose $A \in \mathbb{R}^{n\times n},\; b\in \mathbb{R}^{n},\; b\ne 0$, $Ax=b$, and  $A(x + \delta x) = b + \delta b $. Then,
            \begin{align*}
                A(x + \delta  x) &= b + \delta  b \\
                \implies Ax + A\delta x &= b + \delta  b \\
                \implies A \delta x &= \delta  b  \\
                \implies \delta x &= A^{-1} \delta  b \\
                \implies \norm{\delta x} &= \norm{A^{-1} \delta b } \leq \norm{A^{-1}}\norm{\delta b} \tag{1}
            .\end{align*}
            But, since $Ax = b$, 
            \begin{align*}
                Ax &= b \\
                \implies \norm{Ax} &= \norm{b} \leq \norm{A}\norm{x} \\
                \implies \norm{x} &\geq \frac{\norm{b}}{\norm{A}} \tag{2}
            .\end{align*}
            Dividing (1) by (2) gives
            \begin{align*}
                \frac{\norm{\delta x}}{\norm{x}} &\leq \norm{A^{-1}}\norm{A}\frac{\norm{\delta b}}{\norm{b}} = \kappa(A)\frac{\norm{\delta b}}{\norm{b}}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{Note:} Recall that if $a,b,c,d \in \mathbb{R}$, $0 \leq a \leq b$, and $0 < d \leq c$, then 
            \begin{align*}
                \frac{a}{c} \leq \frac{b}{d}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{Consequences.}
            \begin{enumerate}
                \item If $\kappa(A)$ small, the relative error in $x$ is small.
                \item If $\kappa(A)$ is large, then it is possible to have the relative error in $b$ small, but the relative error in $x$ large.
            \end{enumerate}
        \item \textbf{Well-conditioned and ill-conditioned in terms of $\kappa(A)$}: If $\kappa(A)$ is large, then $(P)$ is ill-conditioned. If $\kappa(A)$ is small (close to one), then $(P)$ is well-conditioned.
        \item \textbf{Pre-conditioned system (preconditioner)}: If the system
            \begin{align*}
                Ax =b
            .\end{align*}
            has a large condition number $\kappa(A)$, the system is ill-conditioned, meaning small perturbations in $b$ cause large changes in $x$.
            \bigbreak \noindent 
            To improve this, we introduce a preconditioner $B$ (sometimes written $M^{-1}$) such that $B \approx A^{-1}$ but is much easier to compute or apply.
            \bigbreak \noindent 
            We then multiply the equation by $B$ on the left
            \begin{align*}
                BAx = Bb
            .\end{align*}
            Define
            \begin{align*}
                \tilde{A} = BA, \quad \tilde{b} = Bb
            .\end{align*}
            This gives the \textbf{preconditioned system}
            \begin{align*}
                \tilde{A}x = \tilde{b}
            .\end{align*}
            We want to choose $B$ so that
            \begin{enumerate}
                \item $\kappa(\tilde{A}) = \kappa(BA) \ll \kappa(A) $, i.e., the new system is better conditioned,
                \item Solving $Bz = y $ is cheap 
            \end{enumerate}
            We don't usually form $BA$ explicitly, it usually destroys the structure and sparsity that make the original system efficient to handle.
            \bigbreak \noindent 
            If $A$ and $B$ are large sparse matrices (which they almost always are in practice), explicitly multiplying them gives a dense matrix $BA$
            \bigbreak \noindent 
            That means:
            \begin{enumerate}
                \item much higher memory usage,
                \item much slower matrix–vector products,
                \item and loss of efficiency in iterative methods.
            \end{enumerate}
            Forming $BA$ explicitly also introduces round-off errors, especially when $B$ approximates $A^{-1}$ You end up multiplying two ill-conditioned matrices, potentially worsening accuracy before solving anything.
            \bigbreak \noindent 
            If:
            \begin{itemize}
                \item $A$ is \textbf{moderate in size} (not huge, maybe $n \lesssim 10^{3}$),
                \item $A$ and $B$ are \textbf{dense} anyway (so sparsity isn’t being destroyed), and
                \item you can \textbf{compute or approximate $B$} reliably and cheaply,
            \end{itemize}
            then \textbf{explicitly forming} $BA$ may sometimes be beneficial.
            \bigbreak \noindent 
            For example:
            \begin{itemize}
                \item in small to medium dense problems (common in computational linear algebra, not large PDEs),
                \item or when using \textbf{direct solvers} (like LU or QR), where forming $BA$ once is acceptable,
                \item or when $B$ comes from a \textbf{stabilizing transformation} (e.g., scaling rows or columns).
            \end{itemize}
            In such cases, if $BA$ has a much smaller condition number than $A$,
            \[
                \kappa(BA) \ll \kappa(A),
            \]
            then solving 
            \[
                BAx = Bb
            \]
            can indeed give a \textbf{more accurate and stable solution} than directly solving 
            \[
                Ax = b.
            \]
            Usually, in \textbf{large or iterative} problems:
            \begin{itemize}
                \item Forming $BA$ destroys \textbf{structure} (sparsity, bandedness, symmetry).
                \item You have to store an entire new matrix (cost $O(n^2)$ memory).
                \item The cost of computing $BA$ can exceed the cost of solving $Ax = b$ itself.
                \item Rounding errors during multiplication can \textbf{degrade} the benefits of preconditioning.
            \end{itemize}
            In these cases, applying $B$ as an \textbf{operator} (by solving $Bz = y$ inside each iteration)
            gives the same effect with \textbf{less cost and better numerical behavior}.
            \bigbreak \noindent 
            If we let $B = A^{-1}$, then the system becomes
            \begin{align*}
                Ix = A^{-1}b
            \end{align*}
            where  $\tilde{A} = A^{-1}A = I$, $\tilde{b} = A^{-1}b = x$, and $\kappa(\tilde{A}) = \kappa(I) = 1$. If $\tilde{A} = I$, then
            \begin{enumerate}
                \item \textbf{The condition number is ideal:}
                    \[
                        \kappa(\tilde{A}) = \kappa(I) = 1.
                    \]
                    This is the \textit{best possible conditioning}—there is no amplification of errors at all.
                \item \textbf{The system becomes trivial:}
                    \[
                        I x = x = \tilde{b}.
                    \]
                    You have effectively solved the problem in one step.
                    \bigbreak \noindent 
                \item \textbf{Interpretation:}
                    \begin{itemize}
                        \item $B = A^{-1}$ is the \textit{perfect preconditioner}.
                        \item In practice, we cannot use it, because computing $A^{-1}$ explicitly 
                            is just as expensive (and less stable) than solving $A x = b$ directly.
                    \end{itemize}
                \item \textbf{Practical takeaway:} 
                    Preconditioning aims to \textbf{approximate this ideal case}:
                    \[
                        B \approx A^{-1},
                    \]
                    such that
                    \[
                        B A \approx I, \qquad \text{and hence} \qquad \kappa(B A) \approx 1,
                    \]
                    but without the full cost of inverting $A$.
            \end{enumerate}
            When we say
            \[
                \kappa(A) \gg 1,
            \]
            we mean the \textbf{mathematical problem} $A x = b$ is \textit{ill-conditioned}—small perturbations in $b$ cause large changes in $x$.
            \bigbreak \noindent 
            If we form
            \[
                \tilde{A} = A^{-1} A = I,
            \]
            then the \textbf{preconditioned system} has
            \[
                \kappa(\tilde{A}) = 1,
            \]
            so that transformed system is \textit{perfectly conditioned}. However, to achieve this we would have to 
            \textbf{compute $A^{-1}$ numerically}, and that step is where the \textit{instability} arises.
        \item \textbf{Numerical stability vs conditioning}
            \begin{itemize}
                \item \textbf{Conditioning}
                \begin{itemize}
                    \item A property of the \textbf{mathematical problem} itself.
                    \item Measures the \textbf{sensitivity} of the true solution to small input changes.
                    \item Example: if $A x = b$, then
                        \[
                            \frac{\|\delta x\|}{\|x\|} \le \kappa(A) \frac{\|\delta b\|}{\|b\|}.
                        \]
                        A large $\kappa(A)$ indicates an \textbf{ill-conditioned problem}.
                \end{itemize}
            \item \textbf{Numerical Stability}
                \begin{itemize}
                    \item A property of the \textbf{algorithm} used to solve the problem.
                    \item Measures how much \textbf{round-off and truncation errors} the algorithm introduces or amplifies.
                    \item A \textbf{stable algorithm} gives the exact solution to a \textit{nearby problem}:
                        \[
                            (A + \delta A)\hat{x} = b + \delta  b , \quad \|\delta A\|,\; \| \delta b\| \text{ small.}
                        \]
                \end{itemize}
        \end{itemize}
        \textbf{Note:} If an algorithm is \textbf{numerically unstable}, then the perturbations 
        $\delta A$ and/or $\delta b$ required to explain its result might be \textbf{large}:
        \[
            \|(A + \delta A) - A\| \text{ is not small.}
        \]
        Hence, the computed $\hat{x}$ is the exact solution to a \textit{far-away problem}:
        \[
            (A + \delta A)\hat{x} = b + \delta b,
        \]
        where $\|\delta A\|$ or $\|\delta b\|$ are no longer small compared to 
        $\|A\|$ or $\|b\|$.
        \bigbreak \noindent 
        This means the algorithm’s result may not correspond meaningfully to the 
        original system at all.
    \item \textbf{Perturbing $A$ but not $b$}: Suppose $A$ nonsingular, and $Ax = b$ yields a numerical solution $\hat{x}$. Then, $\hat{x}$ solves $\hat{A}\hat{x} = b$, where 
        \begin{align*}
            \hat{A} = A + \delta  A
        .\end{align*}
        But, this is only when $\hat{A}$ nonsingular. Let's suppose for a moment that $\hat{A}$ is singular. Then, there exists a $y\ne 0$ such that
        \begin{align*}
            (A + \delta  A)y = 0
        .\end{align*}
        This implies
        \begin{align*}
            Ay + \delta Ay &= 0 \\
            \implies Ay &= - \delta Ay \\
            \implies y &= -A^{-1} \delta  A y \\
            \implies \norm{y} &= \norm{-A^{-1}\delta  Ay} \\
                              &= \left\lvert -1 \right\rvert \norm{A^{-1}\delta  A y} \\
                              &= \norm{A^{-1} \delta Ay} \\
                              & \leq \norm{A^{-1}} \norm{\delta  Ay} \\
                              & \leq \norm{A^{-1}}\norm{\delta  A}\norm{y} \\
            \implies 1 &\leq \norm{A^{-1}}\norm{\delta A}\\
            \implies \norm{A}& \leq \norm{A}\norm{A^{-1}}\norm{\delta A}\\
            \implies \norm{A} & \leq \kappa(A) \norm{\delta  A} \\
            \implies \frac{\norm{\delta A}}{\norm{A}} & \geq \frac{1}{\kappa(A)}
        .\end{align*}
        So, we have the following theorem
    \item \textbf{Theorem (\textit{Singularity of perturbed $A$})}: If
        \begin{align*}
            \frac{\norm{\delta A}}{\norm{A}} < \frac{1}{\kappa(A)}
        \end{align*}
        then $A + \delta  A$ is nonsingular.
        \bigbreak \noindent 
        \begin{itemize}
            \item A large $\kappa(A)$ means $A$ is \textbf{ill-conditioned} — even small perturbations can make it singular.
            \item A small $\kappa(A)$ (close to $1$) means $A$ is \textbf{well-conditioned} — it can tolerate relatively large perturbations without becoming singular.
        \end{itemize}
        If $\kappa(A) = 1$, then
        \begin{align*}
            \frac{\norm{\delta  A}}{\norm{ A}} < 1,
        \end{align*}
        meaning the perturbation can be as large as the matrix itself before singularity is possible.
        \bigbreak \noindent 
        This inequality defines a \textbf{ball in matrix space} with center $A$ and radius $\norm{A} / \kappa(A)$, consistency of nonsingular matrices. The inequality tells us that all matrices within that ball are guaranteed to be nonsingular. All matrices outside that ball (and on the boundary) are singular.
        \bigbreak \noindent 
        This ball is called a \textbf{matrix norm ball} (or \textbf{ball in matrix space}), and is the set
        \begin{align*}
            \mathcal{B}(A,r) = \{A + \delta  A:\; \norm{\delta A} < r\},
        \end{align*}
        where $r = \frac{\norm{A}}{\kappa(A)} $. We can call this specific ball the \textbf{Ball of guaranteed nonsingularity}, or the \textbf{Neighborhood of nonsingularity}.
        \bigbreak \noindent 
        \textbf{\textit{Proof.}} See argument above, the converse reveals the theorem.
    \item \textbf{Theorem \textit{(Relative error bound II)}}: Let $A$ be nonsingular, $b\ne 0$, and $Ax=b$. If $(A + \delta A)(x + \delta x) = b$, and 
        \begin{align*}
            \frac{\norm{\delta  A}}{\norm{A}} < \frac{1}{\kappa(A)},
        \end{align*}
        then
        \begin{align*}
            \frac{\norm{\delta x}}{\norm{x}} \leq \frac{\kappa(A)\frac{\norm{\delta A}}{\norm{A}}}{1-\kappa(A)\frac{\norm{\delta A}}{\norm{A}}}
        .\end{align*}
        \bigbreak \noindent 
        \textbf{\textit{Proof}}. Suppose for a moment that $A$ nonsingular, $b \ne 0$,  $ Ax = b$, and $(A + \delta A)(x + \delta  x) = b$. Then, it's easy to see that
        \begin{align*}
            (A + \delta A)(x + \delta x) &= b \\
            \implies Ax + A\delta x + \delta  A x + \delta A \delta x &= b \\
            \implies A \delta x + \delta A x + \delta A \delta x &=0 \\
            \implies A \delta x &= - \left(\delta Ax + \delta A \delta x\right) \\
            \implies A \delta x &= - \delta A(x + \delta x) \\
            \implies \delta x &= -A^{-1}\delta A(x + \delta x) \\
            \implies \norm{\delta x} &= \norm{-A^{-1}\delta A(x + \delta x)} \\
                                     &=\norm{A^{-1}\delta A(x + \delta x)} \\
            \implies \norm{\delta x} &\leq \norm{A^{-1}}\norm{\delta A}\norm{x + \delta x} \quad \text{(Cauchy-Schwarz)} \\
                                     &\leq \norm{A^{-1}}\norm{\delta  A}\left(\norm{x} + \norm{\delta x}\right) \quad \text{(Triangle inequality)} \\
                                     &\leq \norm{A^{-1}}\norm{\delta A}\norm{x} + \norm{A^{-1}}\norm{\delta A}\norm{\delta x} \\
            \implies \norm{\delta x} - \norm{A^{-1}}\norm{\delta A}\norm{\delta x} & \leq \norm{A^{-1}}\norm{\delta A}\norm{x} \\ 
            \implies \norm{\delta x}\left(1-\norm{A^{-1}}\norm{\delta A}\right) & \leq \norm{A^{-1}}\norm{\delta A}\norm{x} \\
            \implies \frac{\norm{A}}{\norm{A}}\norm{\delta x}\left(1-\norm{A^{-1}}\norm{\delta A}\right) & \leq \frac{\norm{A}}{\norm{A}}\norm{A^{-1}}\norm{\delta A}\norm{x} \\
            \implies \norm{\delta x}\left(1-\frac{\norm{A}}{\norm{A}}\norm{A^{-1}}\norm{\delta A}\right) & \leq \norm{A}\norm{A^{-1}} \frac{\norm{\delta A}}{\norm{A}}\norm{x} \\
            \implies \norm{\delta x}\left(1-\kappa(A)\frac{\norm{\delta A}}{\norm{A}}\right) & \leq \kappa(A) \frac{\norm{\delta A}}{\norm{A}} \norm{x} \\
            \therefore \frac{\norm{\delta x}}{\norm{x}} & \leq \frac{\kappa(A)\frac{\norm{\delta A}}{\norm{A}}}{1-\kappa(A)\frac{\norm{\delta A}}{\norm{A}}}
        \end{align*}
        as desired. $\endpf $




    \item \textbf{Theorem \textit{(Relative error bound III)}}:  Let $A$ be nonsingular, $b\ne 0$, and $Ax=b$. If $(A + \delta A)(x + \delta x) = b + \delta  b$, and 
        \begin{align*}
            \frac{\norm{\delta  A}}{\norm{A}} < \frac{1}{\kappa(A)},
        \end{align*}
        then
        \begin{align*}
            \frac{\norm{\delta x}}{\norm{x}} \leq \frac{\kappa(A)\left(\frac{\norm{\delta A}}{\norm{A}} + \frac{\norm{\delta b}}{\norm{b}}\right)}{1-\kappa(A)\frac{\norm{\delta A}}{\norm{A}}}
        .\end{align*}
        \bigbreak \noindent 
        \begin{remark}[a] Consider the quantity $q = \frac{a}{b}$, $b\ne 0$. If $c \leq b$, then 
            \begin{align*}
                q = \frac{a}{b} \leq \frac{a}{c}
            .\end{align*}
            
        \end{remark} 
        
        \bigbreak \noindent 
        \textbf{\textit{Proof.}} Suppose for a moment that $A$ nonsingular, $b\ne 0$, $Ax= b$, and $(A + \delta A)(x + \delta x) = b + \delta b$. Then, it's immediately obvious that
        \begin{align*}
            (A+\delta A)(x + \delta x) &= b + \delta b \\
            \implies Ax + A\delta x + \delta Ax + \delta A \delta x &= b + \delta b\\
            \implies A\delta x + \delta Ax + \delta A \delta x &= \delta b\\
            \implies A\delta x &= \delta b - (\delta Ax + \delta A \delta x) \\
            \implies A\delta x &= \delta b - \delta A\left(x + \delta x\right) \\
            \implies \delta x &= A^{-1} \delta b - A^{-1}\delta A\left(x+\delta x\right) \\
            \implies \norm{\delta x} &= \norm{A^{-1}\delta b -A^{-1}\delta A\left(x + \delta x\right)} \\
                                     &\leq\norm{A^{-1}\delta b} + \norm{-A^{-1} \delta A\left(x + \delta x\right)} \\
                                     &=\norm{A^{-1}\delta b} + \norm{A^{-1} \delta A\left(x + \delta x\right)}  \\
                                     &\leq \norm{A^{-1}}\norm{\delta b} + \norm{A^{-1}}\norm{\delta A}\left(\norm{x + \delta x}\right) \\
                                     &\leq \norm{A^{-1}}\norm{\delta b} + \norm{A^{-1}}\norm{\delta A}\left(\norm{x} + \norm{\delta x}\right) \\
                                     &=\norm{A^{-1}}\norm{\delta b} + \norm{A^{-1}}\norm{\delta A}\norm{x} + \norm{A^{-1}}\norm{\delta A}\norm{\delta x} \\
            \implies \norm{\delta x} - \norm{A^{-1}}\norm{\delta A}\norm{\delta x} &\leq \norm{A^{-1}}\norm{\delta b} + \norm{A^{-1}}\norm{\delta A}\norm{x} \\
            \implies \norm{\delta x}\left(1-\norm{A^{-1}}\norm{\delta A}\right) &\leq \norm{A^{-1}}\norm{\delta b} + \norm{A^{-1}}\norm{\delta A}\norm{x} \\
            \implies \frac{\norm{A}}{\norm{A}}\norm{\delta x} \left(1-\norm{A^{-1}}\norm{\delta A}\right) &\leq \frac{\norm{A}}{\norm{A}}\left(\norm{A^{-1}}\norm{\delta b} + \norm{A^{-1}}\norm{\delta A}\norm{x}\right) \\
            \implies \norm{\delta x}\left(1-\norm{A}\norm{A^{-1}}\frac{\norm{\delta A}}{\norm{A}}\right) &\leq \norm{A}\norm{A^{-1}}\frac{\norm{\delta b}}{\norm{A}} + \norm{A}\norm{A^{-1}}\frac{\norm{\delta A}}{\norm{A}}\norm{x} \\
            \implies \norm{\delta x}\left(1-\kappa(A)\frac{\norm{\delta A}}{\norm{A}}\right) &\leq \kappa(A)\frac{\norm{\delta b}}{\norm{A}} + \kappa(A)\frac{\norm{\delta A}}{\norm{A}}\norm{x} \\ 
            \implies \frac{\norm{\delta x}}{\norm{x}}\left(1-\kappa(A)\frac{\norm{\delta A}}{\norm{A}}\right) &\leq \kappa(A)\frac{\norm{\delta b}}{\norm{A}\norm{x}} + \kappa(A)\frac{\norm{\delta A}}{\norm{A}}
        .\end{align*} 
        From here, we use 
        \begin{align*}
            Ax &= b \\
            \implies \norm{Ax} &= \norm{b} \\
            \implies \norm{Ax} &\leq \norm{A}\norm{x} \\
            \implies \norm{b} &\leq \norm{A}\norm{x}
        \end{align*}
        and remark \textit{(a)} to see that
        \begin{align*}
            \kappa(A) \frac{\norm{\delta b}}{\norm{A}\norm{x}} + \kappa(A) \frac{\norm{\delta A}}{\norm{A}} & \leq \kappa(A) \frac{\norm{\delta b}}{\norm{b}} + \kappa(A) \frac{\norm{\delta A}}{\norm{A}} 
        .\end{align*}
        Thus, it follows that
        \begin{align*}
            \frac{\norm{\delta x}}{\norm{x}}\left(1-\kappa(A)\frac{\norm{\delta A}}{\norm{A}}\right) &\leq \kappa(A)\frac{\norm{\delta b}}{\norm{A}\norm{x}} + \kappa(A)\frac{\norm{\delta A}}{\norm{A}} \\
                                                                                                              &\leq \kappa(A) \frac{\norm{\delta b}}{\norm{b}} + \kappa(A) \frac{\norm{\delta A}}{\norm{A}}  \\
                                                                                                              &= \kappa(A)\left(\frac{\norm{\delta b}}{\norm{b}}  + \frac{\norm{\delta A}}{\norm{A}}\right) \\
            \therefore \frac{\norm{\delta x}}{\norm{x}} &\leq \frac{\kappa(A)\left(\frac{\norm{\delta A}}{\norm{A}} + \frac{\norm{\delta b}}{\norm{b}}\right)}{1-\kappa(A)\frac{\norm{\delta A}}{\norm{A}}}
        .\end{align*}
        As desired. $\endpf$



    \end{itemize}



    \pagebreak 
    \subsection{The least squares problem and orthogonal matrices}
    \subsubsection{The discrete least squares problem and orthogonal matrices}
    \begin{itemize}
        \item \textbf{Solving systems with no solution}: Suppose that $A \in \mathbb{R}^{m\times n},\; b \in \mathbb{R}^{m}$, where $m > n$. When we go to solve $Ax = b$, it could be that there is no such $x \in \mathbb{R}^{n}$ such that $Ax = b$ for a given $b$. In this case, we know that the linear map $L:\; \mathbb{R}^{n} \to \mathbb{R}^{n}$ is not surjective.
        \item \textbf{Over-determined systems}: If a system $Ax = b$ has more equations than unknowns $(m > n) $, we call the system \textbf{over-determined}
        \item \textbf{under-determined systems}: If a system $Ax = b$ has less equations than unknowns $(m < n) $, we call the system \textbf{under-determined}
        \item \textbf{Determined system}: If a system $Ax = b$ has the same number of equations as unknowns $(m = n)$, we call the system \textbf{determined}.
        \item \textbf{Well-determined and degenerate}: If a system $Ax = b$ has a unique solution for a given $b$, then the system is said to be \textbf{well-determined}. If the system has no solution or infinitely many, the system is \textbf{degenerate}.
        \item \textbf{Geometric interpretation}: Suppose that $A \in \mathbb{R}^{3\times 2}$, so $L:\; \mathbb{R}^{2} \to \mathbb{R}^{3} $. We know that $L$ cannot be surjective, so the image of $L$ is some proper subset of the codomain $\mathbb{R}^{3}$. Suppose that $b \not\in \text{Im}(L)$
            \bigbreak \noindent 
            If we try to solve this system for $x$, we will find that there is no solution. What can we do? We can project $b$ down onto the image, now we have a vector $\bar{b} \in \text{Im}(L)$, and we can solve the system.
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{mf}
                \label{fig:mf}
            \end{figure}
            \bigbreak \noindent 
            Notice that $r = b = A\bar{x}$.
        \item \textbf{The discrete least squares problem}: Let $A \in \mathbb{R}^{m\times n}$, where $m \geq n$, and $b \in \mathbb{R}^{m} $. The discrete least squares problem is finding
            \begin{align*}
                \min_{x\in \mathbb{R}^{n}} \norm{r}_{2}^{2},
            \end{align*}
            where $ r = b - Ax$. If $b \not\in \text{Im}(L) = \text{col}(A)$, then no solution to $Ax = b$ exists, and we can instead solve the discrete least squares problem to get the best approximation. 
            \bigbreak \noindent 
            Recall that since the closest point in a subspace to a vector is its orthogonal projection, minimizing $\norm{r}_{2}^{2}$ is equivalent to finding the projection of $b$ onto the column space of $A$.
        \item \textbf{Data fitting problem}: Suppose we have a function $y(t) = 1 + e^{t} + 3e^{-t}$ that generates $m$ points 
            \begin{align*}
                y(t_{1}),\; y(t_{2}),\; \dots ,\; y(t_{m}) &= (t_{1}, y_{1}),\; (t_{2}, y_{2}),\; \dots ,\; (t_{m}, y_{m})
            .\end{align*}
            Now, suppose we introduce some noise to our points,
            \begin{align*}
                \tilde{y_{i}} = y(t_{i}) + \varepsilon_{i},\quad \varepsilon_{i} \sim N(0, \sigma^{2})
            .\end{align*}
            Given just the noisey data, can we recover the function? If we suspect or somehow find out that the function has the form
            \begin{align*}
                x_{1}(1) + x_{2}(e^{t}) + x_{3}(e^{-t}),
            \end{align*}
            so a linear combination of $\{1, e^{t}, e^{-t}\} $, then $\tilde{y}(t) = x_{1}(1) + x_{2}(e^{t}) + x_{3}(e^{-t}) $. Using the noisey points, we have
            \begin{align*}
                \begin{pmatrix} 1 & e^{t_{i}} & e^{-t_{i}} \end{pmatrix} \begin{pmatrix} x_{1} \\ x_{2} \\ x_{3} \end{pmatrix} &= \tilde{y}_{i}
            ,\end{align*}
            which gives the system of linear equations
            \begin{align*}
                \begin{pmatrix} 
                    1 & e^{t_{1}} & e^{-t_{1}} \\
                    1 & e^{t_{2}} & e^{-t_{2}} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    1 & e^{t_{m}} & e^{-t_{m}} 
                \end{pmatrix}
                \begin{pmatrix} x_{1} \\ x_{2} \\ x_{3} \end{pmatrix}
                =
                \begin{pmatrix} \tilde{y}_{1} \\ \tilde{y}_{2} \\ \vdots \\ \tilde{y}_{m} \end{pmatrix}
            .\end{align*}
            Thus, an over-determined system.
        \item \textbf{Into to $QR$ factorization}: Given a matrix $A \in \mathbb{R}^{m\times n}$, we want to factor $A$ into $QR$, so that $A = QR$, where $Q \in \mathbb{R}^{m\times m}$ is orthogonal ($QQ^{T} = I$), and $R \in \mathbb{R}^{m\times n} $ is upper triangular.
            \bigbreak \noindent 
            $R \in \mathbb{R}^{m\times n}$ is upper triangular if we can split $R$ as follows,
            \begin{align*}
                R &= \begin{bmatrix}
                    \hat{R} \\ 0
                \end{bmatrix}
            ,\end{align*}
            where $\hat{R} \in \mathbb{R}^{n\times n}$, and is upper triangular. Observe that the bottom half has size $m-n \times n$, and is zero.
        \item \textbf{Orthogonal matrices}: A matrix $Q \in \mathbb{R}^{n\times n}$ is orthogonal if $QQ^{T} = Q^{T}Q = I$, so $Q^{T} = Q^{-1}$. 
            \bigbreak \noindent 
            An orthogonal matrix is a matrix whose columns form a set of orthonormal vectors, each has length one and is perpendicular to the others.
            \bigbreak \noindent 
            Suppose $\{q_{1}, q_{2}, \ldots, q_{n}\} $ form a set of orthonormal vectors. Let $Q \in \mathbb{R}^{n\times n}$ be the matrix whose columns are the vectors $q_{i}$, then
            \begin{align*}
                Q = \begin{bmatrix}
                    \mid & \mid & & \mid \\
                    q_{1} & q_{2} & \vdots & q_{n} \\
                    \mid & \mid & &\mid
                \end{bmatrix}
                ,\;
                Q^{T} = \begin{bmatrix}
                    \text{--} & q_{1}^{T} & \text{--}                      \\
                    \text{--} & q_{2}^{T} & \text{--}                      \\
                              & \cdots & \\
                    \text{--} & q_{n}^{T} & \text{--}                      
                \end{bmatrix}
            .\end{align*}
            So, we see that in $Q^{T}Q$, 
            \begin{align*}
                \begin{cases}
                    q_{i}q_{j} =0 &\text{ if } i \ne j \\
                    q_{i}q_{j} = 1 &\text{ if } i = j
                \end{cases}
            .\end{align*}
            Thus,
            \begin{align*}
                Q^{T}Q &= \begin{bmatrix}
                    q_{1}^{T}q_{1} & q_{1}^{T}q_{2} & \cdots & q_{1}^{T}q_{n} \\    
                    q_{2}^{T}q_{1} & q_{2}^{T}q_{2} & \cdots & q_{2}^{T}q_{n} \\    
                    \vdots & \vdots & \ddots & \ddots \\
                    q_{n}^{T}q_{1} & q_{n}^{T}q_{2} & \cdots & q_{n}^{T}q_{n} 
                \end{bmatrix}
                =
                \begin{bmatrix}
                    1 & 0 & \cdots & 0 \\
                    0 & 1 & \cdots & 0 \\
                    \vdots & \vdots & \ddots & \vdots \\
                    0 & 0 & \cdots & 1
                \end{bmatrix}
                 = 
                 I
            .\end{align*}
            Thus, $Q^{T}Q = I$, so $Q^{-1} = Q^{T}$. Also,
            \begin{align*}
                \det(Q^{T}Q) &= \det(I) = 1 
                \implies \det(Q^{T})\det(Q) = 1 
                \implies \det(Q)^{2} = 1  \\
                \therefore \det(Q) &= \pm 1
            .\end{align*}
            \textbf{Note:}  For square matrices, the terms "orthogonal matrix" and "orthonormal matrix" are used interchangeably.
        \item \textbf{Definition of orthogonal matrices}: $Q \in \mathbb{R}^{n\times n}$ is orthogonal if the columns of $Q$ satisfy
            \begin{enumerate}
                \item $\norm{q_{i}} = 1$ for $i = 1,2,...,n $
                \item $\left\langle q_{i}, q_{j} \right\rangle = 0$ if $i \ne j $
            \end{enumerate}
        \item \textbf{Properties of orthogonal matrices}
            \begin{enumerate}
                \item $Q^{T}Q = QQ^{T} = I $
                \item $Q^{-1} = Q^{T} $
                \item $\det(Q) = \pm 1 $
            \end{enumerate}
        \item \textbf{Theorem}: If $Q \in \mathbb{R}^{n\times n}$ is orthogonal, then
            \begin{enumerate}
                \item $\left\langle Qx, Qy \right\rangle  = \left\langle x,y \right\rangle$
                \item $\norm{Qx}_{2} = \norm{x}_{2} $
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} (1). Let $x,y \in \mathbb{R}^{n}$,
            \begin{align*}
                \left\langle Qx, Qy \right\rangle = (Qx)^{T}(Qy) = x^{T}Q^{T}Qy = x^{T}Iy = x^{T}y = \left\langle x,y \right\rangle
            .\end{align*}
            (2).
            \begin{align*}
                \norm{Qx}_{2}^{2} &= \left\langle Qx, Qx \right\rangle^{2} = \left\langle x,x \right\rangle = \norm{x}^{2}_{2}
            .\end{align*}
            Thus, $\norm{Qx}_{2} = \norm{x}_{2} $ $\endpf $
            \bigbreak \noindent 
            \textbf{Note:} Because of the second property $(\norm{Qx}_{2} = \norm{x}_{2})$, orthogonal matrices preserve length. Thus, they represent a \textbf{rotation} or a \textbf{reflection}.
        \item \textbf{Solving the discrete least squares problem (LSP) with the $QR$ factorization}: The LSP has us finding
            \begin{align*}
                \min_{x\in\mathbb{R}^{n}} \norm{b - Ax}_{2}^{2}
            .\end{align*}
            If we find the $QR$ decomposition $A = QR$, then
            \begin{align*}
                \norm{b - Ax}_{2}^{2} = \norm{b-QRx}_{2}^{2} = \norm{QQ^{T}b - QRx}_{2}^{2} = \norm{Q(Q^{T}b - Rx)}_{2}^{2}
            .\end{align*}
            Recall that 
            \begin{align*}
                A \in \mathbb{R}^{m\times n},\; Q \in \mathbb{R}^{m\times m},\; R \in \mathbb{R}^{m\times n},\; x \in \mathbb{R}^{n},\; b \in \mathbb{R}^{m},
            \end{align*}
            so $Q^{T}b \in \mathbb{R}^{m}$, $Rx \in \mathbb{R}^{m}$, and $Q^{T}b - Rx \in \mathbb{R}^{m}$. Thus,
            \begin{align*}
                \norm{Q(Q^{T}b - Rx)}_{2}^{2} &= \norm{Q^{T}b - Rx}_{2}^{2}
            .\end{align*}
            Since 
            \begin{align*}
                R &= \begin{bmatrix} \hat{R} \\ 0 \end{bmatrix}, \quad \hat{R} \in \mathbb{R}^{n\times n}
            ,\end{align*}
            we have that 
            \begin{align*}
                Rx &= \begin{bmatrix} \hat{R}x \\ 0 \end{bmatrix},\quad \hat{R}x \in \mathbb{R}^{n}
            .\end{align*}
            Let $c = Q^{T}b \in \mathbb{R}^{m}$. Divide $c$ into blocks
            \begin{align*}
                c &= \begin{bmatrix} \hat{c} \\ \bar{c} \end{bmatrix}, \quad \hat{c} \in \mathbb{R}^{n},\; \bar{c} \in \mathbb{R}^{m-n}
            .\end{align*}
            So,
            \begin{align*}
                \norm{Q^{T}b - Rx}_{2}^{2} &= \left\lvert \left\lvert \begin{bmatrix} \hat{c} - \hat{R}x \\ \bar{c} \end{bmatrix} \right\rvert \right\rvert_{2}^{2}
            .\end{align*}
            \begin{remark}
               Let $x \in \mathbb{R}^{n + m}$, where  
               \begin{align*}
                   x &= \begin{pmatrix} \hat{x} \\ \bar{x} \end{pmatrix},\quad \hat{x} \in \mathbb{R}^{n},\; \bar{x} \in \mathbb{R}^{m}
               .\end{align*}
               Then,
               \begin{align*}
                   \norm{x}_{2}^{2} = \norm{\hat{x}}_{2}^{2} + \norm{\bar{x}}_{2}^{2}
               .\end{align*}
               \textbf{\textit{Proof.}}
               \begin{align*}
                   \norm{x}_{2}^{2} = \sum_{i=1}^{m+n}\left\lvert x_{i} \right\rvert^{2} = \sum_{i=1}^{n}\left\lvert x_{i} \right\rvert^{2} + \sum_{i=n+1}^{n+m} \left\lvert x_{i} \right\rvert^{2} = \norm{\hat{x}}_{2}^{2} + \norm{\bar{x}}_{2}^{2}
               .\end{align*}
               $\endpf$
            \end{remark}
            \bigbreak \noindent 
            Thus,
            \begin{align*}
                \min_{x\in\mathbb{R}^{n}}\norm{b - Ax}_{2}^{2} = \min_{x\in \mathbb{R}^{n}}\left\lvert \left\lvert \begin{bmatrix} \hat{c} - \hat{R}x \\ \bar{c} \end{bmatrix} \right\rvert \right\rvert_{2}^{2} = \min_{x\in\mathbb{R}^{n}} \norm{\hat{c} - \hat{R}x}_{2}^{2} + \norm{\bar{c}}_{2}^{2}
            .\end{align*}
            Notice that $\norm{\bar{c}}_{2}^{2}$ does not depend on $x$, so we don't need to consider it when finding the minimizer. Second, notice that $\norm{\hat{c} - \hat{R}x}_{2}^{2}$ is minimized when its equal to zero, and since $\norm{\hat{c} - \hat{R}x}_{2}^{2} = 0 \iff \hat{c} - \hat{R}x = 0$, we find the minimizer by solving for $x$ when $\hat{c} - \hat{R}x = 0$, which gives the system
            \begin{align*}
                \hat{R}x = \hat{c}
            .\end{align*}
            Therefore,
            \begin{align*}
                \min_{x\in\mathbb{R}^{n}}\norm{b-Ax}_{2}^{2} \iff \hat{R}x = \hat{c}
            .\end{align*}
            \textbf{Note:} We have
            \begin{align*}
                \min_{x \in \mathbb{R}^{n}} \norm{b - Ax}_{2}^{2} = \min_{x\in \mathbb{R}^{n}} \norm{\hat{c} - \hat{R}x}_{2}^{2} + \norm{\bar{c}}_{2}^{2}
            .\end{align*}
            But, the minimum is achieved when $\hat{c} - \hat{R}x = 0$, so $\norm{\hat{c} - \hat{R}x}_{2}^{2} = 0 $, and thus
            \begin{align*}
                \min_{x\in \mathbb{R}^{n}} \norm{b- Ax} = \min_{x\in \mathbb{R}^{n}} \norm{\hat{c} - \hat{R}x}_{2}^{2} + \norm{\bar{c}}_{2}^{2} = 0 + \norm{\bar{c}}_{2}^{2}  
            .\end{align*}
            So, $x$ is found by solving the system $\hat{R}x = \hat{c}$, and the square of the norm of the residual is precisely $\norm{\bar{c}}_{2}^{2}$. So, $\bar{c}$ represents the residual
        \item \textbf{The residual in the discrete LSP}: Let $A \in \mathbb{R}^{m\times n}$, $m > n$, and $b \in \mathbb{R}^{m}$. If $x^{*}$ solves the discrete least squares problem,
            \begin{align*}
                x^{*} &= \arg\min_{x\in\mathbb{R}^{n}}\norm{b-Ax}_{2}^{2}
            ,\end{align*}
            then the residual vector is given by $r = b - Ax^{*}$. Applying $Q^{T}$ gives
            \begin{align*}
                Q^{T}r &= Q^{T}b -Q^{T}Ax^{*} = Q^{T}b - Q^{T}QRx^{*} = Q^{T} b - Rx^{*} = c - Rx^{*}\\
                       &= \begin{bmatrix} \hat{c} \\ \bar{c} \end{bmatrix} - \begin{bmatrix} \hat{R}\\0 \end{bmatrix}x^{*} = \begin{bmatrix} \hat{c} - \hat{R}x^{*} \\ \bar{c} \end{bmatrix}
            .\end{align*}
            But, $x^{*}$ solves $\hat{R}x = \hat{c}$, so $\hat{c} - \hat{R}x^{*}  = 0 $, so
            \begin{align*}
                Q^{T}r &= \begin{bmatrix} \hat{c} - \hat{R}x^{*} \\ \bar{c} \end{bmatrix}  = \begin{bmatrix} 0 \\ \bar{c} \end{bmatrix}
            .\end{align*}
            Applying $Q$ gives
            \begin{align*}
                r &= Q \begin{bmatrix} 0 \\ \bar{c} \end{bmatrix}, \quad Q\in \mathbb{R}^{m\times m},\; 0 \in \mathbb{R}^{n},\; \bar{c} \in \mathbb{R}^{m-n}
            .\end{align*}
            If we partition $Q$ as 
            \begin{align*}
                Q = \begin{bmatrix} Q_{1} & Q_{2} \end{bmatrix}, \quad Q_{1} \in \mathbb{R}^{m\times n},\; Q_{2} \in \mathbb{R}^{m\times (m-n)}
            ,\end{align*}
            then
            \begin{align*}
                r &= \begin{bmatrix} Q_{1} & Q_{2} \end{bmatrix} \begin{bmatrix} 0 \\ \bar{c} \end{bmatrix} = Q_{2}\bar{c}
            .\end{align*}
            Therefore, the norm of the residual is
            \begin{align*}
                \norm{r}_{2} = \norm{Q_{2}\bar{c}}_{2} = \norm{\bar{c}}_{2}
            \end{align*}
            as expected.
            \bigbreak \noindent 
            If $Ax = b$ has a unique solution, then $Ax = b$, which implies
            \begin{align*}
                QRx = b &\implies Rx = Q^{T}b = c \\
                        &\implies \begin{bmatrix} \hat{R} \\ 0 \end{bmatrix}x = \begin{bmatrix} \hat{c} \\ \bar{c} \end{bmatrix} \\
                        &\implies \bar{c} = 0
            .\end{align*}
            Thus, $\norm{r} = \norm{\bar{c}} = \norm{0} = 0$, as expected.
        \item \textbf{The discrete LSP algorithm}: Let $A \in \mathbb{R}^{m\times n}$, for $m > n$. Define
            \begin{align*}
                (P):\; \min_{x\in \mathbb{R}^{n}}\norm{x-Ax}_{2}^{2}
            .\end{align*}
            \bigbreak \noindent 
            To solve discrete least squares, we take the following steps
            \begin{enumerate}
                \item $c = Q^{T}b = \begin{bmatrix} \hat{c} \\ \bar{c} \end{bmatrix} $, $c \in \mathbb{R}^{m}$, $\hat{c} \in \mathbb{R}^{n}$, $\bar{c} \in \mathbb{R}^{m-n} $
                \item Solve $(\hat{P}):\; \hat{R}x = \hat{c}$, solution of $ (\hat{P})$ is the solution of $(P)$.
                \item $\min_{x\in \mathbb{R}^{n}}\norm{b-Ax}_{2}^{2} = \norm{\bar{c}}_{2}^{2} $
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{Note:} For now we want to assume that $\text{rank}(A) = n$, so all columns are linearly independent. In this case, $\hat{r}_{ii} \ne 0$.
        \item \textbf{$QR$ factorization of a square matrix}: Let $A \in \mathbb{R}^{n\times n}$, then $Q \in \mathbb{R}^{n\times n}$, $R = \hat{R} \in \mathbb{R}^{n\times n}$, $Q^{T}b = c = \hat{c}$, and
            \begin{align*}
                Ax = b \implies QRx = b \implies Rx = Q^{T}b \implies \hat{R}x = Q^{T}b = \hat{c}
            .\end{align*}
            So, since $\hat{R}$ is upper triangular, we can solve the system using backward substitution.
        \item \textbf{Givens rotations}: A Givens rotation is an orthogonal transformation that acts only in a 2-dimensional coordinate plane — say the plane spanned by the $i$-th and $j$-th coordinate axes. It’s the identity matrix except for a $2\times 2$ rotation block:
            \begin{align*}
                G(i,j,\theta ) = \begin{bmatrix}
                    1 & & & & & & \\
                      & \ddots & & & & & \\
                      & & c & & s  & \\
                      & & & 1 & & & \\
                      & & -s & & c & \\
                      & & &  & & \ddots &\\
                      & & & & & & 1
                \end{bmatrix},\; \quad c = \cos{\left(\theta \right)},\; s = \sin{\left(\theta \right)}
            .\end{align*}
            Everywhere else its the identity matrix $I$. Only entries $(i,i), (i,j), (j,i), (j,j)$ are modified.
            \bigbreak \noindent 
            Let $x = \begin{pmatrix} x_{1} & x_{2} & \cdots & x_{i} & \cdots & x_{j} & \cdots & x_{n}\end{pmatrix}^{T} \in \mathbb{R}^{n} $, applying $G(i,j,\theta )$ gives
            \begin{align*}
                G(i,j,\theta )x = \begin{pmatrix} x_{1} \\ \vdots \\ cx_{i} + sx_{j} \\ \vdots \\ -sx_{i} + cx_{j} \\ \vdots \end{pmatrix}   \in \mathbb{R}^{n}
            .\end{align*}
            Note that $G(i,j,\theta )$ is orthogonal, so $\norm{G(i,j,\theta )x}_{2} = \norm{x}_{2}$. Also, if we let $\sqrt{x_{i}^{2} + x_{j}^{2}} = y_{i}$. That is, we rotate such that a vector $\begin{pmatrix} x_{1} & \cdots & x_{i} & \cdots & x_{j} & \cdots & x_{m}\end{pmatrix}^{T} \mapsto \begin{pmatrix} * & \cdots & y_{i} & \cdots & 0 & \cdots & * \end{pmatrix}^{T} $. In this situation,
            \begin{align*}
                c &= \cos{\left(\theta \right)} = \frac{x_{i}}{\norm{x}} = \frac{x_{i}}{y_{i}}, \\
                s &= \sin{\left(\theta \right)} = \frac{x_{j}}{\norm{x}} =\frac{x_{j}}{y_{i}}
            .\end{align*}
            So,
            \begin{align*}
                cx_{i} + sx_{j} &= cy_{i}c + sy_{i}s = y_{i}c^{2} + y_{i}s^{2} = y_{i}(c^{2} + s^{2}) = y_{i}, \\
                -sx_{i} + cx_{j} &= -sy_{i}c + cy_{i}s = -y_{i}sc + y_{i}sc = 0
            .\end{align*}
            Thus,
            \begin{align*}
                G(i,j,\theta )x = \begin{pmatrix} x_{1} \\ \vdots \\ cx_{i} + sx_{j} \\ \vdots \\ -sx_{i} + cx_{j} \\ \vdots \end{pmatrix}  = \begin{pmatrix} x_{1} \\ \vdots \\ y_{i} \\ \vdots \\ 0 \\ \vdots \end{pmatrix} \in \mathbb{R}^{n}
            .\end{align*}
            \textbf{Important}: In computing $y_{i}$, we do not use the entire vector $x$, we only use the $i,j$ entries. So, if 
            \begin{align*}
                \begin{pmatrix} x_{1} \\ \vdots \\  x_{i} \\ \vdots \\ x_{j} \\ \vdots \\ x_{m}  \end{pmatrix} \mapsto \begin{pmatrix} * \\ \vdots \\ y_{i} \\ \vdots \\ 0 \\ \vdots \\ * \end{pmatrix}
            \end{align*}
            using a Givens rotation matrix $Q$, then
            \begin{align*}
                y_{i} = \norm{\begin{pmatrix} x_{i} \\ x_{j} \end{pmatrix}}_{2} = \sqrt{x_{i}^{2} + x_{j}^{2}}
            .\end{align*}


        \item \textbf{Finding $Q$ and $R$, $2\times 2$ example}: Suppose in $\mathbb{R}^{2\times 2} $, 
            \begin{align*}
                A = \begin{bmatrix} x_{1} & x_{3} \\ x_{2} & x_{4} \end{bmatrix}
            .\end{align*}
            $A = QR$, so $Q^{T}A = R$. Recall that $R$ is upper triangular, and $Q$ is orthogonal. Since $Q$ is orthogonal, it must represent a rotation (or reflection). Let's first focus on the first column of $A$, which yields the first column of $R$, we have
            \begin{align*}
                Q^{T}A  = \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix} \begin{bmatrix} x_{1} & * \\ x_{2} & * \end{bmatrix} = \begin{bmatrix} y_{1} & * \\ 0 & * \end{bmatrix} = R
            .\end{align*}
            Thus,
            \begin{align*}
                Q^{T}\text{col}_{1}(A) &= \text{col}_{1}(R) \implies \begin{bmatrix} \alpha & \beta \\ \gamma & \delta   \end{bmatrix} \begin{pmatrix} x_{1} \\ x_{2} \end{pmatrix} = \begin{pmatrix} y_{1} \\ 0 \end{pmatrix}
            .\end{align*}
            So,
            \begin{align*}
                \alpha x_{1} + \beta x_{2} &= y_{1} \tag{1} \\
                \gamma x_{1} + \delta x_{2} &= 0 \tag{2}
            .\end{align*}
            Applying $Q^{T}$ to $\text{col}_{1}(A)$ preserves length, so $\norm{Q^{T}\text{col}_{1}(A)} = \norm{\text{col}_{1}(A)} = \norm{\text{col}_{1}(R)}$. Thus,
            \begin{align*}
                y_{1} &= \sqrt{x_{1}^{2} + x_{2}^{2}} = \norm{x}_{2}
            .\end{align*}
            \bigbreak \noindent 
                \begin{figure}[ht]
                    \centering
                    \incfig{norm1}
                    \label{fig:norm1}
                \end{figure}
            \bigbreak \noindent 
            Notice we have that
            \begin{align*}
                \sin{\left(\theta \right)} &= \frac{x_{2}}{\norm{x}} = \frac{x_{2}}{y_{1}}, \\
                \cos{\left(\theta \right)} &= \frac{x_{1}}{\norm{x}} = \frac{x_{1}}{y_{1}}
            .\end{align*}
            From (1), we have
            \begin{align*}
                \alpha \frac{x_{1}}{y_{1}} + \beta \frac{x_{2}}{y_{1}} = 1 &\implies \alpha \cos{\left(\theta \right)} + \beta \sin{\left(\theta \right)} = 1 \\
                                                                       &\implies \alpha = \cos{\left(\theta \right)},\; \beta = \sin{\left(\theta \right)}
            .\end{align*}
            From (2),
            \begin{align*}
                \gamma x_{1} + \delta x_{2} = 0  &\implies \gamma y_{1}\cos{\left(\theta \right)} + \delta y_{1}\sin{\left(\theta \right)} = 0 \\
                                                &\implies \gamma \cos{\left(\theta \right)} + \delta \sin{\left(\theta \right)} = 0 \\
                                                &\implies \gamma = -\sin{\left(\theta \right)},\; \delta = \cos{\left(\theta \right)}
            .\end{align*}
            So, 
            \begin{align*}
                Q^{T} &= \begin{pmatrix} \cos{\left(\theta \right)} & \sin{\left(\theta \right)} \\ -\sin{\left(\theta \right)} & \cos{\left(\theta \right)} \end{pmatrix} = \begin{pmatrix} \frac{x_{1}}{y_{1}} & \frac{x_{2}}{y_{1}} \\ -\frac{x_{2}}{y_{1}} & \frac{x_{1}}{y_{1}} \end{pmatrix}
            .\end{align*}
            Now that we have $Q^{T}$, we can get the second column of $R$ with $\text{col}_{2}(R) = Q^{T}\text{col}_{2}(A) $.
            \bigbreak \noindent 
            So, in the $2\times 2$ case, we got $Q^{T}$ from the first column of $A$, since we know where the first column should map to under $Q^{T}$s transformation. Then, after we found $Q^{T}$, finding  the second column of $R$ is simple.
            \bigbreak \noindent 
            \textbf{Example}: Let $A \in \mathbb{R}^{2\times 2}$, 
            \begin{align*}
                A = \begin{pmatrix} 1 & 2 \\ 1 & 3 \end{pmatrix}
            .\end{align*}
            We have
            \begin{align*}
                y_{1} &= \sqrt{1^{2} + 1^{2}} = \sqrt{2}, \\
                \cos{\left(\theta \right)} &= \frac{1}{\sqrt{2}} = \frac{\sqrt{2}}{2}, \\
                \sin{\left(\theta \right)} &= \frac{1}{\sqrt{2}} = \frac{\sqrt{2}}{2}
            .\end{align*}
            Thus,
            \begin{align*}
                Q^{T} = \begin{pmatrix} \frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} \\ -\frac{\sqrt{2}}{2} & \frac{\sqrt{2}}{2} \end{pmatrix} = \frac{\sqrt{2}}{2}\begin{pmatrix} 1 & 1 \\ -1 & 1 \end{pmatrix}
            .\end{align*}
            So, $\text{col}_{1}(R) = \begin{pmatrix} y_{1} & 0 \end{pmatrix}^{T} = \begin{pmatrix} \sqrt{2} & 0 \end{pmatrix}^{T} $, and
            \begin{align*}
                \text{col}_{2}(R) &= Q^{T}\text{col}_{1}(A) = \frac{\sqrt{2}}{2} \begin{pmatrix} 1  & 1 \\ -1 & 1 \end{pmatrix} \begin{pmatrix} 2 \\ 3 \end{pmatrix} = \begin{pmatrix} \frac{5\sqrt{2}}{2} \\ \frac{\sqrt{2}}{2} \end{pmatrix} = \sqrt{2}\begin{pmatrix} \frac{5}{2} \\ \frac{1}{2}\end{pmatrix}
            .\end{align*}
            Now we have $Q$ and $R$,
            \begin{align*}
                Q^{T} = \frac{\sqrt{2}}{2}\begin{pmatrix} 1 & 1 \\ -1 & 1 \end{pmatrix},\; R = \sqrt{2}\begin{pmatrix} 1 & \frac{5}{2} \\ 0 & \frac{1}{2} \end{pmatrix}
            .\end{align*}
            Suppose that $b = \begin{pmatrix} -1 & -2 \end{pmatrix}^{T} \in \mathbb{R}^{2}$. Then,
            \begin{align*}
                Ax = b \iff QRx = b \iff Rx = Q^{T}b
            .\end{align*}
            So, we can solve the system for $x$ by solving the upper triangular system $Rx = Q^{T} b$
        \item \textbf{General process for finding $Q$ and $R$}: We use the fact that for $x \in \mathbb{R}^{m}$, 
            \begin{align*}
                \begin{pmatrix} \vdots \\ x_{i} \\ \vdots \\ x_{j} \\ \vdots \end{pmatrix} \mapsto \begin{pmatrix} \vdots \\ y_{i} \\ \vdots \\ 0 \\ \vdots \end{pmatrix}
            .\end{align*}
            Under the transformation
            \begin{align*}
                (Q_{\ell}^{T})_{ii} &= \cos{\left(\theta \right)},\; (Q_{\ell}^{T})_{ij} = \sin{\left(\theta \right)} \\
                (Q_{\ell}^{T})_{ji} &= -\sin{\left(\theta \right)},\; (Q_{\ell}^{T})_{jj} = \cos{\left(\theta \right)} 
            ,\end{align*}
            and with
            \begin{align*}
                \cos{\left(\theta \right)} &= \frac{x_{i}}{y_{i}},\; \sin{\left(\theta \right)} =\frac{x_{j}}{y_{i}},\; y_{i} = \sqrt{x_{i}^{2} + x_{j}^{2}}
            .\end{align*}
            \bigbreak \noindent 
            For $Q_{k} \in \mathbb{R}^{m\times m} = I$, except for at the positions above. 
            \bigbreak \noindent 
            In the $2\times 2$ example we only needed to apply one rotation to build $Q^{T}$, but for bigger matrices we will need to apply many rotations under we are able to fully build the matrix $\hat{R} \in \mathbb{R}^{n\times n}$. At the end, we will have
            \begin{align*}
                Q^{T}A = Q_{k}^{T}Q_{k-1}^{T} \cdots Q_{2}^{T}Q_{1}^{T}A  = R
            .\end{align*}
            So, 
            \begin{align*}
                Q^{T} = Q_{k}^{T}Q_{k-1}^{T} \cdots Q_{2}^{T}Q_{1}^{T}
            .\end{align*}
            We build these matrices in the same way as Gaussian elimination, top to bottom, left to right, choosing two indices at a time, until we have built $R$.
            \bigbreak \noindent 
            For example, suppose $A \in \mathbb{R}^{3\times 2}$, 
            \begin{align*}
                A = \begin{pmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \\ a_{31} & a_{32} \\ a_{41} & a_{42} \end{pmatrix}
            .\end{align*}
            So,
            \begin{align*}
                Q^T \begin{pmatrix} a_{11} & a_{12} \\ a_{21} & a_{22} \\ a_{31} & a_{32} \\ a_{41} & a_{42} \end{pmatrix} = \begin{pmatrix} r_{11} & r_{12} \\ 0 & r_{22} \\ 0 & 0 \\ 0 & 0 \end{pmatrix}
            .\end{align*}
            We work top to bottom left to right. Looking at the structure of $R$ in this example, our first transformation will map
            \begin{align*}
                Q_{1}^{T}\begin{pmatrix} a_{11} \\ a_{21} \\ a_{31} \\ a_{41} \end{pmatrix} \mapsto \begin{pmatrix} y_{1} \\ 0 \\ a_{31} \\ a_{41} \end{pmatrix}
            .\end{align*}
            Where 
            \begin{align*}
                Q^{T} = 
                \begin{pmatrix} 
                    \cos{\left(\theta \right)}  & \sin{\left(\theta \right)} & 0  & 0 \\
                    -\sin{\left(\theta \right)} & \cos{\left(\theta \right)} & 0 & 0 \\
                    0 & 0 & 1 & 0 \\
                    0 & 0 & 0 & 1
                \end{pmatrix}
            .\end{align*}
            Notice connection between the targets in $A$, and the matrix $Q$, which uses the fact described above. After we have $Q_{\ell}^{T}$, we can use the following. Eventually, we will have performed enough transformations, and $R_{k} = R$.
            \bigbreak \noindent 
            Let $R_{1} = A$, then $Q_{\ell}^{T}R_{\ell} = R_{\ell+1} $. So, after the first step,
            \begin{align*}
                R_{2} &= Q_{1}^{T}R_{1} = \begin{pmatrix} y_{1} & * \\ 0  & * \\ a_{31} & *  \\ a_{41} & * \end{pmatrix}
            ,\end{align*}
            with
            \begin{align*}
                \begin{pmatrix} * \\ * \\ * \\ *  \end{pmatrix} = Q_{1}^{T}\text{col}_{2}(R_{1})
            .\end{align*}
            In the second step, we target $y_{1}$, and $a_{31}$, we want
            \begin{align*}
                Q_{2}^{T}\begin{pmatrix} y_{1} \\ 0 \\ a_{31} \\ a_{41} \end{pmatrix} \mapsto \begin{pmatrix} y_{2} \\ 0 \\ 0 \\ a_{41} \end{pmatrix}
            ,\end{align*}
            so
            \begin{align*}
                Q_{2}^{T} = 
                \begin{pmatrix} 
                    \cos{\left(\theta \right)} & 0 & \sin{\left(\theta \right)} & 0 \\
                    0 & 1 & 0 & 0 \\
                    -\sin{\left(\theta \right)} & 0 & \cos{\left(\theta \right)} & 0 \\
                    0 & 0 & 0 & 1
                \end{pmatrix}
            .\end{align*}
            Thus,
            \begin{align*}
                R_{3} &= Q_{2}^{T}R_{2} = Q_{2}^{T}(Q_{1}^{T}A)
            ,\end{align*}
            with
            \begin{align*}
                R_{3} &= \begin{pmatrix} y_{2} & *  \\ 0  & * \\ 0  & * \\ a_{41} & * \end{pmatrix}
            .\end{align*}
            Notice how we are slowly building the structure of $R$, similar to how we build the structure of $U$ using Gaussian elimination.
            \bigbreak \noindent 
            To finish off the first column of $R$, we will have
            \begin{align*}
                R_{4} &= Q_{3}^{T}R_{3} = Q_{3}^{T}(Q_{2}^{T}(Q_{1}^{T}A))
            ,\end{align*}
            with
            \begin{align*}
                R_{4} = \begin{pmatrix} y_{3} & * \\ 0 & * \\ 0 & * \\ 0 & * \end{pmatrix}
            .\end{align*}
            Now, we proceed to the second column, we need the structure to be
            \begin{align*}
                \begin{pmatrix} r_{12} \\ r_{22} \\ 0 \\ 0 \end{pmatrix}
            .\end{align*}
            So, we start by selecting the second and third element of the second column of  $R_{4}$, so that we can get the third element zero.
            \bigbreak \noindent 
            Note that as we are working on the second column, the nonzero elements in the columns before will change, but the zero elements are safe, so the structure that we have already built will be preserved.
        \item \textbf{Product of orthogonal matrices is orthogonal}: Let $Q_{1}$ and $Q_{2}$ be orthogonal, then $Q = Q_{1}Q_{2} $ is orthogonal.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} $Q_{1}$, $Q_{2}$ are orthogonal, so $Q_{1}^{T}Q_{1} = I$, and $Q_{2}^{T}Q_{2} = I$. $Q = Q_{1}Q_{2}$, so
            \begin{align*}
                Q^{T}Q = (Q_{1}Q_{2})^{T}(Q_{1}Q_{2}) = Q_{2}^{T}Q_{1}^{T}Q_{1}Q_{2} = Q_{2}^{T}IQ_{2} = Q_{2}^{T}Q_{2} = I
            .\end{align*}
            Thus, $Q$ is orthogonal. $\endpf$
        \item \textbf{Householder reflection}: A Householder reflection is a linear transformation
            \begin{align*}
                H = I - 2 \frac{vv^{T}}{v^{T}v}
            .\end{align*}
            Where $v\ne 0$ is a chosen vector. It geometrically represents a reflection across the hyperplane orthogonal to $v$, this means
            \begin{enumerate}
                \item $Hv = -v$
                \item For any vector $z$ orthogonal to $v$, $Hz = z $
            \end{enumerate}
            So $H$ keeps the subspace orthogonal to $v$ fixed and reverses the component of a vector along $v$.
        \item \textbf{Direction vector}: A direction vector describes how you can move within a geometric object without leaving it.
            \begin{itemize}
                \item In a line, a direction vector tells you which way the line goes.
                \item In a plane, direction vectors describe all the ways you can move along the plane.
                \item In a curve or surface, a direction vector describes a tangent direction — an infinitesimal direction of movement within the object.
            \end{itemize}
            Let $S \subseteq \mathbb{R}^{n}$. A \textbf{direction vector} of $S$ is any vector $d$ such that for some point $x_{0} \in S$, we have
            \begin{align*}
                x_{0} + td \in S \quad \text{for all } t \in \mathbb{R}
            .\end{align*}
            So, if you start at $x_{0}$ and move in the direction $d$ by any scalar multiple $t$, you stay inside $S$.
            \bigbreak \noindent 
            If $S$ is a linear subspace (passes through origin), then every vector $d \in S$ is a direction vector, since
            \begin{align*}
                0 + td = td \in S 
            .\end{align*}
        \item \textbf{Linear subspace}: A linear subspace (often called simply a subspace) $S \subseteq V$ is a subset of a vector space $V$ (the ambient space) that is itself a vector space under the same operations (vector addition and scalar multiplication).
            \bigbreak \noindent 
            $S$ is a subspace iff it satisfies:
            \begin{align*}
                \forall u,v \in S,;\ \forall \alpha, \beta \in \mathbb{R},\; \alpha u + \beta v \in S
            .\end{align*}
            This property is called the closure under linear combinations. Notice that if $\alpha,\beta = 0$, then $0 \in S$ is a requirement. Thus, there are three key properties for a subset $S \subseteq V$ to be a linear subspace
            \begin{enumerate}
                \item $0 \in S $
                \item $u,v \in S \implies u + v \in S$
                \item $u\in S,\; \alpha \in \mathbb{R} \implies \alpha u\in S$
            \end{enumerate}
            If we wanted to be more general, we could swap $\mathbb{R}$ with any field $F$. I.e the scalars must live in some field $F$.
        \item \textbf{Affine subspaces}: An affine set is a translation of a linear subspace. A set $A \subseteq V$ is an affine subspace of the ambient set $V$ if it can be written as
            \begin{align*}
                A = S + v = \{s + v:\; s \in S\}
            ,\end{align*}
            where $S$ is a linear subspace of the ambient space $V$ ($S \subseteq V$), and $v$ is a fixed member of the ambient space $V$
            \begin{itemize}
                \item $S$ is called the direction subspace or associated subspace of $A$
                \item $v$ is any base point through which the affine subspace passes.
            \end{itemize}
            \textbf{Note:} So, $a \in A$ implies that $a = s + v = td + v$, for  $t \in \mathbb{R}, d \in \mathbb{S}$. Since $S$ is linear $td \in S$. So, every vector $s \in S$ is a direction vector for $A$.
            



        \item \textbf{Orientation}: The direction it "points" in — how it’s aligned relative to coordinate axes, changes if you rotate or reflect it
            \bigbreak \noindent 
            So "orientation" answers questions like:
            \begin{itemize}
                \item Is this plane horizontal or vertical?
                \item Does this line go northeast–southwest or northwest–southeast?
                \item Is the coordinate basis right-handed or left-handed?
            \end{itemize}
            A linear subspace $S \subseteq \mathbb{R}^{n}$ always passes through the origin. Its orientation is determined entirely by the directions it contains — that is, by its basis vectors.
            \bigbreak \noindent 
            The orientation of a subspace is defined by the set of directions it spans, or equivalently, by any orthonormal basis for it. Two subspaces have the same orientation if they are related by a rotation, not a reflection.
            \bigbreak \noindent 
            An affine subspace (or affine space) is a translation of a linear subspace:
            \begin{align*}
                S = S_{0} + x_{0}
            .\end{align*}
            $S_{0}$ gives the orientation (the directions it extends in), so the affine subspace has the same orientation as its linear part $S_{0}$, translating doesn't affect orientation.
        \item \textbf{Intro to Hyperplanes}: In $\mathbb{R}^{n}$ , a hyperplane is an $(n-1)$-dimensional affine subspace defined by a linear equation of the form:
            \begin{align*}
                H = \{x \in \mathbb{R}^{n}:\; a^{T}x = b\}
            ,\end{align*}
            where
            \begin{itemize}
                \item $a\in \mathbb{R}^{n}$ is a nonzero vector (called the \textbf{normal vector} to the hyperplane),
                \item $b \in \mathbb{R} $ is a scalar constant.
            \end{itemize}
            The vector $a$ determines the orientation of the hyperplane (it’s perpendicular to it), the constant $b$ determines its position relative to the origin.
            \bigbreak \noindent 
            If $b = 0$, the hyperplane passes through the origin and is called a linear subspace, call this hyperplane space $H_{0}$
            \begin{align*}
                H_{0} = \{s \in \mathbb{R}^{n}:\; a^{T}s = 0\}
            .\end{align*}
            In this case, all $s\in H_{0}$ are orthogonal to $a$.
            \bigbreak \noindent 
            If $b\ne 0$, the set
            \begin{align*}
                H = \{x \in \mathbb{R}^{n}:\; a^{T}x = b\}
            .\end{align*}
            is no longer a linear subspace, it does not pass through the origin. Instead, its a translated copy of the original hyperplane $H_{0}$. That is,
            \begin{align*}
                H = H_{0} + x_{0} = \{s+x_{0}:\; x_{0} \in H,\; s \in H_{0},\; a^{T}s = 0\}
            .\end{align*}
            So, $H$ is an \textbf{affine} hyperplane instead of a linear one. To prove this fact holds, we can show that $H \subseteq H_{0} + x_{0}$, and $H_{0} + x_{0} \subseteq H$.
            \bigbreak \noindent 
            First, consider $x = s + x_{0}$, for $s \in H_{0}$, and $x_{0} \in H$. We have
            \begin{align*}
                a^{T}x = a^{T}(s + x_{0}) = a^{T}s + a^{T}x_{0} = 0 + b =  b
            .\end{align*}
            So, $x \in H$, and $H_{0} + x_{0} \subseteq H$. 
            \bigbreak \noindent 
            Next, let $x, x_{0} \in H$, we aim to show that $x$ can be written as $s + x_{0}$, for $s \in H_{0}$, and $x_{0} \in H$. At this point we don't know where $s$ lives. If $x = s + x_{0}$, then $s = x - x_{0}$, and
            \begin{align*}
                a^{T}s = a^{T}(x-x_{0}) = a^{T}x - a^{T}x_{0} = b - b = 0
            .\end{align*}
            So, $s \in H_{0}$, and $x$ can indeed be written as $s + x_{0}$. This implies that $H \subseteq H_{0} + x_{0}$
            \bigbreak \noindent 
            Since $H_{0} + x_{0} \subseteq H$, and $H \subseteq H_{0} + x_{0}$, it must be that $H = H_{0} + x_{0} $ $\endpf$
            \bigbreak \noindent 
            You may have noticed that we said the hyperplane is orthogonal to $a$. But, in $H$, $a^{T}x = b$ implies that vectors in $H$ are not orthogonal to $a$. Instead, the \textbf{directions} lying within the hyperplane are orthogonal to $a$.
            \bigbreak \noindent 
            Let $x_{0}, x_{1} \in H$. Define the difference $d$ as
            \begin{align*}
               d = x_{0} - x_{1} 
            .\end{align*}
            Notice that since $x_{0}$ and $x_{1}$ are in $H$, we have $a^{T}x_{0} = a^{T}x_{1} = b$. Thus,
            \begin{align*}
                a^{T}d = a^{T}(x_{0} - x_{1}) = a^{T}x_{0} -a^{T}x_{1} = b - b = 0
            .\end{align*}
            For example, in 3D, if $a = \begin{pmatrix} 0 & 0 & 1 \end{pmatrix}^{T}$, the plane $a^{T}x = b$ is 
            \begin{align*}
                0x + 0y + 1z = b \implies z = b
            .\end{align*}
            Every point on that plane has $z = b$, and these points are not orthogonal to $a$. But, any direction vector lying along the plane, for example $(1,0,0)$ or $(0,1,0)$ \textit{is} orthogonal to $a$.
            \bigbreak \noindent 
            So when we say "the hyperplane orthogonal to $a$", we mean that the plane’s orientation is determined by $a$, not that its points themselves are orthogonal to $a$.
            \bigbreak \noindent 
            Some hyperplane examples are...
            \begin{center}
                \begin{tabularx}{\textwidth}{@{}lXX@{}}
                    \toprule
                    \textbf{Space} & \textbf{Equation} & \text{Description} \\
                    \midrule
                    $\mathbb{R}^{2}$ & $a_{1}x_{1} + a_{2}x_{2} = b$ & A \textbf{line} (1D hyperplane) \\[2ex]
                    $\mathbb{R}^{3}$ & $a_{1}x_{1} + a_{2}x_{2} + a_{3}x_{3} = b$ & A \textbf{plane} (2D hyperplane) \\[2ex]
                    $\mathbb{R}^{n}$ &$a_{1}x_{1} + a_{2}x_{2} + a_{3}x_{3} +  = b$ & An $(n-1)$-dimensional \textbf{flat surface} \\
                    \bottomrule
                \end{tabularx}
            \end{center}
            Why does the hyperplane with orientation perpendicular to $a \in \mathbb{R}^{2}$, with position $b$ relative to the origin form a 1D line? Let $a \in \mathbb{R}^{2}$, $a = \begin{pmatrix} a_{1} \\ a_{2} \end{pmatrix} $. Then, $x \in \mathbb{R}^{2}$ is on the hyperplane if
            \begin{align*}
                a^{T}x = b
            ,\end{align*}
            which implies 
            \begin{align*}
                a_{1}x_{1} + a_{2}x_{2} = b
            .\end{align*}
            We know that $a^{T}x = b$ says that all vectors $x$ in the hyperplane when projected onto $a$ have length $\frac{b}{\norm{a}}$.
            \bigbreak \noindent 
            So, if we take the component of each $x$ in the direction of $a$, it must equal the same value $(b/\norm{a})$.
            \bigbreak \noindent 
            If $\ell$ is a line not orthogonal to $a$, and $y$ is any vector on that line, then $a^{T}y$ does not stay fixed as we move along the line.
            \bigbreak \noindent 
            However, if $\ell$ is a line orthogonal to $a$, then any vector $x$ on that line is orthogonal to $a$, and so the dot product is constant (0).
            \bigbreak \noindent 
            Let $n$ be a vector orthogonal to $a$. Then,
            \begin{align*}
                a^{T}n = 0
            .\end{align*}
            Let $x_{0}$ be a vector that satisfies $a^{T}x_{0} = b$, then all vectors $x$ that satisfy $x = x_{0} + tn$, for $t \in \mathbb{R}$ satisfy $a^{T}x = b$, since
            \begin{align*}
                a^{T}x = a^{T}(x_{0} + tn) = a^{T}x_{0} + a^{T}tn = a^{T}x_{0} + ta^{T}n = b + t \cdot 0 = b
            .\end{align*}
            Notice that our vector generator $x = x_{0} + tn$ generates all vectors $x \in \mathbb{R}^{n}$ such that $a^{T}x = b$, and $x_{0} + tn$ is precisely the vector equation for a line. Thus, the hyperplane orthogonal to $a$ (the hyperplane with normal $a$), for $a \in \mathbb{R}^{2}$ is a 1D line.
        \item \textbf{Hyperplanes}: Let $\mathbb{R}^{n}$ be the ambient space. Let $a$ be a member in the ambient space. The space orthogonal to $a$ is a hyperplane. That is,
            \begin{align*}
                H = \{x \in \mathbb{R}^{n}:\; a^{T}x = b\}
            .\end{align*}
            Observe that the vectors $x$ in the hyperplane are not orthogonal to $a$ if $b\ne 0$, since their dot product is nonzero. Instead, the direction vectors in $H$ are orthogonal to $a$. This is why we say the hyperplanes orientation is orthogonal to $a$.
            \bigbreak \noindent 
            If $b  = 0$, the hyperplane is a linear subspace of $\mathbb{R}^{n}$. If $b\ne 0$, the hyperplane is an affine subspace of $\mathbb{R}^{n}$. 
            \bigbreak \noindent 
            We know that $H = H_{0} + v$, for $v$ in the ambient space. So, $H = \{s + v:\; s \in \mathbb{H}_{0}\} $. Thus,
            \begin{align*}
                x \in H \implies x = s + v = td + v
            ,\end{align*}
            for $t \in \mathbb{R}$, $d \in H_{0} $. So, any member of $H_{0}$ is a direction vector for $H$. Let $x \in H$ be written as $x = x_{0} + s$, for $x_{0} \in H$, and $s \in H_{0}$. We have
            \begin{align*}
                a^{T}x = a^{T}(x_{0} + s) = a^{T}x_{0} + a^{T}s = b + 0 = b
            ,\end{align*}
            and 
            \begin{align*}
                a^{T}s = 0
            .\end{align*}
            Thus, the direction of $H$ is orthogonal to $a$, but the members are not.

            



        \item \textbf{Intro to Householder reflections for $QR$ factorizations}: Using givens rotations, we could only zero out one entry per $Q_{k}$, so building one column of $R$ took many rotations. Suppose instead we wanted to build each column of $R$ with just one transformation. This is not possible with givens rotations, but we can use Householder reflections.
            \bigbreak \noindent 
            We could perform the transformation
            \begin{align*}
                Qx = Q\begin{pmatrix} x_{1} \\ x_{2} \\ \vdots \\ x_{i} \\ \vdots \\ x_{j} \\ \vdots \\ x_{n} \end{pmatrix} = \begin{pmatrix} x_{1} \\ x_{2} \\ \vdots \\ -\tau_{i} \\ \vdots \\ 0 \\ \vdots \\ 0 \end{pmatrix} = y
            ,\end{align*}
            with
            \begin{align*}
                Q &= I - \gamma uu^{T},\; \tau = \text{sgn}(x_{i})\norm{x}_{2},\; u = \frac{x-y}{\tau + x_{i}} = \begin{pmatrix} 1 \\ x_{2} / (\tau + x_{1}) \\ x_{3} / (\tau + x_{1}) \\ \vdots \\ x_{n} / (\tau + x_{1}) \end{pmatrix},\; \norm{u}_{2} = 1, \\
                \gamma &= \frac{\tau + x_{i}}{\tau}
            ,\end{align*}
            and
            \begin{align*}
                \text{sgn}(x_{i}) = 
                \begin{cases}
                    1 & \text{ if } x_{i} > 0 \\
                    -1 & \text{ if } x_{i} < 0 \\
                    0 & \text{ if } x_{i}  = 0 \\
                \end{cases}
            .\end{align*}
            $Q$ is called the \textbf{Householder matrix}.
        \item \textbf{Properties of the Householder matrix}
            \begin{enumerate}
                \item \textbf{Symmetry}: $Q = Q^{T}$
                \item \textbf{Orthogonality}: $Q^{T}Q = QQ^{T} = I $
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof (1)}}.
            \begin{align*}
                Q^{T} = (I - 2uu^{T})^{T} = I - 2(uu^{T})^{T} = I - 2(u^{T})^{T}u^{T} = I - 2uu^{T} = Q
            .\end{align*}
            \textbf{(2)}.
            \begin{align*}
                Q^{T}Q &= QQ = (I-2uu^{T})(I - 2uu^{T}) = I - 2uu^{T} - 2uu^{T} + 4uu^{T}uu^{T} \\
                       &= I - 4uu^{T} + 4u(u^{T}u)u^{T} = I - 4uu^{T} + 4(u^{T}u)uu^{T}\\
                       &= I - 4uu^{T} + 4\norm{u}_{2}uu^{T} = I - 4uu^{T} + 4uu^{T} = I
            .\end{align*}
        \item \textbf{$QR$ with Householder reflectors}: Let $A \in \mathbb{R}^{m\times n}$, where
            \begin{align*}
                A =
                \begin{bmatrix}
                    \mid & \mid & \cdots & \mid \\
                    x^{1} & x^{2} & \cdots & x^{n} \\
                    \mid & \mid & \cdots & \mid
                \end{bmatrix}                
            ,\end{align*}
            where $x^{j}$ denotes the $j^{\text{th}}$ column of $A$. For each column $j$ of $A$, we have the following steps
            \begin{enumerate}
                \item $\tau_{j} = \text{sgn}(x_{1})\norm{x^{j}}_{2}$ 
                \item $\gamma_{j} = \frac{\tau_{j} + x_{1}}{\tau_{j}} $
                \item $u_{j} = \begin{pmatrix} 1 \\ x_{2}/(\tau_{j} + x_{1}) \\ \vdots \\ x_{m}/(\tau_{j} + x_{1})\end{pmatrix} $
                \item $Q_{j} = I - \gamma_{j}u_{j}u_{j}^{T} $
            \end{enumerate}
            Then, just like with givens rotations, $Q = Q_{k} \cdots Q_{j} \cdots Q_{2}Q_{1}$, and $R = QA  = Q_{k}\cdots Q_{j} \cdots Q_{2}Q_{1}A$.
        \item \textbf{Householder reflector decompositions}: We don't transform an entire column. Instead, we act on a block of each column, where the first entry is the first nonzero entry starting from the bottom to the top for each column of $R$. For example, if
            \begin{align*}
                A = \begin{pmatrix} 
                    a_{11} & a_{12} \\ 
                    a_{21} & a_{22} \\ 
                    a_{31} & a_{32} \\ 
                    a_{41} & a_{42}
                \end{pmatrix}
            .\end{align*}
            Then $R$ looks like
            \begin{align*}
                R = \begin{pmatrix} 
                    r_{11} & r_{12} \\
                    0 & r_{22} \\
                    0 & 0\\
                    0 & 0
                \end{pmatrix}
            .\end{align*}
            So, for the first column of $A$, we do need to act on the entire column. But, for the second column, we only need from the second element onward.
            \bigbreak \noindent 
            Because the vectors that we need $Q_{j}$ to act on will be of size one less than the previous, the portion of $Q_{j}$ that is not $I$ will also decrease in size. Note that $Q_{j}$ will always be of size $m\times m$. We will have
            \begin{align*}
                Q_{1} = I_{m} - \gamma_{1}u_{1}u_{1}^{T},\; Q_{2} = I_{m-1} - \gamma_{2}u_{2}u_{2}^{T}, \ldots
            .\end{align*}
            Consider $Q_{2}$, the first row and the first column will be $I$, and the remaining $(m-1\times m-1) $ block will be $I_{m-1} - \gamma_{2}u_{2}u_{2}^{T}$. Because of this fact, the first row and first column of $A$ will be unchanged.
            \bigbreak \noindent 
            If $A \in \mathbb{R}^{m\times n}$, then
            \begin{align*}
                A_{1} = Q_{1}A = 
                \begin{pmatrix}
                    \begin{array}{c|c}
                        -\tau_{1} & a_{1}^{T} \\[2ex]
                        \hline\\[0.01cm]
                        0 & \tilde{A}_{1}
                    \end{array}
                \end{pmatrix}
            ,\end{align*}
            where 
            \begin{align*}
                Q_{1} = I_{m} - \gamma_{1}u_{1}u_{1}^{T}
            .\end{align*}
            Then,
            \begin{align*}
                A_{2} = Q_{2}A_{1} = Q_{2}Q_{1}A = 
                \begin{pmatrix} 
                    \begin{array}{c|c}
                        -\tau_{1} & a_{1}^{T} \\[2ex]  
                        \hline\\[0.01cm]
                        0 & \begin{array}{c|c}
                           - \tau_{2} & a_{2}^{T}\\[2ex] 
                            \hline\\[0.01cm]
                            0 & \tilde{A}_{2}
                        \end{array}
                    \end{array}
                \end{pmatrix}
            ,\end{align*}
            with 
            \begin{align*}
                Q_{2} = \begin{pmatrix}
                    \begin{array}{c|c}
                        1 & 0 \\[2ex]
                        \hline\\[0.01cm]
                        0 & I_{m-1}-\gamma_{2}u_{2}u_{2}^{T}
                    \end{array}
                \end{pmatrix}
            .\end{align*}
            Then,
            \begin{align*}
                A_{3} = Q_{3}A_{2} =Q_{3}Q_{2}Q_{1}A =
                \begin{pmatrix} 
                    \begin{array}{c|c}
                        -\tau_{1} & a_{1}^{T} \\[2ex]  
                        \hline\\[0.01cm]
                        0 & \begin{array}{c|c}
                           - \tau_{2} & a_{2}^{T}\\[2ex] 
                            \hline\\[0.01cm]
                           0 & \begin{array}{c|c}
                               -\tau_{3} & a_{3}^{T}\\[2ex] 
                               \hline\\[0.01cm]
                               0 & \tilde{A}_{3}
                            \end{array}
                        \end{array}
                    \end{array}
                \end{pmatrix}
            ,\end{align*}
            with
            \begin{align*}
                Q_{3} = \begin{pmatrix} 
                    \begin{array}{c|c}
                        1 & 0 \\[2ex]
                        \hline\\[0.01cm]
                        0 & \begin{array}{c|c}
                            1 & 0 \\[2ex]     
                            \hline\\[0.01cm]
                            1 & I_{m-2} - \gamma_{3}u_{3}u_{3}^{T}
                        \end{array}
                    \end{array}
                \end{pmatrix}
            .\end{align*}
            We proceed in this fashion until $A_{n} = R$. Note that we use the blocks of $Q$ that contain the reflector to find the blocks of $A$ that are changed in each step. Call this block $\bar{Q}$.

        \item \textbf{Flop counts for $QR$ with Householder reflectors}: Consider the steps of Householder
            \begin{enumerate}
                \item $\tau_{j} = \text{sgn}(x_{1}) \norm{x^{j}}_{2}$ $(\mathcal{O}(m) \text{ flops})$
                \item $\gamma_{j} = \frac{\tau_{j} + x_{1}}{\tau_{j}} $ $(\mathcal{O}(1) \text{ flops}) $
                \item $u_{j} = \begin{pmatrix} 1 \\ x_{2}/(\tau_{j} + x_{1}) \\ \vdots \\ x_{m}/(\tau_{j} + x_{1}) \end{pmatrix} $ $(\mathcal{O}(m) \text{ flops}) $
                \item $Q_{j} = I - \gamma_{j}u_{j}u_{j}^{T}$ $(\mathcal{O}(m^{2}) \text{ flops}) $
            \end{enumerate}
            So, each $Q_{j}$ requires roughly $\mathcal{O}(m^{2})$ flops. But, we compute these steps for each column of $A$. If $A$ has $n$ columns, then we require roughly $\mathcal{O}(nm^{2})$ flops. If $A$ is square, then we need $\mathcal{O}(m^{3})$ flops for the $QR$ factorization of $A$ with Householder reflectors.
            \bigbreak \noindent 
            To be precise, $QR$ factorization with Householder reflectors requires $\frac{4}{3}m^{3}$ flops. Not as efficient as $LU$ or Cholesky, but more efficient that computing the inverse.
        \item \textbf{Reducing flops in $QR$ factorization with Householder reflectors}: Consider a system $Ax = b$, with the $QR$ factorization,
            \begin{align*}
                Ax = b \implies QRx = b \implies Rx = Qb
            .\end{align*}
            But, $R = QA$, so
            \begin{align*}
                Rx = Qb \implies QA = Qb \implies Q_{k} \cdots Q_{2}Q_{1}A = Q_{k} \cdots Q_{2}Q_{1}b
            .\end{align*}
            However, we don't really matrix multiply $Q_{j}$ by $A$, what we do is multiply columns of $A$ by $Q_{j}$. Consider a vector $x$ multiplied by a Householder reflector $Q$...
            \begin{align*}
                Qx = (I - \gamma uu_{T})x = x - \gamma uu^{T}x
            .\end{align*}
            The expensive part is computing the outer product $uu^{T}$. Instead, lets use the associative law of vectors to instead do
            \begin{align*}
                Qx = x - \gamma u(u^{T}x)
            .\end{align*}
            Notice that $u^{T}x$ is an inner product, just a real number. Thus, we can move it. We have
            \begin{align*}
                Qx = x - \gamma (u^{T}x)u
            .\end{align*}
            This simple fact reduces the flops for this step by a factor of $m$, i.e $\mathcal{O}(m)$ flops instead of $\mathcal{O}(m^{2})$. 
            \bigbreak \noindent 
            We now don't even need to form $Q$ at all, using the fact that since
            \begin{align*}
                Rx = Qb \implies QA = Qb
            ,\end{align*}
            all we need is vector multiplication by the form of $Q$, the form that we have above $(x - \gamma(u^{T}x)u) $
        \item \textbf{Normal equations}: Consider again the geometric interpretation of a vector $b$ outside of the column space of $A$. 
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{mf}
                \label{fig:mf}
            \end{figure}
            \bigbreak \noindent 
            Which can happen if our system is over-determined. Since there is clearly no solution to the system for the given $b$, we instead solve the least squares problem
            \begin{align*}
                (p):\; \min_{x\in \mathbb{R}^{n}}\norm{b-Ax}_{2}^{2} 
            .\end{align*}
            Thus, we aim to find some vector $\bar{x}$ such that the residual $b - A\bar{x}$ is minimized. We know that this vector is found by projecting $b$ onto the column space $Ax$, and thus the residual $r = b -A\bar{x}$ is orthogonal to $A\bar{x} $, where $A\bar{x}$ is the projection of $b$ onto the column space.
            \bigbreak \noindent 
            So, we have
            \begin{align*}
                A\bar{x} \perp r
            ,\end{align*}
            which implies that
            \begin{align*}
                (A\bar{x})^{T}r &= 0 \\
                \implies (A\bar{x})^{T}(b-A\bar{x}) &= 0 \\
                \implies \bar{x}^{T}A^{T}b - \bar{x}^{T}A^{T}A\bar{x} &= 0\\
                \implies \bar{x}^{T}(A^{T}b - A^{T}A\bar{x}) = 0
            .\end{align*}
            But, notice that $\bar{x} \ne 0$ since if it were, then $A\bar{x} = b = 0$. Since the zero vector is in the column space, $b$ is non-zero, and so is $\bar{x}$. Thus,
            \begin{align*}
                A^{T}b - A^{T}A\bar{x} &= 0 \\
                \implies A^{T}A\bar{x} &= A^{T}b
            .\end{align*}
            Therefore, $\bar{x}$ is found by solving the system $A^{T}Ax = A^{T}b $, and 
            \begin{align*}
                \bar{x} = \text{arg min}_{x\in \mathbb{R}^{n}}\norm{b-Ax}_{2}^{2}
            .\end{align*}
            Although this method is far easier than $QR$ factorization methods, one can prove that
            \begin{align*}
                \kappa(A^{T}A) = \kappa^{2}(A)
            \end{align*}
            So, if $A$ is moderately ill-conditioned, then $A^{T}A$ can be severely ill-conditioned.
            \bigbreak \noindent 
            \textbf{Note:} The "normal equations" are the equations
            \begin{align*}
                A^{T}Ax = A^{T}b
            .\end{align*}
            They are "normal" because they enforce that the residual is \textbf{normal} to the column space.
        \item \textbf{Gram Matrix}: The matrix $A^{T}A$ is referred to as the \textit{Gram matrix} of the columns of $A$. Any matrix of inner products is called a \textit{Gram} matrix.
            \bigbreak \noindent 
            The matrix $A^{T}A$ is also sometimes referred to as the normal matrix, in the context of the normal equations.
        \item \textbf{Property of the normal matrix}: Consider the normal matrix $A^{T}A$, we can verify that this matrix is symmetric,
            \begin{align*}
                (A^{T}A)^{T} = A^{T}(A^{T})^{T} = A^{T}A
            .\end{align*}
            Thus, it is symmetric. Next, for any nonzero vector $x$, we have
            \begin{align*}
                x^{T}A^{T}Ax = (Ax)^{T}(Ax) = \norm{Ax}^{2}_{2}
            .\end{align*}
            Since $\norm{Ax}_{2} \geq 0$ for all $x$, $A^{T}A \succeq 0$.
            \bigbreak \noindent 
            But, notice that if $A$ has full column rank ($\text{rank}(A) = n$), then $Ax$ is injective and the kernel space is trivial
            \begin{align*}
                Ax = 0 \iff x = 0
            .\end{align*}
            Thus for $A\in \mathbb{R}^{m\times n}$,
            \begin{align*}
                A^{T}A \succ 0 \iff \text{ rank}(A) = n
            .\end{align*}
            Therefore, if $A$ has full column rank, then $A^{T}A$ is positive definite, and we can use Cholesky decomposition for the normal equations.

    \end{itemize}

    \pagebreak 
    \subsubsection{Singular value decomposition (SVD)}
    \begin{itemize}
        \item \textbf{Singular values}: For a matrix $A\in \mathbb{R}^{m\times n}$, its singular values are
            \begin{align*}
                \sigma_{1} \geq \sigma_{2} \geq \cdots \geq \sigma_{r} > 0 
            ,\end{align*}
            where $r$ is the rank of $A$. Each singular value is defined by
            \begin{align*}
                \sigma_{i} = \sqrt{\lambda_{i}(A^{T}A)}
            ,\end{align*}
            where $\lambda_{i}$ is the $i^{\text{th}} $ eigenvalue for $A^{T}A$.
        \item \textbf{Rank of $A^{T}A$}: Let $A \in \mathbb{R}^{m\times n}$. Recall by the rank-nullity theorem,
            \begin{align*}
                \text{rank}(A) = n - \text{dim}(\text{ker}(A))
            .\end{align*}
            The key insight is that $A^{T}A $ and $A$ share the same null space. Suppose $x \in \text{null}(A^{T}A)$, then
            \begin{align*}
                A^{T}Ax = 0 \iff x^{T}A^{T}Ax = 0 \iff (Ax)^{T}(Ax) = 0 \iff \norm{Ax}^{2} = 0 \iff Ax = 0    
            .\end{align*}
            Thus, $x \in \text{null}(A) $. So, since $\text{ker}(A^{T}A)  = \text{ker}(A)$, 
            \begin{align*}
                \text{rank}(A^{T}A) = n - \text{dim}(\text{ker}(A^{T}A)) = n - \text{dim}(\text{ker}(A)) = \text{rank}(A)
            .\end{align*}
        \item \textbf{SVD}: The Singular Value Decomposition (SVD) is a fundamental factorization in linear algebra that applies to any real or complex matrix, square or rectangular. For a matrix
            \begin{align*}
                A \in \mathbb{R}^{m\times n}
            ,\end{align*}
            The SVD expresses $A$ as 
            \begin{align*}
                A = U \Sigma V^{T}
            \end{align*}
            where
            \begin{itemize}
                \item $U \in \mathbb{R}^{m\times m} $ An orthogonal matrix ($U^{T}U = I$). Its columns are called \textbf{left singular vectors}.
                \item $\sum \in \mathbb{R}^{m\times n} $ A diagonal (rectangular) matrix whose entries are the singular values
                    \begin{align*}
                        \sigma_{1} \geq \sigma_{2} \geq \cdots \geq 0
                    \end{align*}
                \item $V \in \mathbb{R}^{n\times m}$ An orthogonal matrix. Its columns are the \textbf{right singular vectors}

            \end{itemize}
    \end{itemize}

    \pagebreak 
    \subsection{The Determinant}
    \begin{itemize}
        \item \textbf{Bilinear function}: Let $f:\ V \times W \to \mathbb{F}$, where $V$ and $W$ are vector spaces over the field $\mathbb{F}$. $f$ is called bilinear if it is linear in each argument separately. So,
            \begin{align*}
                f(\alpha v + \beta u, w) &= \alpha f(v,w) + \beta f(u,w), \\
                f(v,\alpha w+\beta u) &= \alpha f(v,w) + \beta f(v,u)
            .\end{align*}
            Thus,
            \begin{align*}
                f(\alpha v_{1} + \beta v_{2}, \gamma w_{1} + \lambda w_{2}) &= f(\alpha v_{1}, \gamma w_{1} + \lambda w_{2}) + f(\beta v_{2}, \gamma w_{1} + \lambda w_{2}) \\
                &=f(\alpha v_{1}, \gamma w_{1}) + f(\alpha v_{1}, \lambda w_{2}) + f(\beta v_{2}, \gamma w_{1}) + f(\beta v_{2}, \lambda w_{2}) \\
                &=\alpha \gamma f(v_{1}, w_{1}) + \alpha \lambda f(v_{1}, w_{2}) + \beta \gamma f(v_{2}, w_{1}) + \beta \lambda f(v_{2}, w_{2})
            .\end{align*}
            \textbf{Note:} As an example, the inner product $\left\langle v,w \right\rangle = v^{T}w$ is a bilinear function.
            \bigbreak \noindent 
            The row-column matrix multiplication $(v^{T}A)w$ is also bilinear in $v$ and $w$.
        \item \textbf{Multilinear function}:
            For a single-variable function 
            \[
                f : \mathbb{R}^n \to \mathbb{R}
            \]
            (that takes one vector as input), we say that $f$ is \textbf{linear} if for all scalars 
            $c_1, c_2 \in \mathbb{R}$ and vectors $u, w \in \mathbb{R}^n$,
            \[
                f(c_1 u + c_2 w) = c_1 f(u) + c_2 f(w).
            \]
            Where
            \begin{itemize}
                \item \textbf{Additivity}: $f(u + w) = f(u) + f(w) $
                \item \textbf{Homogeneity}: $f(cu) = cf(u) $
            \end{itemize}
            This is just the usual definition of linearity that you already know from linear algebra.
            \bigbreak \noindent 
            Now suppose $f$ takes several vectors as arguments:
            \[
                f(v_1, v_2, \dots, v_n).
            \]
            We cannot talk about linearity in all of them at once (since we could mix them in complicated ways),
            so we instead require linearity in each one separately, while holding the others fixed.
            \bigbreak \noindent 
            Pick one argument, say the $i^{\text{th}}$ one, and replace it with a linear combination 
            $c_1u + c_2w$. The function is \textbf{multilinear} if this linearity property holds in that position:
            \[
                f(v_1, \dots, c_1u + c_2w, \dots, v_n)
                = c_1 f(v_1, \dots, u, \dots, v_n)
                + c_2 f(v_1, \dots, w, \dots, v_n).
            \]
        \item \textbf{Properties of multilinear functions}: Suppose $f:\; V^{n} \to \mathbb{F}$ is multilinear, then the following properties can be observed
            \begin{enumerate}
                \item \textbf{Zero vector kills the value}: If any argument is the zero vector, then $f(\dots, 0,\dots) = 0$. This follows immediately from homogeneity.
                \item \textbf{Expansion property (multilinear expansion)}: If each argument is written as a sum, the function expands as a sum over all combinations. For example, if 
                    \begin{align*}
                        v_{i} = u_{i} + w_{i} \quad \text{ for all $i$}
                    ,\end{align*}
                    then
                    \begin{align*}
                        f(v_{1}, \dots, v_{n}) = \sum f(\text{all choices of $u_{i}$ or $w_{i}$})
                    .\end{align*}
                    This is exactly the algebraic mechanism behind the Leibniz determinant formula.
                \item \textbf{Behavior under scaling all arguments}: If all arguments are scaled by the same scalar $\alpha$, then
                    \begin{align*}
                        f(\alpha v_{1}, \dots, \alpha v_{n}) = \alpha^{n}f(v_{1}, \dots, v_{n})
                    .\end{align*}
                    This follows from applying homogeneity for all $n$ arguments.
            \end{enumerate}
        \item \textbf{Expansion property (multilinear expansion)}: We saw in the bilinear case that
            \begin{align*}
                f( v_{1} +  v_{2},  w_{1} +  w_{2}) &= f( v_{1},  w_{1} +  w_{2}) + f( v_{2},  w_{1} +  w_{2}) \\
                &=f( v_{1},  w_{1}) + f( v_{1},  w_{2}) + f( v_{2},  w_{1}) + f( v_{2},  w_{2}) \\
                &=  f(v_{1}, w_{1}) +   f(v_{1}, w_{2}) +   f(v_{2}, w_{1}) +   f(v_{2}, w_{2})
            .\end{align*}
            This is precisely the expansion property of multilinear functions. In this case, the bilinear function $f(v_{1}, v_{2}) $ replaced arguments so that each argument was a linear combination. That is,
            \begin{align*}
                v &= v_{1} + v_{2}, \\
                w &= w_{1} + w_{2}
            .\end{align*}
            So, by the expansion property,
            \begin{align*}
                f(v,w) = f(v_{1} + v_{2}, w_{1} + w_{2}) = f\left(\sum_{i=1}^{2} v_{i}, \sum_{j=1}^{2}w_{j}\right) = \sum_{i=1}^{2}\sum_{j=1}^{2}f(v_{i}, w_{j})
            .\end{align*}
            In fact, the decomposition does not need to be limited to two terms, if $f$ has two arguments $v_{1}, v_{2}$, then we can express each argument as a finite sum of vectors,
            \begin{align*}
                v_{1} &= v_{1}^{(1)} + v_{1}^{(2)} + \dots + v_{1}^{(m_{1})}, \\
                v_{2} &= v_{2}^{(1)} + v_{2}^{(2)} + \dots + v_{2}^{(m_{2})}
            .\end{align*}
            Then,
            \begin{align*}
                f(v_{1}, v_{2}) &= f\left(\sum_{i=1}^{m_{1}}v_{1}^{(i)}, \sum_{j=1}^{m_{2}} v_{2}^{(j)}\right) = \sum_{i=1}^{m_{1}}\sum_{j=1}^{m_{2}}f(v_{1}^{(i)}, v_{2}^{(j)})
            .\end{align*}
            Now, consider a general multilinear function $f:\; V^{n} \to \mathbb{F}$, where $f$ has $n$ vector arguments $v_{1}, \dots, v_{n}$. Replace each $v_{i}$ by a sum,
            \begin{align*}
                v_{i} &= v_{i}^{(1)} + v_{i}^{(2)} + \dots + v_{i}^{(m_{i})}
            .\end{align*}
            Then,
            \begin{align*}
                f(v_{1}, \dots, v_{n}) &= f\left(\sum_{k_{1}}v_{1}^{(k_{1})},\dots,\sum_{k_{i}}v_{i}^{(k_{i})}, \dots, \sum_{k_{n}}v_{n}^{(k_{n})}\right) \\
                &= \sum_{k_{1}=1}^{m_{1}} \cdots \sum_{k_{i}=1}^{m_{i}} \cdots \sum_{k_{n}=1}^{m_{n}} f(v_{1}^{(k_{1})}, \dots, v_{i}^{(k_{i})}, \dots, v_{n}^{(k_{n})})
            .\end{align*}
        \item \textbf{Ordinary multiplication is multilinear}: Consider the map
            \begin{align*}
                m:\; \mathbb{R}^{n} \to \mathbb{R} \quad m(x_{1}, \dots, x_{n}) \mapsto x_{1}\cdots x_{n}
            .\end{align*}
            Note that in this situation, $\mathbb{R}^{n}$ is taken to mean $\mathbb{R} \times \cdots \times \mathbb{R}$, an $n$-tuple of scalars in $\mathbb{R}$, not the vector space $\mathbb{R}^{n}$.
            \bigbreak \noindent 
            This map is multilinear, so
            \begin{align*}
                m(x_{1}, \dots, \alpha x_{i}, \dots, x_{n}) =&\; \alpha m(x_{1}, \dots, x_{i}, \dots, x_{n}), \\
                m(x_{1},\dots, x_{i}^{(1)} + x_{i}^{(2)}, \dots, x_{n}) =&\; m(x_{1}, \dots, x_{i}^{(1)}, \dots, x_{n}) \\
                                                                        &+ m(x_{1}, \dots, x_{i}^{(2)}, \dots, x_{n})
            .\end{align*}
            Which means,
            \begin{align*}
                x_{1}x_{2}\cdots \alpha x_{i} \cdots x_{n} &= \alpha(x_{1}x_{2}\cdots x_{i}\cdots x_{n}),\\
                x_{1}\cdots (x_{i}^{(1)} + x_{i}^{(2)}) \cdots x_{n} &= (x_{1}\cdots x_{i}^{(1)} \cdots x_{n}) + (x_{1} \cdots x_{i}^{(2)} \cdots x_{n})
            .\end{align*}
            For example, if $n=3$, the map becomes
            \begin{align*}
                m(x_{1}, x_{2}, x_{3}) = x_{1}x_{2}x_{3} = \prod_{i=1}^{3}x_{i}
            .\end{align*}
            So,
            \begin{align*}
                m(x_{1}, \alpha x_{2}, x_{3}) &=  x_{1}\alpha x_{2} x_{3} = \alpha (x_{1}x_{2} x_{3}) = \alpha \prod_{i=1}^{3}x_{i}\\
                m(x_{1}, x_{2}^{(1)} + x_{2}^{(2)}, x_{3}) &= x_{1}(x_{2}^{(1)} + x_{2}^{(2)})x_{3} = x_{1}x_{2}^{(1)}x_{3} + x_{1}x_{2}^{(2)}x_{3}\\
                                                           &= \sum_{k=1}^{2}\prod_{i=1}^{3}x_{i}^{(k)}
            ,\end{align*}
            where $x_{1} = x_{1}^{(1)} = x_{1}^{(2)}$, and $x_{3} = x_{3}^{(1)} = x_{3}^{(2)}$, since these terms are not split into a sum.
            \bigbreak \noindent 
            Now consider $x_{i} = x_{i}^{(1)} + \dots + x_{i}^{(m_{i})} $, by the expansion property of multilinearity,
            \begin{align*}
                m(x_{1}, \dots, x_{n}) &= m\left(\sum_{k_{1}=1}^{m_{1}}x_{1}^{(k_{1})}, \dots, \sum_{k_{n} = 1}^{m_{n}}x_{n}^{(k_{n})}\right) = \sum_{k_{1} = 1}^{m_{1}} \cdots \sum_{k_{n} = 1}^{m_{n}}m(x_{1}^{(k_{1})}, \dots, x_{n}^{(k_{n})}) \\
                                       &= \sum_{k_{1}, \dots, k_{n}}m(x_{1}^{(k_{1})}, \dots, x_{n}^{(k_{n})}) = \sum_{k_{1}, \dots, k_{n}} x_{1}^{(k_{1})} \cdots x_{n}^{(k_{n})}
            .\end{align*}
            Consider again the $n=3$ case, let $x_{i} = x_{i}^{(1)} + \dots + x_{i}^{(m_{i})} $ for $i=1,2,3 $. So,
            \begin{align*}
                m(x_{1}, x_{2}, x_{3}) &= m\left(\sum_{k_{1}=1}^{m_{1}} x_{1}^{(k_{1})}, \sum_{k_{2}=1}^{m_{2}} x_{2}^{(k_{2})}, \sum_{k_{3}=1}^{m_{3}} x_{3}^{(k_{3})}\right) \\
                &= \sum_{k_{1}=1}^{m_{1}}\sum_{k_{2}=1}^{m_{2}}\sum_{k_{3}=1}^{m_{3}} m(x_{1}^{(k_{1})}, x_{2}^{(k_{2})}, x_{3}^{(k_{3})}) = \sum_{k_{1}, k_{2}, k_{3}} m(x_{1}^{(k_{1})}, x_{2}^{(k_{2})}, x_{3}^{(k_{3})})
            .\end{align*}
            So,
            \begin{align*}
                x_{1}x_{2}x_{3} &= (x_{1}^{(1)} + \dots + x_{1}^{(m_{1})})(x_{2}^{(1)} + \dots + x_{2}^{(m_{2})})(x_{3}^{(1)} + \dots + x_{3}^{(m_{3})})  \\
                                &= \prod_{i=1}^{3}\sum_{k_{i}=1}^{m_{i}} x_{i}^{(k_{i})} = \sum_{k_{1} = 1}^{m_{1}} \sum_{k_{2} = 1}^{m_{2}} \sum_{k_{3} = 1}^{m_{3}} x_{1}^{(k_{1})}x_{2}^{(k_{2})}x_{3}^{(k_{3})}  \\
                                &=  \sum_{k_{1} = 1}^{m_{1}} \sum_{k_{2} = 1}^{m_{2}} \sum_{k_{3} = 1}^{m_{3}} \prod_{i=1}^{3} x_{i}^{(k_{i})} = \sum_{k_{1}, k_{2}, k_{3}}\prod_{i=1}^{3}x_{i}^{(k_{i})}
            .\end{align*}
            So, if $m_{1}=m_{2}=m_{3} = 2$, then
            \begin{align*}
                x_{1}x_{2}x_{3} &= (x_{1}^{(1)} + x_{1}^{(2)} ) (x_{2}^{(1)} + x_{2}^{(2)} ) (x_{3}^{(1)} + x_{3}^{(2)} ) \\
                &= x_{1}^{(1)}x_{2}^{(1)}x_{3}^{(1)} +  x_{1}^{(1)}x_{2}^{(1)}x_{3}^{(2)} + x_{1}^{(1)}x_{2}^{(2)}x_{3}^{(1)} +  x_{1}^{(1)}x_{2}^{(2)}x_{3}^{(2)} \\
                &+x_{1}^{(2)}x_{2}^{(1)}x_{3}^{(1)} + x_{1}^{(2)}x_{2}^{(1)}x_{3}^{(2)} + x_{1}^{(2)}x_{2}^{(2)}x_{3}^{(1)} + x_{1}^{(2)}x_{2}^{(2)}x_{3}^{(2)} 
            .\end{align*}
            Now, consider the map
            \begin{align*}
                m(x,y) = xy
            .\end{align*}
            But, let's let $y=x$, and $x = (z_{1} + z_{2})$, so
            \begin{align*}
                m(x,y) = xx = (z_{1} + z_{2})(z_{1}+z_{2}) = \prod_{i=1}^{2}x = \prod_{i=1}^{2}(z_{1} + z_{2}) = \prod_{i=1}^{2}\sum_{k=1}^{2} z_{k}
            .\end{align*}
            By the expansion property,
            \begin{align*}
                \prod_{i=1}^{2}\sum_{k=1}^{2}z_{k} = \sum_{k_{1}=1}^{2}\sum_{k_{2}=1}^{2}z_{k_{1}}z_{k_{2}} = \sum_{k_{1}=1}^{2}\sum_{k_{2}=1}^{2} \prod_{i=1}^{2}z_{k_{i}} 
            .\end{align*}
            Which if we expand is
            \begin{align*}
                z_{1}z_{1} + z_{1}z_{2} + z_{2}z_{1} + z_{2}z_{2} = z_{1}^{2} + 2z_{1}z_{2} + z_{2}^{2} = (z_{1} + z_{2})^{2}
            .\end{align*}
            More generally,
            \begin{align*}
                (z_{1}+z_{2})^{n} = \prod_{i=1}^{n} \sum_{k=1}^{2}z_{k} = \sum_{k_{1}=1}^{2}\cdots \sum_{k_{n}=1}^{2} \prod_{i=1}^{n}z_{k_{i}}
            .\end{align*}
            Even more generally, 
            \begin{align*}
                (z_{1} + z_{2} + \dots + z_{m})^{n} = \prod_{i=1}^{n}\sum_{k=1}^{m}z_{k} = \sum_{k_{1}=1}^{m} \cdots \sum_{k_{n}=1}^{m} \prod_{i=1}^{n} z_{k_{i}} = \sum_{k_{1}, k_{2}, \dots, k_{n}} \prod_{i=1}^{n}z_{k_{i}}
            .\end{align*}
            Notice that this describes the distributive property.
            \bigbreak \noindent 
            Note that $\sum_{k_{1}, \dots k_{n}}$ is shorthand for $\sum_{k_{1}=1}^{m_{1}} \cdots \sum_{k_{n} = 1}^{m_{n}}$. Or, we can use the set-theoretic notation
            \begin{align*}
                \sum_{(k_{1}, \dots, k_{n}) \in \{1,\dots, m\}^{n}}
            \end{align*}
            to describe the shorthand. Note that $\{1,\dots, m\}^{n}$ means the Cartesian product $\{1,\dots, m\} \times \cdots \times \{1,\dots, m\}$, where a member of this set is an $n$-tuple $(k_{1}, \dots, k_{n})$, where $k_{i} \in \{1,\dots, m\} $.
        \item \textbf{Alternating function}: Let $V$ be a vector space, and let
            \begin{align*}
                f:\ V^{n} \to \mathbb{F}
            \end{align*}
            be a function of $n$ vector arguments. The function $f$ is called alternating if
            \begin{align*}
                f(v_{1}, \dots, v_{i}, \dots, v_{j}, \dots, v_{n}) = -f(v_{1}, \dots, v_{j}, \dots, v_{i}, \dots, v_{n})
            .\end{align*}
            That is, swapping any two inputs flips the sign of the output.
        \item \textbf{Multilinear alternating functions}: Consider a multilinear alternating function $f(v_{1}, \dots, v_{i}, \dots, v_{n}) $, if two arguments are equal, say $v_{j} = v_{i}$, then
            \begin{align*}
                f(v_{1}, \dots, v_{i}, \dots, v_{j}, \dots, v_{n}) &= f(v_{1}, \dots, v_{j}, \dots, v_{i}, \dots, v_{n}) \\
                                                                   &= f(v_{1}, \dots, v_{i}, \dots, v_{i}, \dots, v_{n})
            .\end{align*}
            Thus, $f = -f$ implies $f = 0$. So, when two arguments are equal, the function vanishes. 
            \bigbreak \noindent 
            \textbf{Note:} This is often taken as the definition of an alternating multilinear function $(f(v_{1}, \dots, v_{i}, \dots, v_{i}, \dots, v_{n})=0) $.
            \bigbreak \noindent 
            Suppose one argument is a linear combination of the others, let
            \begin{align*}
                v_{k}=\alpha_{1} v_{1} + \dots + \alpha_{k-1} v_{k-1}
            .\end{align*}
            Then,
            \begin{align*}
                f(v_{1}, \dots, v_{k}, \dots, v_{n}) &= f(v_{1}, \dots, \alpha_{1} v_{1} + \dots + \alpha_{k-1} v_{k-1}, \dots, v_{n}) \\
                                                     &= \sum_{i<k}f(v_{1}, \dots, v_{i}, \dots, v_{i}, \dots, v_{n}) = 0
            .\end{align*}
            Each term contains two equal arguments, so by alternation each term is zero. Hence the entire sum is zero.
            \bigbreak \noindent 
            Lastly, if $\sigma \in S_{n}$ is a permutation of the inputs, then
            \begin{align*}
                f(v_{\sigma(1)}, \dots, v_{\sigma(n)}) = \text{sgn}(\sigma)f(v_{1}, \dots, v_{n})
            .\end{align*}
            Since the $\text{sgn}(\sigma) = (-1)^{k}$, where $k$ is the number of swaps in the permutation.



        \item \textbf{Determinant as a function of the rows (or column)}:
            If you view the determinant as a function of the rows (or columns) of a matrix,
            \begin{align*}
                \det:\; \left(\mathbb{R}^{n}\right)^{n} \to \mathbb{R}, \quad (r_{1}, r_{2}, ... ,r_{n}) \mapsto \det(A)
            .\end{align*}
            The determinant $\det$ is \textbf{linear in each row}, scaling a row by $c$ multiplies the determinant by $c$. Replacing a row by a sum of two rows adds the corresponding determinants.
            \begin{align*}
                \det(r_1, \dots, c r_i, \dots, r_n) = c\,\det(r_1, \dots, r_i, \dots, r_n),
            .\end{align*}
            \begin{align*}
                \det(A) &= \det(r_1, \dots, r_i + r_k, \dots, r_k, \dots, r_n)  \\
                        &= \det(r_1, \dots, r_i, \dots, r_k, \dots, r_n) + \det(r_1, \dots, k_i, \dots, r_k, \dots, r_n).
            .\end{align*}
            It is also \textbf{alternating}: if two rows are equal, the determinant is $0$.
            \bigbreak \noindent 
            Because the determinant is multilinear, if you scale every row of $A$ by $\alpha$, you multiply the determinant by $\alpha$ once for each row:
            \begin{align*}
                \det(\alpha A) = \alpha^{n}\det(A)
            .\end{align*}
            Thus, the determinant function $\det$ is multilinear and alternating.

        \item \textbf{Symmetries of an object}:  A symmetry of an object means a transformation that rearranges its components while preserving their structure.
            \bigbreak \noindent 
            For a set with no additional structure, the only structure-preserving operations are permutations (bijections from the set to itself). Thus, the \textbf{symmetries} of a set are the permutations of the set.
        \item \textbf{The symmetric group $S_{n}$ and permutations}: Consider the set $\{1,2,...,n\} $, the symmetries of this set are its permutations. The collection of all such symmetries form the symmetric group $S_{n}$. For example, consider the set
            \begin{align*}
                \{1,2,3\}
            .\end{align*}
            The symmetries are  $(1,2,3), (1,3,2), (2,1,3), (2,3,1), (3,2,1), (3,1,2)$, there are exactly $3!$ symmetries. The collection of these symmetries form the set $S_{3}$,
            \begin{align*}
                S_{3} = \{(1,2,3), (1,3,2), (2,1,3), (2,3,1), (3,2,1), (3,1,2)\}
            .\end{align*}
            Every permutation in $S_{n}$ is a bijection $\sigma$, 
            \begin{align*}
                \sigma:\; \{1,2,...,n\} \to \{1,2,...,n\}
            ,\end{align*}
            where $\sigma(i)$ tells you which number $i$ is mapped to under the permutation
            \bigbreak \noindent 
            For example, the permutation $(1,3,2)$ in $S_{3}$. For this permutation, 
            \begin{align*}
                \sigma(1) = 1,\quad \sigma(2) = 3,\quad \sigma(3) = 2
            .\end{align*}
            The \textbf{identity} permutation is 
            \begin{align*}
                \sigma(i) = i
            .\end{align*}
        \item \textbf{Notation for permutations}: We can write a specific permutation as
            \begin{align*}
               \sigma = (\sigma(1), \sigma(2), ..., \sigma(n)) 
            .\end{align*}
            We may also name the permutations with subscripts, 
            \begin{align*}
                \sigma_{1},\; \sigma_{2},\; \cdots,\; \sigma_{n!}
            .\end{align*}
            In this case, we denote a specific permutation $\sigma_{k} \in S_{n}$ as
            \begin{align*}
                \sigma_{k} = (\sigma_{k}(1), \sigma_{k}(2), ..., \sigma_{k}(n))
            .\end{align*}
            Then, we can write $S_{n}$ as 
            \begin{align*}
                S_{n} = \{\sigma_{1}, \sigma_{2}, ..., \sigma_{n!}\}
            .\end{align*}
        \item \textbf{Transpositions and inversions}: A \textbf{Transposition} A transposition is a permutation that exchanges two elements and leaves the others fixed. A transposition is written as $(i\; j)$, which means swap $i$ and $j$. Consider $\{1,2,3\}$, the transposition $(1\; 3)$ means swap $1$ and $3$, so the permutation is
            \begin{align*}
                (3,2,1)
            .\end{align*}
            Any permutation can be written as a product of transpositions. For example, 
            \begin{align*}
                (3,1,2) = (1\; 3)(1\; 2)
            .\end{align*}
            First we swap $1$ and $3$, then we swap $1$ and $2$.
            \bigbreak \noindent 
            \textbf{Note:} For a given permutation, a decomposition into a product of transpositions is not unique, but the parity of the number of transpositions is unique. You can always insert extra "canceling" swaps or factor swaps differently.
            \bigbreak \noindent 
            For a permutation written as a list $(\sigma(1), \sigma(2),...,\sigma(n)) $, an \textbf{inversion} is a pair $(i,j)$ with $i < j$ but $\sigma(i) > \sigma(j) $
        \item \textbf{Sign of a permutation}: The sign (also called the parity or signature) of a permutation tells you whether the permutation is built from an even or odd number of swaps. 
            \begin{align*}
                \text{sgn}(\sigma) = \begin{cases}
                    +1 & \text{ if the permutation is even} \\     
                    -1 & \text{ if the permutation is odd}
                \end{cases}
            .\end{align*}
            Given any decomposition of a permutation $\sigma $ into transpositions,
            \begin{align*}
                \sigma = \tau_{1}\tau_{2} \cdots \tau_{k}
            ,\end{align*}
            where each $\tau_{i}$ is a transposition, the sign of $\sigma$ is 
            \begin{align*}
                \text{sgn}(\sigma) = (-1)^{k}
            .\end{align*}
            Similarly, the parity of a permutation can be determined by the number of inversions,
            \begin{align*}
                \text{sgn}(\sigma) = \begin{cases}
                    +1 & \text{ if the number of inversions is even} \\     
                    -1 & \text{ if the number of inversions is odd} \\     
                \end{cases}
            .\end{align*}
            \textbf{Note:} $S_{n}$ contains $n!$ permutations, if $n \geq 2$, then there are always $n!/2$ even permutations, and $n!/2$ odd permutations.
        \item \textbf{Composition of permutations}: A composition of permutations means performing one permutation after another. It is the way we "multiply" permutations, and it is the group operation in $S_{n}$
            \bigbreak \noindent 
            If $\sigma$ and $\tau$ are permutations of $\{1,2,\ldots,n\} $, then their composition is the permutation
            \begin{align*}
                (\tau \circ \sigma)(i) = \tau(\sigma(i))
            .\end{align*}
            For example, if $\sigma = (3,2,1)$, and $\tau = (2,3,1)$, then the composition $(\tau \circ \sigma)(i) = \tau(\sigma(i)) $ is the permutation
            \begin{align*}
                ((\tau \circ \sigma)(1), (\tau \circ \sigma)(2), (\tau \circ \sigma)(3))   = (\tau(\sigma(1), \tau(\sigma(2), \tau(\sigma(3))))) &= (\tau(3), \tau(2), \tau(1))  \\
                &= (1,3,2)
            .\end{align*}
            We can write the composition $(\tau \circ \sigma)(i) = \tau(\sigma(i))$ simply as $\tau\sigma $. Both refer to $\tau $ composed with $\sigma$.
        \item \textbf{Sign of a composition of permutations}: Let $\sigma, \tau \in S_{n}$. Suppose $\sigma$ can be written as a product of $k$ transpositions and $\tau$ as a product of $\ell$ transpositions, where $k$ and $\ell$ are taken modulo 2 (Since transpositions are not unique, but the parity in the number of transpositions is). Then
            \begin{align*}
                \text{sgn}(\sigma) = (-1)^{k},\quad  \text{sgn}(\tau) = (-1)^{\ell}
            .\end{align*}
            So,
            \begin{align*}
                \sigma &= \pi_{1}\pi_{2} \cdots \pi_{k}, \\
                \tau &= \hat{\pi}_{1}\hat{\pi}_{2} \cdots \hat{\pi}_{\ell}
            .\end{align*}
            Then, the composition 
            \begin{align*}
                \sigma \circ \tau = \sigma \tau 
            \end{align*}
            can be constructed by combining the transpositions,
            \begin{align*}
                \sigma \circ \tau = \sigma \tau =  \pi_{1}\pi_{2} \cdots \pi_{k} \hat{\pi}_{1}\hat{\pi}_{2} \cdots \hat{\pi}_{\ell}
            .\end{align*}
            Thus,
            \begin{align*}
                \text{sgn}(\sigma \circ \tau) = (-1)^{k+\ell} = (-1)^{k}(-1)^{\ell} = \text{sgn}(\sigma)\text{sgn}(\tau)
            .\end{align*}

        \item \textbf{The inverse of a permutation}: Consider a permutation $\sigma$, we want a permutation $\tau $ such that
            \begin{align*}
                \tau(\sigma(i)) = \sigma(\tau(i)) = i
            ,\end{align*}
            where $i$ is the identity permutation $i(i) = i $. If $\sigma(i) = j$, then we require $\tau(\sigma(i)) = i$, so $\tau(i) = j$, where  $\sigma(j) = i$. For example, if $\sigma = (3,1,2)$, then
            \begin{align*}
                \sigma(1) &= 3 \\
                \sigma(2) &= 1 \\
                \sigma(3) &= 2
            .\end{align*}
            Thus, $\tau = (2,3,1)$, since $\sigma(2) = 1,\; \sigma(3) = 2$, and $\sigma(1) = 3$. Observe that
            \begin{align*}
                (\tau \circ \sigma)(i) &= \tau(\sigma(i)) = (\tau(\sigma(1)), \tau(\sigma(2)), \tau(\sigma(3))) = (\tau(3), \tau(1), \tau(2)) = (1,2,3), \\
                (\sigma \circ \tau)(i) &= \sigma(\tau(i)) = (\sigma(\tau(1)), \sigma(\tau(2)), \sigma(\tau(3))) = (\sigma(2), \sigma(3), \sigma(1)) = (1,2,3)
            .\end{align*}
            Thus, $\tau = \sigma^{-1} $
        \item \textbf{Sign of the inverse permutation}: Let $\sigma \in S_{n}$, and $\sigma^{-1} \in S_{n}$ be the inverse of $\sigma$. Then,
            \begin{align*}
                \sigma \sigma^{-1} = i
            ,\end{align*}
            Where $i$ is the identity permutation, $i(i) = i$. Notice that the sign of the identity permutation is $+1$. So,
            \begin{align*}
                \sigma \sigma^{-1} = i \implies \text{sgn}(\sigma \sigma^{-1}) = \text{sgn}(i) = 1 \implies \text{sgn}(\sigma^{-1}) = \frac{1}{\text{sgn}(\sigma)}
            .\end{align*}
            Notice that $\text{sgn}(\sigma) \in \{\pm 1\} $. If $\text{sgn}(\sigma) = 1$, then 
            \begin{align*}
                \text{sgn}(\sigma^{-1}) = \frac{1}{1} = 1 = \text{sgn}(\sigma)
            .\end{align*}
            If $\text{sgn}(\sigma) = -1$, then
            \begin{align*}
                \text{sgn}(\sigma^{-1}) = \frac{1}{-1} = -1 = \text{sgn}(\sigma)
            .\end{align*}
            In either case, $\text{sgn}(\sigma^{-1}) = \text{sgn}(\sigma)$.
        \item \textbf{Inversion map}: Let $S_{n}$ be the set of all permutations over $\{1,\dots, n\}$, define the map
            \begin{align*}
                \Phi:\; S_{n} \to S_{n}, \quad \Phi(\sigma) = \sigma^{-1}
            .\end{align*}
            Suppose that $\Phi(\sigma_{1}) = \Phi(\sigma_{2})$, then
            \begin{align*}
                \sigma^{-1}_{1} = \sigma^{-1}_{2}
            .\end{align*}
            If we take the inverse of both sides,
            \begin{align*}
                \left(\sigma_{1}^{-1}\right)^{-1} = \left(\sigma_{2}^{-1}\right)^{-1} \implies \sigma_{1} = \sigma_{2}
            .\end{align*}
            Thus,
            \begin{align*}
                \Phi(\sigma_{1}) = \Phi(\sigma_{2}) \implies \sigma_{1} = \sigma_{2}
           ,\end{align*}
           so $\Phi$ is injective. Next, let $\tau \in S_{n}$, we require $\sigma \in S_{n}$ such that $\Phi(\sigma) = \tau$. Choose $\sigma = \tau^{-1}$, then
           \begin{align*}
               \Phi(\sigma) = \sigma^{-1} = \left(\tau^{-1}\right)^{-1} = \tau
           .\end{align*}
           So, every $\tau \in S_{n}$ is hit by its inverse, and $\Phi$ is surjective.
           \bigbreak \noindent 
           Since $\Phi$ is both injective and surjective, $\Phi$ is a bijection of $S_{n}$.

        \item \textbf{Parity decomposition of $S_{n}$}: Consider the set $S_{n}$, every even $\sigma \in S_{n}$ pairs with a permutation of opposite parity. Thus, for any $n \geq 2$, there are exactly $n!/2$ even permutations, and $n!/2$ odd permutations.
            \bigbreak \noindent 
            Pick any odd permutation $\tau$. The simplest choice is a transposition (a swap), since transpositions are always odd permutations. Let $\tau =(1\; 2) $. Now, define a mapping 
            \begin{align*}
                f:\; S_{n} \to S_{n}, \quad f(\sigma) = \tau \sigma
            .\end{align*}
            This mapping has two crucial properties
            \begin{enumerate}
                \item Bijective
                \item It flips parity 
                    \begin{align*}
                        \text{sgn}(f(\sigma)) = - \text{sgn}(\sigma)
                    .\end{align*}
            \end{enumerate}
            Because composition with a fixed permutation always has an inverse, $f(\sigma)$ is a bijection. Given $f(\sigma) = \tau \sigma$, we can recover $\sigma$ by multiplying by $\tau^{-1} $
            \begin{align*}
                f(\sigma) = \tau \sigma \implies \sigma = \tau^{-1}f(\sigma)
            .\end{align*}
            Thus, $f$ is bijective. Furthermore, notice that
            \begin{align*}
                \text{sgn}(\tau \sigma) = \text{sgn}(tau)\text{sgn}(\sigma) = (-1)\text{sgn}(\sigma)
            .\end{align*}
            Recall that $\tau$ is odd, so $\text{sgn}(\tau) = -1$. So, we see that $f(\sigma)$ flips the parity. Thus, $f(\sigma)$ is odd when $\sigma$ is even, and even when $\sigma$ is odd.
            \bigbreak \noindent 
            Because $f$ is a bijection from $S_{n}$ to itself, maps odd permutations to even permutations, and even permutations to odd permutations, it must be that the number of even permutations in $S_{n}$ matches the number of odd permutations in $S_{n}$ and that number is precisely $n!/2 $
            \bigbreak \noindent 
            As an example, consider $S_{3}$. There are exactly $3! = 6$ permutations, with $6 / 2 = 3$ of them being odd, and $6/2 = 3$ of them being even. If we generate all the odd permutations by making one swap, then we can generate the remaining three even permutations by defining the bijection $f(\sigma) = \tau \sigma$, where $\tau = (1\; 2)$ is an odd transposition. Let $\sigma_{o}$ be the set of odd permutations,
            \begin{align*}
                \sigma_{o} = \{(2,1,3),\; (3,2,1),\; (1,3,2)\}
            .\end{align*}
            Then, 
            \begin{align*}
                f(2,1,3) &= (1\; 2)(2,1,3) = (1,2,3) \\
                f(3,2,1) &= (1\; 2)(3,2,1) = (2,3,1) \\
                f(1,3,2) &= (1\; 2)(1,3,2) = (3,1,2) 
            .\end{align*}
            So,
            \begin{align*}
                S_{n}=\{(2,1,3),\; (3,2,1),\; (1,3,2),\; (1,2,3),\; (2,3,1),\; (3,1,2)\}
            .\end{align*}


            

        \item \textbf{$S_{n}$ on the dimensions of a matrix}: Consider $A \in \mathbb{R}^{n\times n}$, $\sigma \in S_{n} $ tells us how to choose an element from each row. For example, in $S_{3}$ if $\sigma_{1} = (\sigma_{1}(1), \sigma_{1}(2), \sigma_{1}(3)) = (3,2,1)$,
            \begin{align*}
                \sigma_{1}(1) = 3 \quad \text{(choose the element in row 1 column 3)}\\
                \sigma_{1}(2) = 2 \quad \text{(choose the element in row 1 column 2)} \\
                \sigma_{1}(3) = 1 \quad \text{(choose the element in row 1 column 1)}
            .\end{align*}
            Furthermore, $\sigma_{1} = (3,2,1) = (1\; 3)$, so $\text{sgn}(\sigma_{1}) = -1$.
            \bigbreak \noindent 
            $\sigma(i) = j$ says from the $i^{\text{th}}$ row, choose the element in the $j^{\text{th}} $ column. The collection of all permutations $S_{n}$ tells us all the ways of choosing an element from each row.
            \bigbreak \noindent 
            Because permutations are bijections, they guarantee
            \begin{itemize}
                \item each row gets one column,
                \item each column is used exactly once.
            \end{itemize}
        \item \textbf{Geometry of linear transformations and the determinant}: Consider a $1\times 1$ matrix, which is just a number $A = (a) $. It acts on one dimensional vectors (numbers) by multiplication,
            \begin{align*}
                Ax = ax
            .\end{align*}
            It is a linear map from $\mathbb{R}$ to $\mathbb{R}$. In 1-dimensional space, the only shape is a line. The unit segment is $[0,1]$, with length 1.
            \bigbreak \noindent 
            A vector $x \in \mathbb{R}$ is a segment $[0,x]$ with length $\left\lvert x \right\rvert $. A transformation $Ax$ on a vector $x \in \mathbb{R}$, where $A = (a)$ scales $x$ by a, so
            \begin{align*}
                [0,x] \mapsto [0,ax]
            .\end{align*}
            Thus, the length is scaled by $a$. $\left\lvert x \right\rvert \mapsto \left\lvert ax \right\rvert = \left\lvert a \right\rvert \cdot \left\lvert x \right\rvert$. Thus, the transformation scales lengths by $\left\lvert a \right\rvert $.
            \bigbreak \noindent 
            The determinant of this transformation $\det(A)$ is $a$. So,
            \begin{align*}
                \text{length after transformation } = \left\lvert \det(A) \right\rvert \cdot \text{length before transformation}
            .\end{align*}
            If 
            \begin{itemize}
                \item $a>0$, the map stretches/compresses without reversing orientation.
                \item $a<0$, the map reflects the line (flips orientation)
            \end{itemize}
            This parallels the 2D and 3D cases
            \begin{itemize}
                \item $\mathbf{\text{\textbf{det}} > 0}$: Orientation preserved.
                \item $\mathbf{\text{\textbf{det}} < 0}$: Orientation reversed.
            \end{itemize}
            In the $2\times 2$ case, $A \in \mathbb{R}^{2\times 2} $ scales area. 
            \bigbreak \noindent 
            Any parallelogram in the plane is determined by two vectors. 
            \begin{align*}
                v_{1},\; v_{2} \in \mathbb{R}^{2}
            .\end{align*}
            Take any point $P$ in the plane, one side extends from $P$ in the direction of $v_{1}$, the adjacent side extends from $P$ in the direction of $v_{2}$, and opposite sides run parallel. Any other geometric shape can be approximated by many tiny parallelograms, which is why understanding just parallelograms is enough to understand how a transformation scales area.
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{shapes}
                \label{fig:shapes}
            \end{figure}
            \bigbreak \noindent 
            $A\in \mathbb{R}^{2\times 2}$ sends each vector to a new vector
            \begin{align*}
                Av_{1},\quad Av_{2}
            .\end{align*}
            So the original parallelogram becomes a new parallelogram with sides
            \begin{itemize}
                \item $v_{1}^{\prime}  = Av_{1}$
                \item $v_{2}^{\prime}  = Av_{2}$
            \end{itemize}
            So the matrix transforms the shape by transforming the vectors that define it.
            \bigbreak \noindent 
            For two vectors $v_{1}, v_{2} \in \mathbb{R}^{2}$, the area of the parallelogram $P$, $\mathcal{A}(P)$, spanned by $v_{1}$ and $v_{2}$ is given by
            \begin{align*}
                \mathcal{A}(P) = \left\lvert \det\begin{pmatrix} x_{1} & x_{2} \\ y_{1} & y_{2} \end{pmatrix} \right\rvert
            .\end{align*}
            If $v_{1}^{\prime},v_{2}^{\prime}$ are the vectors transformed by $A$, where 
            \begin{align*}
                A = \begin{pmatrix} a & b \\ c & d \end{pmatrix},\; v_{1}^{\prime} = \begin{pmatrix} ax_{1} + by_{1} \\ cx_{1} + dy_{1} \end{pmatrix},\; v_{2}^{\prime} = \begin{pmatrix} ax_{2} + by_{2} \\ cx_{2} + dy_{2} \end{pmatrix}
            ,\end{align*}
            then the area of the parallelogram $P^{\prime}$ after $A$s effect is
            \begin{align*}
                \mathcal{A}(P^{\prime}) &= \left\lvert \det\begin{pmatrix} ax_{1} + by_{1} & ax_{2} + by_{2} \\ cx_{1} + dy_{1} & cx_{2} + dy_{2} \end{pmatrix}\right\rvert = \left\lvert \det \left(\begin{pmatrix} a & b \\ c & d \end{pmatrix} \begin{pmatrix} x_{1} & x_{2} \\ y_{1} & y_{2} \end{pmatrix}\right) \right\rvert \\
                                                                                  &= \left\lvert \det \begin{pmatrix} a & b \\ c & d \end{pmatrix}  \det \begin{pmatrix} x_{1} & x_{2} \\ y_{1} & y_{2} \end{pmatrix}\right\rvert = \left\lvert \det \begin{pmatrix} a & b \\ c & d \end{pmatrix}\right\rvert  \left\lvert \det \begin{pmatrix} x_{1} & x_{2} \\ y_{1} & y_{2} \end{pmatrix} \right\rvert \\
                                                                                  &= \left\lvert \det(A) \right\rvert \mathcal{A}(P)
            .\end{align*}
            Thus, in 2-space, the determinant of $A$ tells us how much the area of the parallelogram $P$ spanned by two vectors $v_{1}$ and $v_{2}$ is scaled when $v_{1}$ and $v_{2}$ are transformed by $A$.
            \bigbreak \noindent 
            Similarly, for three vectors $v_{1}, v_{2}, v_{3} \in \mathbb{R}^{3}$ that define a parallelepiped $P$, with
            \begin{align*}
                v_{1} = \begin{pmatrix} x_{1} \\ y_{1} \\ z_{1} \end{pmatrix}, v_{2} = \begin{pmatrix} x_{2} \\ y_{2} \\ z_{2} \end{pmatrix}, v_{3} = \begin{pmatrix} x_{3} \\ y_{3} \\ z_{3} \end{pmatrix}
            ,\end{align*}
            the volume of the $P $ is given by
            \begin{align*}
                \mathcal{V}(P) = \det\begin{pmatrix} x_{1} & x_{2} & x_{3} \\ y_{1} & y_{2} & y_{3} \\ z_{1} & z_{2} & z_{3} \\ \end{pmatrix}
            .\end{align*}
            Let $A \in \mathbb{R}^{3\times 3}$ be a linear transformation, 
            \begin{align*}
                A = \begin{pmatrix} a & b & c \\ d & e & f \\ g & h & i \end{pmatrix}
            .\end{align*}
            Then, $A$ scales $P$ by acting on the vectors $v_{1}, v_{2}$ and $v_{3}$. Call the scaled parallelepiped $P^{\prime}$ with defining sides
            \begin{align*}
                v_{1}^{\prime} = Av_{1},\quad v_{2}^{\prime} = Av_{2},\quad v_{3}^{\prime} = Av_{3}
            .\end{align*}
            The new volume is given by
            \begin{align*}
                \mathcal{V}(P^{\prime}) &= \left\lvert  \det\left(\begin{bmatrix} Av_{1} & Av_{2} & Av_{3} \end{bmatrix}\right)\right\rvert = \left\lvert  \det\left(\begin{pmatrix} a & b & c \\ d & e & f \\ g & h & i \end{pmatrix}\begin{pmatrix} x_{1} & x_{2} & x_{3} \\ y_{1} & y_{2} & y_{3} \\ z_{1} & z_{2} & z_{3} \\ \end{pmatrix}\right) \right\rvert\\
                                                                           &= \left\lvert  \det(A) \det\begin{pmatrix} x_{1} & x_{2} & x_{3} \\ y_{1} & y_{2} & y_{3} \\ z_{1} & z_{2} & z_{3} \\ \end{pmatrix} \right\rvert = \left\lvert  \det(A) \right\rvert \mathcal{V}(P)
            .\end{align*}
            Thus, in 3-space, the determinant of $A$ tells us how much the volume of the parallelepiped spanned by $v_{1}, v_{2}$ and $v_{3}$ is scaled when $v_{1}, v_{2}$, and $v_{3}$ are transformed by $A$. Just like in 1-space and 2-space.
            \bigbreak \noindent 
            The pattern we have developed in dimensions 1, 2, and 3 generalizes cleanly and conceptually to $n$-\textbf{dimensional space}. The key point is that the determinant always measures how a linear transformation scales $n$-\textbf{dimensional volume}.
            \bigbreak \noindent 
            Let $A \in \mathbb{R}^{n\times n}$ be a linear transformation, and let
            \begin{align*}
                v_{1}, v_{2}, \dots, v_{n} \in \mathbb{R}^{n}
            \end{align*}
            be vectors that define an $n$-dimensional parallelepiped $P$. Define the matrix $V$ whose columns define the edges of $P$,
            \begin{align*}
                V = \begin{bmatrix} v_{1} & v_{2} & \cdots & v_{n} \end{bmatrix} \in \mathbb{R}^{n\times n}
            .\end{align*}
            The transformation $A$ acts by sending each edge to 
            \begin{align*}
                v_{i}^{\prime} = Av_{i}
            .\end{align*}
            The transformed parallelepiped $P^{\prime}$ is defined by the columns of 
            \begin{align*}
                AV = \begin{bmatrix} Av_{1} & Av_{2} & \cdots & Av_{n} \end{bmatrix}
            .\end{align*}
            In $\mathbb{R}^{n}$, the volume of the $n$-dimensional parallelepiped spanned by $v_{1}, v_{2}, \cdots, v_{n} $ is
            \begin{align*}
                \mathcal{V}(P) = \left\lvert \det(V) \right\rvert
            .\end{align*}
            Which, 
            \begin{itemize}
                \item reduces to length in 1D,
                \item area in 2D,
                \item volume in 3D,
                \item and gives the correct  $n$-dimensional volume in general.
            \end{itemize}
            The volume of the transformed parallelepiped is
            \begin{align*}
                \mathcal{V}(P^{\prime}) = \left\lvert \det(AV) \right\rvert
            .\end{align*}
            Using the multiplicativity of determinants,
            \begin{align*}
                \det(AV) = \det(A)\det(V)
            .\end{align*}
            Taking absolute values,
            \begin{align*}
                \mathcal{V}(P^{\prime}) = \left\lvert \det(A)\det(V) \right\rvert = \left\lvert \det(A) \right\rvert \mathcal{V}(P)
            .\end{align*}
            Thus,
            \begin{align*}
                \text{For } A \in \mathbb{R}^{n\times n},\quad \mathcal{V}(Av_{1},\dots, Av_{n}) = \left\lvert \det(A) \right\rvert \mathcal{V}(v_{1}, \dots, v_{n})
            .\end{align*}
            That is, The determinant of $A$ is the factor by which $A$ scales $n$-dimensional volume.
            \begin{itemize}
                \item If $\det(A)>0$, orientation is preserved.
                \item If $\det(A)<0$, orientation is reversed.
                \item If $\det(A)=0$, all $n$-dimensional volumes collapse to zero (the image lies in a lower-dimensional subspace)
            \end{itemize}
            The determinant is the unique multilinear, alternating function that measures how a linear transformation scales oriented $n$-dimensional volume.
        \item \textbf{Properties of volume}: Let $v_{1}, v_{2}, \dots, v_{k} \in \mathbb{R}^{n}$ be the edge vectors of a $k$-dimensional parallelepiped embedded in the ambient space $\mathbb{R}^{n}$. Note that $k \leq n$.
            \bigbreak \noindent 
            The volume of the $k$-dimensional shape is given by
            \begin{align*}
                \mathcal{V}(v_{1}, \dots, v_{k}) = \sqrt{\det\left(\text{Gram}(v_{1},\dots, v_{k})\right)}
            ,\end{align*}
            where
            \begin{align*}
                G = \text{Gram}(v_{1}, \dots, v_{k}) = (v_{i}^{T}v_{j})_{i,j=1}^{k} =
                \begin{pmatrix} 
                    v_{1}^{T}v_{1} & \cdots & v_{1}^{T}v_{k} \\
                    \vdots & \ddots & \vdots \\
                    v_{k}^{T}v_{1} & \cdots & v_{k}^{T}v_{k} \\
                \end{pmatrix} \in \mathbb{R}^{k\times k}
            .\end{align*}
            Suppose we scale one of the edge vectors $v_{i} \to \lambda v_{i} = v_{i}^{\prime}$, for $\lambda \in \mathbb{R} $. Notice what happens to $v_{i}^{\prime T}v_{j}$
            \begin{align*}
                v_{i}^{\prime T}v_{i}^{\prime} &= \norm{v_{i}^{\prime}}_{2}^{2} = \norm{\lambda v_{i}}_{2}^{2} = \norm{\lambda v_{i}}_{2} \norm{\lambda v_{i}}_{2} = \lambda^{2} \norm{v_{i}}_{2}^{2}, \\
                v_{i}^{\prime T}v_{j} &= \lambda v_{i}^{T}v_{j}
            .\end{align*}
            So,
            \begin{align*}
                G^{\prime} = \text{Gram}(v_{1}, \dots, v_{i}^{\prime}, \dots, v_{k}) = \begin{pmatrix} 
                    v_{1}^{T}v_{1} & \cdots & \lambda v_{1}^{T}v_{i} & \cdots & v_{1}^{T}v_{k} \\
                    \vdots & \ddots &  \vdots & \vdots & \vdots \\
                    \lambda v_{i}^{T}v_{1} & \cdots  & \lambda^{2} v_{i}^{T}v_{i} & \cdots  & \lambda v_{i}^{T}v_{k} \\
                    \vdots & \vdots & \vdots & \ddots  & \vdots \\
                    v_{k}^{T}v_{1} & \cdots & \lambda v_{k}^{T}v_{i} & \cdots & v_{k}^{T}v_{k} \\
                \end{pmatrix}
            .\end{align*}
            Notice that one row and one column are scaled by $\lambda$, so
            \begin{align*}
               \det(G^{\prime}) = \lambda^{2} \det(G)
            .\end{align*}
            Which implies
            \begin{align*}
                \mathcal{V}^{\prime} = \mathcal{V}(v_{1}, \dots, v_{i}^{\prime}, \dots, v_{k}) = \sqrt{\lambda^{2} \det(G)} = \left\lvert \lambda \right\rvert\mathcal{V}(v_{1}, \dots, v_{k})
            .\end{align*}
            When an edge vector is replaced by a linear combination, $v_{i} = u_{1} + u_{2}$, 
            \begin{align*}
                \mathcal{V}(v_{1}, \dots, v_{i}, \dots, v_{k}) = \mathcal{V}(v_{1}, \dots, u_{1}, \dots, v_{k}) + \mathcal{V}(v_{1}, \dots, u_{2}, \dots, v_{k})
            .\end{align*}
            Lastly, volume is alternating, swapping two edge vectors swaps the sign of the oriented volume.

        \item \textbf{The goal of the determinant}: The determinant of an $n\times n$ matrix is a single number that measures How the linear transformation encoded by the matrix scales oriented volume
            \begin{itemize}
                \item A $1\times 1$ matrix scales length.
                \item A $2\times 2$ matrix scales area.
                \item A $3\times 3$ matrix scales volume.
            \end{itemize}
            Thus, we need a function that given the edge vectors of a $n$-dimensional parallelepiped, outputs the volume. And, given a linear transformation, outputs the scaling factor of the transformed parallelepiped when the linear transformation acts on the edge vectors of the solid.
        \item \textbf{The Leibniz formula for the determinant}: Let $A = (a_{ij})$ be an $n\times n$ matrix. We want a function $\det(A) $ with certain properties. Specifically, we want
            \begin{enumerate}
                \item Linear in each row
                \item Alternating (swapping rows changes the sign)
                \item Normalized so $\det(I) = 1 $
            \end{enumerate}
            The core idea is to choose on entry per row and per column. A determinant term must use
            \begin{itemize}
                \item One entry from row 1,
                \item One entry from row 2,
                \item $\cdots$
                \item One entry from row $n$.
            \end{itemize}
            But, you cannot reuse a column, the order of column choices must matter. Thus, the correct way to index the choices is 
            \begin{align*}
                \text{choose column $\sigma(i)$ for row $i$}
            ,\end{align*}
            where $\sigma$ is permutation. Because permutations are bijections, they guarantee
            \begin{itemize}
                \item Each row gets one column,
                \item Each column is used exactly once.
            \end{itemize}
            There are $n!$ such choices, which is precisely the size of $S_{n}$.
            \bigbreak \noindent 
            For a given permutation $\sigma$, consider the product 
            \begin{align*}
                \prod_{i=1}^{n}a_{i,\sigma(i)} 
            .\end{align*}
            This is the product of the entries chosen by the pattern $\sigma$. For example, in $S_{3}$, if $\sigma_{1} = (3,2,1)$, then 
            \begin{align*}
                \prod_{i=1}^{3}a_{i,\sigma_{1}(i)} = a_{13}a_{22}a_{31}
            .\end{align*}
            Each permutation $\sigma_{k} \in S_{n}$ gives one such product. There are exactly $n!$ products.
            \bigbreak \noindent 
            Now, to get the determinant, we need to sum these products, but also include the sign of the permutation. The determinant of a square matrix $A \in \mathbb{R}^{n\times n}$ is given by
            \begin{align*}
                \det(A) = \sum_{\sigma \in S_{n}} \text{sgn}(\sigma)\prod_{i=1}^{n}a_{i,\sigma(i)}
            .\end{align*}
            If we did not include the sign of the permutation, this would force
            \begin{itemize}
                \item matrices with two equal rows to have nonzero determinant (incorrect),
                \item row-swapping to leave determinant unchanged (incorrect),
                \item multiplicativity to fail.
            \end{itemize}
            So we need something that makes the sum change sign whenever two rows are swapped.
            \bigbreak \noindent 
            Swapping two rows reverses the order of multiplication in each term. If the original product was
            \begin{align*}
                a_{i,\sigma(i)}a_{j,\sigma(j)}
            ,\end{align*}
            then after swapping rows $i$ and $j$, the product becomes
            \begin{align*}
                a_{j,\sigma(j)}a_{i,\sigma(i)}
            .\end{align*}
            This corresponds to replacing each permutation $\sigma$ by a new permutation
            \begin{align*}
                (i\; j)\sigma                
            .\end{align*}
            Where $(i\; j)$ is a transposition. Since a transposition flips the parity of a permutation,
            \begin{align*}
                \text{sgn}((i\; j)\sigma) = -\text{sgn}(\sigma)
            .\end{align*}
            This is exactly the behavior needed for the determinant.
        \item \textbf{Determinant identity}: Let $v_{1}, v_{2},\dots, v_{n} \in \mathbb{R}^{n}$. Define $A = \begin{bmatrix} v_{1} & v_{2} & \cdots & v_{n} \end{bmatrix} \in \mathbb{R}^{n\times n}$. Recall the Gram matrix
            \begin{align*}
                G = (v_{i}^{T}v_{j})_{i,j=1}^{n} = A^{T}A
            .\end{align*}
            So,
            \begin{align*}
                \det(G) = \det(A^{T}A) = \det(A^{T})\det(A) = \left(\det(A)\right)^{2}
            .\end{align*}
            Thus,
            \begin{align*}
                \left(\det(v_{1}, \dots, v_{n})\right)^{2} = 
                \det\begin{pmatrix} 
                    v_{1}^{T}v_{1} & v_{1}^{T}v_{2} & \cdots & v_{1}^{T}v_{n}  \\
                    v_{2}^{T}v_{1} & v_{2}^{T}v_{2} & \cdots & v_{2}^{T}v_{n}  \\
                    \vdots & \vdots & \ddots & \vdots \\
                    v_{n}^{T}v_{1} & v_{n}^{T}v_{2} & \cdots & v_{n}^{T}v_{n}  \\
                \end{pmatrix}
            .\end{align*}
        \item \textbf{Determinant of the transpose}: Suppose $A \in \mathbb{R}^{n\times n}$, then $A^{T} \in \mathbb{R}^{n\times n}$, and
            \begin{align*}
                \det(A^{T}) &= \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \prod_{i=1}^{n}(A^{T})_{i,\sigma(i)} = \sum_{\sigma \in S_{n}}\text{sgn}(\sigma) \prod_{i=1}^{n} a_{\sigma(i), i}
            .\end{align*}

        \item \textbf{Efficient determinants}: Consider the Leibniz determinant formula. For $A \in \mathbb{R}^{n\times n} $
            \begin{align*}
                \det(A) = \sum_{\sigma \in S_{n}}\text{sgn}(\sigma)\prod_{i=1}^{n}a_{i, \sigma(i)}
            .\end{align*}
            There are exactly
            \begin{align*}
                nPn = \frac{n!}{(n-n)!} = n!
            \end{align*}
            permutations in $S_{n} $, and for each permutation we take the product of $n$ terms in $A$. Thus, using this formula requires
            \begin{align*}
                n \cdot n!
            \end{align*}
            flops. Instead, we can compute the $LU$ decomposition $PA = LU$, which requires roughly $\frac{2}{3}n^{3} + \mathcal{O}(n^{2}) $ flops. Then,
            \begin{align*}
                PA = LU \implies A = P^{T}LU
            .\end{align*}
            Where $P$ is a permutation matrix, $L$ is unit lower triangular, and $U$ is upper triangular. So,
            \begin{align*}
                \det(A) = \det(P^{T}LU) = \det(P^{T})\det(L)\det(U)
            .\end{align*}
            Notice that since $P$ is a permutation matrix, which is just $I$ after $k$ row swaps, $\det(P^{T}) = \det(P) = \pm 1 $. Also, $L$ is unit lower triangular, so
            \begin{align*}
                \det(L) = \prod_{i=1}^{n} \ell_{ii} = 1
            ,\end{align*}
            since $\ell_{ii} = 1 $ for $i=1,\dots, n$. Thus,
            \begin{align*}
               \det(A) = \text{sgn}(P) \det(U)  = \text{sgn}(P)\prod_{i=1}^{n} u_{ii}
            .\end{align*}
            Note that if $P$ is obtained from the identity by $k$ row swaps, then
            \begin{align*}
                \text{sgn}(P) = (-1)^{k}
            .\end{align*}
            Thus, computing the determinant in this way requires only
            \begin{align*}
                \frac{2}{3}n^{3} + n + \mathcal{O}(n^{2}) \approx \frac{2}{3}n^{3} = \mathcal{O}(n^{3})
            \end{align*}
            flops. If $LU$ is already known, the determinant can be found in only $n$ flops.








    \end{itemize}

    \pagebreak 
    \subsubsection{Determinant proofs}
    \begin{itemize}
        \item \textbf{Multiplicative Property of Determinants}: Suppose $A,B\in \mathbb{R}^{n\times n}$, then $\det(AB) = \det(A)\det(B) $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A,B \in \mathbb{R}^{n\times n}$, then
            \begin{align*}
                \det(AB) = \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \prod_{i=1}^{n} (AB)_{i, \sigma(i)}
            .\end{align*}
            But, by matrix multiplication, 
            \begin{align*}
                (AB)_{i, \sigma(i)}  = \sum_{k=1}^{n} a_{ik}b_{k,\sigma(i)}
            .\end{align*}
            So,
            \begin{align*}
                \det(AB) = \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \prod_{i=1}^{n} (AB)_{i, \sigma(i)} = \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \prod_{i=1}^{n} \sum_{k=1}^{n}a_{ik}b_{k,\sigma(i)}
            .\end{align*}
            Since ordinary multiplication is multilinear, we can use the expansion property. Thus,
            \begin{align*}
                \prod_{i=1}^{n}\sum_{k=1}^{n} = \sum_{k_{1} = 1}^{n} \cdots \sum_{k_{n} = 1}^{n} \prod_{i=1}^{n} a_{ik_{i}}b_{k_{i}, \sigma(i)} = \sum_{k_{1}, \dots, k_{n}} \prod_{i=1}^{n} a_{ik_{i}}b_{k_{i}, \sigma(i)}
            ,\end{align*}
            where $(k_{1}, \dots, k_{n}) \in \{1,\dots,n\}^{n}$. Thus,
            \begin{align*}
                \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \prod_{i=1}^{n} \sum_{k=1}^{n}a_{ik}b_{k,\sigma(i)} = \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \sum_{k_{1}, \dots, k_{n}} \prod_{i=1}^{n}a_{ik_{i}}b_{k_{i}, \sigma(i)}
            .\end{align*}
            Notice that we can split the product, $\prod_{i=1}^{n}a_{ik_{i}}b_{k_{i}, \sigma(i)} = \prod_{i=1}^{n}a_{ik_{i}}\prod_{i=1}b_{k_{i}, \sigma(i)}$. So,
            \begin{align*}
                \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \sum_{k_{1}, \dots, k_{n}} \prod_{i=1}^{n}a_{ik_{i}}b_{k_{i}, \sigma(i)} = \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \sum_{k_{1}, \dots, k_{n}} \prod_{i=1}^{n}a_{ik_{i}} \prod_{i=1}^{n}b_{k_{i}, \sigma(i)}
            .\end{align*}
            Now, since we are summing a finite number of terms, we can interchange the sums
            \begin{align*}
                \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \sum_{k_{1}, \dots, k_{n}} \prod_{i=1}^{n}a_{ik_{i}} \prod_{i=1}^{n}b_{k_{i}, \sigma(i)} =  \sum_{k_{1}, \dots, k_{n}} \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \prod_{i=1}^{n}a_{ik_{i}} \prod_{i=1}^{n}b_{k_{i}, \sigma(i)}
            .\end{align*}
            But, notice that $\prod_{i=1}^{n}a_{ik_{i}} $ does not depend on $\sigma$. So, we can move it outside the sum
            \begin{align*}
                \sum_{k_{1}, \dots, k_{n}} \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \prod_{i=1}^{n}a_{ik_{i}} \prod_{i=1}^{n}b_{k_{i}, \sigma(i)} =  \sum_{k_{1}, \dots, k_{n}} \left(\prod_{i=1}^{n}a_{ik_{i}}\right) \sum_{\sigma \in S_{n}} \text{sgn}(\sigma)  \prod_{i=1}^{n}b_{k_{i}, \sigma(i)}
            .\end{align*}
            Now the structure is becoming clear. Let's consider an iteration of the outer sum. So, fix an index tuple $(k_{1}, \dots, k_{n}) $, which is a permutation of the indices in the long form
            \begin{align*}
                \sum_{k_{1} = 1}^{n} \sum_{k_{2} =1}^{n} \cdots \sum_{k_{n} =1}^{n}
            .\end{align*}
            Now, this index tuple is fixed for all iterations of the inner sum, so this index tuple is used for all $\sigma \in S_{n}$. If two indices coincide, say $k_{p} = k_{q}$ with $p\ne q$, then the inner sum
            \begin{align*}
                \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \prod_{i=1}^{n} b_{k_{i}, \sigma(i)}
            \end{align*}
            vanishes. This expression is precisely the Leibniz formula for a determinant whose matrix has two identical rows (rows $k_{p}$ and $k_{q}$). Determinants are alternating, so this term is zero.
            \bigbreak \noindent 
            Thus, only index tuples $(k_{1}, \dots, k_{n}) $ with all entries distinct contribute. If all $k_{i}$ are distinct and each lies in $\{1,\dots, n\} $, then
            \begin{align*}
                (k_{1}, \dots, k_{n})
            \end{align*}
            is a permutation of $(1,\dots, n) $. So, there exists a unique permutation $\tau \in S_{n}$ such that 
            \begin{align*}
                k_{i} = \tau(i)
            .\end{align*}
            Thus the sum over index tuples collapses to a sum over permutations
            \begin{align*}
                \sum_{k_{1}, \dots, k_{n}} \left(\prod_{i=1}^{n}a_{ik_{i}}\right) \sum_{\sigma \in S_{n}} \text{sgn}(\sigma)  \prod_{i=1}^{n}b_{k_{i}, \sigma(i)} = \sum_{\tau \in S_{n}} \left(\prod_{i=1}^{n}a_{i,\tau(i)}\right) \sum_{\sigma \in S_{n}} \text{sgn}(\sigma)  \prod_{i=1}^{n}b_{\tau(i), \sigma(i)}
            .\end{align*}
            Now, notice that $\tau \in S_{n}$. Thus, $\tau$ is a bijection of $\{1,\dots, n\} $, as $i$ runs over $1,\dots, n$, so does $\tau(i) $. Let
            \begin{align*}
                \sigma^{\prime} = \sigma \tau^{-1}, \quad \sigma = \sigma^{\prime} \tau
            .\end{align*}
            So, $\sigma(i) = \sigma^{\prime}(\tau(i)) $. Thus,
            \begin{align*}
                \prod_{i=1}^{n}b_{\tau(i), \sigma(i)} = \prod_{i=1}^{n}b_{\tau(i), \sigma^{\prime}(\tau(i))}
            .\end{align*}
            Since $\tau$ is a bijection of $\{1,\dots, n\} $, we can set $\tau(i) = j$, where $j$ runs over $\{1,\dots, n\} $. Now, we have
            \begin{align*}
                \prod_{i=1}^{n}b_{\tau(i), \sigma^{\prime}(\tau(i))} = \prod_{j=1}^{n}b_{j, \sigma^{\prime}(j)}
            .\end{align*}
            Since $\sigma = \sigma^{\prime} \tau$, 
            \begin{align*}
                \text{sgn}(\sigma) = \text{sgn}(\sigma^{\prime} \tau) = \text{sgn}(\sigma^{\prime}) \text{sgn}(\tau)
            .\end{align*}
            So, we have
            \begin{align*}
                \sum_{\tau \in S_{n}} \left(\prod_{i=1}^{n}a_{i,\tau(i)}\right) \sum_{\sigma^{\prime} \in S_{n}} \text{sgn}(\sigma^{\prime}) \text{sgn}(\tau)  \prod_{j=1}^{n}b_{j, \sigma^{\prime}(j)}
            .\end{align*}
            Notice by the start of the inner sum $\tau$ is a constant factor. So we can move it outside,
            \begin{align*}
                \sum_{\tau \in S_{n}} \left(\prod_{i=1}^{n}a_{i,\tau(i)}\right) \text{sgn}(\tau) \sum_{\sigma^{\prime} \in S_{n}} \text{sgn}(\sigma^{\prime})   \prod_{j=1}^{n}b_{j, \sigma^{\prime}(j)}
            .\end{align*}
            Notice, we now have $\det(B)$, 
            \begin{align*}
                \sum_{\tau \in S_{n}} \left(\prod_{i=1}^{n}a_{i,\tau(i)}\right) \text{sgn}(\tau) \sum_{\sigma^{\prime} \in S_{n}} \text{sgn}(\sigma^{\prime})   \prod_{j=1}^{n}b_{j, \sigma^{\prime}(j)} = \sum_{\tau \in S_{n}} \left(\prod_{i=1}^{n}a_{i,\tau(i)}\right) \text{sgn}(\tau) \det(B)
            .\end{align*}
            Lastly, notice that we can move the $\text{sgn}(\tau)$ so that it is the first term instead of the last, 
            \begin{align*}
                \sum_{\tau \in S_{n}} \left(\prod_{i=1}^{n}a_{i,\tau(i)}\right) \text{sgn}(\tau) \det(B) = \sum_{\tau \in S_{n}}\text{sgn}(\tau)  \left(\prod_{i=1}^{n}a_{i,\tau(i)}\right) \det(B)
            .\end{align*}
            Which is precisely $\det(A)\det(B)$. Thus,
            \begin{align*}
                \sum_{\tau \in S_{n}}\text{sgn}(\tau)  \left(\prod_{i=1}^{n}a_{i,\tau(i)}\right) \det(B) = \det(A)\det(B)
            .\end{align*}
            And we conclude that $\det(AB) = \det(A) \det(B)$. $\endpf$
        \item \textbf{Transpose invariance}: Suppose $A \in \mathbb{R}^{n\times n}$, then
            \begin{align*}
                \det(A^{T}) = \det(A)
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A\in \mathbb{R}^{n\times n}$, then $A^{T} \in \mathbb{R}^{n\times n}$, and
            \begin{align*}
                \det(A^{T}) &= \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \prod_{i=1}^{n} a_{\sigma(i), i}
            .\end{align*}
            Let $j = \sigma(i)$, then $i = \sigma^{-1}(j) $. Recall that $\text{sgn}(\sigma) = \text{sgn}(\sigma^{-1})$, so
            \begin{align*}
                \sum_{\sigma \in S_{n}} \text{sgn}(\sigma) \prod_{i=1}^{n} a_{\sigma(i), i} = \sum_{\sigma \in S_{n}} \text{sgn}(\sigma^{-1}) \prod_{j=1}^{n} a_{j, \sigma^{-1}(j)}
            .\end{align*}
            Let $\Phi$ be the inversion map
            \begin{align*}
                \Phi:\; S_{n} \to S_{n},\quad \Phi(\sigma) = \sigma^{-1}
            .\end{align*}
            Since $\Phi$ is a bijection over $S_{n} $, 
            \begin{align*}
                \sum_{\sigma \in S_{n}} f(\sigma) = \sum_{\sigma \in S_{n}} f(\sigma^{-1})
            .\end{align*}
            Let $\tau = \sigma^{-1}$, then
            \begin{align*}
                \sum_{\sigma \in S_{n}}\text{sgn}(\sigma^{-1})\prod_{j=1}^{n}a_{j, \sigma^{-1}(j)} = \sum_{\tau \in S_{n}}\text{sgn}(\tau) \prod_{j=1}^{n} a_{j, \tau(j)} = \det(A)
            .\end{align*}
        \item \textbf{Determinant of the inverse}: Suppose $A \in \mathbb{R}^{n\times n} $ is invertible, then
            \begin{align*}
                \det(A^{-1}) = \frac{1}{\det(A)}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A\in \mathbb{R}^{n\times n}$ admits an inverse $A^{-1} \in \mathbb{R}^{n\times n}$, where
            \begin{align*}
                AA^{-1} = A^{-1}A = I
            .\end{align*}
            So,
            \begin{align*}
                \det(AA^{-1}) &= \det(I) = 1 \implies \det(A)\det(A^{-1}) = 1 \\
                \therefore \det(A^{-1}) &= \frac{1}{\det(A)}
            .\end{align*}
            As desired. $\endpf$
            \bigbreak \noindent 
            \textbf{\textit{Corollary.}} From above, we see
            \begin{align*}
                \det(A) = \frac{1}{\det(A^{-1})}
            .\end{align*}
        \item \textbf{Determinant of triangular matrices}:  







    \end{itemize}

    


    \pagebreak 
    \subsection{Chapter 1: Gaussian Elimination and its variants}
    \bigbreak \noindent 
    \subsubsection{Definitions}
    \begin{itemize}
        \item \textbf{Matrix multiplication}: If $A$ is an $n \times m$ matrix, and $X$ is $m \times p$, we can form the product $B = AX$, which is $n \times p$. The $(i,j)$ entry of $B$ is
        \[
            b_{ij} = \sum_{k=1}^{m} a_{ik} x_{kj}.
        \]
    \item \textbf{Triangular matrix}:
        A matrix $G = (g_{ij})$ is \textit{lower triangular} if $g_{ij} = 0$ whenever $i < j$. 
        Thus a lower-triangular matrix has the form
        \[
            G =
            \begin{bmatrix}
                g_{11} & 0      & 0      & \cdots & 0 \\
                g_{21} & g_{22} & 0      & \cdots & 0 \\
                g_{31} & g_{32} & g_{33} & \cdots & \vdots \\
                \vdots & \vdots & \vdots & \ddots & 0 \\
                g_{n1} & g_{n2} & g_{n3} & \cdots & g_{nn}
            \end{bmatrix}.
        \]
        Similarly, an \textit{upper triangular} matrix is one for which $g_{ij} = 0$ whenever $i > j$. 
        A \textit{triangular} matrix is one that is either upper or lower triangular.
    \item \textbf{Positive definite matrix}: A square matrix $A$ is positive definite provided it satisfies
        \begin{enumerate}
            \item $A = A^{\top} $
            \item $x^{\top}Ax > 0$ for all $x\in \mathbb{R}^{n}$, $x\ne 0$
        \end{enumerate}
    \item \textbf{Column envelope}: The envelope of a sparse matrix is the set of positions around the diagonal that "must be included" when storing or working with the matrix in a compressed way.
        \bigbreak \noindent 
        It essentially captures the profile of where the nonzeros start (or stop) in each column.
        \bigbreak \noindent 
        Let $A  = (a_{ij})$. Define for each column $j$
        \begin{align*}
            q(j) = \text{min}\{i:\ a_{ij} \ne 0\}
        \end{align*}
        I.e the first nonzero entry in column $j$. Then, the column envelope of column $j$ is 
        \begin{align*}
            \{(i,j):\ q(j) \leq i \leq j\}
        \end{align*}
        So, for column $j$, you start at the first nonzero entry $q(j)$ and include all positions down to the diagonal ( $i=j$), whether or not some of them are explicitly zero.
        \bigbreak \noindent 
        The column envelope of the matrix $A$ is the union over all columns:
        \begin{align*}
            \text{colenv}\{A\} = \bigcup_{j=1}^{n}\{(i,j):\ q(j) \leq i \leq j\}
        \end{align*}
        with 
        \begin{align*}
            q(j) = \text{min}\{i:\ a_{ij} \ne 0\}
        \end{align*}
    \item \textbf{Row envelope}: For each row $i$ find the first nonzero entry
        \begin{align*}
            p(i) = \text{min}\{j:\ a_{ij} \ne 0\}.
        \end{align*}
        Then, the row envelope of row $i$ is 
        \begin{align*}
            \{(i,j):\ p(i) \leq j \leq i\}
        \end{align*}
        So, the row envelope is in the lower triangular part ($j \leq i $)
        \bigbreak \noindent 
        The row envelope of $A$ is then
        \begin{align*}
            \text{rowenv}\{A\} = \bigcup_{i=1}^{m}\{(i,j):\ p(i) \leq j \leq i\}
        \end{align*}
    \item \textbf{Envelope}: The envelope is the union of both envelopes. That is,
        \begin{align*}
            \text{env}\{A\} = &\text{rowenv}\{A\} = \bigcup_{i=1}^{m}\{(i,j):\ p(i) \leq j \leq i\}  \\
            \cup &\text{colenv}\{A\} = \bigcup_{j=1}^{n}\{(i,j):\ q(j) \leq i \leq j\}
        \end{align*}
    \item \textbf{Elementary operations on systems}:
        \begin{enumerate}
            \item Interchange rows.
            \item Multiply an equation by a nonzero constant.
            \item Add a multiple of one equation to another equation.
        \end{enumerate}

    \item \textbf{Transpose of block matrices}: Let $A \in \mathbb{R}^{n\times n}$, with
        \begin{align*}
            A  = \begin{bmatrix} A_{11} & a_{12} \\ A_{21} & a_{22} \end{bmatrix}
        .\end{align*}
        Then, 
        \begin{align*}
            A^{\top} = \begin{bmatrix}
                A_{11}^{\top} & A_{21}^{\top} \\ A_{12}^{\top} & A_{22}^{\top}
            \end{bmatrix}
        \end{align*}
    \item \textbf{Transpose of a block vector}: Similarly, if $ x \in \mathbb{R}^{n}$ is decomposed into blocks
        \begin{align*}
            \begin{pmatrix} x_{1} \\ x_{2} \end{pmatrix}
        ,\end{align*}
        with $x_{1} \in \mathbb{R}^{n_{1}} ,\; x_{2} \in \mathbb{R}^{n_{2}},\; n = n_{1} + n_{2}$, then
        \begin{align*}
            x^{\top} = \begin{pmatrix} x_{1}^{\top} & x_{2}^{\top} \end{pmatrix}
        \end{align*}

    \item \textbf{Nonsingular matrix}: A nonsingular matrix is a matrix that has an inverse
    \item \textbf{Singular matrix}: A singular matrix is a matrix that does not have an inverse
            \item \textbf{Positive definite matrix}: A matrix $A$ is \textbf{positive definite} provided that the following two conditions are satisfied
            \begin{enumerate}
                \item $A$ is symmetric. That is, $A = A^{\top} $
                \item $x^{\top}Ax > 0 $ for all $x\ne 0$
            \end{enumerate}

        \item \textbf{Cholesky decomposition and the Cholesky Factor}: Let $A \in \mathbb{R}^{n\times n}$ be p.d, then $A = R^{\top}R$ where $R$ is upper triangular with $r_{ii} > 0$. The matrix $R$ is called the \textbf{Cholesky factor}.
            \bigbreak \noindent 
            If $A = R^{\top}R$, then $Ax = b$ can be written as 
            \begin{align*}
                R^{\top}Rx = b
            \end{align*}
            where
            \begin{align*}
                \begin{cases}
                        Rx &= y \quad \text{(Lower triangular)}              \\
                        R^{\top}y &= b \quad \text{(Upper triangular)}
                \end{cases}
            \end{align*}
            and since these new systems are triangular, they can be solved quickly with forward or backward substitution.
        \item \textbf{Banded matrix}: A banded matrix is a sparse matrix whose nonzero entries are confined to a diagonal band, consisting of the main diagonal and a fixed number of diagonals on either side of it.
            \bigbreak \noindent 
                Let $A \in \mathbb{R}^{m \times n}$.  
                Then $A$ is called a \textbf{banded matrix} if there exist nonnegative integers $p, q$ (called the \emph{lower} and \emph{upper bandwidths}) such that
                \[
                    a_{ij} = 0 \quad \text{whenever } i - j > p \text{ or } j - i > q.
                \]
                \begin{itemize}
                    \item The \emph{lower bandwidth} $p$ is the number of subdiagonals (below the main diagonal) that may contain nonzero entries.
                    \item The \emph{upper bandwidth} $q$ is the number of superdiagonals (above the main diagonal) that may contain nonzero entries.
                \end{itemize}
                The \emph{total bandwidth} is sometimes defined as $p + q + 1$, counting the main diagonal as well.
        \item \textbf{$LU$ decomposition}: Consider a matrix $A \in \mathbb{R}^{n\times n} $. If we can factor $A$ as $A = LU$, for $L$ lower triangular, $U$ upper triangular, then the system $Ax = b$, for vectors $x,b \in \mathbb{R}^{n}$ turns into
            \begin{align*}
                LUx = b
            .\end{align*}
            We can then split this system as follows
            \begin{align*}
                \begin{cases}
                    Ly &= b \\
                    Ux &= y
                \end{cases}
            \end{align*}
            First, we solve $Ly = b$ with forward substitution to find $y$. We can then solve $Ux = y$ with backward substitution to find the target $x$.
        \item \textbf{More definiteness}: Let $A \in \mathbb{R}^{n\times n}$ be symmetric. Then,
            \begin{itemize}
                \item $A$ is \textbf{positive semidefinite} if $x^{\top}Ax \geq 0 $ for all $x\in \mathbb{R}^{n} $
                \item $A$ is negative definite if $x^{\top}Ax < 0 $ for all nonzero $x\in \mathbb{R}^{n}$
                \item $A$ is negative semidefinite if $x^{\top}Ax \leq 0$ for all $x\in \mathbb{R}^{n} $
            \end{itemize}
        \item \textbf{Definiteness notation}: Let $A\in \mathbb{R}^{n\times n}$ by symmetric.
            \begin{itemize}
                \item $A \succ 0$ means $A$ is positive definite.        
                \item $A \succeq 0$ means $A$ is positive semidefinite
                \item $A \prec 0$ means $A$ is negative definite
                \item $A \preceq 0$ means $A$ is negative semidefinite
            \end{itemize}

        \item \textbf{Ill-conditioned problem}: A problem $P$ is \textbf{ill-conditioned} if tiny variations in the information of $P$ leads to large variations of the solution of $P$
            \bigbreak \noindent 
            Consider a linear system. If $A,b$ is the information of the problem, then for a slightly perturbed $A$ and $b$, call them $\bar{A},\bar{b}$, where $\bar{A} - A$ and $\bar{b} - b$ tiny, an ill-conditioned problem will have 
            \begin{align*}
                \bar{x} - x
            \end{align*}
            large, if $x$ is the solution to $Ax = b$, and $\bar{x}$ is the solution to the system with $\bar{A}$ and $\bar{b}$.
            \bigbreak \noindent 
            If the problem is \textbf{well-conditioned}, $\bar{x} -x$ is also tiny.
        \item \textbf{Permutation matrix}: A permutation matrix is a special kind of square matrix that represents a permutation of elements. Formally:
            It is obtained from the identity matrix by rearranging its rows (or equivalently, its columns).
            \bigbreak \noindent 
            Each row and each column has exactly one entry equal to 1, and all other entries are 0.
            \bigbreak \noindent 
            Multiplying a vector (or another matrix) by a permutation matrix reorders its entries.
            \bigbreak \noindent 
            Suppose $P$ is formed by taking $I$ and interchanging rows one and two. Then,
            \begin{align*}
                P = \begin{pmatrix} 0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1 \end{pmatrix}
            .\end{align*}
            Then, 
            \begin{align*}
                P\begin{pmatrix} a \\ b \\ c \end{pmatrix} = \begin{pmatrix} b \\ a \\ c \end{pmatrix}
            .\end{align*}
            So, it swaps the first two entries.


    \end{itemize}

    \pagebreak 
    \bigbreak \noindent 
    \subsubsection{Properties}
    \begin{itemize}
        \item \textbf{Eigenvalues of a triangular or diagonal matrix}: The eigenvalues are simply the entries on the main diagonal. Suppose $A \in \mathbb{R}^{n\times n}$ is triangular or diagonal. Then, $A$ is one of  
            \begin{align*}
                A = &\begin{bmatrix} a_{11} & a_{12} & ... & a_{1n} \\ 0 & a_{22} & ... & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & ... & a_{nn} \end{bmatrix}, \\
                    &\begin{bmatrix} a_{11} & 0 & ... & 0 \\ a_{21} & a_{22} & ... & 0\\ \vdots & \vdots& \ddots & \vdots \\ a_{n1} & a_{n2} & ... & a_{nn} \end{bmatrix}, \\
                    &\begin{bmatrix} a_{11} & 0 & ... & 0\\ 0 & a_{22} & ... & 0\\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & ... & a_{nn} \end{bmatrix}
            .\end{align*}
            Then, $\lambda_{1} = a_{11},\; \lambda_{2} = a_{22},\; ...,\; \lambda_{n} = a_{nn}$
        \item \textbf{Properties of a nonsingular matrix}:
            The following are equivalent, if any one holds, they all hold
            \begin{itemize}
                \item $Ax = b$ has a unique solution
                \item $\det(A)\ne 0$
                \item $A^{-1}$ exists
                \item There is no nonzero vector $y \in \mathbb{R}^{m}$ such that $Ay=0 $
                \item The columns of $A$ are linearly independent
                \item The rows of $A$ are linearly independent
                \item Given any vector $b$, there is exactly one vector $x$ such that $Ax=b$
            \end{itemize}
            If any one of the following are true, they all are true, and $A$ is nonsingular
        \item \textbf{More properties of nonsingular matrices}:
            \begin{enumerate}
                \item The product of nonsingular matrices is nonsingular.
                \item The inverse of a nonsingular matrix is nonsingular (obvious)
                \item The sum of two nonsingular matrices \textbf{may not be} nonsingular
                \item A nonsingular matrix scaled by a nonzero scalar is nonsingular
            \end{enumerate}
        \item \textbf{Triangular matrices}: 
            Triangular matrices are invariant under multiplication, transposition, and inversion
            \begin{itemize}
                \item Upper triangular $\times$ upper triangular = upper triangular
                \item Lower triangular $\times$ lower triangular = lower triangular
                \item The transpose of an upper triangular matrix is a lower triangular matrix
                \item The transpose of an lower triangular matrix is a upper triangular matrix
                \item The inverse of a lower triangular matrix is lower triangular, and the inverse of an upper triangular matrix is upper triangular
            \end{itemize}
        \item \textbf{Properties of positive definite (p.d) matrices}:
            \begin{enumerate}
                \item If $A$ is p.d then $A$ is \textit{nonsingular}
                    \bigbreak \noindent 
                    \textbf{Note:} Since $A$ is nonsingular there is no $y \in \mathbb{R}^{n}$, $y\ne 0$ such that $Ay = 0$
                \item If $A = M^{\top}M$ for some $M$ nonsingular than $A$ is p.d
                \item If $A$ is p.d than $\det(A) > 0$
                \item If $A$ is p.d then all principal submatrices are p.d
                \item If $A$ is p.d then $a_{ii}>0$ for $i=1,2,...,n$. So, if any $a_{ii} \leq 0$, $A$ is not p.d.
                \item $A$ is p.d if and only if all leading principal minors are positive
                \item $A$ is p.d if and only if there exists a unique upper triangular matrix $R$ such that $A = R^{\top}R$ (Cholesky factorization described below)
                \item $A$ is p.d if and only if all eigenvalues of $A$ are positive
                    \bigbreak \noindent 
                    Recall that $\lambda$ is an eigenvalue of $A$ if there exists $x_{\lambda} \ne 0$ such that $Ax_{\lambda}  = \lambda x_{\lambda}$
            \end{enumerate}
            \textbf{Note:} Property two is a key property.
        \item \textbf{Relationship between definiteness and eigenvalue signs}: 
            \begin{center}
                \begin{tabularx}{\textwidth}{@{}llX@{}}
                    \toprule
                    \textbf{Definiteness} & \textbf{Eigenvalue signs} & \textbf{Name} \\
                    \midrule
                    $A \succ 0$ &	all  $\lambda_{i} > 0$ & Positive definite \\[2ex]
                    $A \succeq 0$ &	all  $\lambda_{i} \geq 0$ & Positive semidefinite \\[2ex]
                    $A \prec 0$ &	all  $\lambda_{i} < 0$ & Negative definite \\[2ex]
                    $A \preceq 0$ &	all  $\lambda_{i} \leq 0$ & Positive definite \\[2ex]
                    \bottomrule
                \end{tabularx}
            \end{center}
            \textbf{Note:} Eigenvalue signs are a necessary and sufficient condition for definiteness. Also, recall that in all cases, $A$ is symmetric, so all eigenvalues are real.
        \item \textbf{Cholesky factor $R$ in a diagonal matrix}: If $A = D = \begin{bmatrix}
                a_{11} & 0 & \cdots & 0 \\
                0 & a_{22} & \cdots & 0 \\
                \vdots & \vdots & \ddots & \vdots \\
                0 & 0 & \cdots & a_{nn} 
        \end{bmatrix}$ then
        \begin{align*}
            R = \begin{bmatrix}
                \sqrt{a_{11}} & 0 & \cdots & 0 \\
                0 & \sqrt{a_{22}} & \cdots & 0 \\
                \vdots & \vdots & \ddots & \vdots \\
                0 & 0 & \cdots & \sqrt{a_{nn}}
            \end{bmatrix}
        \end{align*}
    \item \textbf{$LU$ factorization in a symmetric matrix}: 
    \item \textbf{Properties of a permutation matrix}:
        \begin{enumerate}
            \item \textbf{Orthogonal:} $P^{T} = P^{-1} $
            \item \textbf{Determinant:}: $\det(P)=\pm 1$, depending on whether the permutation is even or odd.
            \item \textbf{Action on vectors:}: $Px$ permutes the coordinates of $x$
            \item \textbf{Action on matrices:} Left multiplication permutes rows; right multiplication permutes columns.
        \end{enumerate}



    \end{itemize}

    \pagebreak \bigbreak \noindent 
    \subsubsection{Theorems}
    \begin{itemize}
        \item \textbf{Theorem 1.1.19}: 
            Let $A \in \mathbb{R}^{m\times n}$ ,$X\in \mathbb{n\times p}$ and $B \in \mathbb{R}^{m \times p}$ be partitioned as follows
            \begin{align*}
                A &= 
                \begin{blockarray}{ccc} & m_{1} & m_{2} \\ 
                    \begin{block}{c[cc]} 
                        n_{1} & A_{11} & A_{12} \\ 
                        n_{2} & A_{21} & A_{22} 
                    \end{block} 
                \end{blockarray},\quad 
                \begin{cases}
                    m_{1} + m_{2} = m \\
                    n_{1} + n_{2} = n
                \end{cases} \\
                    X &= 
                \begin{blockarray}{ccc} 
                    & p_{1} & p_{2} \\ 
                    \begin{block}{c[cc]} 
                        n_{1} & X_{11} & X_{12} \\ 
                        n_{2} & X_{21} & X_{22} 
                    \end{block} 
                \end{blockarray}, 
                \quad \begin{cases} 
                    p_{1} + p_{2} = p \\ 
                    n_{1} + n_{2} = n 
                \end{cases} \\
                    B &= 
                \begin{blockarray}{ccc} & p_{1} & p_{2} \\ 
                    \begin{block}{c[cc]} m_{1} & B_{11} & B_{12} \\ 
                        m_{2} & B_{21} & B_{22} 
                    \end{block} 
                \end{blockarray}, 
                \quad \begin{cases} 
                        p_{1} + p_{2} = p \\ 
                        m_{1} + m_{2} = m 
                    \end{cases} 
            \end{align*}
            Then $AX = B$ if and only if 
            \begin{align*}
                A_{i1}X_{1j} = B_{ij} \quad \text{ for } i,j=1,2
            \end{align*}
        \item \textbf{Theorem 1.1.24}:  
            Make a finer partition of $A$ into $r$ block rows and $s$ block columns.
            \[
                A =
                \begin{bmatrix}
                    A_{11} & \cdots & A_{1s} \\
                    \vdots & \ddots & \vdots \\
                    A_{r1} & \cdots & A_{rs}
                \end{bmatrix}, \quad
                \begin{array}{l}
                    n_1 + \cdots + n_r = n \\
                    m_1 + \cdots + m_s = m
                \end{array}
            \]
            Then partition $X$ \emph{conformably} with $A$; that is, make the block row structure of
            $X$ identical to the block column structure of $A$.

            \[
                X =
                \begin{bmatrix}
                    X_{11} & \cdots & X_{1t} \\
                    \vdots & \ddots & \vdots \\
                    X_{s1} & \cdots & X_{st}
                \end{bmatrix}, \quad
                \begin{array}{l}
                    m_1 + \cdots + m_s = m \\
                    p_1 + \cdots + p_t = p
                \end{array}
            \]
            Finally, partition the product $B$ conformably with both $A$ and $X$.
            \[
                B =
                \begin{bmatrix}
                    B_{11} & \cdots & B_{1t} \\
                    \vdots & \ddots & \vdots \\
                    B_{r1} & \cdots & B_{rt}
                \end{bmatrix}, \quad
                \begin{array}{l}
                    n_1 + \cdots + n_r = n \\
                    p_1 + \cdots + p_t = p
                \end{array}
            \]
            \bigbreak \noindent 
            \textbf{Theorem}: Let $A,X$ and $B$ be partitioned like they are above. Then, $AX = B$ if and only if 
            \begin{align*}
                B_{ij} = \sum_{k=1}^{s}A_{ik}X_{kj} \quad i=1,...,r,\; j=1,...,t
            \end{align*}
        \item \textbf{Theorem 1.2.3}: Let $A$ be a square matrix. The following six conditions are equivalent; 
            that is, if any one holds, they all hold.
            \begin{enumerate}[label=(\alph*)]
                \item $A^{-1}$ exists.
                \item There is no nonzero $y$ such that $Ay = 0$.
                \item The columns of $A$ are linearly independent.
                \item The rows of $A$ are linearly independent.
                \item $\det(A) \neq 0$.
                \item Given any vector $b$, there is exactly one vector $x$ such that $Ax = b$.
            \end{enumerate}
        \item \textbf{Theorem 1.3.1}: Let $G$ be a triangular matrix. Then $G$ is \textbf{nonsingular} if and only if
            $g_{ij} \ne 0$ for $i=1,...,n $
        \item \textbf{Theorem 1.4.2}: If $A$ is positive definite, then $A$ is nonsingular
        \item \textbf{Corollary 1.4.3}: If $A$ is positive definite, the linear system $Ax = b$ has exactly one solution.
        \item \textbf{Theorem 1.4.4}: Let $M$ be any $n \times n$ nonsingular matrix, and let $A = M^{\top}M$. Then $A$ is positive definite.
        \item \textbf{Theorem 1.4.7 (\textit{Cholesky Decomposition Theorem})}: Let $A$ be positive definite. Then $A$ can be decomposed in exactly one way into a product
            \begin{align*}
                A = R^{\top}R
            \end{align*}
            such that $R$ is upper triangular and has all main diagonal entries $r_{ii}$ positive. $R$ is called the Cholesky factor of $A$.
            \bigbreak \noindent 
            We have
            \begin{align*}
                r_{ii} &= +\sqrt{a_{ii} - \sum_{k=1}^{i-1}r_{ki}^{2}}, \\
                r_{ij} &= \frac{\left(a_{ij} - \sum_{k=1}^{i-1}r_{ki}r_{kj}\right)}{r_{ii}} \quad j=i+1,...,n
            \end{align*}
            \textbf{Note:} $R$ is upper triangular, so we do not have to calculate entries $r_{ij}$ for $i > j $
        \item \textbf{Theorem 1.5.7}: Let $A$ be positive definite, and let $R$ be the Cholesky factor of A. Then $R$ and $A$ have the same envelope.
        \item \textbf{Theorem}: Let $A$ be p.d, if $R$ is the Cholesky factor of $A$, then
            \begin{align*}
                \text{colenv}\{R\}  = \text{colenv}\{A\}
            \end{align*}
    \item \textbf{Theorem}: Let $A \in \mathbb{R}^{n\times n}$ be nonsingular. Then, we can solve the system $Ax = b$, $b \in \mathbb{R}^{n}$ using Gaussian Elimination without row interchanges if and only if all landing principal sub-matrices of $A$ are nonsingular.
    \item \textbf{Theorem}: Let $A \in \mathbb{R}^{n \times n}$. Then $A$ admits an LU factorization
            \[
                A = LU,
            \]
            where $L \in \mathbb{R}^{n \times n}$ is unit lower triangular and 
            $U \in \mathbb{R}^{n \times n}$ is upper triangular, 
            \textbf{without row interchanges}, if and only if all leading principal 
            submatrices of $A$ are nonsingular.
    \item \textbf{Theorem 1.7.19 \textit{($LU$ Decomposition Theorem)}}: Let $A$ be an $n\times n$ matrix whose leading principal submatrices are all nonsingular. Then, $A$ can be decomposed in exactly one way into a product $A = LU$ such that $L$ is unit lower triangular and $U$ is upper triangular.


    \end{itemize}

    \pagebreak \bigbreak \noindent 
    \subsubsection{Propositions}
    \begin{itemize}
        \item \textbf{Proposition 1.1.6}: If $b = Ax$, then $b$ is a linear combination of the columns of $A$.
            \bigbreak \noindent 
            If we let $A_{j}$ denote the $j$th column of $A$, we have
            \[
                b = \sum_{j=1}^{m} A_{j} x_{j}.
            \]
        \item \textbf{Proposition 1.4.24}: Cholesky's algorithm (Row-oriented inner product formals) applied to an $n \times n$ matrix performs about $\frac{n^{3}}{3} $ flops.
        \item \textbf{Proposition 1.4.51}: If $A$ is positive definite, then $a_{ii} > 0$ for $i = 1,2,..,n$
        \item  \textbf{Proposition 1.4.53}: Let $A$ be positive definite, and consider a partition
            \begin{align*}
                A = \begin{bmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{bmatrix}
            \end{align*}
            in which $A_{11}$ and $A_{22} $ are square. Then $A_{11}$ and $A_{22}$ are positive definite.
        \item \textbf{Proposition 1.4.55} If $A$ and $X$ are $n\times n$, $A$ is positive definite, and $X$ is nonsingular then the matrix $B = X^{\top}AX$ is also positive definite.
        \item \textbf{Proposition 1.7.1}: If $\hat{A}x = \hat{b}$ is obtained from $Ax = b$ by an elementary operation of type 1,2, or 3, then the systems $Ax = b$ and $\hat{A}x = \hat{b}$ are equivalent.
        \item \textbf{Proposition 1.7.3}:  Suppose $\hat{A}$ is obtained from $A$ by an elementary row operation of
            type 1, 2, or 3. Then $\hat{A}$ is nonsingular if and only if $A$ is.
    \end{itemize}

    \pagebreak \bigbreak \noindent 
    \subsubsection{Algorithms and complexities}
    \begin{itemize}
        \item \textbf{Matrix multiplication}: $\mathcal{O}(n^{3}) $
        \item \textbf{Row oriented forward substitution of a lower triangular matrix}:
            Consider the system
            \begin{align*}
                \begin{bmatrix}
                    \ell_{11} & 0 & \cdots & 0 \\
                    \ell_{21} & \ell_{22} & \cdots & 0 \\
                    \vdots & \vdots & \ddots & \vdots \\
                    \ell_{n1} & \ell_{n2} & \cdots & \ell_{nn}
                    \end{bmatrix} \begin{bmatrix}
                    x_{1} \\ x_{2} \\ \vdots \\ x_{n}
                \end{bmatrix}
                =
                \begin{bmatrix}
                    b_{1} \\ b_{2} \\ \vdots \\ b_{n}
                \end{bmatrix}
            .\end{align*}
            In general, we have
            \begin{align*}
                x_{i} = \frac{b_{i} - \sum_{j=1}^{i-1}\ell_{ij}x_{j}}{\ell_{ii}}
            \end{align*}
            for $i =1,2,...,n $. This method is called \textbf{Forward Substitution}.
            \bigbreak \noindent 
            The row oriented forward substitution algorithm requires $\mathcal{O}(n^{2})$ flops.
        \item \textbf{Column oriented forward substitution (recursive algorithm)}: 
            Suppose we have $Lx = b$ when $L$ is lower triangular, we split the matrix into the following blocks
            \begin{align*}
                \begin{bmatrix}
                    \ell_{11} & 0 \\
                    \hat{\ell} & \hat{L}
                \end{bmatrix}
                \begin{bmatrix}
                    x_{1} \\ \hat{x} 
                \end{bmatrix}
                = \begin{bmatrix}
                    b_{1} \\ \hat{b}
                \end{bmatrix}
            .\end{align*}
            With $\hat{\ell} \in \mathbb{R}^{n-1}$, $\hat{L} \in \mathbb{R}^{n-1 \times n-1} $, $\hat{x} \in \mathbb{R}^{n-1}$, $\ell_{11}, x_{1}, b_{1} \in \mathbb{R}$. Note that $\hat{L}$ is also lower triangular.
            \begin{enumerate}
                \item Compute $x_{1} = \frac{b_{1}}{\ell_{11}} $
                \item Compute $\hat{b} - \hat{\ell}x_{1} = \tilde{b} \in \mathbb{R}^{n-1} $
                \item Find $\hat{L}x = \tilde{b} $
                \item Run the algorithm on $\hat{L}$, $\tilde{b}$. That is, $\text{Alg}(\hat{L}, \tilde{b}) $
            \end{enumerate}
            The recursive column oriented forward substitution algorithm requires $\mathcal{O}(n^{2})$ flops.
        \item \textbf{Row oriented backward substitution of an upper triangular matrix}:
            Let $A \in \mathbb{R}^{n\times n},\ x \in \mathbb{R}^{n},\ b \in \mathbb{R}^{n}$, with
            \begin{align*}
                A = \begin{bmatrix}
                    a_{11} & a_{12} & \cdots & a_{1n} \\
                    0 & a_{22} & \cdots & a_{2n} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    0 & 0 & \cdots & a_{nn}
                \end{bmatrix},  \quad \;
                x = \begin{bmatrix}
                    x_{1} \\ x_{2} \\ \vdots \\ x_{n}
                \end{bmatrix}, \quad \;
                b = \begin{bmatrix}
                    b_{1} \\ b_{2} \\ \vdots \\ b_{n}
                \end{bmatrix}
            .\end{align*}
            In general, we have that
            \begin{align*}
                x_{i} &= \frac{b_{i} - \sum_{j=i+1}^{n}a_{ij}x_{j}}{a_{ii}}, \quad i=n,n-1,...,1
            \end{align*}
            The row oriented backward substitution algorithm requires $\mathcal{O}(n^{2})$ flops.
        \item \textbf{Column-oriented backward substitution}:
            Let $U \in \mathbb{R}^{n\times n}$ be upper triangular, $x \in \mathbb{R}^{n}$, and $ b \in \mathbb{R}^{n}$ which gives the system
            \begin{align*}
                \begin{bmatrix}
                    u_{11} & u_{12} & \cdots & u_{1n} \\
                    0 & u_{22} & \cdots & u_{2n} \\
                    \vdots & \vdots & \ddots & \vdots \\
                    0 & 0 & \cdots & u_{nn}
                \end{bmatrix} 
                \begin{bmatrix}
                    x_{1} \\ x_{2} \\ \vdots \\ x_{n}
                \end{bmatrix}
                = 
                \begin{bmatrix}
                    b_{1} \\ b_{2} \\ \vdots \\ b_{n}
                \end{bmatrix}
            \end{align*}
            Split the system into the following block decomposition
            \begin{align*}
                \begin{bmatrix}
                    \hat{U} & u \\
                    0^{\top} & u_{nn}
                \end{bmatrix}
                \begin{bmatrix}
                    \hat{x} \\ x_{n}
                \end{bmatrix}
                = 
                \begin{bmatrix}
                    \hat{b} \\ b_{n}
                \end{bmatrix}
            \end{align*}
            Then,
            \begin{align*}
                \hat{U}\hat{x} + ux_{n} &= \hat{b} \implies \hat{U}\hat{x} = \hat{b} - ux_{n} = \tilde{b}, \\
                u_{nn}x_{n} &= b_{n} \implies x_{n} = \frac{b_{n}}{u_{nn}}
            \end{align*}
            Thus, the column-oriented backward substitution algorithm is defined by the following steps
            \begin{enumerate}
                \item Compute $x_{n} = \frac{b_{n}}{u_{nn}} $
                \item Compute $\tilde{b} = \hat{b} - ux_{n} $
                \item Run the algorithm on $\hat{U}, \tilde{b}$. That is, $\text{Alg}(\hat{U}, \tilde{b})$
            \end{enumerate}
            \bigbreak \noindent 
            The non-recursive pseudocode in the spirit of 1.3.5 and 1.3.13 is
            \bigbreak \noindent 
            \begin{jlcode}
                for |$i=n,...,1$|
                    if |$U[i,i] = 0$|, set error flag, exit

                    |$b[i] = b[i] / U[i,i]$|

                    for |$j = i-1,...,1$|
                        |$b[j] = b[j] - U[j,i] \cdot b[i]$|
                    end
                end
            \end{jlcode}
            \bigbreak \noindent 
            Requires $\mathcal{O}(n^{2})$ flops.

        \item \textbf{Flops required to solve triangular systems}: Let $Ax = b$ be a system of linear equations where $A$ is nonsingular. If $A$ is upper triangular or lower triangular we can solve the system in roughly $n^{2}$ flops.
        \item \textbf{Inner product formulas to compute $R$ (Cholesky factor)}: We have the formulas
            \begin{align*}
                r_{ii} &= \sqrt{a_{ii} - \sum_{k=1}^{i-1}r_{ki}^{2}} \quad i = 1,2,...,n \\
                r_{ij} &= \frac{a_{ij} - \sum_{k=1}^{i-1}r_{ki}r_{kj}}{r_{ii}} \quad j = i+1,...,n
            \end{align*}
            \bigbreak \noindent 
            The inner product formulas to compute $R$ requires $\mathcal{O}(n^{3})$ flops.
        \item \textbf{Recursive column oriented method to find the Cholesky factor $R$ (Outer product method)}: Let $A \in \mathbb{R}^{n\times n}$. Assume that $A$ is positive definite, so $A = A^{\top}$, and $A = R^{\top}R$ for a unique upper triangular matrix $R$. We have,
            \begin{align*}
                A &= \begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \cdots & a_{nn} \end{bmatrix} = 
                \begin{bmatrix}
                    r_{11} & 0  & \cdots & 0\\
                    r_{12} & r_{22}  &  \cdots & 0 \\
                    \vdots & \vdots & \ddots & \vdots\\
                    r_{1n} & r_{2n} & \cdots & r_{nn}
                \end{bmatrix}
                \begin{bmatrix}
                    r_{11} & r_{12} & \cdots & r_{1n} \\
                    0 & r_{22} & \cdots & r_{2n} \\
                    0 & 0 & \ddots & \vdots \\
                    0 & 0  & \cdots & r_{nn}
                \end{bmatrix}
            \end{align*}
            We then perform a matrix decomposition 
            \begin{align*}
                \begin{bmatrix}
                    a_{11} & a^{\top} \\
                    a & \hat{A}
                \end{bmatrix}
                =
                \begin{bmatrix}
                    r_{11} & 0^{\top} \\
                    r & \hat{R}^{\top}
                \end{bmatrix}
                \begin{bmatrix}
                    r_{11} & r^{\top} \\
                    0 & \hat{R}
                \end{bmatrix}
            .\end{align*}
            Where $\hat{A} = \hat{A}^{\top} \in \mathbb{R}^{n-1 \times n-1}$, $a \in \mathbb{R}^{n-1}$, $\hat{R}^{\top} \in \mathbb{R}^{n-1\times n-1}$ lower triangular, and $\hat{R} \in \mathbb{R}^{n-1\times n-1}$ upper triangular. Further,
            \bigbreak \noindent 
            The recursive column oriented algorithm to compute the Cholesky factor $R$ is given by the following steps
            \begin{enumerate}
                \item $r_{11} = \sqrt{a_{11}}$
                \item $r = \frac{a}{r_{11}} $
                \item $\tilde{A} = \hat{A} - rr^{\top} $
                \item $\text{Alg}(\tilde{A}) = \hat{R} $
            \end{enumerate}
            \bigbreak \noindent 
            The recursive column oriented algorithm to compute the Cholesky factor $R$ requires $\mathcal{O}(n^{3})$ flops.
        \item \textbf{Cholesky's algorithm}: Cholesky's algorithm  applied to an $n \times n$ matrix performs about $\frac{n^{3}}{3} $
        \item \textbf{Bordered form of Choleskys method}: Suppose $A \in \mathbb{R}^{n\times n}$ is positive definite. Then, $A$ admits a decomposition $A = R^{\top}R$, for a unique upper triangular matrix $R$ called the Cholesky factor, with $r_{ii} > 0$ for $i =1,2,...,n$. So,
            \begin{align*}
                        A &= \begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \cdots & a_{nn} \end{bmatrix} = 
                \begin{bmatrix}
                    r_{11} & 0  & \cdots & 0\\
                    r_{12} & r_{22}  &  \cdots & 0 \\
                    \vdots & \vdots & \ddots & \vdots\\
                    r_{1n} & r_{2n} & \cdots & r_{nn}
                \end{bmatrix}
                \begin{bmatrix}
                    r_{11} & r_{12} & \cdots & r_{1n} \\
                    0 & r_{22} & \cdots & r_{2n} \\
                    0 & 0 & \ddots & \vdots \\
                    0 & 0  & \cdots & r_{nn}
                \end{bmatrix}
            \end{align*}
        We then perform a matrix decomposition 
        \begin{align*}
            \begin{bmatrix}
                \hat{A} & a \\
                a^{\top} & a_{nn}
            \end{bmatrix}
             =
             \begin{bmatrix}
                 \hat{R}^{\top} & 0 \\
                 r^{\top} & r_{nn}
             \end{bmatrix}
             \begin{bmatrix}
                 \hat{R} & r \\
                 0 & r_{nn}
             \end{bmatrix}
        .\end{align*}
        So, 
        \begin{align*}
            \hat{A} &= \hat{R}^{\top}\hat{R}, \\
            a &= \hat{R}^{\top}r, \\
            a_{nn} &= r^{\top}r + r_{nn}^{2} \implies r_{nn} = \sqrt{a_{nn} - r^{\top}r}
        .\end{align*}
        So, the steps for the algorithm are 
        \begin{enumerate}
            \item Recurse $\hat{A}$ until $A \in \mathbb{R}^{1\times 1}$
            \item Solve the lower triangular system $\hat{R}^{\top}r = a$ by forward substitution
            \item Compute $r_{nn} = \sqrt{a_{nn} - r^{\top}r} $
            \item Return the step two on the previous call
        \end{enumerate}
        The above algorithm is postorder recursion and requires $\mathcal{O}(n^{3})$ flops.

        \item \textbf{Row oriented algorithm to compute $LU $ factorization}:
            Let $A \in \mathbb{R}^{n\times n}$. If $A$ can be factored into products $LU$, for $U \in \mathbb{R}^{n\times n}$ upper triangular, $L \in \mathbb{R}^{n\times n}$ unit lower triangular, then
            \begin{align*}
                A &= LU  
            \end{align*}
            implies
            \begin{align*}
                \begin{bmatrix}
                    a_{11} & a_{12} & a_{13} & \cdots & a_{1n} \\
                    a_{21} & a_{22} & a_{23} & \cdots & a_{2n} \\
                    a_{31} & a_{32} & a_{33} & \cdots & a_{3n} \\
                    \vdots & \vdots & \vdots & \ddots & \vdots \\
                    a_{n1} & a_{n2} & a_{n3} & \cdots & a_{nn} \\
                \end{bmatrix}
                = \begin{bmatrix}
                    1 & 0 & 0 & \cdots & 0 \\
                    \ell_{21} & 1 & 0 & \cdots & 0 \\
                    \ell_{31} & \ell_{32} & 1 & \cdots & 0 \\
                    \vdots & \vdots & \vdots & \ddots & \vdots \\
                    \ell_{n1} & \ell_{n2} & \ell_{n3} & \cdots & 1
                \end{bmatrix}
                \begin{bmatrix}
                    u_{11} & u_{12} & u_{13} & \cdots & u_{1n} \\
                    0  & u_{22} & u_{23} & \cdots & u_{1n} \\
                    0& 0& u_{33} & \cdots & u_{3n} \\
                    \vdots & \vdots & \vdots & \ddots & \vdots \\
                    0 & 0 & 0 & \cdots & u_{nn}
                \end{bmatrix}
            .\end{align*}
            The formulas are
        \begin{align*}
            u_{ij} &= a_{ij} - \sum_{k=1}^{i-1}\ell_{ik}u_{kj} \quad j=i,i+1,...,n \tag{1}, \\
            \ell_{ij} &= \frac{a_{ij} - \sum_{k=1}^{j-1}\ell_{ik}u_{kj}}{u_{jj}} \quad i=j+1,j+2,...,n \tag{2}
        .\end{align*}
        \bigbreak \noindent 
        To use these formulas to find each $u_{ij}$ we first need to plug $i=1$ into $(1)$, then after we get the first row of $U$, we can plug in $j=1$ into $(2)$ to get the first column of $L$, and so on.
        \item \textbf{Column oriented recursive algorithm to find the $LU$ factorization}: Assume $A \in \mathbb{R}^{n\times n }$ admits an $LU$ factorization for $L\in \mathbb{R}^{n\times n}$ unit lower triangular, $U$ upper triangular. Then,
            \begin{align*}
                A = LU
            \end{align*}
            implies
            \begin{align*}
                \begin{bmatrix} a_{11} & a_{12} & \cdots & a_{1n} \\ a_{21} & a_{22} & \cdots & a_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \cdots & a_{nn} \end{bmatrix} = 
                \begin{bmatrix} 1 & 0 & \cdots & 0 \\ \ell_{21} & \ell_{22} & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ \ell_{n1} & \ell_{n2} & \cdots & 1 \end{bmatrix}
                \begin{bmatrix} u_{11} & u_{12} & \cdots & u_{1n} \\ 0 & u_{22} & \cdots & u_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & u_{nn} \end{bmatrix}
            .\end{align*}
            Decompose $A = LU$ into the blocks
            \begin{align*}
                \begin{bmatrix}
                    a_{11} & b^{\top} \\
                    a & \hat{A}
                \end{bmatrix}
                =
                \begin{bmatrix}
                    1 & 0^{\top} \\
                    \ell & \hat{L}
                \end{bmatrix}
                \begin{bmatrix}
                    u_{11} & u^{\top} \\
                    0 & \hat{U}
                \end{bmatrix}
            .\end{align*}
            The recursive algorithm is defined by the following steps.
            \begin{enumerate}
                \item $u_{11} = a_{11} $ (zero flops)
                \item $u^{\top} = b^{\top} $ (zero flops)
                \item $\ell = \frac{a}{u_{11}} $ ($n-1$ flops) 
                \item $\tilde{A} = \hat{L}\hat{U} = \hat{A} - \ell u^{\top} $ ($2(n-1)^{2}$ flops)
                \item $\text{Alg}(\tilde{A})$
            \end{enumerate}
            The number of flops required for the recursive outer product method to find the $LU$ factorization is $\frac{2}{3}n^{3} + \mathcal{O}(n^{2}) $
        \item \textbf{Bordered form $LU$ decomposition algorithm}:
        \item \textbf{Flops required to find $LU$ decomposition}: Suppose $A$ is a matrix that admits an $LU$ decomposition $A = LU$ for $L$ unit lower triangular, and $U$ upper triangular. The flops required to find this decomposition is roughly $\frac{2}{3}n^{3}$.
            \bigbreak \noindent 
            Thus, to solve the system $Ax = b$, we have
            \begin{align*}
                Ax = b \iff LUx = b
            .\end{align*}
            Let 
            \begin{align*}
                \begin{cases}
                    Ly &= b \quad \text{($n^{2}$ flops)} \\
                    Ux &=y \quad \text{($n^{2}$ flops)}
                \end{cases}
            .\end{align*}
            So, in total, we have $\frac{2}{3}n^{3} + n^{2} + n^{2} = \frac{2}{3}n^{3} + 2n^{2} = \mathcal{O}(n^{3})$ flops to solve the system $Ax = b$ with an $LU$ decomposition.
        \item \textbf{Flops required to perform Gaussian Elimination without row interchanges (pivoting)}: For a system $Ax = b$, reducing the system to $Ux = b^{\prime}$, where $U$ is upper triangular requires roughly $\frac{2}{3}n^{3} + n^{2} + 2n = \mathcal{O}(n^{3})$ flops
            \bigbreak \noindent 
            Consider step $k$ of the process. We need to eliminate all entries below the pivot in column $k$, there are $(n-k)$ of them. Then, we need to update the $(n-k) \times (n-k)$ submatrix that doesn't include column $k$ and row $k$. The operation on each element $a_{ij}$ in the $(n-k) \times (n-k)$ submatrix is
            \begin{align*}
                a_{ij} \to a_{ij} - m_{ik}a_{kj}
            \end{align*}
            where $m_{ik} = a_{ik} / a_{kk}$ is the multiplier. Thus, updating the $(n-k) \times (n-k)$ submatrix requires $2(n-k)^{2}$ flops.
            \bigbreak \noindent 
            We require an additional $(n-k)$ flops to each multiplier, and an additional $2(n-k)$ flops to eliminate each entry below the pivot. 
            \bigbreak \noindent 
            In total, we have
            \begin{align*}
                \sum_{k=1}^{n-1}2(n-k)^{2} + (n-k) + 2(n-k) = \sum_{k=1}^{n-1}2(n-k)^{2} + 3(n-k)
            .\end{align*}
            Let $j = n-k$. When $k=1$, $j=n-1$, and when $k=n-1$, $j = 1$. So, we have
            \begin{align*}
                \sum_{j=1}^{n-1}2j^{2} + 3j &= 2 \cdot \frac{(n-1)n(2n-1)}{6} + 3 \cdot \frac{(n-1)n}{2} \\
                                            &=\frac{2}{3}n^{3} + \frac{1}{2}n^{2} - \frac{7}{6}n \approx \frac{2}{3}n^{3} + \mathcal{O}(n^{2})= \mathcal{O}(n^{3})
            .\end{align*}
        \item \textbf{Flops required to solve $Ax =b$ with $A^{-1}$}: Suppose we have a system $Ax = b$, where $A$ is nonsingular. How many flops would it take to find $A^{-1}$, and then solve $x = A^{-1}b$.
            \bigbreak \noindent 
            If $A^{-1}$ exists, then it is a matrix $X$ such that $AX = I$. So, 
            \begin{align*}
                A\begin{bmatrix} x_{11} & x_{12} & \cdots & x_{1n} \\ x_{21} & x_{22} & \cdots & x_{2n} \\ \vdots & \vdots & \ddots & \vdots \\ x_{n1} & x_{n2} & \cdots & x_{nn} \end{bmatrix}
                &= \begin{bmatrix} 1 & 0 & \cdots & 0 \\ 0 & 1 & \cdots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \cdots & 1 \end{bmatrix}
            .\end{align*}
            Let $\text{col}_{j}(X)$ denote the $j^{\text{th}}$ column of $X$, and $e_{j}$ denote the $j^{\text{th}} $ column of $I$. Then,
            \begin{align*}
               A\text{col}_{1}(X) = e_{1}, \quad A\text{col}_{2}(X) = e_{2}, \quad ..., \quad A\text{col}_{n}(X) = e_{n} 
            .\end{align*}
            In total we need to solve $n$ systems. If we solved all $n$ systems with Gaussian Elimination, it would require
            \begin{align*}
                n\left(\frac{2}{3}n^{3} + \mathcal{O}(n^{2})\right) = \frac{2}{3}n^{4} + \mathcal{O}(n^{3})
            \end{align*}
            flops. But, we can do better. Instead if we find the $LU$ decomposition for $A$, which would require $\frac{2}{3}n^{3}$ flops, we would have the $n$ systems
            \begin{align*}
                Ly_{1} &= e_{1} \quad Ly_{2} = e_{2} \quad \cdots \quad Ly_{n} = e_{n}\\
                U\text{col}_{1}(X) &= y_{1} \quad U\text{col}_{2}(X) = y_{2} \quad \cdots \quad U\text{col}_{n}(X) = y_{n}
            .\end{align*}
            We see that each system would require $2n^{2}$ flops. So, in total $2n^{3}$ flops to solve all systems. For the whole process,
            \begin{align*}
                \frac{2}{3}n^{3} + 2n^{3} = \frac{8}{3}n^{3}
            \end{align*}
            flops are required. So, $4$ times the flops of $LU$ decomposition and $8$ times the flops of Choleksy decomposition. 
    \end{itemize}


    \pagebreak 
    \subsection{Chapter 2: Sensitivity of linear systems}
    \bigbreak \noindent 
    \subsubsection{Definitions}
    \begin{itemize}
        \item \textbf{Unit ball}: A unit ball is the set of all points whose distance from the origin is less than or equal to 1
            \bigbreak \noindent 
            Given a norm $\norm{\cdot}$ on a vector space (say $\mathbb{R}^{n}$), the unit ball is the set of all points that are within distance 1 of the origin under that norm:
            \begin{align*}
                B_{\norm{\cdot }}(0,1) = \{x \in \mathbb{R}^{n}:\; \norm{x} \leq 1\}
            .\end{align*}
            Where
            \begin{itemize}
                \item \textbf{B	"Ball"}: the set of all points within a certain distance (radius)
                \item \textbf{$\mathbf{0}$}: The center of the ball (here, the origin)
                \item $\mathbf{1}$:	The radius of the ball
                \item $\norm{\cdot}$: The norm used to measure distance
            \end{itemize}
            \bigbreak \noindent 
            It’s the region that's "1 unit away" from the origin according to the norm.
            \bigbreak \noindent 
            The boundary of this set, where $\norm{x} = 1$, is called the \textbf{unit sphere} (even though it might not look like a sphere geometrically).
            \bigbreak \noindent 
            It’s the set of all vectors you can "reach" from the origin if your allowed length is 1 (according to your chosen norm).
        \item \textbf{A more general ball}: In general, a ball with center at $a$, and radius $r$ is defined as 
            \begin{align*}
                B_{\norm{\cdot }}(a,r) = \{x \in \mathbb{R}^{n}:\; \norm{x-a} \leq r\}
            .\end{align*}
        \item \textbf{Vector norms}:
            \begin{itemize}
                \item \textbf{Euclidean norm (2-norm)}: The standard Euclidean distance. For $x \in \mathbb{R}^{n}$,
                    \begin{align*}
                        \norm{x}_{2} = \sqrt{x_{1}^{2} + x_{2}^{2} + ... + x_{n}^{2}}
                    .\end{align*}
                \item \textbf{Manhattan norm (1-norm)}: Denoted $L^{1} $, and also called \textbf{Taxicab norm}. For $x \in \mathbb{R}^{n} $,
                    \begin{align*}
                        \norm{x}_{1} = \left\lvert x_{1} \right\rvert + \left\lvert x_{2} \right\rvert + ... + \left\lvert x_{n} \right\rvert
                    .\end{align*}
                \item \textbf{$L$-Infinity (max) norm ($\infty$-norm)}: Denoted $L^{\infty}$. for $x\in \mathbb{R}^{n}$,
                    \begin{align*}
                        \norm{x}_{\infty} = \max_{1 \leq i \leq n} \left\lvert x_{i} \right\rvert = \max\{\left\lvert x_{1} \right\rvert, x_{2}, ..., x_{n}\} 
                    .\end{align*}
                \item \textbf{$p$-norm}: In $\mathbb{R}^{n}$, A more general norm is
                    \begin{align*}
                        \norm{x}_{p} = \left(\sum_{i=1}^{n} \left\lvert x_{i} \right\rvert^{p}\right)^{\frac{1}{p}} = \left(\left\lvert x_{1}^{p} \right\rvert + \left\lvert x_{2} \right\rvert^{p} + ... + \left\lvert x_{n} \right\rvert^{p}\right)^{\frac{1}{p}}
                    \end{align*}
                    for $1 \leq p < \infty $. The general $p$-norm satisfies all three properties of a norm only when $p \geq 1$. For smaller $p$, the triangle inequality does not hold.
            \end{itemize}
        \item \textbf{Frobenius norm}
            \begin{align*}
                \norm{A}_{2} = \norm{A}_{F} = \left(\sum_{i=1}^{n}\sum_{j=1}^{n}\left\lvert a_{ij} \right\rvert^{2}\right)^{\frac{1}{2}}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{Note:} The Frobenius norm is not an induced norm. We have for the identity matrix $I$,
            \begin{align*}
                \norm{I}_{F} = \sqrt{n} \ne 1    
            .\end{align*}
        \item \textbf{Induced (operator) matrix norms}:     Induced (or operator) matrix norms tell us exactly how much a matrix can stretch a vector under a given vector norm.
            Given a vector norm  $\|\cdot\|$ on $\mathbb{R}^n$, the induced matrix norm of 
            $A \in \mathbb{R}^{n \times n}$ is defined as
            \begin{align*}
                \|A\| := \max_{x \neq 0} \frac{\|Ax\|}{\|x\|} = \max_{\|x\| = 1} \|Ax\|.
            .\end{align*}
            So it’s the \textbf{largest possible magnification factor} of the matrix $A$ acting as a linear transformation.
            \bigbreak \noindent 
            We know $A$ is a map that sends vectors to new vectors.  Each vector $x$ has a direction and a length:
            \begin{itemize}
                \item $\|x\|$ = its original length.
                \item $\|Ax\|$ = its new length after transformation.
            \end{itemize}
            The ratio $\dfrac{\|Ax\|}{\|x\|}$ tells you \textbf{how much} $A$ stretches or shrinks that vector.
            \bigbreak \noindent 
            The induced norm picks out the \textbf{maximum stretching} over all possible directions.  
            So $\|A\|$ represents the largest factor by which $A$ can stretch any vector.
            \bigbreak \noindent 
            If the induced norm is defined as 
            \begin{align*}
                \norm{A} = \max_{x\in \mathbb{R}^{n}\setminus \{0\}} \frac{\norm{Ax}}{\norm{x}}
            ,\end{align*}
            write $x = \norm{x} y$, so $y = \frac{x}{\norm{x}}$. Then,
            \begin{align*}
                \norm{A} = \max_{x\in \mathbb{R}^{n} \setminus \{0\}}\frac{\norm{Ax}}{\norm{x}} = \max_{\norm{y} = 1} \frac{\norm{A(\norm{x}y)}}{\norm{x}} = \max_{\norm{y} = 1} \frac{\norm{x}\norm{Ay}}{\norm{x}} = \max_{\norm{y} = 1} \norm{Ay}
            .\end{align*}


       
        \item \textbf{Induced matrix norms special cases}:
            \begin{center}
                \begin{tabular}{p{1cm}|p{5cm}|p{5cm}}
                    \toprule
                    $p$ & \textbf{Name} & \textbf{Explicit formula} \\
                    \midrule
                    $1$ & Maximum column sum &
                    $\displaystyle \|A\|_{1} = \max_{1 \leq j \leq n} \sum_{i=1}^{m} |a_{ij}|$ \\[3ex]
                    $2$ & Spectral norm &
                    $\displaystyle \|A\|_{2} = \sqrt{\lambda_{\max}(A^{T}A)}$ \\[3ex]
                    $\infty$ & Maximum row sum &
                    $\displaystyle \|A\|_{\infty} = \max_{1 \leq i \leq m} \sum_{j=1}^{n} |a_{ij}|$ \\
                    \bottomrule
                \end{tabular}
            \end{center}
            \bigbreak \noindent 
            \textbf{Note:} Recall that the eigenvalues of a $2\times 2$ matrix are
            \begin{align*}
                \lambda(A) &= \lambda^{2} - \text{Tr}(A)\lambda + \det(A) = \frac{a+d}{2} \pm \sqrt{\left(\frac{a-d}{2}\right)^{2} + bc}
            .\end{align*}
        \item \textbf{Singular values}: For $A \in \mathbb{R}^{m\times n}$, its \textbf{singular values} are the numbers
            \begin{align*}
                \sigma_{1} \geq \sigma_{2} \geq \cdots \geq \sigma_{r} > 0 
            ,\end{align*}
            defined as the square roots of the eigenvalues of $A^{T}A$
            \begin{align*}
                \sigma_{i}(A) = \sqrt{\lambda_{i}(A^{T}A)}
            .\end{align*}
            If $A$ has rank $r$, then there are $r$ positive singular values. The rest are zero.
        \item \textbf{Singular values of $A^{-1}$}: The singular values of $A^{-1}$ are the reciprocals of the singular values of $A$.
            \begin{align*}
                \sigma_{1}(A^{-1}) = \frac{1}{\sigma_{1}(A)}, \sigma_{2}(A^{-1}) = \frac{1}{\sigma_{2}(A)}, \cdots , \sigma_{n}(A^{-1}) = \frac{1}{\sigma_{n}(A)}
            .\end{align*}
        \item \textbf{Eigenvalues of $A^{T}A$}:
            \begin{align*}
                \lambda_{i}(A^{T}A) = \sigma_{i}(A)^{2}
            .\end{align*}
            Where $\sigma_{i}(A)$ is the $i$th singular value for $A$.
        \item \textbf{Singular values of $A^{T}A $}:
            \begin{align*}
                \sigma_{i}(A^{T}A) = \sqrt{\lambda_{i}((A^{T}A)^{T}(A^{T}A))} = \sqrt{\lambda_{i}(A^{T}A)^{2}}
            .\end{align*}
            But, to get the eigenvalues for the square of a matrix you square the eigenvalues for the matrix. So, $\lambda_{i}(A^{T}A)^{2} = (\lambda_{i}(A^{T}A))^{2} $. Thus,
            \begin{align*}
                \sigma_{i}(A^{T}A) = \sqrt{(\lambda_{i}(A^{T}A))^{2}} = \lambda_{i}(A^{T}A) = \sigma_{i}(A)^{2}
            .\end{align*}
            So, the singular values for $A^{T}A$ are the squares of the singular values of $A$. Thus, the set of eigenvalues for $A^{T}A$ is the same as the set of singular values for $A^{T}A$
        \item \textbf{Spectral norm}: We have
            \begin{align*}
                \norm{A}_{2} &= \max_{\norm{x}_{2} = 1} \norm{Ax}_{2} = \sigma_{1} = \sqrt{\lambda_{\text{max}}(A^{T}A)}, \\
                \norm{A^{-1}}_{2} = \frac{1}{\sigma_{n}} = \frac{1}{\sqrt{\lambda_{\text{min}}}(A^{T}A)}
            .\end{align*}
        \item \textbf{Relative error}: The relative error in $\hat{x}$ is given by
            \begin{align*}
                \frac{\norm{\hat{x} - x}}{\norm{x}} = \frac{\norm{\delta x}}{\norm{x}}
            \end{align*}
            where $\hat{x} = x + \delta  x $, which implies $x = \hat{x} - \delta  x $.
        \item \textbf{Perturbation}: $\hat{A}$ and $\hat{b}$ are called perturbed if they are modified versions of the original. If $\hat{A}$ is a perturbed matrix $A$, and $\hat{b}$ is a perturbed vector $b$, then
            \begin{align*}
                \hat{A} &= A + \delta A, \\
                \hat{b} &= b + \delta  b
            .\end{align*}
            \textbf{Note:} When we say $\delta A$ or $\delta  b$, we do not mean some constant $\delta$ times some matrix $A$ or some vector $b$, They represent changes (perturbations), we have
            \begin{align*}
                \delta A &= \hat{A} - A, \\
                \delta b &= \hat{b} - b
            .\end{align*}
            They are differences, not scaled versions. If $\hat{A}$ is a perturbed $A$, then $\delta A$ is simply the matrix of entrywise differences:
            \begin{align*}
                \left(\delta A\right)_{ij} = \hat{a}_{ij} - a_{ij}
            .\end{align*}
        \item \textbf{Condition number $\kappa(A)$}: The condition number of a matrix $A$ measures how sensitive the solution of a linear system $A x = b$ is to small changes in $b$ (or in $A$).
            \begin{align*}
                \kappa(A) = \norm{A^{-1}}\norm{A}
            .\end{align*}
            \bigbreak \noindent 
            We see that as $\kappa(A) \to \infty$, the relative error in $x$ grows without bound.
        \item \textbf{Condition number $(\kappa_{2}(A))$}:
            \begin{align*}
                \kappa_{2}(A) = \norm{A^{-1}}_{2}\norm{A}_{2} = \sigma_{\text{max}} \cdot \frac{1}{\sigma_{\text{min}}} = \frac{\sigma_{\text{max}}}{\sigma_{\text{min}}}
            .\end{align*}
        \item \textbf{Condition number $(\kappa_{2}(A^{T}A)) $}:
            \begin{align*}
                \kappa_{2}(A^{T}A) = \frac{\sigma_{\text{max}}(A^{T}A)}{\sigma_{\text{min}}(A^{T}A)} =\frac{\sigma_{\text{max}}(A)^{2}}{\sigma_{\text{min}}(A)^{2}} = \kappa_{2}^{2}(A)
            .\end{align*}
        \item \textbf{Numerical stability vs conditioning}
            \begin{itemize}
                \item \textbf{Conditioning}
                \begin{itemize}
                    \item A property of the \textbf{mathematical problem} itself.
                    \item Measures the \textbf{sensitivity} of the true solution to small input changes.
                    \item Example: if $A x = b$, then
                        \[
                            \frac{\|\delta x\|}{\|x\|} \le \kappa(A) \frac{\|\delta b\|}{\|b\|}.
                        \]
                        A large $\kappa(A)$ indicates an \textbf{ill-conditioned problem}.
                \end{itemize}
            \item \textbf{Numerical Stability}
                \begin{itemize}
                    \item A property of the \textbf{algorithm} used to solve the problem.
                    \item Measures how much \textbf{round-off and truncation errors} the algorithm introduces or amplifies.
                    \item A \textbf{stable algorithm} gives the exact solution to a \textit{nearby problem}:
                        \[
                            (A + \delta A)\hat{x} = b + \delta  b , \quad \|\delta A\|,\; \| \delta b\| \text{ small.}
                        \]
                \end{itemize}
        \end{itemize}
        \textbf{Note:} If an algorithm is \textbf{numerically unstable}, then the perturbations 
        $\delta A$ and/or $\delta b$ required to explain its result might be \textbf{large}:
        \[
            \|(A + \delta A) - A\| \text{ is not small.}
        \]
        Hence, the computed $\hat{x}$ is the exact solution to a \textit{far-away problem}:
        \[
            (A + \delta A)\hat{x} = b + \delta b,
        \]
        where $\|\delta A\|$ or $\|\delta b\|$ are no longer small compared to 
        $\|A\|$ or $\|b\|$.
        \bigbreak \noindent 
        This means the algorithm’s result may not correspond meaningfully to the 
        original system at all.
        \item \textbf{Ball of guaranteed nonsingularity (neigborhood of nonsingularity)}: The ball in matrix space with center $A$ and radius $r = \norm{A} / \kappa(A)$ is
        \begin{align*}
            \mathcal{B}(A,r) = \{A + \delta  A:\; \norm{\delta A} < r\},
        \end{align*}
        where $r = \frac{\norm{A}}{\kappa(A)} $. Any matrix within the ball is nonsingular, and any matrix outside the ball or on the boundary is singular.

    \item \textbf{Backward stable algorithm}: A backward stable algorithm is one that produces the exact solution to a slightly perturbed version of the original problem.



    \end{itemize}

    \pagebreak 
    \subsubsection{Properties}
    \begin{itemize}
        \item \textbf{Norms}: 
            $\norm{\cdot}$ is a norm if and only if the following properties are satisfied
            \begin{enumerate}
                \item $\norm{x} = 0 \iff x= 0 $ 
                \item $ \norm{\alpha x} = \left\lvert \alpha \right\rvert \norm{x}$
                \item $\norm{x+y} \leq \norm{x} + \norm{y} $ (triangle inequality)
            \end{enumerate}
        \item \textbf{Matrix norms}: A matrix norm is a function 
            \begin{align*}
                \norm{\cdot }:\ \mathbb{R}^{n\times n} \to \mathbb{R}_{+}:\ A \mapsto  \norm{A}
            .\end{align*}
        \item \textbf{Properties of matrix norms}: Matrix norms satisfy the three required properties of norms.
            \begin{enumerate}
                \item $\norm{A} = 0 \iff A = 0 $
                \item $\norm{\alpha A} = \left\lvert \alpha \right\rvert \norm{A} $
                \item $\norm{A + B} \leq \norm{A} + \norm{B} $ (Triangle inequality)
            \end{enumerate}
       
        \item \textbf{Additional properties of matrix norms};
            \begin{enumerate}
                \item $\norm{A} < \infty$ for any finite matrix $A$
            \end{enumerate}

        \item \textbf{Properties of induced matrix norms}
            \begin{itemize}
                \item \textbf{Sub-multiplicativity}: $\norm{AB}_{p} \leq \norm{A}_{p}\norm{B}_{p} $
                \item \textbf{Consistency}: $\norm{Ax}_{p} \leq \norm{A}_{p}\norm{x}_{p} $
                \item \textbf{Normalization}: $\norm{I}_{p} = 1 $
            \end{itemize}
        \item \textbf{Additional induced matrix norm properties}
            \begin{enumerate}
                \item If $A$ is singular, then $A^{-1}$ does not exists, we define
                    \begin{align*}
                        \norm{A^{-1}} = \infty
                    .\end{align*}
                \item For any $A \in \mathbb{R}^{m\times n} $, 
                    \begin{align*}
                        \norm{A} = \norm{A^{T}}
                    .\end{align*}
                    Except for $\norm{A}_{1}$ and $\norm{A}_{\infty}$. In this case,
                    \begin{align*}
                        \norm{A^{T}}_{1}= \norm{A}_{\infty}
                    .\end{align*}
            \end{enumerate}
        \item \textbf{Properties of the spectral norm}
            \begin{enumerate}
                \item $\norm{I}_{2} = 1 $ (Since the eigenvalues are all one)
                \item $\norm{A^{T}}_{2} = \norm{A}_{2} $
                \item $\norm{Q} = \norm{Q^{T}} = \norm{Q^{-1}} = 1$ for $Q$ orthogonal
            \end{enumerate}
        \item \textbf{Properties of the condition number}: Let $A$ be a matrix, and $\kappa(A)$ be the condition number that measures the system $Ax = b$. The following two properties hold
            \begin{enumerate}
                \item $\kappa(A) \geq 1$
                \item $\kappa(I) = 1$
                \item $\kappa(A) = \kappa(A^{-1}) $
            \end{enumerate}
        \item \textbf{Additional properties of the condition number}:
            \begin{enumerate}
                \item Since $\norm{A} = \norm{A^{T}}$, 
                    \begin{align*}
                        \kappa(A) = \kappa(A^{T}) 
                    .\end{align*}
            \end{enumerate}
        \item \textbf{Well-conditioned and ill-conditioned in terms of $\kappa(A)$}: If $\kappa(A)$ is large, then $(P)$ is ill-conditioned. If $\kappa(A)$ is small (close to one), then $(P)$ is well-conditioned.
        \item \textbf{The condition number also measures how close $A$ is to singularity}: The condition number
            \begin{align*}
                \kappa(A) = \norm{A^{-1}}\norm{A}
            \end{align*}
            measures how close a matrix $A $ is to being \textbf{singular}. If $A$ is singular, then $A^{-1}$ does not exist, meaning that
            \[
                \norm{A^{-1}} = \infty.
            \]
            Therefore,
            \[
                \kappa(A) = \infty 
                \quad \text{if and only if} \quad 
                A \text{ is singular},
            \]
            and $\kappa(A) \to \infty$ as $A$ approaches singularity.



    \end{itemize}

    \pagebreak 
    \subsubsection{Theorems}
    \begin{itemize}
        \item \textbf{Theorem \textit{(Relative Error Bound I)}}: Let $A$ be nonsingular, $b \ne 0$, and $Ax = b$. If $A(x + \delta  x) = b + \delta  b$, then
            \begin{align*}
                \frac{\norm{ \delta  x}}{\norm{ x}} \leq \kappa(A) \frac{\norm{\delta  b }}{\norm{ b}}
            \end{align*}
            where $\kappa(A) = \norm{A^{-1}}\norm{A}$. According to this bound.
            \bigbreak \noindent 
            \textbf{Analysis}: As $\kappa(A) \to \infty$, 
            \begin{align*}
                \frac{\norm{\delta x}}{\norm{x}} \leq \kappa(A) \frac{\norm{\delta b}}{\norm{b}} \to \infty
            .\end{align*}
            So, as $\kappa(A)\to \infty$, for a fixed nonzero relative perturbation in $b$, the bound allows the relative error in $x$ to become arbitrarily large. If the relative error in $b$ is zero, then 
            \begin{align*}
                0 \leq \frac{\norm{\delta x}}{\norm{x}}  \leq 0  \implies \frac{\norm{\delta x}}{\norm{x}} = 0
            .\end{align*}
            \bigbreak \noindent 
            As $\kappa(A) \to 1$, 
            \begin{align*}
                \frac{\norm{\delta x}}{\norm{x}} \leq \kappa(A) \frac{\norm{\delta b}}{\norm{b}} \to \frac{\norm{\delta b}}{\norm{b}}
            .\end{align*}
            Thus, perturbations in $b$ produce at most proportional perturbations in $x$.
        \item \textbf{Theorem (\textit{Singularity of perturbed $A$})}: If
            \begin{align*}
                \frac{\norm{\delta A}}{\norm{A}} < \frac{1}{\kappa(A)}
            \end{align*}
            then $A + \delta  A$ is nonsingular.
        \item \textbf{Theorem \textit{(Relative error bound II)}}: Let $A$ be nonsingular, $b\ne 0$, and $Ax=b$. If $(A + \delta A)(x + \delta x) = b$, and 
            \begin{align*}
                \frac{\norm{\delta  A}}{\norm{A}} < \frac{1}{\kappa(A)},
            \end{align*}
            then
            \begin{align*}
                \frac{\norm{\delta x}}{\norm{x}} \leq \frac{\kappa(A)\frac{\norm{\delta A}}{\norm{A}}}{1-\kappa(A)\frac{\norm{\delta A}}{\norm{A}}}
            .\end{align*}
        \item \textbf{Theorem \textit{(Relative error bound III)}}:  Let $A$ be nonsingular, $b\ne 0$, and $Ax=b$. If $(A + \delta A)(x + \delta x) = b + \delta  b$, and 
            \begin{align*}
                \frac{\norm{\delta  A}}{\norm{A}} < \frac{1}{\kappa(A)},
            \end{align*}
            then
            \begin{align*}
                \frac{\norm{\delta x}}{\norm{x}} \leq \frac{\kappa(A)\left(\frac{\norm{\delta A}}{\norm{A}} + \frac{\norm{\delta b}}{\norm{b}}\right)}{1-\kappa(A)\frac{\norm{\delta A}}{\norm{A}}}
            .\end{align*}


    \end{itemize}

    \pagebreak 
    \subsubsection{Algorithms and complexities}
    \begin{itemize}
        \item \relax
    \end{itemize}

    \pagebreak 
    \subsection{Chapter 3: The least squares problem and orthogonal matrices}
    \subsubsection{Definitions}
    \begin{itemize}
        \item \textbf{Over-determined systems}: If a system $Ax = b$ has more equations than unknowns $(m > n) $, we call the system \textbf{over-determined}
        \item \textbf{under-determined systems}: If a system $Ax = b$ has less equations than unknowns $(m < n) $, we call the system \textbf{under-determined}
        \item \textbf{Determined system}: If a system $Ax = b$ has the same number of equations as unknowns $(m = n)$, we call the system \textbf{determined}.
        \item \textbf{Well-determined and degenerate}: If a system $Ax = b$ has a unique solution for a given $b$, then the system is said to be \textbf{well-determined}. If the system has no solution or infinitely many, the system is \textbf{degenerate}.
        \item \textbf{The discrete least squares problem}: Let $A \in \mathbb{R}^{m\times n}$, where $m \geq n$, and $b \in \mathbb{R}^{m} $. The discrete least squares problem is finding
            \begin{align*}
                \min_{x\in \mathbb{R}^{n}} \norm{r}_{2}^{2},
            \end{align*}
            where $ r = b - Ax$. If $b \not\in \text{Im}(L) = \text{col}(A)$, then no solution to $Ax = b$ exists, and we can instead solve the discrete least squares problem to get the best approximation. 
            \bigbreak \noindent 
            Recall that since the closest point in a subspace to a vector is its orthogonal projection, minimizing $\norm{r}_{2}^{2}$ is equivalent to finding the projection of $b$ onto the column space of $A$.
        \item \textbf{Orthogonal matrices}: A matrix $Q \in \mathbb{R}^{n\times n}$ is orthogonal if $QQ^{T} = Q^{T}Q = I$, so $Q^{T} = Q^{-1}$. 
            \bigbreak \noindent 
            An orthogonal matrix is a matrix whose columns form a set of orthonormal vectors, each has length one and is perpendicular to the others.
        \item \textbf{Definition of orthogonal matrices}: $Q \in \mathbb{R}^{n\times n}$ is orthogonal if the columns of $Q$ satisfy
            \begin{enumerate}
                \item $\norm{q_{i}} = 1$ for $i = 1,2,...,n $
                \item $\left\langle q_{i}, q_{j} \right\rangle = 0$ if $i \ne j $
            \end{enumerate}
        \item \textbf{The discrete LSP with $QR$}
            \begin{align*}
                \min_{x\in \mathbb{R}^{n}}\norm{b- Ax}_{2}^{2} = \min_{x\in \mathbb{R}^{n}}\norm{\hat{c}-\hat{R}x}_{2}^{2} + \norm{\bar{c}}_{2}^{2},\\
            .\end{align*}
            $x$ is found by solving the system $\hat{R}x = \hat{c}$, and the residual is $\norm{\bar{c}}_{2}^{2}$
        \item \textbf{$QR$ factorization of a square matrix}: Let $A \in \mathbb{R}^{n\times n}$, then $Q \in \mathbb{R}^{n\times n}$, $R = \hat{R} \in \mathbb{R}^{n\times n}$, $Q^{T}b = c = \hat{c}$, and
            \begin{align*}
                Ax = b \implies QRx = b \implies Rx = Q^{T}b \implies \hat{R}x = Q^{T}b = \hat{c}
            .\end{align*}
            So, since $\hat{R}$ is upper triangular, we can solve the system using backward substitution.
        \item \textbf{Givens rotations}: A Givens rotation is an orthogonal transformation that acts only in a 2-dimensional coordinate plane — say the plane spanned by the $i$-th and $j$-th coordinate axes. It’s the identity matrix except for a $2\times 2$ rotation block:
            \begin{align*}
                G(i,j,\theta ) = \begin{bmatrix}
                    1 & & & & & & \\
                      & \ddots & & & & & \\
                      & & c & & s  & \\
                      & & & 1 & & & \\
                      & & -s & & c & \\
                      & & &  & & \ddots &\\
                      & & & & & & 1
                \end{bmatrix},\; \quad c = \cos{\left(\theta \right)},\; s = \sin{\left(\theta \right)}
            .\end{align*}
            Everywhere else its the identity matrix $I$. Only entries $(i,i), (i,j), (j,i), (j,j)$ are modified.
        \item \textbf{$QR$ with Householder reflectors}: Let $A \in \mathbb{R}^{m\times n}$, where
            \begin{align*}
                A =
                \begin{bmatrix}
                    \mid & \mid & \cdots & \mid \\
                    x^{1} & x^{2} & \cdots & x^{n} \\
                    \mid & \mid & \cdots & \mid
                \end{bmatrix}                
            ,\end{align*}
            where $x^{j}$ denotes the $j^{\text{th}}$ column of $A$. For each column $j$ of $A$, we have the following steps
            \begin{enumerate}
                \item $\tau_{j} = \text{sgn}(x_{1})\norm{x^{j}}_{2}$ 
                \item $\gamma_{j} = \frac{\tau_{j} + x_{1}}{\tau_{j}} $
                \item $u_{j} = \begin{pmatrix} 1 \\ x_{2}/(\tau_{j} + x_{1}) \\ \vdots \\ x_{m}/(\tau_{j} + x_{1})\end{pmatrix} $
                \item $Q_{j} = I - \gamma_{j}u_{j}u_{j}^{T} $
            \end{enumerate}
            Then, just like with givens rotations, $Q = Q_{k} \cdots Q_{j} \cdots Q_{2}Q_{1}$, and $R = QA  = Q_{k}\cdots Q_{j} \cdots Q_{2}Q_{1}A$.
            \bigbreak \noindent 
            We can avoid forming $Q$ with
            \begin{align*}
                Qx = x - \gamma (u^{T}x)u
            .\end{align*}

        \item \textbf{Normal equations}: The equations
            \begin{align*}
                A^{T}Ax = A^{T}b
            \end{align*}
            that solve the least squares problem
            \begin{align*}
                \min_{x\in\mathbb{R}^{n}}\norm{b-Ax}_{2}^{2}
            \end{align*}
            are called the \textbf{normal equations}. They characterize the vector $x$ for which the residual $b-Ax$ is orthogonal to the column space of $A$.
            


    \end{itemize}

    \pagebreak 
    \subsubsection{Properties}
    \begin{itemize}
        \item \textbf{Properties of orthogonal matrices}
            \begin{enumerate}
                \item $Q^{T}Q = QQ^{T} = I $
                \item $Q^{-1} = Q^{T} $
                \item $\det(Q) = \pm 1 $
            \end{enumerate}
        \item \textbf{Additional properties of orthogonal matrices}:
            \begin{enumerate}
                \item The product of orthogonal matrices is orthogonal
                \item If $Q$ is orthogonal, so is $Q^{T} $
            \end{enumerate}
        \item \textbf{Properties of Givens rotation}: Let $Q$ be the givens rotation matrix
            \begin{enumerate}
                \item $Q^{T}Q = QQ^{T} = I$ ($Q$ is orthogonal)
            \end{enumerate}
        \item \textbf{Properties of Householder reflection matrices}
            \begin{enumerate}
                \item \textbf{Symmetry}: $Q = Q^{T}$
                \item \textbf{Orthogonality}: $Q^{T}Q = QQ^{T} = I $
            \end{enumerate}
        \item \textbf{Properties of the normal matrix}: Let $A \in \mathbb{R}^{m\times n}$
            \begin{enumerate}
                \item $A^{T}A \succeq 0$
                \item $A^{T}A \succ 0 \iff \text{ rank}(A) = n $
            \end{enumerate}

    \end{itemize}

    \pagebreak 
    \subsubsection{Theorems}
    \begin{itemize}
        \item \textbf{Projection onto a line theorem}: Let $\ell$ be a line spanned by a vector $q$, and $v$ be a vector not on $\ell$. Project $v$ down onto $\ell$, call this projection $p$. The residual (error) vector $v - p$ is orthogonal to the line $\ell$.
        \item \textbf{Orthogonal projection theorem}: Let $W$ be a subspace of $\mathbb{R}^{n}$, and $x$ be a vector in $\mathbb{R}^{n}$. The closest point in $W$ to $x$ is its orthogonal projection onto $W$, denoted $\text{proj}_{W}(x) = w$. That is,
            \begin{align*}
                \min_{w\in W} \norm{x - w} = \text{proj}_{W}(x)
            .\end{align*}
        \item \textbf{Theorem}: If $Q \in \mathbb{R}^{n\times n}$ is orthogonal, then
            \begin{enumerate}
                \item $\left\langle Qx, Qy \right\rangle  = \left\langle x,y \right\rangle$
                \item $\norm{Qx}_{2} = \norm{x}_{2} $
            \end{enumerate}

    \end{itemize}

    \pagebreak 
    \subsubsection{Propositions}
    \begin{itemize}
        \item \relax
    \end{itemize}

    \pagebreak 
    \subsubsection{Algorithms and complexities}
    \begin{itemize}
        \item \textbf{The discrete LSP algorithm}: Let $A \in \mathbb{R}^{m\times n}$, for $m > n$. Define
            \begin{align*}
                (P):\; \min_{x\in \mathbb{R}^{n}}\norm{x-Ax}_{2}^{2}
            .\end{align*}
            \bigbreak \noindent 
            To solve discrete least squares, we take the following steps
            \begin{enumerate}
                \item $c = Q^{T}b = \begin{bmatrix} \hat{c} \\ \bar{c} \end{bmatrix} $, $c \in \mathbb{R}^{m}$, $\hat{c} \in \mathbb{R}^{n}$, $\bar{c} \in \mathbb{R}^{m-n} $
                \item Solve $(\hat{P}):\; \hat{R}x = \hat{c}$, solution of $ (\hat{P})$ is the solution of $(P)$.
                \item $\min_{x\in \mathbb{R}^{n}}\norm{b-Ax}_{2}^{2} = \norm{\bar{c}}_{2}^{2} $
            \end{enumerate}
            \textbf{Note:} For now we want to assume that $\text{rank}(A) = n$, so all columns are linearly independent. In this case, $\hat{r}_{ii} \ne 0$.
    \end{itemize}

    \pagebreak 
    \subsection{Chapter 1 Proofs}
    \bigbreak \noindent 
    \subsubsection{Positive definite (1)}
    \begin{itemize}
        \item \textbf{Theorem n.1.1}: Let $A\in \mathbb{R}^{n\times n}$, $ A = \begin{bmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{bmatrix} $ be a positive definite matrix. Then $A_{11}, \; A_{22}$ are positive definite.
            \bigbreak \noindent 
            Note that $A_{11} \in \mathbb{R}^{n_{1} \times n_{1}}$, $A_{12} \in \mathbb{R}^{n_{1} \times n_{2}}$, $A_{21} \in \mathbb{R}^{n_{2} \times n_{1}}$, and $A_{22} \in \mathbb{R}^{n_{2} \times n_{2}}$. So, $n = n_{1} + n_{2} $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A \in \mathbb{R}^{n\times n}$, $A = \begin{bmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{bmatrix} $, $A$ positive definite.
            \bigbreak \noindent
            First, we show that $A_{11} = A_{11}^{\top}$, and $A_{22} = A_{22}^{\top}$. Since $A$ p.d, 
            \begin{align*}
                A = A^{\top} \implies \begin{bmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{bmatrix} = \begin{bmatrix} A_{11}^{\top} & A_{21}^{\top} \\ A_{12}^{\top} & A_{22}^{\top} \end{bmatrix}
            .\end{align*}
            So, we see that
            \begin{align*}
                A_{11} &= A_{11}^{\top}, \\
                A_{22} &= A_{22}^{\top}
            .\end{align*}
            \bigbreak \noindent 
            Next, we show that $x^{\top}A_{11}x >0$, for $x \in \mathbb{R}^{n_{1}}$, $x\ne 0$ and $x^{\top}A_{22} x > 0$ for $x \in \mathbb{R}^{n_{2}} $, $x \ne 0 $
            \bigbreak \noindent 
            Let $ \bar{x} \in \mathbb{R}^{n_{1}}$, $ \bar{x} = \begin{pmatrix} x_{1} \\ 0 \end{pmatrix} $, $x_{1} \ne 0 $. Note that $ \bar{x}^{\top} = \begin{pmatrix} x_{1}^{\top} & 0\end{pmatrix} $. We observe
            \begin{align*}
                0 < \bar{x}^{\top} A x &= \begin{pmatrix} x_{1}^{\top} & 0 \end{pmatrix} \begin{bmatrix} A_{11} & A_{12} \\ A_{21} & A_{22} \end{bmatrix} \begin{pmatrix} x_{1} \\ 0 \end{pmatrix} \\
                    &= x_{1}^{\top}A_{11}x_{1} > 0
            .\end{align*}
            Similarly, $ \bar{x} \in \mathbb{R}^{n}$, $ \bar{x} = \begin{pmatrix} 0 \\ x_{2} \end{pmatrix} $, $ x_{2} \ne 0 \in \mathbb{R}^{n_{2}}$ reveals $x_{2}^{\top}A_{22}x_{2} > 0$.
            \bigbreak \noindent 
            Therefore, $A_{11},\; A_{22}$ are positive definite. $\endpf$
        \item \textbf{Theorem n.1.2}: Let $A \in \mathbb{R}^{n\times n}$ be a positive definite matrix, then $a_{ii} > 0$ for $i = 1,2,...,n $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume that $A \in \mathbb{R}^{n\times n}$ is a positive definite matrix. Define $e_{i}$ as the set of vectors with all zeros except for a one at the $i^{\text{th}}$ position. Since $A$ is positive definite,
            \begin{align}
                e_{i}^{\top} A e_{i} = a_{ii} > 0
            \end{align}
            for $i = 1,2,...,n$ $ \endpf $
            \bigbreak \noindent 
        \item \textbf{Theorem n.1.3}: Let $A \in \mathbb{R}^{n \times n}$ be a positive definite matrix and $X \in \mathbb{R}^{n\times n}$ be nonsingular. Then, $B = X^{\top}AX$ is positive definite.
            \bigbreak \noindent 
            \begin{remark}
                If $A,B,C$ are matrices, then     
                \begin{align*}
                    (ABC)^{\top} = C^{\top}B^{\top}A^{\top}
                \end{align*}
            \end{remark}
            \textbf{\textit{Proof.}} Assume that $A \in \mathbb{R}^{n\times n}$ is positive definite, $X\in \mathbb{R}^{n\times n}$ nonsingular, and $B = X^{\top}AX$. 
            \bigbreak \noindent 
            First, we show that $B = B^{\top}$. We have
            \begin{align*}
                B^{\top} &= (X^{\top}AX)^{\top} = X^{\top}A^{\top}(X^{\top})^{\top} \\
                &= X^{\top}A^{\top}X
            .\end{align*}
            But, $A$ is positive definite, and is therefore symmetric. So,
            \begin{align*}
                B^{\top} &= X^{\top}AX = B
            .\end{align*}
            Thus, $B$ is symmetric.
            \bigbreak \noindent 
            Next, we show that $x^{\top}Bx >0$, for $x \in \mathbb{R}^{n}$, $x\ne 0$. We have
            \begin{align*}
                x^{\top}Bx &= x^{\top}(X^{\top}AX)x = (x^{\top}X^{\top})A(Xx) \\
                &= (Xx)^{\top}A(Xx)
            \end{align*}
            Let $y = Xx$. Thus,
            \begin{align*}
                (Xx)^{\top}A(Xx) = y^{\top}Ay
            \end{align*}
            \bigbreak \noindent 
            Note that since $ x \ne 0 $, and $X$ nonsingular, $y = Xx \ne 0$. Since $y \ne 0$, and $A$ p.d, $y^{\top}Ay >0$. 
            \bigbreak \noindent 
            Therefore, $B$ is positive definite. $\endpf $
        \item \textbf{Theorem n.1.4}: Let $A$ be positive definite. Then, $\det(A) > 0$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A$ is a positive definite matrix.
            \bigbreak \noindent 
            Since $A$ p.d,  $A = R^{\top}R$ for a unique upper triangular matrix $R$. Further, $r_{ii} >0$. We have
            \begin{align*}
                A &= R^{\top}R \\
                \implies \det(A) &= \det(R^{\top}R) \\
                                 &= \det(R^{\top})\det(R) \\
                                 &= \det(R)\det(R) \\
                                 &= \det(R)^{2} \\
                                 &= (r_{11}\cdot r_{12}\cdot \cdots \cdot r_{1n})^{2} \\
                                 &= r_{11}^{2}\cdot r_{12}^{2}\cdot \cdots \cdot r_{1n}^{2} > 0 \\
            .\end{align*}
            Therefore $\det(A)  > 0$ $\endpf $




    \end{itemize}

    \pagebreak 
    \subsection{Chapter 2 Proofs}
    \begin{itemize}
        \item \textbf{The vector 2-norm is a norm}: To prove that this is true, we need to show that $\norm{x}_{2}$ satisfies the following properties
            \begin{enumerate}
                \item $\norm{x}_{2} = 0 \iff x = 0$
                \item $\norm{\alpha x}_{2} = \left\lvert \alpha \right\rvert \norm{x}_{2} $
                \item $\norm{x + y}_{2} \leq \norm{x}_{2}  + \norm{y}_{2} $
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} (1) If $\norm{x}_{2} = 0$, then
            \begin{align*}
                \norm{x} = 0 &\implies \left(x_{1}^{2} + x_{2}^{2} + ... + x_{n}^{2}\right)^{\frac{1}{2}} = 0 \\
                             &\iff x_{1}^{2} + x_{2}^{2} + ... + x_{n}^{2} = 0 \\
                             &\iff x_{1} = x_{2} =  ... = x_{n} = 0
            .\end{align*}
            Conversely, if $x=0$, then
            \begin{align*}
                \norm{0}_{2} &= \left(0^{2} + 0^{2} + ... + 0^{2}\right)^{\frac{1}{2}} = 0^{\frac{1}{2}} = 0
            .\end{align*}
            (2)
            \begin{align*}
                \norm{\alpha x}_{2} &= \left((\alpha x_{1})^{2} + (\alpha x_{2})^{2} + ... + (\alpha x_{n})^{2}\right)^{\frac{1}{2}} \\
                                &= \left(\alpha^{2} x_{1}^{2} + \alpha^{2} x_{2}^{2} + ... + \alpha^{2} x_{n}^{2}\right)^{\frac{1}{2}} \\
                                &= \left(\alpha^{2}(x_{1}^{2} + x_{2}^{2} + ... + x_{n}^{2})\right)^{\frac{1}{2}} \\
                                &= (\alpha^{2})^{\frac{1}{2}}  (x_{1}^{2} + x_{2}^{2} + ... + x_{n}^{2})^{\frac{1}{2}} \\
                                &= \left\lvert \alpha \right\rvert \norm{x}_{2}
            .\end{align*}
            As desired.
            \bigbreak \noindent 
            (3)
            \begin{align*}
                \norm{x + y}^{2}_{2} &= (x+y)^{T}(x+y) = x^{T}x + x^{T}y + y^{T}x + y^{T}y \\
                                 &= x^{T}x + 2x^{T}y + y^{T}y = \norm{x}_{2}^{2} + 2x^{T}y + \norm{y}_{2}^{2}
            .\end{align*}
            By Cauchy Schwarz, $x^{T}y \leq \norm{x}_{2}\norm{y}_{2}$. So,
            \begin{align*}
                \norm{x}_{2}^{2} + 2x^{T}y + \norm{y}_{2}^{2} \leq \norm{x}_{2}^{2} + 2\norm{x}_{2}\norm{y}_{2} + \norm{y}_{2}^{2} = \left(\norm{x}_{2} + \norm{y}_{2}\right)^{2}
            .\end{align*}
            Since $\norm{x}_{2}^{2} + 2x^{T}y + \norm{y}_{2}^{2} = \norm{x+y}^{2}$, we have
            \begin{align*}
                \norm{x+y}_{2}^{2} \leq \left(\norm{x}_{2} + \norm{y}_{2}\right)^{2},
            \end{align*}
            which implies $\norm{x+y}_{2} \leq \norm{x}_{2} + \norm{y}_{2}$ $\endpf$



    \end{itemize}

    \pagebreak 
    \unsect{Geometric linear algebra}
    \subsection{Vectors in $\mathbb{R}^{n}$, projections, and parallelepipeds}
    \begin{itemize}
        \item \textbf{Displacement vector}: Let $P,Q$ be points in $\mathbb{R}^{n} $, the vector that goes from $P$ to $Q$ is denoted
            \begin{align*}
                \overrightarrow{PQ} = Q - P
            .\end{align*}
            This vector represents the \textbf{displacement} needed to move from $P$ to $Q$. So, $\overrightarrow{PQ}$ is called the \textbf{displacement vector} and represents the displacement from $P$ to $Q$.
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{displace}
                \label{fig:displace}
            \end{figure}
            \bigbreak \noindent 
            Recall that the position of a vector is arbitrary. Vectors only encode two things, length and direction. 
            \bigbreak \noindent 
            Vectors in $\mathbb{R}^{n}$ are always defined by two points, a starting point and an ending point. When a vector in $\mathbb{R}^{n}$ begins at the origin, then $P-O = P$, since $O = (0,0,0,...,0)$. Thus, the end point $P$ is what determines the length and direction, and so the coordinates of the vector are precisely the coordinates of $P$.
            \bigbreak \noindent 
            Notice that we can flip the vector by starting at $P$ and arriving at $O$, this gives $O - P$, or $-P$.
            \bigbreak \noindent 
            So, the displacement vector from $P_{\text{start}}$ to $P_{\text{end}}$ is always
            \begin{align*}
                P_{\text{end}} - P_{\text{start}}
            .\end{align*}
            \bigbreak \noindent 
            Consider a displacement vector from $P$ to $Q$ in $\mathbb{R}^{2}$. If $P = (2,3)$, and $Q =(4,1) $, then
            \begin{align*}
             v_{PQ} = \overrightarrow{PQ} = Q-P = \begin{pmatrix} 4-2 \\ 1-4 \end{pmatrix}    =\begin{pmatrix} 2 \\ -3 \end{pmatrix}
            .\end{align*}
            If we were to position this vector $v_{PQ}$ starting from the origin, the length and direction would remain the same, but the destination would loose meaning, as it would arrive at a different point. The destination would be $(2,-3)$.
        \item \textbf{Vector acting at a point}: Suppose we had some point $P \in \mathbb{R}^{n}$, and a vector $v \in \mathbb{R}^{n} $. Then, 
            \begin{align*}
                P + v 
            \end{align*}
            is the point you reach by starting at $P$ and moving in the direction of $v$. So, a vector \textbf{based at} $P$ is represented as 
            \begin{align*}
                P \xrightarrow{\; v \;} P + v
            .\end{align*}
            We can see this by using displacement vectors. Starting from $P$ and moving along $v$, we will reach some end point $Q$, if $P$ and $v$ are known, and $Q$ is unknown, then we can find $Q$ by solving for $v$ using the displacement from $P$ to $Q$
            \begin{align*}
                Q - P = v \implies Q = P + v    
            .\end{align*}
        \item \textbf{Projection onto a line theorem}: Let $\ell$ be a line spanned by a vector $q$, and $v$ be a vector not on $\ell$. Project $v$ down onto $\ell$, call this projection $p$. The residual (error) vector $v - p$ is orthogonal to the line $\ell$.
            \bigbreak \noindent 
            \textbf{\textit{Proof}}. The projection of $v$ onto $\ell$ is given by
            \begin{align*}
                \text{proj}_{\ell}(v) = \frac{v^{T}q}{q^{T}q}q
            .\end{align*}
            Thus, the error $v-p$ is
            \begin{align*}
                r = v - \frac{v^{T}q}{q^{T}q}q
            .\end{align*}
            So,
            \begin{align*}
                r^{T}q &= \left(v - \frac{v^{T}q}{q^{T}q}q\right)^{T} q \\
                       &= v^{T}q - \left(\frac{v^{T}q}{q^{T}q}q\right)^{T}q \\
                       &=v^{T}q - q^{T} \left(\frac{v^{T}q}{q^{T}q}\right)^{T}q \\
                       &= v^{T}q - \frac{v^{T}q}{q^{T}q}q^{T}q \\
                       &=v^{T}q - v^{T}q = 0
                   .\end{align*}
                   So, $r \perp q $.
                   \bigbreak \noindent 
                   \begin{figure}[ht]
                       \centering
                       \incfig{iamperp}
                       \label{fig:iamperp}
                   \end{figure}
                   \bigbreak \noindent 
                   In general, the residual in the projection of a vector onto a space is orthogonal to the space.
               \item \textbf{Projection onto a line derivation}: Consider a line $\ell$, a vector $a$ on $\ell$, and a vector $b$. Define the projection of $b$ onto $a$ as $p$. That is, $p = \text{proj}_{a}(b)$. Since $p$ and $a$ lie on the same line, they are parallel. So, $p = xa$, for $x \in \mathbb{R}$.
                   \bigbreak \noindent 
                   Define the residual as $r = b - p$. Since the residual $r$ is orthogonal to $p$, we have $r \perp p$, so
                   \begin{align*}
                       r^{T}p &= 0\\ 
                       \implies (b-p)^{T}p &= 0 \\
                       \implies (b-xa)^{T}xa &= 0 \\
                       \implies b^{T}xa - xa^{T}xa &= 0 \\
                       \implies b^{T}xa &= x^{2}a^{T}a \\
                       \implies b^{T}a &=  xa^{T}a \\
                       \implies x &= \frac{b^{T}a}{a^{T}a} = \frac{a^{T}b}{a^{T}a}
                   .\end{align*}
                   Thus, 
                   \begin{align*}
                       \text{proj}_{a}(b) = p = xa = \frac{a^{T}b}{a^{T}a}a 
                   .\end{align*}
                   Notice that we can move some things around, and get
                   \begin{align*}
                       p &= a \frac{a^{T}b}{a^{T}a} = \frac{1}{a^{T}a}aa^{T} b
                   .\end{align*}
                   Notice that $\frac{1}{a^{T}a}aa^{T}$ is a matrix. Call this matrix the projection matrix $P$. We therefore have that
                   \begin{align*}
                       \text{proj}_{a}(b) = p = Pb 
                   ,\end{align*}
                   where $P = \frac{1}{a^{T}a}aa^{T}$ is the projection matrix that projects vectors onto $a$ (the line $\ell $).
               \item \textbf{Norm of the projection onto a line}: Let $a,b \in \mathbb{R}^{n}$. From above,
                   \begin{align*}
                       p = \text{proj}_{a}(b) = \frac{a^{T}b}{a^{T}a} a
                   .\end{align*}
                   Thus,
                   \begin{align*}
                       \norm{p} = \norm{\frac{a^{T}b}{a^{T}a}a} = \left\lvert \frac{a^{T}b}{a^{T}a} \right\rvert \norm{a} = \frac{a^{T}b}{\norm{a}^{2}} \norm{a} = \frac{a^{T}b}{\norm{a}}
                   .\end{align*}
               \item \textbf{Geometric inner product}: Let $a,b \in \mathbb{R}^{n}$. By projecting one onto the other, we create a right triangle since the residual is always orthogonal to the vector being projected onto. 
                   \bigbreak \noindent 
                   \begin{figure}[ht]
                       \centering
                       \incfig{res}
                       \label{fig:res}
                   \end{figure}
                   \bigbreak \noindent 
                   Thus, a right triangle is formed. This fact is true regardless of the dimension $n$. Notice that
                   \begin{align*}
                       p = \frac{a^{T}b}{a^{T}a}a,\quad \norm{p}_{2} = \frac{a^{T}b}{\norm{a}_{2}}
                   ,\end{align*}
                   and
                   \begin{align*}
                       \cos{\left(\theta \right)} = \frac{\norm{p}_{2}}{\norm{b}_{2}} = \frac{a^{T}b}{\norm{a}_{2}} \left(\frac{1}{\norm{b}_{2}}\right)
                   .\end{align*}
                   Thus,
                   \begin{align*}
                       a^{T}b = \norm{a}_{2}\norm{b}_{2}\cos{\left(\theta \right)},\quad \theta = \cos^{-1}{\left(\frac{a^{T}b}{\norm{a}_{2}\norm{b}_{2}}\right)}
                   .\end{align*}
               \item \textbf{Sine of the angle between $a$ and $b$}: Consider the figure above, we have that 
                   \begin{align*}
                       \sin{\left(\theta \right)} = \frac{\norm{r}_{2}}{\norm{b}_{2}}
                   .\end{align*}
                   Since $r = b - p$, 
                   \begin{align*}
                       r = b - \frac{a^{T}b}{a^{T}a}a = \frac{(a^{T}a)b - (a^{T}b)a}{a^{T}a}
                   .\end{align*}
                   So,
                   \begin{align*}
                       \norm{r}_{2} = \frac{1}{a^{T}a}\norm{(a^{T}a)b - (a^{T}b)a}_{2}
                   .\end{align*}
                   Thus,
                   \begin{align*}
                       \sin{\left(\theta \right)} = \frac{\norm{(a^{T}a)b - (a^{T}b)a}_{2}}{\norm{a}^{2}_{2}\norm{b}_{2}} = \frac{\norm{q}_{2}}{\norm{a}_{2}^{2}\norm{b}_{2}}
                   ,\end{align*}
                   where $q = (a^{T}a)b - (a^{T}b)a$
               \item \textbf{Area of the parallelogram spanned by $a$ and $b$}: Consider a parallelogram with sides spanned by $a,b \in \mathbb{R}^{n}$
                   \bigbreak \noindent 
                   \begin{figure}[ht]
                       \centering
                       \incfig{pgram}
                       \label{fig:pgram}
                   \end{figure}
                   \bigbreak \noindent 
                   Recall that the area of such a shape is base $\times$ height, so
                   \begin{align*}
                       A = \norm{b}_{2} \cdot h
                   .\end{align*}
                   Notice that
                   \begin{align*}
                       \sin{\left(\theta \right)} = \frac{h}{\norm{a}_{2}} \implies h = \norm{a}_{2}\sin{\left(\theta \right)}
                   .\end{align*}
                   But, $\theta$ is precisely the angle between $a$ and $b$, and we derived a formula for the sine of that angle above. That formula is
                   \begin{align*}
                       \sin{\left(\theta \right)} = \frac{\norm{(a^{T}a)b - (a^{T}b)a}_{2}}{\norm{a}_{2}^{2}\norm{b}_{2}}
                   .\end{align*}
                   So, the height of the parallelogram is given by
                   \begin{align*}
                       h = \norm{a}_{2}\sin{\left(\theta \right)} = \norm{a}_{2} \frac{\norm{(a^{T}a)b - (a^{T}b)a}_{2}}{\norm{a}_{2}^{2}\norm{b}_{2}} = \frac{\norm{(a^{T}a)b - (a^{T}b)a}_{2}}{\norm{a}_{2}\norm{b}_{2}}
                   .\end{align*}
                   With this information, the area of the parallelogram spanned by two vectors $a,b \in \mathbb{R}^{n}$ is given by 
                   \begin{align*}
                       A = \norm{b}_{2} h = \norm{a}_{2} \norm{b}_{2}\sin{\left(\theta \right)} &= \norm{a}_{2}\norm{b}_{2} \frac{\norm{(a^{T}a)b - (a^{T}b)a}_{2}}{\norm{a}_{2}^{2}\norm{b}_{2}} \\
                        &= \frac{\norm{(a^{T}a)b - (a^{T}b)a}_{2}}{\norm{a}_{2}} 
                    .\end{align*}
                \item \textbf{Gram determinants form of area of a parallelogram spanned by $a$ and $b$ and the sine of the angle between them}: Let $a,b\in \mathbb{R}^{n}$, consider the form above for $\sin{\left(\theta \right)} $,
                    \begin{align*}
                        \sin{\left(\theta \right)} = \frac{\norm{(a^{T}a)b - (a^{T}b)a}_{2}}{\norm{a}_{2}^{2}\norm{b}_{2}}
                    .\end{align*}
                    Let $\alpha,\;\beta,\; \gamma \in \mathbb{R} $ with
                    \begin{align*}
                        \alpha = a^{T}a = \norm{a}_{2}^{2},\quad \beta = a^{T}b,\quad \gamma = b^{T}b = \norm{b}_{2}^{2},
                    \end{align*}
                    and define
                    \begin{align*}
                        v := (a^{T}a)b - (a^{T}b)a
                    .\end{align*}
                    Thus,
                    \begin{align*}
                        v = \alpha b - \beta a
                    .\end{align*}
                    Compute $\norm{v}_{2}^{2}$,
                    \begin{align*}
                        \norm{v}_{2}^{2} = v^{T}v &= (\alpha b - \beta a)^{T}(\alpha b - \beta a) = (\alpha b^{T} - \beta a^{T})(\alpha b - \beta a) \\
                                                  &=\alpha^{2}b^{T}b - \alpha \beta b^{T}a - \alpha \beta a^{T}b + \beta^{2}a^{T}a = \alpha^{2}b^{T}b - 2\alpha \beta a^{T}b + \beta^{2}a^{T}a \\
                                                  &= \alpha^{2}\gamma - 2 \alpha \beta^{2} + \beta^{2} \alpha = \alpha^{2}\gamma - \alpha \beta^{2} = \alpha(\alpha \gamma - \beta^{2})
                  .\end{align*}
                  Thus,
                  \begin{align*}
                      \norm{v}_{2} = \sqrt{\norm{v}_{2}^{2}} = \sqrt{\alpha(\alpha\gamma - \beta^{2})} = \sqrt{\alpha}\sqrt{\alpha\gamma - \beta^{2}}
                  .\end{align*}
                  So,
                  \begin{align*}
                      \sin{\left(\theta \right)} &= \frac{\norm{v}_{2}}{\norm{a}_{2}^{2}\norm{b}_{2}} = \frac{\sqrt{\alpha}\sqrt{\alpha\gamma - \beta^{2}}}{\alpha \sqrt{\gamma}} = \frac{\sqrt{\alpha\gamma - \beta^{2}}}{\sqrt{\alpha}\sqrt{\gamma}} \\
                     &= \frac{\sqrt{(a^{T}a)(b^{T}b)-(a^{T}b)^{2}}}{\norm{a}_{2}\norm{b}_{2}} = \frac{\sqrt{\norm{a}_{2}^{2}\norm{b}_{2}^{2} - (a^{T}b)^{2}}}{\norm{a}_{2}\norm{b}_{2}}
                 ,\end{align*}
                 and the height is therefore given by
                 \begin{align*}
                    h = \norm{a}_{2}\sin{\left(\theta \right)} = \norm{a}_{2} \frac{\sqrt{\norm{a}_{2}^{2}\norm{b}_{2}^{2} - (a^{T}b)^{2}}}{\norm{a}_{2}\norm{b}_{2}} = \frac{\sqrt{\norm{a}_{2}^{2}\norm{b}_{2}^{2} - (a^{T}b)^{2}}}{\norm{b}_{2}}
                 .\end{align*}
                 Thus, the area of the parallelogram is
                 \begin{align*}
                     A = \norm{b}_{2} h = \norm{a}_{2}\norm{b}_{2}\sin{\left(\theta \right)} = \sqrt{\norm{a}_{2}^{2}\norm{b}_{2}^{2} - (a^{T}b)^{2}}
                 .\end{align*}
                 \textbf{Note:} Notice that the quantity $\sqrt{(a^{T}a)(b^{T}b) - (a^{T}b)^{2}} $ can be expressed with
                 \begin{align*}
                     \sqrt{\det\begin{pmatrix} a^{T}a & a^{T}b \\ a^{T}b & b^{T}b \end{pmatrix}}
                 .\end{align*}
                 Thus,
                 \begin{align*}
                     A = \sqrt{\det\begin{pmatrix} a^{T}a & a^{T}b \\ a^{T}b & b^{T}b \end{pmatrix}} = \norm{a}_{2}\norm{b}_{2}\sin{\left(\theta \right)}
                 .\end{align*}
                 That determinant you see above is called the \textbf{Gram determinant}, or the \textbf{Gramian determinant} of the pair $\{a,b\} $, for $a,b \in \mathbb{R}^{n} $
             \item \textbf{Gram matrix and Gram determinant}: Given vectors $v_{1},...,v_{k} $ in an inner product space, their \textbf{Gram matrix} is 
                 \begin{align*}
                     G = (v_{i}^{T}v_{j})_{i,j=1}^{k}
                 ,\end{align*}
                 and the determinant $\det(G) $ is the \textbf{Gram} determinant, with interpretations
                 \begin{itemize}
                     \item It equals the squared $k$-dimensional volume of the parallelepiped spanned by the vectors $v_{1},...,v_{k}$
                     \item It is always nonnegative (Gram matrix is positive semidefinite).
                     \item It vanishes exactly when the vectors are linearly dependent.
                 \end{itemize}
 \item \textbf{Area of parallelogram spanned by two vectors $a$, $b$ in 2-d space}: Consider $a,b \in \mathbb{R}^{2}$ with
     \begin{align*}
         a = \begin{pmatrix} x_{1} \\ y_{1} \end{pmatrix},\quad b = \begin{pmatrix} x_{2} \\ y_{2} \end{pmatrix}
     .\end{align*}
     From the derivation above,
     \begin{align*}
         A = \sqrt{\det\begin{pmatrix} a^{T}a & a^{T}b \\ a^{T}b & b^{T}b  \end{pmatrix}}
     .\end{align*}
     Since
     \begin{align*}
         a^{T}a &= x_{1}^{2} + y_{1}^{2}, \quad a^{T}b = x_{1}x_{2} + y_{1}y_{2}, \quad b^{T}b = x_{2}^{2} + y_{2}^{2}
     ,\end{align*}
     we have
     \begin{align*}
         A &= \sqrt{(x_{1}^{2} + y_{1}^{2})(x_{2}^{2} + y_{2}^{2}) - (x_{1}x_{2} + y_{1}y_{2})^{2}} \\
           &= \sqrt{(x_{1}x_{2})^{2}  + (x_{1}y_{2})^{2} + (x_{2}y_{1})^{2} + (y_{1}y_{2})^{2} - ((x_{1}x_{2})^{2} + 2x_{1}y_{1}x_{2}y_{2} + (y_{1}y_{2})^{2})} \\
           &=\sqrt{(x_{1}x_{2})^{2}  + (x_{1}y_{2})^{2} + (x_{2}y_{1})^{2} + (y_{1}y_{2})^{2} - (x_{1}x_{2})^{2} - 2x_{1}y_{1}x_{2}y_{2} - (y_{1}y_{2})^{2}} \\
           &= \sqrt{(x_{1}y_{2})^{2}-2x_{1}y_{2}x_{2}y_{1} + (x_{2}y_{1})^{2}} = \sqrt{(x_{1}y_{2} - x_{2}y_{1})^{2}} = \left\lvert  x_{1}y_{2} - x_{2}y_{1} \right\rvert
       .\end{align*}
       Thus, the area of the parallelogram spanned by $a,b \in \mathbb{R}^{2}$ is the absolute value of the determinant of the matrix formed by $a,b$ as the columns. Specifically,
       \begin{align*}
           A = \left\lvert \det(M)  \right\rvert = \left\lvert \det\begin{pmatrix} x_{1} & x_{2} \\ y_{1} & y_{2} \end{pmatrix} \right\rvert
       .\end{align*}
   \item \textbf{Parallelograms in $n$-dimensional space}: A parallelogram can be formed by two vectors in any dimension $\mathbb{R}^{n}$. Two vectors always span a $2$-dimensional plane inside $\mathbb{R}^{n} $, and in that plane you can form a parallelogram exactly as in 2D.
       \bigbreak \noindent 
       Let $v,w \in \mathbb{R}^{n} $. If they are not multiples of each other, the set
       \begin{align*}
           \text{span}\{v,w\}
       \end{align*}
       is a 2-dimensional plane inside $\mathbb{R}^{n} $. Inside that plane, the geometry is exactly like ordinary 2D geometry, and the two vectors form a parallelogram the same way they do in the plane.
       \bigbreak \noindent 
       If $v$ and $w$ are multiples, then they lie on a line and the parallelogram collapses to a segment (area 0).
       \bigbreak \noindent 
       Take two vectors  $v,w \in \mathbb{R}^{n}$. Consider the set of all linear combinations:
       \begin{align*}
           \text{span}\{v,w\} = \{sv + tw:\; s,t \in \mathbb{R}\}
       .\end{align*}
       This set contains all vectors you can reach by moving in directions $v$ and $w$
       \bigbreak \noindent 
       There are two possibilities
       \begin{enumerate}
           \item $v$ and $w$ are multiples. Then,
               \begin{align*}
                   w = \lambda v 
               .\end{align*}
               Everything in the span lies on a single line. So the span is 1-dimensional.
           \item If $v$ and $w$ are not multiples, then the two directions are independent. You can move forward / backward along $v$, and forward / backward along $w$, and by combing these motions, you generate a flat 2-dimensional plane inside $\mathbb{R}^{n}$.
               \bigbreak \noindent 
               This plane behaves exactly like $\mathbb{R}^{2} $, but embedded in higher-dimensional space.
               \bigbreak \noindent 
               Thus,
               \begin{align*}
                   \text{dim}(\text{span}\{v,w\}) = 2
               .\end{align*}
       \end{enumerate}
       So, even if the vectors have 5 or 100 coordinates, $v,w \in \mathbb{R}^{100} $, they still span a 2D plane (inside 100-dimensional space), so long as they are not multiples. 
       \bigbreak \noindent 
       The key idea is that $k$ independent vectors in $n$-dimensional space define $k$ unique directions, so the span of these $k$ independent vectors in $n$-space define a $k$-dimensional space embedded in $k$-space.
       \bigbreak \noindent 
       This is why 
       \begin{align*}
           A = \sqrt{(v^{T}v)(w^{T}w) - (v^{T}w)^{2}}
       \end{align*}
       even when $v,w \in \mathbb{R}^{n}$
   \item \textbf{Unit square}: The unit square is the set
       \begin{align*}
           Q = \{(c_{1}, c_{2} \in \mathbb{R}^{2}:\; 0 \leq c_{1}, c_{2} \leq 1)\}
       ,\end{align*}
       which is intrinsically a 2-dimensional object. Its defining basis vectors are
       \begin{align*}
           e_{1} = \begin{pmatrix} 1 \\ 0 \end{pmatrix},\quad e_{2} = \begin{pmatrix} 0 \\ 1 \end{pmatrix}
       ,\end{align*}
       and they live in $\mathbb{R}^{2}$, not $\mathbb{R}^{n}$.
       \bigbreak \noindent 
       When we talk about parallelograms in higher-dimensional spaces, the unit square does not move into $\mathbb{R}^{n}$ . Instead, it is mapped into $\mathbb{R}^{n}$ by a linear transformation.
    \item \textbf{Describing a parallelogram using a matrix}: Let $v_{1}, v_{2} \in \mathbb{R}^{n}$ define a parallelogram. Define the matrix
        \begin{align*}
            A = \begin{bmatrix} v_{1} & v_{2} \end{bmatrix}
        .\end{align*}
        These vectors define the set
        \begin{align*}
            P = \{av_{1} + bv_{2}:\; 0 \leq a,b \leq 1\}
        ,\end{align*}
        which is the parallelogram that lives in the 2-dimensional subspace
        \begin{align*}
            W = \text{span}\{v_{1}, v_{2}\} \subset \mathbb{R}^{n}
        .\end{align*}
        Although the ambient space is $\mathbb{R}^{n}$, all geometry is intrinsically planar. The extra dimensions are irrelevant except for how the plane is embedded.
        \bigbreak \noindent 
        \textbf{Note:} "\textbf{Planar geometry}" refers to shapes and arrangements confined to a single flat plane (2D).
        \bigbreak \noindent 
        The matrix $A$ defines
        \begin{align*}
            A:\; \mathbb{R}^{2} \to \mathbb{R}^{n},\quad (c_{1}, c_{2}) \mapsto c_{1}v_{1} + c_{2} v_{2}
        .\end{align*}
        Consider the unit square, defined by basis vectors $e_{1}, e_{2} \in \mathbb{R}^{2} $. Under $A$, 
        \begin{align*}
            Ae_{1} = v_{1}, \quad Ae_{2} = v_{2}
        .\end{align*}
        Thus, the unit square in $\mathbb{R}^{2}$ is mapped to the parallelogram defined by $v_{1}$ and $v_{2}$.
        \bigbreak \noindent 
        Consider $u \in \mathbb{R}^{2}$, with $u = \begin{pmatrix} u_{1} \\ u_{2} \end{pmatrix} $
        \begin{align*}
            Au = u_{1}v_{1} + u_{2}v_{2}
        .\end{align*}
        If $0 \leq u_{1}, u_{2} \leq 1$, then $Au$ lies inside the parallelogram (or on its boundary). If one or the coordinates is negative or exceeds 1, then $Au$ lies in the same plane, but outside the parallelogram. Thus, $Au$ parameterizes position relative to the parallelograms edges.
        \bigbreak \noindent 
        Consider the map $A^{T}$, 
        \begin{align*}
            A^{T} = \begin{pmatrix} v_{1}^{T} \\ v_{2}^{T} \end{pmatrix}
        .\end{align*}
        So, 
        \begin{align*}
            A^{T}A = \begin{pmatrix} v_{1}^{T} \\ v_{2}^{T} \end{pmatrix} \begin{pmatrix} v_{1} & v_{2} \end{pmatrix} = \begin{pmatrix} v_{1}^{T}v_{1} & v_{1}^{T} v_{2} \\ v_{1}^{T} v_{2} & v_{2}^{T} v_{2} \end{pmatrix}
        ,\end{align*}
        which is precisely the Gram matrix. Thus,
        \begin{align*}
            \mathcal{A}(P) = \sqrt{\det(A^{T}A)}
        ,\end{align*}
        where $\mathcal{A}(P)$ is the area of the parallelogram spanned by $v_{1}$ and $v_{2}$.
    \item \textbf{Parallelograms using a point $P$}: Take any point $P \in \mathbb{R}^{n}$, define one side as 
        \begin{align*}
            P \rightarrow P + v
        ,\end{align*}
        and the adjacent side
        \begin{align*}
            P \rightarrow P + w
        .\end{align*}
        For two vectors $v,w \in \mathbb{R}^{n}$. Then, the parallelogram is
        \begin{align*}
            \{P + sv + tw:\; 0 \leq s \leq 1,\; 0 \leq t \leq 1\}
        .\end{align*}
        This describes a true parallelogram lying in the 2D subspace embedded in $n$-space
    \item \textbf{Cross product for area}: Recall that for two vectors $v,w \in \mathbb{R}^{3}$, the cross product $v \times w$ gives the third vector $u \in \mathbb{R}^{3}$ orthogonal to $v$ and $w$, and the area of the parallelogram formed by $v,w$ is given by
        \begin{align*}
            \norm{v\times w}_{2} = \norm{v}_{2}\norm{w}_{2}\sin{\left(\theta \right)}
        .\end{align*}
        In higher dimensions, the cross product does not exist as a vector, but the same geometric quantity exists:
        \begin{align*}
            \text{Area} = \norm{v}_{2}\norm{w}_{2}\sin{\left(\theta \right)}
        .\end{align*}
        This is valid in any inner product space, including $\mathbb{R}^{n}$. Alternatively, one can compute the Gram determinant.
    \item \textbf{Unit cube}: Just like how $e_{1}, e_{2} \in \mathbb{R}^{2}$ defines the \textbf{unit square} in 2-dimensional space $(\mathbb{R}^{2})$, the basis vectors $e_{1},e_{2}, e_{3}$ define the \textbf{unit cube} in $\mathbb{R}^{3}$. The unit cube is the set of points
        \begin{align*}
            Q = \{(c_{1}, c_{2}, c_{3}) \in \mathbb{R}^{3}:\; 0 \leq c_{1}, c_{2}, c_{3} \leq 1\}
        .\end{align*}
    \item \textbf{Parallelepiped}: A parallelepiped is a 3D geometric shape made of six parallelograms, like a slanted box, where opposite faces are parallel and congruent, related to a parallelogram as a cube is to a square.  
        \bigbreak \noindent 
        A parallelepiped is the solid generated by three vectors $v_{1}, v_{2}, v_{3} \in \mathbb{R}^{3}$, and consists of all points of the form
        \begin{align*}
            \{av_{1} + bv_{2} + cv_{3}:\; 0 \leq a,b,c \leq 1\}
        .\end{align*}
        \bigbreak \noindent 
        \begin{figure}[h]
            \centering
            \incfig{piped}
            \label{fig:piped}
        \end{figure}
        \bigbreak \noindent 
        Equivalently, it is the image of the unit cube under the linear map whose columns are $v_{1}, v_{2}, v_{3}$. A parallelepiped has the following properties
        \begin{itemize}
            \item 8 vertices
            \item 12 edges
            \item 6 faces, each a parallelogram
            \item Opposite faces are parallel and congruent
            \item All edges come in three parallel families corresponding to $v_{1}, v_{2}, v_{3}$
            \item It has $3C2 = 3$ distinct parallelograms, the remaining three faces are congruent to one of the three distinct ones.
        \end{itemize}
        It need not have right angles; a rectangular box is a special case.
        \bigbreak \noindent 
        The parallelepiped has three distinct parallelogram faces, each defined by choosing two of the three vectors that define it. Thus, 
        \begin{align*}
            P_{1} &= \{a_{1} v_{1} + b_{1}v_{2}:\; 0 \leq a_{1}, b_{1} \leq 1\}, \\
            P_{2} &= \{a_{2} v_{1} + b_{2}v_{2}:\; 0 \leq a_{2}, b_{2} \leq 1\}, \\
            P_{3} &= \{a_{3} v_{1} + b_{3}v_{2}:\; 0 \leq a_{3}, b_{3} \leq 1\} 
        .\end{align*}
        Let $\mathcal{A}(P_{i})$ be the area of such faces. Then, the surface area of the parallelepiped is
        \begin{align*}
            \mathcal{S} = 2(\mathcal{A}(P_{1}) + \mathcal{A}(P_{2}) + \mathcal{A}(P_{3}))
        .\end{align*}
        Let $A_{1} = \begin{bmatrix} v_{1} & v_{2} \end{bmatrix},\; A_{2} = \begin{bmatrix} v_{1} & v_{3} \end{bmatrix},\; A_{3} = \begin{bmatrix} v_{2} & v_{3} \end{bmatrix}$, for each distinct face $P_{i}$, 
        \begin{align*}
            \mathcal{A}(P_{i}) = \sqrt{\det\left(A_{i}^{T}A_{i}\right)}
        .\end{align*}
        Thus,
        \begin{align*}
            \mathcal{S} = 2 \left(\sqrt{\det\left(A_{1}^{T}A_{1}\right)} + \sqrt{\det\left(A_{2}^{T}A_{2}\right)} + \sqrt{\det\left(A_{3}^{T}A_{3}\right)} \right)
        .\end{align*}
        The volume of the solid is given by the area of base times the height. If the base is the parallelogram spanned by $v_{1}$ and $v_{2}$, then the height of the solid orthogonal to these sides.
        \bigbreak \noindent 
        The area of the base defined by $v_{1}$ and $v_{2}$ is 
        \begin{align*}
            \mathcal{A}(v_{1}, v_{2}) = \sqrt{\det \left(\begin{pmatrix} v_{1}^{T} \\ v_{2}^{T} \end{pmatrix} \begin{pmatrix} v_{1} & v_{2} \end{pmatrix}\right)} = \sqrt{(v_{1}^{T}v_{1})(v_{2}^{T}v_{2}) - (v_{1}^{T}v_{2})^{2}}
        .\end{align*}
        To find the height of the solid $h$, we can project $v_{3}$ onto the plane spanned by $v_{1}$ and $v_{2}$, then the height $h$ is the residual $v_{3} - \text{proj}_{\text{span}\{v_{1}, v_{2}\}}(v_{3}) $.
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{proj2}
            \label{fig:proj2}
        \end{figure}
        \bigbreak \noindent 
        Where $\mathcal{W} = \text{span}\{v_{1}, v_{2}\}$, $p \in \mathcal{W} $, and $v_{3} - p = h \perp \mathcal{W}$. Thus, let $V = \begin{bmatrix} v_{1} & v_{2} \end{bmatrix} $, then
        \begin{align*}
            p = \text{proj}_{\mathcal{W}}(v_{3}) = V(V^{T}V)^{-1}V^{T}v_{3}
        .\end{align*}
        Note that we can instead find the projection by solving the normal equations
        \begin{align*}
            V^{T}V \begin{pmatrix} \alpha \\ \beta \end{pmatrix} = V^{T}v_{3}
        \end{align*}
        for $\alpha$ and $\beta$, then finding $p$ with
        \begin{align*}
            p = \alpha v_{1} + \beta v_{2}
        .\end{align*}
        Then, the height vector is given by $v_{3} - p$, and so the height of the solid is
        \begin{align*}
            \norm{h}_{2} &= \norm{v_{3} - p}_{2} = \norm{v_{3} - V\left(V^{T}V\right)^{-1}V^{T}v_{3}}_{2}
        .\end{align*}
        If we compute the square of the norm of $h$, we see
        \begin{align*}
            \norm{h}_{2}^{2} &= h^{T}h = (v_{3} - p)^{T}(v_{3} - p) = v_{3}^{T}v_{3} -2v_{3}^{T}p + p^{T}p
        .\end{align*}
        But,
        \begin{align*}
            p^{T}p = v_{3}^{T}V(V^{T}V)^{-1}V^{T}v_{3} = v_{3}^{T}p
        ,\end{align*}
        so
        \begin{align*}
            \norm{h}_{2} &=  \sqrt{\norm{v_{3}}_{2}^{2} - v_{3}^{T}p} = \sqrt{\norm{v_{3}}_{2}^{2} - v_{3}^{T}V(V^{T}V)^{-1}V^{T}v_{3} } \\
            &= \sqrt{v_{3}^{T}(I-P)v_{3}}
        .\end{align*}
        \bigbreak \noindent 
        Then, with the area of the base and the height, we can compute the volume $\mathcal{V}$ of the parallelepiped spanned by $v_{1},\; v_{2}$, and $v_{3}$
        \begin{align*}
            \mathcal{V} &= \mathcal{A}(v_{1}, v_{2})\norm{h}_{2} = \sqrt{(v_{1}^{T}v_{1})(v_{2}^{T}v_{2}) - (v_{1}^{T}v_{2})^{2}} \sqrt{\norm{v_{3}}_{2}^{2} - v_{3}^{T}V(V^{T}V)^{-1}V^{T}v_{3} } 
        .\end{align*}
        With some work, one can show that
        \begin{align*}
            v_{3}^{T}V(V^{T}V)^{-1}V^{T}v_{3} &= \frac{v_{3}^{T}v_{1}(v_{2}^{T}v_{2}v_{1}^{T}v_{3}-v_{1}^{T}v_{2}v_{2}^{T}v_{3}) + v_{3}^{T}v_{2}(v_{1}^{T}v_{1}v_{2}^{T}v_{3} - v_{1}^{T}v_{2}v_{1}^{T}v_{3})}{v_{1}^{T}v_{1}v_{2}^{T}v_{2} - (v_{1}^{T}v_{2})^{2}}
        .\end{align*}
        Thus,
        \begin{align*}
            &\norm{h}_{2} = \sqrt{v_{3}^{T}v_{3} - \frac{v_{3}^{T}v_{1}(v_{2}^{T}v_{2}v_{1}^{T}v_{3}-v_{1}^{T}v_{2}v_{2}^{T}v_{3}) + v_{3}^{T}v_{2}(v_{1}^{T}v_{1}v_{2}^{T}v_{3} - v_{1}^{T}v_{2}v_{1}^{T}v_{3})}{v_{1}^{T}v_{1}v_{2}^{T}v_{2} - (v_{1}^{T}v_{2})^{2}}} \\
            &=\sqrt{\frac{v_{3}^{T}v_{3}(v_{1}^{T}v_{1}v_{2}^{T}v_{2} - (v_{1}^{T}v_{2})^{2}) - v_{3}^{T}v_{1}(v_{2}^{T}v_{2}v_{1}^{T}v_{3}-v_{1}^{T}v_{2}v_{2}^{T}v_{3}) - v_{3}^{T}v_{2}(v_{1}^{T}v_{1}v_{2}^{T}v_{3} - v_{1}^{T}v_{2}v_{1}^{T}v_{3})      }{v_{1}^{T}v_{1}v_{2}^{T}v_{2} - (v_{1}^{T}v_{2})^{2}}}\\
            &=\sqrt{\frac{v_{3}^{T}v_{3}(v_{1}^{T}v_{1}v_{2}^{T}v_{2} - (v_{1}^{T}v_{2})^{2}) + v_{3}^{T}v_{1}(v_{1}^{T}v_{2}v_{2}^{T}v_{3}-v_{2}^{T}v_{2}v_{1}^{T}v_{3}) - v_{3}^{T}v_{2}(v_{1}^{T}v_{1}v_{2}^{T}v_{3} - v_{1}^{T}v_{2}v_{1}^{T}v_{3})      }{v_{1}^{T}v_{1}v_{2}^{T}v_{2} - (v_{1}^{T}v_{2})^{2}}}
        .\end{align*}
        Let $G$ be the Gram matrix, and $A$ be the matrix whose columns are $v_{1}, v_{2}, v_{3}$. That is, $A = \begin{bmatrix} v_{1} & v_{2} & v_{3} \end{bmatrix} \in \mathbb{R}^{n\times 3}$
        \begin{align*}
            G = \begin{bmatrix} V^{T}V & V^{T}v_{3} \\ v_{3}^{T}V & v_{3}^{T}v_{3} \end{bmatrix} = \begin{bmatrix} v_{1}^{T}v_{1} & v_{1}^{T}v_{2} & v_{1}^{T} v_{3} \\ v_{2}^{T}v_{1} & v_{2}^{T}v_{2} & v_{2}^{T} v_{3} \\ v_{3}^{T}v_{1} & v_{3}^{T}v_{2} & v_{3}^{T} v_{3} \\ \end{bmatrix} = A^{T}A
        .\end{align*}
        Notice that the numerator of $\norm{h}_{2}$ is precisely the determinant of $G$ (expand along the bottom row). So,
        \begin{align*}
            \norm{h}_{2} = \sqrt{\frac{\det(G)}{v_{1}^{T}v_{1}v_{2}^{T}v_{2} - (v_{1}^{T}v_{2})^{2}}} = \sqrt{\frac{\det(G)}{\det(V^{T}V)}}
        .\end{align*}
        Thus, we finally arrive at the volume of the parallelepiped spanned by three vectors $v_{1},v_{2},v_{3} \in \mathbb{R}^{n}$, where $v_{1}$ and $v_{2}$ define the base parallelogram.
        \begin{align*}
            \mathcal{V} &= \sqrt{(v_{1}^{T}v_{1})(v_{2}^{T}v_{2}) - (v_{1}^{T}v_{2})^{2}} \sqrt{\frac{\det(G)}{\det(V^{T}V)}} \\
                        &= \sqrt{\det(V^{T}V)} \sqrt{\frac{\det(G)}{\det(V^{T}V)}} = \sqrt{\det(G)}
        .\end{align*}
        \textbf{Note:} If $v_{1}, v_{2}, v_{3} \in \mathbb{R}^{3}$, then $A = \begin{bmatrix} v_{1} & v_{2} & v_{3} \end{bmatrix}\in \mathbb{R}^{3\times 3}$. So $\det(A)$ exists, and
        \begin{align*}
            G = A^{T}A \implies \det(G) = \det(A^{T}A) = \det(A^{T})\det(A) = \det(A)^{2}
        .\end{align*}
        Therefore, for $v_{1}, v_{2}, v_{3} \in \mathbb{R}^{3}$, 
        \begin{align*}
            \mathcal{V} = \sqrt{\det(G)} = \sqrt{(\det(A))^{2}} = \left\lvert \det(A) \right\rvert
        .\end{align*}
    \item \textbf{Projection onto a plane}: Consider a plane spanned by linearly independent vectors $v,w\in \mathbb{R}^{n}$, so
        \begin{align*}
            \mathcal{P} = \text{span}\{v,w\}
        .\end{align*}
        Observe that this is a 2-dimensional plane embedded in the ambient space $\mathbb{R}^{n}$. Suppose that $b\in \mathbb{R}^{n}$ is a vector not in the plane $\mathcal{P}$. We wish to project this vector $b$ onto $\mathcal{P}$. That is, we project $b$ onto $\text{span}\{v,w\} $. Call this projection $p$. The residual is then $b - p$, which is orthogonal to all vectors in $\mathcal{P}$, namely $v$ and $w$.
        \bigbreak \noindent 
        Projecting $b$ onto $\mathcal{P}$ yields $p \in \mathcal{P}$, so 
        \begin{align*}
            p = \alpha v + \beta w
        .\end{align*}
        $b-p$ is orthogonal to both $v$ and $w$, so
        \begin{align*}
            v^{T}(b-p) = 0 \implies v^{T}(b-(\alpha v + \beta w)) = 0, \\
            w^{T}(b-p) = 0 \implies w^{T}(b-(\alpha v + \beta w)) = 0
        .\end{align*}
        Thus, 
        \begin{align*}
            \alpha v^{T} v + \beta v^{T} w = v^{T}b, \\
            \alpha w^{T} v + \beta w^{T} w = w^{T}b
        .\end{align*}
        Let $V = \begin{bmatrix} v & w \end{bmatrix}  \in \mathbb{R}^{n\times 2}$, so $V^{T} = \begin{bmatrix} v^{T} \\ w^{T} \end{bmatrix} \in \mathbb{R}^{2\times n}$, and 
        \begin{align*}
            V^{T}V = \begin{bmatrix} v^{T}v & v^{T}w \\ v^{T}w & w^{T}w \end{bmatrix} \in \mathbb{R}^{2\times 2}
        .\end{align*}
        So, our \textbf{projection system}, which yields the \textbf{projection equations}, also called the \textbf{normal equations} is
        \begin{align*}
            V^{T}Vc = V^{T}b 
        ,\end{align*}
        where $c = \begin{pmatrix} \alpha \\ \beta \end{pmatrix} $ is the coefficient vector containing the coefficients to $p \in \mathcal{P}$, the projection of $b$ onto the space spanned by $v$ and $w$.
        \bigbreak \noindent 
        \textbf{Note:} Notice that $p = Vc$, and $c = (V^{T}V)^{-1}V^{T}b $. Thus,
        \begin{align*}
            p = \text{proj}_{\mathcal{P}}(b) = V(V^{T}V)^{-1}V^{T}b
        .\end{align*}
        Define the projection matrix $V(V^{T}V)^{-1}V^{T} = P$, then
        \begin{align*}
            p = \text{proj}_{\mathcal{P}}(b) = Pb
        .\end{align*}
        The 2-norm of $p$ is given by
        \begin{align*}
           \norm{p}_{2} = \norm{V(V^{T}V)^{-1}V^{T}b}_{2}
        .\end{align*}
        If we compute the square of the norm,
        \begin{align*}
            \norm{p}_{2} = p^{T}p &= \left(V(V^{T}V)^{-1}V^{T}b\right)^{T}\left(V(V^{T}V)^{-1}V^{T}b\right) \\
                         &=\left(VV^{-1}V^{-T}V^{T}b\right)^{T}\left(VV^{-1}V^{-T}V^{T}b\right) \\
                         &=b^{T}VV^{-1}V^{-T}V^{T}VV^{-1}V^{-T}V^{T}b \\
                         &=b^{T}VV^{-1}V^{-T}V^{T}b = b^{T}V(V^{T}V)^{-1}V^{T}b
        .\end{align*}
        Thus,
        \begin{align*}
            \norm{p}_{2} =\sqrt{\norm{p}_{2}^{2}} = \sqrt{b^{T}V(V^{T}V)^{-1}V^{T}b}
        .\end{align*}

    \item \textbf{Projection onto a space}: Let $v$ be a vector in some space $V$, and $W$ be a subspace of $V$. If $W$ is spanned by a single vector $b$ ($W$ is one-dimensional), then the projection is the one we know,
       \begin{align*}
           \text{proj}_{W}(v) = \text{proj}_{b}(v) = \frac{v^{T}b}{b^{T}b}b
       .\end{align*}
       If $W$ is spanned by an orthonormal basis $\mathcal{B} = \{q_{1},...,q_{k}\} $, then
       \begin{align*}
           \text{proj}_{W}(v) = \sum_{i=1}^{k}(v^{T}q_{i})q_{i},
       \end{align*}
       and if $Q$ is the matrix formed by the orthonormal basis $\mathcal{B}$, $Q = \begin{bmatrix} q_{1} & \cdots & q_{k}\end{bmatrix} $, then
       \begin{align*}
           \text{proj}_{W}(v) = QQ^{T}v
       .\end{align*}
       If $W$ is spanned by a basis $\mathcal{B} = \{a_{1},...,a_{k}\}$ that may not be orthonormal, and $A = \begin{bmatrix} a_{1} & ... & a_{k} \end{bmatrix} $, then the projection of $v$ onto the subspace $W$ is given by
       \begin{align*}
           \text{proj}_{W}(v) = A(A^{T}A)^{-1}A^{T}v
       .\end{align*}
       The matrix $P = A(A^{T}A)^{-1}A^{T}$ is called the \textbf{projection matrix}, so $\text{proj}_{W}(v) = Pv $

   \item \textbf{Orthogonal projection theorem}: Let $W$ be a subspace of $\mathbb{R}^{n}$, and $x$ be a vector in $\mathbb{R}^{n}$. The closest point in $W$ to $x$ is its orthogonal projection onto $W$, denoted $\text{proj}_{W}(x)$. That is,
       \begin{align*}
           \min_{w\in W} \norm{x - w}_{2} = \text{proj}_{W}(x)
       .\end{align*}
       \textbf{\textit{Proof.}} Let $w \in W$, and $p$ be the projection of $x$ onto the subspace $W$. We have
       \begin{align*}
           x - w &= x - w + p - p = (x-p) + (p-w) 
       .\end{align*}
       Observe that $x-w \not\in W$, $x-p \not\in W$, $p-w \in W$. So, three noncollinear points, which form a triangle. Since $x-p \perp W$, and $p-w \in W$, $x-w$ is the hypotenuse, and by the Pythagorean Theorem,
       \begin{align*}
           \norm{x-w}_{2}^{2} = \norm{x-p}_{2}^{2} + \norm{p-w}_{2}^{2} 
       .\end{align*}
       Now, since $\norm{p-w}_{2} \geq 0$, $\norm{x-w}_{2}^{2} \geq \norm{x-p}_{2}^{2} $, and $\norm{x-w}_{2}^{2} = \norm{x-p}_{2}^{2}$ when $w = p$. 
       \bigbreak \noindent 
       This fact is only true in inner-product space, where distance is defined using the norm induced by that inner product, so
       \begin{align*}
           \left\langle x,x \right\rangle = \sqrt{\norm{x}}
       .\end{align*}
    \item \textbf{$n$-dimensional parallelepiped}: Let 
        \begin{align*}
            v_{1}, v_{2}, \dots, v_{k} \in \mathbb{R}^{n}, \quad k \leq n
        .\end{align*}
        The \textbf{parallelepiped} spanned by $v_{1}, \dots, v_{k} $ is the set
        \begin{align*}
            P(v_{1}, \dots, v_{k}) = \left\{\sum_{i=1}^{k}t_{i}v_{i}:\; 0 \leq t_{i} \leq 1\right\}
        .\end{align*}
        \begin{itemize}
            \item For $k=1$: a line segment
            \item For $k=2$: a parallelogram
            \item For $k=3$: a 3D parallelepiped
            \item For $k=n$: an $n$-dimensional parallelepiped (sometimes called a parallelotope)
        \end{itemize}
        This definition works in any ambient dimension $n$. 
        \bigbreak \noindent 
        An $n$-dimensional parallelepiped has
        \begin{itemize}
            \item $n$ edge vectors $v_{1}, \dots, v_{k}$
            \item $2^{n}$ vertices
            \item All faces are lower-dimensional parallelepipeds
            \item Opposite faces are parallel and congruent
        \end{itemize}
        Each $(n−1)$-dimensional face of an $n$-parallelepiped is itself an $(n−1)$-dimensional parallelepiped, with volume given by determinants of submatrices (or Gram minors).
        \bigbreak \noindent 
        The $n$-dimensional volume (hypervolume) of the parallelepiped spanned by $v_{1}, \dots, v_{k}$ is given by
        \begin{align*}
            \mathcal{V}(v_{1}, \dots, v_{k}) = \sqrt{\det\left(\text{Gram}(v_{1}, \dots, v_{k})\right)}
        .\end{align*}
        Where $\text{Gram}(v_{1}, \dots, v_{k})$ is the Gram matrix
        \begin{align*}
            \text{Gram}(v_{1}, \dots, v_{k}) = G = \left(v_{i}^{T}v_{j}\right)_{i,j=1}^{n} = A^{T}A
        ,\end{align*}
        with $A = \begin{bmatrix} v_{1} & v_{2} & \cdots & v_{k} \end{bmatrix} $. If $k = n$, then $\det(A)$ is defined, and
        \begin{align*}
            \det(G) = \det(A^{T}A) = \det(A^{T})\det(A) = \left(\det(A)\right)^{2}
        .\end{align*}
        So,
        \begin{align*}
            \mathcal{V}(v_{1}, \dots, v_{n}) = \sqrt{\left(\det(A)\right)^{2}} = \left\lvert \det(A) \right\rvert
        .\end{align*}
        If the set of vectors $v_{1}, \dots, v_{k}$ is orthonormal, then $v_{i}v_{j} = 0$ for $i\ne j$, and $\norm{v_{i}}_{2}= 1$. So, 
        \begin{align*}
            G = (v_{i}^{T}v_{j})_{i,j=1}^{k} = I_{k}
        .\end{align*}
        Thus,
        \begin{align*}
            \mathcal{V}(v_{1}, \dots, v_{k}) = \sqrt{\det(G)} = \sqrt{\det(I_{k})} = 1
        .\end{align*}
        So, if the edges vectors form an orthonormal set, the volume of $k$-dimensional parallelepiped is one.
        \bigbreak \noindent 
        Suppose that a $k$-dimensional parallelepiped with edge vectors $v_{1}, \dots, v_{k}$ is embedded in the ambient space $\mathbb{R}^{n}$, so $v_{1}, \dots, v_{k} \in \mathbb{R}^{n} $. But, suppose that the set of edge vectors is not linearly independent. 
        \bigbreak \noindent 
        Recall that the Gram matrix $G = V^{T}V$, where $V = \begin{bmatrix} v_{1} & \cdots & v_{k} \end{bmatrix} $. So, $G \in \mathbb{R}^{k\times k}$, and $V \in \mathbb{R}^{n\times k}$. Let $u \in \mathbb{R}^{k}$ such that $Gu = 0$, so $u \in \text{ker}(G) $,
        \begin{align*}
            Gu = 0 &\iff V^{T}Vu = 0 \iff u^{T}V^{T}Vu = 0 \iff (Vu)^{T}(Vu) = 0 \\
                   &\iff \norm{Vu}_{2}^{2} = 0 \iff Vu = 0
        .\end{align*}
        Thus, $u \in \text{ker}(V)$, and $\text{ker}(G) = \text{ker}(V)$. Consider the mapping of $G$ and $V$, 
        \begin{align*}
            G:\ \mathbb{R}^{k} \to \mathbb{R}^{k}, \\
            V:\ \mathbb{R}^{k} \to \mathbb{R}^{n}
        .\end{align*}
        By the rank-nullity theorem,
        \begin{align*}
            k = \text{rank}(G) + \text{dim}(\text{ker}(G)), \\
            k = \text{rank}(V) + \text{dim}(\text{ker}(V))
        .\end{align*}
        But, since  $\text{dim}(\text{ker}(G)) = \text{dim}(\text{ker}(V))$, $\text{rank}(G) = \text{rank}(V)$
        \bigbreak \noindent 
        If the $v_{1}, \dots, v_{k}$ is linearly dependent, then $\text{rank}(V) < k$, so $\text{rank}(G) < k$. Thus,
        \begin{align*}
            \det(G) = 0
        .\end{align*}
        Since the determinant is zero,
        \begin{align*}
            \mathcal{V}(v_{1}, \dots, v_{k}) = \sqrt{\det(G)} = 0
        .\end{align*}
        Thus, the volume is zero.
        \bigbreak \noindent 
        \textbf{Note:} The parallelepiped does exist, but it is degenerate. “Volume zero” does not mean “nonexistent”; it means the object has collapsed into a lower-dimensional shape.
        \bigbreak \noindent 
        \textbf{Collapsed} means that the set defined by the vectors still exists as a set of points, but it no longer occupies the full dimension you are trying to measure. One or more independent directions have disappeared. A direction that was supposed to provide thickness or height becomes zero. The shape lies entirely in a lower-dimensional subspace.
        \begin{itemize}
            \item In $\mathbb{R}^{3}$ : three dependent vectors span a plane or a line, not a volume-filling solid.
            \item In $\mathbb{R}^{2}$: two dependent vectors give a line segment, not an area.
            \item In $\mathbb{R}^{n}$: $k$ dependent vectors span a subspace of dimension $r < k$
        \end{itemize}
        Algebraically, let $V = \begin{bmatrix} v_{1} & v_{2} & \cdots & v_{k} \end{bmatrix} $, for $v_{1}, \dots, v_{k} \in \mathbb{R}^{n}$ where $k \leq n$. If $\text{rank}(V) = r < k $, then the linear map
        \begin{align*}
            x \mapsto Vx
        \end{align*}
        maps the $k$-dimensional unit cube into an $r$-dimensional set, so the “collapse” is exactly the loss of injectivity of this map.
    \item \textbf{Understanding the cross product}: In $\mathbb{R}^{3}$, the cross product is a binary operation that takes two vectors and returns a third vector that is orthogonal to both. It is a geometric construction specific to three-dimensional Euclidean space.
        \bigbreak \noindent 
        Let $a,b \in \mathbb{R}^{3}$, with
        \begin{align*}
            a = \begin{pmatrix} a_{1} \\ a_{2} \\ a_{3} \end{pmatrix}, \quad b = \begin{pmatrix} b_{1} \\ b_{2} \\ b_{3} \end{pmatrix}
        .\end{align*}
        The cross product $a\times b$ is
        \begin{align*}
            a\times b = \begin{pmatrix}  a_{2}b_{3} - a_{3}b_{2} \\ a_{1}b_{3} - a_{3}b_{1} \\ a_{1}b_{2} - a_{2}b_{1} \end{pmatrix}
        ,\end{align*}
        which can also be expressed as a determinant
        \begin{align*}
            a\times b = \det\begin{pmatrix} i & j & k \\ a_{1} & a_{2} & a_{3} \\ b_{1} & b_{2} & b_{3} \end{pmatrix} 
        .\end{align*}
        The cross product satisfies the following key properties
        \begin{itemize}
            \item \textbf{Orthogonality}: $(a\times b) \cdot a = 0$, $(a\times b) \cdot b = 0 $    
            \item \textbf{Bilinearity}: Linear in each argument separately
            \item \textbf{Anti-commutativity}: $a\times b = - (b\times a) $
            \item \textbf{Zero condition}: $a\times b = 0 \iff  $ $a$ and $b$ are linearly dependent
        \end{itemize}
        Observe $(a\times b)^{T}a$ and $(a\times b)^{T}b$,
        \begin{align*}
            (a\times b)^{T}a &= \begin{pmatrix}  a_{2}b_{3} - a_{3}b_{2} \\ a_{1}b_{3} - a_{3}b_{1} \\ a_{1}b_{2} - a_{2}b_{1} \end{pmatrix}^{T} \begin{pmatrix} a_{1} \\ a_{2} \\ a_{3} \end{pmatrix} \\
                             &= a_{1}(a_{2}b_{3} - a_{3}b_{2}) + a_{2}(a_{1}b_{3} - a_{3}b_{1}) + a_{3}(a_{1}b_{2} - a_{2}b_{1}) \\
                             &= \det \begin{pmatrix} a_{1} & a_{2} & a_{3} \\ a_{1} & a_{2} & a_{3} \\ b_{1} & b_{2} & b_{3} \end{pmatrix} = 0
        .\end{align*}
        The same goes for $(a\times b)^{T}b$,
        \begin{align*}
            (a\times b)^{T}b &= \begin{pmatrix}  a_{2}b_{3} - a_{3}b_{2} \\ a_{1}b_{3} - a_{3}b_{1} \\ a_{1}b_{2} - a_{2}b_{1} \end{pmatrix}^{T} \begin{pmatrix} b_{1} \\ b_{2} \\ b_{3} \end{pmatrix} \\
                             &= b_{1}(a_{2}b_{3} - a_{3}b_{2}) + b_{2}(a_{1}b_{3} - a_{3}b_{1}) + b_{3}(a_{1}b_{2} - a_{2}b_{1}) \\
                             &= \det \begin{pmatrix} b_{1} & b_{2} & b_{3} \\ a_{1} & a_{2} & a_{3} \\ b_{1} & b_{2} & b_{3} \end{pmatrix} = 0
        .\end{align*}
        Thus,
        \begin{align*}
            a\times b = \det\begin{pmatrix} i & j & k \\ a_{1} & a_{2} & a_{3} \\ b_{1} & b_{2} & b_{3} \end{pmatrix} 
        \end{align*}
        forms a vector orthogonal to both $a$ and $b$.
        \bigbreak \noindent 
        Next, from the logic above we see that for $a,b,c \in \mathbb{R}^{3}$, we have
        \begin{align*}
            (a\times b)^{T} c = (a\times b) \cdot c  = \det \begin{pmatrix} c_{1} & c_{2} & c_{3} \\ a_{1} & a_{2} & a_{3} \\ b_{1} & b_{2} & b_{3} \end{pmatrix} = \det\left(\begin{bmatrix}
                a & b & c
            \end{bmatrix}\right)
        .\end{align*}
        Notice that we made two row swaps, which has equal determinant, then took the transpose, which also has equal determinant.
        \bigbreak \noindent 
        Using this fact, we can see that
        \begin{align*}
            \norm{a \times b}_{2}^{2} = (a\times b)^{T}(a\times b) = \det(\begin{bmatrix} a & b & a\times b \end{bmatrix})
        .\end{align*}
        From here, we can use the Gram determinant identity $\det(G) = \left(\det(A)\right)^{2} $
        \begin{align*}
            \left(\norm{a\times b}_{2}^{2}\right)^{2} &= \left(\det\begin{bmatrix} a  & b & a\times b \end{bmatrix} \right)^{2} 
                                                      = 
            \det\begin{pmatrix} 
                a^{T}a & a^{T}b & a^{T}(a\times b)  \\
                b^{T}a & b^{T}b & b^{T}(a\times b) \\
                (a\times b)^{T}a & (a\times b)^{T}b & (a\times b)^{T}(a\times b)
            \end{pmatrix}
        .\end{align*}
        But, $a\times b $ is orthogonal to $a$ and $b$, so
        \begin{align*}
            \norm{a\times b}_{2}^{4} = \det\begin{pmatrix} 
                a^{T}a & a^{T}b & 0  \\
                b^{T}a & b^{T}b & 0 \\
                0 & 0 & (a\times b)^{T}(a\times b)
            \end{pmatrix}
        .\end{align*}
        Notice that we can expand along the bottom row to get
        \begin{align*}
            \norm{a\times b}_{2}^{4} &= \det\begin{pmatrix} 
                a^{T}a & a^{T}b & 0  \\
                b^{T}a & b^{T}b & 0 \\
                0 & 0 & (a\times b)^{T}(a\times b)
            \end{pmatrix} \\
            &= (a\times b)^{T}(a\times b)\left((a^{T}a)(b^{T}b) - (a^{T}b)^{2}\right) \\
            &=\norm{a\times b}_{2}^{2}\left((a^{T}a)(b^{T}b) - (a^{T}b)^{2}\right)  \\
            &= \norm{a\times b}_{2}^{2}\det\begin{pmatrix} a^{T}a & a^{T}b \\a^{T}b & b^{T}b \end{pmatrix}
        .\end{align*}
        Thus,
        \begin{align*}
            \norm{a\times b}_{2}^{2} = \det\begin{pmatrix} a^{T}a & a^{T}b \\ a^{T}b & b^{T}b \end{pmatrix} = \det\left(\text{Gram}(a,b)\right)
        .\end{align*}
        Now, recall that the area of the parallelogram spanned by $a$ and $b$ is precisely $\sqrt{\det\text{Gram}(a,b)} $. Thus, we can conclude that
        \begin{align*}
            \norm{a\times b}_{2} = \sqrt{\det\left(\text{Gram}(a,b)\right)} = \mathcal{A}(a,b) = \norm{a}_{2}\norm{b}_{2}\sin{\left(\theta \right)}
        .\end{align*}
        From this fact, we see that if $a\times b= 0$, then $\norm{a\times b} = 0$, and so the area of the parallelogram spanned by $a$ and $b$ is zero, and so $a$ and $b$ are linearly dependent.
        \bigbreak \noindent 
        Bilinearity and anti-commutativity comes from the multilinearity and alternating nature of the determinant.
    \item \textbf{Summary of the cross product}: Let $a,b \in \mathbb{R}^{3}$, the cross product $a\times b$ produces a vector $c \in \mathbb{R}^{3}$ orthogonal to both $a$ and $b$, with length equal to the area of the parallelogram spanned by $a$ and $b$.
        \bigbreak \noindent 
        The cross product $a\times b$ is defined as
        \begin{align*}
            a\times b = \det\begin{pmatrix} i & j & k \\ a_{1} & a_{2} & a_{3} \\ b_{1} & b_{2} & b_{3} \end{pmatrix} = \begin{pmatrix} a_{2}b_{3} - a_{3}b_{2} \\ a_{1}b_{3} - a_{3}b_{1} \\ a_{1}b_{2} - a_{2}b_{1} \end{pmatrix}
        ,\end{align*}
        with
        \begin{align*}
            \norm{a\times b}_{2} = \norm{a}_{2}\norm{b}_{2}\sin{\left(\theta \right)} = \sqrt{\det\left(\text{Gram}(a,b)\right)} 
        ,\end{align*}
        and
        \begin{align*}
            (a\times b)^{T} c = \det\left(\begin{bmatrix} a & b & c \end{bmatrix}\right)
        \end{align*}
        for all $c \in \mathbb{R}^{3}$.
        \bigbreak \noindent 
        The cross product is bilinear in $a$ and $b$ and anti-commutative. Also, $a\times b  = 0 $ is a necessary and sufficient condition to $a$ and $b$ being linearly dependent.
    \item \textbf{Triple scalar product}:  The triple scalar product is a scalar quantity associated with three vectors in $\mathbb{R}^{3}$. It combines the cross product and the dot product and is the standard algebraic representation of oriented volume.
        \bigbreak \noindent 
        For $\mathbf{a}, \mathbf{b}, \mathbf{c} \in \mathbb{R}^{3} $, the triple scalar product is defined as 
        \begin{align*}
            [\mathbf{a,b,c}] = \mathbf{a} \cdot (\mathbf{b}\times \mathbf{c}) = \det \begin{bmatrix} \mathbf{a} & \mathbf{b} & \mathbf{c} \end{bmatrix}
        .\end{align*}
        By the alternating nature of the determinant, 
        \begin{align*}
            \det \begin{bmatrix} \mathbf{a} & \mathbf{b} & \mathbf{c} \end{bmatrix} =
            \det \begin{bmatrix} \mathbf{b} & \mathbf{c} & \mathbf{a} \end{bmatrix} =
            \det \begin{bmatrix} \mathbf{c} & \mathbf{a} & \mathbf{b} \end{bmatrix} 
        .\end{align*}
        Thus,
        \begin{align*}
            \mathbf{a}  \cdot (\mathbf{b}\times \mathbf{c}) = \mathbf{b} \cdot (\mathbf{c}\times \mathbf{a}) = \mathbf{c} \cdot (\mathbf{a} \times \mathbf{b})
        .\end{align*}
        Also, by the nature of the dot product,
        \begin{align*}
            \mathbf{a} \cdot (\mathbf{b}\times \mathbf{c}) = (\mathbf{b}\times \mathbf{c}) \cdot \mathbf{a}
        .\end{align*}
        Since 
        \begin{align*}
            \mathbf{a} \cdot (\mathbf{b} \times \mathbf{c}) =\det\begin{pmatrix} a_{1} & b_{1} & c_{1} \\ a_{2} & b_{2} & c_{2} \\ a_{3} & b_{3} & c_{3} \end{pmatrix}
        ,\end{align*}
        the volume of the parallelepiped spanned by $\mathbf{a,b}$, and $\mathbf{c}$ is given by
        \begin{align*}
            \mathcal{V}(\mathbf{a,b,c}) = \left\lvert \mathbf{a} \cdot (\mathbf{b} \times \mathbf{c}) \right\rvert
        .\end{align*}

    \end{itemize}

    \pagebreak 
    \subsection{Geometric operations}
    \subsubsection{Position vectors and Translations}
    \begin{itemize}
        \item \textbf{Positions vs directions}: Vectors play two roles
            \begin{enumerate}
                \item \textbf{Direction / displacement}: Free vectors
                \item \textbf{Location / position}: Points, identified with position vectors
            \end{enumerate}
            So, either a vector is a \textbf{direction vector} or a \textbf{position vector}. Direction vectors are sometimes called \textbf{free vectors}.
        \item \textbf{Direction (free) vectors}: A direction vector represents a change.
            \begin{itemize}
                \item It can be freely added to other direction vectors.
                \item It can be scaled.
                \item It represents “how to move,” not “where you are.”
            \end{itemize}
            For example, 
            \begin{itemize}
                \item Elements of $\text{ker}(A)$
                \item Basis vectors
                \item Velocity, force, displacement in physics
            \end{itemize}
            Formally, these live in \textbf{vector spaces}. Direction vectors by convention start at the origin, their position in space is not of concern. These vectors encode a direction and a length (magnitude).
            \bigbreak \noindent 
            The sum of two direction vectors is also a direction vector, and so it also begins at the origin by convention.
        \item \textbf{Position vectors}: A position vector represents a location relative to a chosen origin.
            \begin{itemize}
                \item You do not add two positions meaningfully.
                \item You can subtract two positions to get a direction.
                \item You can add a direction to a position.
            \end{itemize}
            For example, 
            \begin{itemize}
                \item A particular solution $x_{0}$
                \item A point on an affine line or plane
                \item Coordinates of a physical location
            \end{itemize}
            Formally, these live in \textbf{affine spaces}. Position vectors also start at the origin by convention.
            \bigbreak \noindent 
            When we add a position vector to a direction vector, the starting point is at the position vector, and the direction is 
        \item \textbf{Position and direction}: Suppose $x_{0}$ is a position vector, which represents a point in space, and $v$ is a direction vector, with length and direction.
            \begin{align*}
                x_{0} + v
            \end{align*}
            means start at $x_{0}$, and move in the direction of $v$ for the length of $v$. The norm $\norm{v}$ gives us the distance to travel from $x_{0}$.
            \bigbreak \noindent 
            Let $x_{0} = \begin{pmatrix} 0 \\ 1 \end{pmatrix}$, and $v = \begin{pmatrix} 1 \\ 0 \end{pmatrix} $. Then, 
            \begin{align*}
                x_{0} + v = \begin{pmatrix} 0 + 1 \\ 1 + 0  \end{pmatrix} = \begin{pmatrix} 1 \\ 1 \end{pmatrix}
            .\end{align*}
            We do not interpret $x_{0} + v $ as a direction vector, it is a new position vector. Thus, length and direction is not of concern. It is a new point, not a new direction.

        \item \textbf{Translations}: Fix a direction vector $a\in \mathbb{R}^{n}$. The translation by $a$ is the map
            \begin{align*}
                T_{a}:\; \mathbb{R}^{n} \to \mathbb{R}^{n}, \quad T_{a}(x) = x + a
            ,\end{align*}
            where the input $x$ is a point in space, a position. Since the domain of this translation is $\mathbb{R}^{n}$, every point in $\mathbb{R}^{n}$ is moved by the displacement $a$.
            \bigbreak \noindent 
            In $\mathbb{R}^{2}$, 
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{translate}
                \label{fig:translate}
            \end{figure}
            \bigbreak \noindent 



    \end{itemize}

    \pagebreak 
    \subsection{Geometry of linear equations}
    \begin{itemize}
        \item \textbf{Direct sum}: A direct sum is a way of saying that a vector space can be decomposed into smaller subspaces in a manner that is both complete and non-overlapping.
            \bigbreak \noindent 
            Let $V$ be a vector space and let $U,W \subseteq V$ be subspaces. We write
            \begin{align*}
                V = U \oplus W
            \end{align*}
            if and only if both of the following hold.
            \begin{enumerate}
                \item \textbf{Every vector can be written as a sum}:
                    \begin{align*}
                        \forall v \in V, \quad v = u+w \quad \text{ with } u\in U,\; w \in W
                    .\end{align*}
                \item \textbf{The representation is unique}:
                    \begin{align*}
                        U \cap W = \{0\}
                    .\end{align*}
            \end{enumerate}
            Suppose $v$ has two different decompositions,
            \begin{align*}
                v=u_{1}+w_{1} = u_{2} + w_{2}
            \end{align*}
            for $u_{1}, u_{2} \in U,\; w_{1}, w_{2} \in W $. Then, subtracting the two equations gives
            \begin{align*}
                0 = u_{1} + w_{1} - u_{2} - w_{2}    
            .\end{align*}
            So,
            \begin{align*}
                u_{1} - u_{2} = -(w_{1} - w_{2})
            .\end{align*}
            Thus, this vector is common to both subspaces. If we enforce that $U \cap W = \{0\}$, then this vector must be zero. So,
            \begin{align*}
                u_{1} - u_{2} &= 0, \\
                -w_{1}+w_{2} &=0
            .\end{align*}
            Therefore, $u_{1} = u_{2}$, $w_{1} = w_{2} $, and the decomposition is unique.
            \bigbreak \noindent 
            Equivalent characterizations are
            \begin{itemize}
                \item $V = U \oplus W $ 
                \item $V = U + W $ and $U \cap W = \{0\} $
                \item Every $v\in V $ has a \textbf{unique} decomposition $v = u + w$.
            \end{itemize}
            So, the $\oplus$ notation when used on subspaces explains that an ambient space can be decomposed into subspaces, and the subspaces only share the zero vector.
            \bigbreak \noindent 
            Without the word \textit{direct}, the sum
            \begin{align*}
                V = U + W 
            \end{align*}
            only means that vectors can be written as sums, but not uniquely. In this case, $V \cap W \ne \{0\} $, and some vectors admit multiple decompositions, so the subspaces overlap.
            \bigbreak \noindent 
            If 
            \begin{align*}
                V = U \oplus W
            ,\end{align*}
            then
            \begin{align*}
                \text{dim}(V) = \text{dim}(U) + \text{dim}(W)
            .\end{align*}
            This definition extends naturally. For subspaces $U_{1}, \dots, U_{k} $, 
            \begin{align*}
                V = U_{1} \oplus \dots \oplus U_{k}
            .\end{align*}
            So, every vector in $V$ can be uniquely expressed as a sum $v = u_{1} + \dots + u_{k} $, for $u_{i} \in U_{i} $
            \bigbreak \noindent 
            Geometrically, each subspace provides an independent “direction of freedom”, no direction is counted twice, together they span the entire space.
            \bigbreak \noindent 
            As an example, consider standard coordinates in $\mathbb{R}^{2}$,
            \begin{align*}
                \mathbb{R}^{2} = \text{span}\{(1,0)\} \oplus \text{span}\{(0,1)\}
            .\end{align*}
            Every vector $(x,y) $ decomposes uniquely as 
            \begin{align*}
                (x,y) = (x,0) \oplus (0,y)
            .\end{align*}

        \item \textbf{Linear functionals and the dual space}: A linear functional is a map
            \begin{align*}
                \ell:\; V \to \mathbb{F}
            ,\end{align*}
            where $V$ is a vector space over a field $\mathbb{F}$. In $\mathbb{R}^{n}$, every linear functional has the form
            \begin{align*}
                \ell(x) = a_{1}x_{1} + a_{2}x_{2} + \dots + a_{n}x_{n} = a^{T}x
            \end{align*}
            for a fixed vector $a\in \mathbb{R}^{n}, a\ne 0$.
            \bigbreak \noindent 
            The set of all linear functionals on $V$ forms a vector space, called the \textbf{dual space $\mathbf{V}^{*} $}. In finite dimensions, 
            \begin{align*}
                \text{dim}(v^{*}) = \text{dim}(V)
            .\end{align*}
            A linear functional measures a signed component of a vector along a fixed direction. For $ \ell(x) = a^{T}x$, the vector $a$ acts as a \textbf{normal vector}. The value $\ell(x) $ is proportional to the projection of $x$ onto $a$. This makes linear functionals fundamental tools for describing orientation, constraints, and projections.
        \item \textbf{Nonzero functional}: If $V$ is a vector space over a field $\mathbb{F}$, then a linear functional
            \begin{align*}
                \ell:\; V \to \mathbb{F}
            \end{align*}
            is called \textbf{nonzero} if
            \begin{align*}
                \ell(v) \ne 0  \quad \text{for at least one } v\in V
            \end{align*}
        \item \textbf{The zero functional}: The zero functional is the map
            \begin{align*}
                \ell_{0}(v) = 0 \quad \text{for all }  v \in V
            .\end{align*}
            It is linear, but geometrically degenerate. Only nonzero functional produce meaningful geometry.
        \item \textbf{Rank and nullity of a linear functional}: For $\mathbb{R}^{n}$ over $\mathbb{R}$, the linear functional
            \begin{align*}
                \ell:\; V \to \mathbb{F},\quad \ell(x) = a_{1}x_{1} + \dots + a_{n}x_{n} = Ax
            \end{align*}
            Has rank one, since $A$ has one row and the functional maps to $\mathbb{R}$. By the rank-nullity theorem,
            \begin{align*}
                n = \text{dim}(\text{ker}(\ell)) + \text{dim}(\text{Im}(\ell)) = \text{nullity}(A) + \text{rank}(A)
            .\end{align*}
            Since $\text{rank}(A) = \text{dim}(\text{ker}(\ell)) =1$, 
            \begin{align*}
                n = \text{dim}(\text{ker}(\ell))+1 
            .\end{align*}
            So, the dimension of the kernel is $n-1$. The kernel is the set of vectors $v \in \mathbb{R}^{n}$ such that
            \begin{align*}
                Av = 0
            .\end{align*}
            So, it is the set of vectors orthogonal to $a$, where $a$ is the first (only) row of $A$, the normal vector that describes the orientation.
            \begin{align*}
                a_{1}v_{1} + \dots + a_{n}v_{n} = 0
            .\end{align*}
            Which describes the $(n-1)$-dimensional hyperplane through the origin.
            \bigbreak \noindent 
            Thus, 
            \begin{align*}
                \mathbb{R}^{n} = \text{ker}(\ell) \oplus \text{span}\{a\}
            .\end{align*}
            So, every vector in $\mathbb{R}^{n}$ can be uniquely expressed as a sum of two components, one lying in the kernel of $\ell$, and one lying in the direction of $a$.
            \bigbreak \noindent 
            Take any vector $x \in \mathbb{R}^{n} $, let $x_{\parallel}$ be the projection of $x$ onto the span of $a$. So,
            \begin{align*}
                x_{\parallel} = \frac{a^{T}x}{a^{T}a}a
            .\end{align*}
            Now, observe that $a^{T}x = a^{T}x_{\parallel} $. That is the amount of $x$ in the direction of $a$ is the same as the amount of $x_{\parallel}$ is the direction of $a$, because the amount of $x$ in the direction of $a$ is expressed in $x_{\parallel} $.
            \bigbreak \noindent 
            We want a vector $x_{\perp} $ such that $a^{T}x_{\perp} = 0$. Notice that we have two quantities equal to $a^{T}x$. So, 
            \begin{align*}
                a^{T}x_{\perp} = 0  = a^{T}x - a^{T}x = a^{T}x - a^{T}x_{\parallel} 
            .\end{align*}
            So, define
            \begin{align*}
                x_{\perp} := x-x_{\parallel}
            .\end{align*}
            Then, 
            \begin{align*}
                a^{T}x_{\perp} = a^{T}(x-x_{\parallel}) = a^{T}x - a^{T}x_{\parallel} = a^{T}x-a^{T}x = 0
            .\end{align*}
            Thus, $x_{\perp}$ is orthogonal to $a$. Therefore,
            \begin{align*}
                x = x_{\perp} + x_{\parallel}
            .\end{align*}
            This shows that every vector is a sum of an element in $\text{ker}(\ell) $ and an element of $\text{span}\{a\} $.
            \bigbreak \noindent 
            Recall that
            \begin{align*}
                \text{ker}(\ell) &= \{v \in \mathbb{R}^{n}:\; a^{T}v = 0\}, \\
                \text{span}\{a\} &= \{\lambda a:\; \lambda \in \mathbb{R}\}
            .\end{align*}
            Suppose that $\lambda a \in \text{ker}(\ell) $. Then,
            \begin{align*}
                a^{T}(\lambda a) &= \lambda a^{T}a = \lambda \norm{a}_{2}^{2} = 0
            .\end{align*}
            But, recall that in the definition of a linear functional, $a \ne 0$. Thus, $\lambda = 0$, which implies that $\lambda a=0$, which is the zero vector. So, since a member of the span of $a$ being in the kernel of $\ell$ implies the zero vector, it must be that
            \begin{align*}
                \text{ker}(\ell) \cap \text{span}\{a\} = \{0\}   
            .\end{align*}
            Thus, the sum is direct.
        \item \textbf{Level sets and hyperplanes}: For a fixed scalar $b$, the equation
            \begin{align*}
                \ell(x) = b
            \end{align*}
            defines a \textbf{level set}. This set is an $(n-1)$-dimensional \textbf{affine hyperplane} in $\mathbb{R}^{n}$. All points on the hyperplane have the same dot product with $a$. Changing $b$ translates the hyperplane parallel to itself.
            \bigbreak \noindent 
            When $b=0$, the level set is the \textbf{kernel} of $\ell$, a linear subspace of dimension $n-1$.
        \item \textbf{Kronecker delta}: For integers $i$ and $j$, 
            \begin{align*}
                \delta_{ij} = \begin{cases}
                        1 &\text{ if } i = j, \\
                        0 &\text{ if } i\ne j
                \end{cases}
            .\end{align*}
            The Kronecker delta acts as an index selector. It allows you to write statements that “pick out” a specific component while annihilating the others.
            \bigbreak \noindent 
            For example, the identity matrix $I_{n} \in \mathbb{R}^{n\times n} $ can be expressed with the Kronecker delta as follows,
            \begin{align*}
                (I_{n})_{ij} = \delta_{ij} 
            .\end{align*}
        \item \textbf{The dual space}: Let $V$ be a vector space over a field $\mathbb{F} $. The \textbf{dual space} of $V$, denoted $V^{*} $, is defined as 
            \begin{align*}
                V^{*} := \{\ell:\; V \to \mathbb{F}\; \mid\; \ell \text{ is linear} \}
            .\end{align*}
            So, $V^{*}$ is the vector space of \textbf{all linear functionals} on $V$.
            \bigbreak \noindent 
            The dual space is itself a vector space, with operations defined pointwise:
            \begin{itemize}
                \item $(\ell_{1} + \ell_{2})(v) = \ell_{1}(v) + \ell_{2}(v) $
                \item $(\alpha \ell)(v) = \alpha \ell(v) $
            \end{itemize}
        \item \textbf{The dual space is a morphism space}: Let $V$ be a vector space over a field $\mathbb{F}$. The dual space of $V$ is defined as
            \begin{align*}
                V^{*} := \text{Hom}(V,\mathbb{F})
            .\end{align*}
            That is, the space of all linear morphisms from $V$ to the base field.
        \item \textbf{The dual basis}: Let $V^{*}$ be the dual space of $V $. If $\mathcal{B} = \{b_{1}, \dots, b_{n}\} $ is a basis of $V$, then there exists a unique \textbf{dual basis}
            \begin{align*}
                \{\varphi^{1}, \dots, \varphi^{n}\} \subset V^{*}
            \end{align*}
            such that
            \begin{align*}
                \varphi^{i}(b_{j}) = \delta_{ij}
            .\end{align*}
            Consider some vector $v \in V$. Since $\mathcal{B}$ is a basis for $V$,
            \begin{align*}
                v = \sum_{j=1}^{n}x_{j}b_{j}
            .\end{align*}
            If we apply $\varphi^{i}$, we get
            \begin{align*}
                \varphi^{i}(v) = \varphi^{i}\left(\sum_{j=1}^{n}x_{j}b_{j}\right)
            .\end{align*}
            Notice that $\varphi^{i} $ is a linear functional $\varphi^{i}:\; V \to \mathbb{F} $, and each basis vector $b_{j} \in V$. Thus, by linearity, 
            \begin{align*}
                \varphi^{i}\left(\sum_{j=1}^{n}x_{j}b_{j}\right) = \sum_{j=1}^{n}x_{j}\varphi^{i}(b_{j}) = \sum_{j=1}^{n}x_{j}\delta_{ij} = x_{i}
            \end{align*}
            Therefore, 
            \begin{align*}
                \varphi^{i}(v) = x_{i}
            .\end{align*}
            So, the $i^{\text{th}}$ dual basis applied to a vector $v \in V$ extracts the $i^{\text{th}}$ entry of $v$.
        \item \textbf{Dual basis example}: Let $V = \mathbb{R}^{2}$, and $\mathbb{F} = \mathbb{R} $. Then, the dual space $\left(\mathbb{R}^{2}\right)^{*} $ is
            \begin{align*}
                (\mathbb{R}^{2})^{*} = \{\ell:\; \mathbb{R}^{2} \to \mathbb{R}\}
            .\end{align*}
            So, $\ell \in \left(\mathbb{R}^{2}\right)^{*}$ implies 
            \begin{align*}
                \ell(x) = a_{1}x_{1} + a_{2}x_{2}
            .\end{align*}
            Let $\mathcal{B}$ be the standard basis for $\mathbb{R}^{2}$, so
            \begin{align*}
                \mathcal{B} = \{b_{1}, b_{2}\} = \left\{\begin{pmatrix} 1 \\ 0 \end{pmatrix}, \begin{pmatrix} 0 \\ 1 \end{pmatrix}\right\}
            .\end{align*}
            The unique dual basis is then $\Phi = \{\varphi^{1}, \varphi^{2}\} $, defined by
            \begin{align*}
                \varphi^{i}b_{j} = \delta_{ij}
            ,\end{align*}
            where 
            \begin{align*}
                \varphi^{i} = \varphi^{i}_{1}x_{1} + \varphi^{i}_{2}x_{2}
            .\end{align*}
            Thus, 
            \begin{align*}
                \varphi^{1}\begin{pmatrix} 1 \\ 0 \end{pmatrix} &= 1, \quad \varphi^{1}\begin{pmatrix} 0 \\ 1 \end{pmatrix} = 0, \\
                \varphi^{2}\begin{pmatrix} 1 \\ 0 \end{pmatrix} &= 0, \quad \varphi^{2}\begin{pmatrix} 0 \\ 1 \end{pmatrix} = 1
            .\end{align*}
            So, we have
            \begin{align*}
                \varphi^{1}_{1}(1) + \varphi^{1}_{2}(0) &= \varphi^{1}_{1} = 1, \quad \varphi^{1}_{1}(0) + \varphi^{1}_{2}(1) = \varphi^{1}_{2} = 0, \\
                \varphi^{2}_{1}(1) + \varphi^{2}_{2}(0) &= \varphi^{2}_{1} = 0, \quad \varphi^{2}_{1}(0) + \varphi^{2}_{2}(1) = \varphi^{2}_{2} = 1
            .\end{align*}
            Hence,
            \begin{align*}
                \varphi^{1} = x_{1}, \quad \varphi^{2} = x_{2}
            .\end{align*}
            Suppose instead that we use $\mathcal{B} = \left\{\begin{pmatrix} 1 \\ -1 \end{pmatrix}, \begin{pmatrix} 1 \\ 1 \end{pmatrix}\right\} $ as our basis for $\mathbb{R}^{2}$. Then, using
            \begin{align*}
                &\varphi^{1}\begin{pmatrix} 1 \\ -1 \end{pmatrix} = 1, \quad \varphi^{1}\begin{pmatrix} 1 \\1 \end{pmatrix} = 0, \\
                &\varphi^{2}\begin{pmatrix} 1 \\ -1 \end{pmatrix} = 0, \quad \varphi^{2}\begin{pmatrix} 1 \\ 1 \end{pmatrix} = 1
            ,\end{align*}
            we find that
            \begin{align*}
                \varphi^{1} &= \frac{1}{2}x_{1} - \frac{1}{2}x_{2} = \frac{1}{2}(x_{1} - x_{2}), \\
                \varphi^{2} &= \frac{1}{2}x_{1} + \frac{1}{2}x_{2} = \frac{1}{2}(x_{1} + x_{2})
            .\end{align*}
            Let $v \in \mathbb{R}^{2}$, $v = \begin{pmatrix} v_{1} \\ v_{2} \end{pmatrix} $. Sending this vector to our basis $\mathcal{B}$ yields
            \begin{align*}
                v_{\mathcal{B}} = \frac{1}{2}\begin{bmatrix} 1 & -1 \\ 1 & 1 \end{bmatrix} \begin{pmatrix} v_{1} \\ v_{2} \end{pmatrix} = \frac{1}{2}\begin{pmatrix} v_{1} - v_{2} \\ v_{1} + v_{2} \end{pmatrix}
            .\end{align*}
            If we instead use the fact that $v_{i} = \varphi^{i}(v)$, we see that
            \begin{align*}
                v_{1} &= \varphi^{1}\begin{pmatrix} v_{1} \\ v_{2} \end{pmatrix} = \frac{1}{2}(v_{1} - v_{2}), \\
                v_{2} &= \varphi^{2}\begin{pmatrix} v_{1} \\ v_{2} \end{pmatrix} = \frac{1}{2}(v_{1} +v_{2})
            .\end{align*}
            Thus, 
            \begin{align*}
                v_{\mathcal{B}} = \frac{1}{2}\begin{pmatrix} v_{1} - v_{2} \\ v_{1} + v_{2} \end{pmatrix}
            .\end{align*}


        \item \textbf{Linear equations}: A single linear equation
            \begin{align*}
                a_{1}x_{1} + a_{2}x_{2} + \dots + a_{n}x_{n} = b
            \end{align*}
            describes a hyperplane in  $\mathbb{R}^{n} $
            \begin{itemize}
                \item In $\mathbb{R}^{2}$: A line
                \item In $\mathbb{R}^{3}$: A plane
                \item In $\mathbb{R}^{n}$: A $(n-1)$ dimensional object
            \end{itemize}
            The normal vector $\begin{pmatrix} a_{1} & a_{2} & \cdots & a_{n} \end{pmatrix}^{\top} $ is perpendicular to this hyperplane. Changing $b$ translates the hyperplane without changing its orientation.
            \bigbreak \noindent 
            A single linear equation in $n$ variables describes an $(n-1)$-dimensional hyperplane because we can solve for one variable in terms of the others. Observe
            \begin{align*}
                a_{1}x_{1} + a_{2}x_{2} + \dots + a_{n}x_{n} &= b \implies x_{n} =  \frac{b-\left(a_{1}x_{1} + a_{2}x_{2} + \dots + a_{n-1}x_{n-1}\right)}{a_{n}}
            .\end{align*}
            Thus, there are exactly $(n-1)$ free parameters, so the solution set is $(n-1)$-dimensional
        \item \textbf{Linear maps vs equations}: When we write
            \begin{align*}
                \ell(x) = a_{1}x_{1} + a_{2}x_{2} + \dots + a_{n}x_{n}
            \end{align*}
            we are defining a linear functional $\ell:\; \mathbb{R}^{n} \to \mathbb{R} $. At this stage, we are not yet describing a geometric object. We are defining a function.
            \bigbreak \noindent 
            The geometry appears only when we impose a constraint
            \begin{align*}
                \ell(x) = b
            .\end{align*}
            This equation is asking for the \textbf{preimage} of the scalar $b$ under $\ell$,
            \begin{align*}
                \ell^{-1}(\{b\}) = \{(x_{1}, \dots, x_{n}) \in \mathbb{R}^{n}:\; a_{1}x_{1} + \dots + a_{n}x_{n} = b\}
            .\end{align*}
            This set is the geometric object, the $(n-1)$-dimensional hyperplane.
        \item \textbf{Geometry of linear functionals}: A linear functional $\ell:\; \mathbb{R}^{n} \to \mathbb{R} $ does not by itself describe a geometric object. Instead, it describes a \textbf{family of geometric objects}: its level sets, 
            \begin{align*}
                \{\ell^{-1}(\{b\}):\; b \in \mathbb{R}\}
            .\end{align*}
            A linear functional $\ell$ is a rule assigning a scalar value to each vector. As an object, $\ell$ lives in the dual space $\left(\mathbb{R}^{n}\right)^{*} $, not in $\mathbb{R}^{n}$ itself. So it is not a subset of space, and hence not a geometric object in the sense of a set of points.
            \bigbreak \noindent 
            $\ell$ determines all level sets at once,
            \begin{align*}
                \mathbb{R}^{n} = \bigsqcup_{b\in \mathbb{R}} \ell^{-1}(\{b\})
            .\end{align*}
            Every vector lies in exactly one level set of $\ell$, different level sets do not intersect. Together, they partition the space.
        \item \textbf{Family of level sets versus the graph}: Consider a linear functional 
            \begin{align*}
                \ell:\; \mathbb{R}^{3} \to \mathbb{R},\quad \ell(x) = a_{1}x_{1} + a_{2}x_{2} + a_{3}x_{3}
            .\end{align*}
            Then, $\ell$ describes the family of level sets
            \begin{align*}
                \mathcal{L} = \{\ell^{-1}(\{d\}):\; d \in \mathbb{R}\}
            .\end{align*}
            Each level set in $\mathcal{L}$ is a $2$-dimensional affine hyperplane in $\mathbb{R}^{3}$. This family of parallel planes partition $\mathbb{R}^{3}$. 
            \begin{align*}
                \mathbb{R}^{3} = \bigsqcup_{d\in \mathbb{R}}\ell^{-1}(\{d\})
            .\end{align*}
            We can rename $\ell$ to
            \begin{align*}
                \ell(x,y,z) = ax + by + cz
            .\end{align*}
            Then, the graph of $\ell$, $\mathcal{G}(\ell)$ is
            \begin{align*}
                \mathcal{G}(\ell) = \{(x,y,z,d) \in \mathbb{R}^{4}:\; d = \ell(x,y,z)\}
            .\end{align*}
            This is a 3-dimensional affine subspace of $\mathbb{R}^{4}$. Although these two objects look the same, there is difference in what they mean.
            \bigbreak \noindent 
            A level set is defined by fixing an output values $d \in \mathbb{R} $ and collecting all inputs that map to it,
            \begin{align*}
                \ell^{-1}(\{d\}) = \{(x,y,z) \in \mathbb{R}^{3}:\; ax + by + cz = d\}
            .\end{align*}
            The inputs of $\ell$ are points in $\mathbb{R}^{3} $, a level set is a subset of the domain. Therefore, every level set is a subset of $\mathbb{R}^{3} $. The family is simply a collection of subsets of $\mathbb{R}^{3} $. Nothing leaves $\mathbb{R}^{3} $, we are simply slicing it.
            \bigbreak \noindent 
            The graph of $\ell$ is defined as 
            \begin{align*}
                \mathcal{G}(\ell) = \{(x,y,z,d)\in \mathbb{R}^{3} \times \mathbb{R}:\; d = \ell(x,y,z)\}
            .\end{align*}
            A graph records both input and output simultaneously. Inputs live in $\mathbb{R}^{3}$, outputs live in $\mathbb{R} $. Therefore, ordered pairs (input, output) live in 
            \begin{align*}
                \mathbb{R}^{3} \times \mathbb{R} \cong \mathbb{R}^{4}
            .\end{align*}
            So, the graph must live in $\mathbb{R}^{4} $, because it is a set of input-output pairs.
            \bigbreak \noindent 
            The graph is defined by a single linear equation in four variables, 
            \begin{align*}
                ax + by + cz - d = 0
            .\end{align*}
            Therefore, the solution set has dimension $4-1 = 3 $. So, $\mathcal{G}(\ell)$ is a 3-dimensional affine subspace of $\mathbb{R}^{4} $.
            \bigbreak \noindent 
            So, the graph is the disjoint union of all level sets, indexed by $d $, but lifted into one higher dimension. Formally, 
            \begin{align*}
                \mathcal{G}(\ell) \cong \bigsqcup_{d\in\mathbb{R}}\left(\ell^{-1}(\{d\}) \times \{d\}\right)
            .\end{align*}
            We say that the graph is the \textbf{total space}, and the level sets are its \textbf{fibers}.

            

    \end{itemize}

    \pagebreak 
    \subsection{Geometry of systems of linear equations}
    \begin{itemize}
        \item \textbf{Linear systems}: Consider a system
            \begin{align*}
                Ax = b
            ,\end{align*}
            where $A \in \mathbb{R}^{m\times n}$, $x\in \mathbb{R}^{n}$, and $b\in \mathbb{R}^{m} $. Each row of $Ax=b$ represents a hyperplane in $\mathbb{R}^{n}$. The solution set is the intersection of these hyperplanes.
            \bigbreak \noindent 
            Three fundamental cases arise:
            \begin{enumerate}
                \item \textbf{Unique solution}: The hyperplanes intersect at exactly one point.
                \item \textbf{Infinitely many solutions}: The hyperplanes intersect along a line, plane, or higher-dimensional affine subspace.
                \item \textbf{No solution}: The hyperplanes have no common intersection (they are inconsistent).
            \end{enumerate}
        \item \textbf{Homogeneous systems and the null space}: A homogeneous system has the form
            \begin{align*}
                Ax = 0
            .\end{align*}
            Its solution set is always a linear subspace of $\mathbb{R}^{n} $, called the null space of $A$.
            \begin{itemize}
                \item The zero vector is always a solution
                \item If $x$ and $y$ are solutions, then so is any linear combination $\alpha x + \beta y$
                \item The dimension of the solution space equals $n - \text{rank}(A) $
            \end{itemize}
            Geometrically, solutions form a hyperplane through the origin.
        \item \textbf{Nonhomogeneous systems and translation}: For a nonhomogeneous system $Ax = b$, assume at least one solution $x_{0}$ exists. Then, every solution can be written as 
            \begin{align*}
                x = x_{0} + v, \quad \text{with } v\in \text{null}(A)
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume that $Ax = b$ is a nonhomogeneous system with at least one solution $x_{0}$. Suppose that $x$ is any other solution, so $Ax=b$. If we subtract these two equations,
            \begin{align*}
                Ax - Ax_{0} = A(x-x_{0}) = b - b = 0 
            .\end{align*}
            Thus, $x-x_{0} \in \text{ker}(A)$. Call this vector $v$. So, $v = x - x_{0} \in \text{ker}(A)$. But, this implies that
            \begin{align*}
                x = x_{0} + v, \quad v \in \text{ker}(A)
            .\end{align*}
            This shows that \textbf{every} solution differs from $x_{0}$ by a null-space vector. $\endpf$
            \bigbreak \noindent 
            Thus, the solution set is an \textbf{affine subspace}, a translation of the null space by a vector $x_{0}$. We say that the solution set $\mathcal{S} := \{x \in \mathbb{R}^{n}:\; Ax = b\}$ is
            \begin{align*}
                \mathcal{S} = \{x_{0} + v:\; v \in \text{ker}(A)\} = x_{0} + \text{ker}(A)
            \end{align*}
            for a fixed solution $x_{0}$. So, the dimension of the solution space is given by the dimension of the kernel, which is given by
            \begin{align*}
               \text{ker}(A) = n - \text{rank}(A) 
            .\end{align*}
        \item \textbf{Dimension of the solution set}: So, either the system is homogeneous or nonhomogeneous. In any case, the dimension of the solution set $\mathcal{S}$ is given by the dimension of the kernel. Thus, 
            \begin{itemize}
                \item $\text{dim}(\text{ker}(A)) = 0$ implies $\mathcal{S}$ is a single point.
                \item $\text{dim}(\text{ker}(A)) = 1$ implies $\mathcal{S}$ forms a 1-dimensional line
                \item $\text{dim}(\text{ker}(A)) = 2$ implies $\mathcal{S}$ forms a 2-dimensional plane
                \item $\text{dim}(\text{ker}(A)) = k$ implies $\mathcal{S}$ forms a $k$-dimensional subspace of $\mathbb{R}^{n}$
            \end{itemize}
            Since the domain is $\mathbb{R}^{n}$, the ambient space is $\mathbb{R}^{n}$, and the solution set is therefore embedded in $\mathbb{R}^{n}$.




    \end{itemize}

    \pagebreak 
    \subsubsection{Eigenvalues and eigenvectors}
    \begin{itemize}
        \item \textbf{Geometry of a linear transformation}: Let $A \in \mathbb{R}^{n\times n} $, so
            \begin{align*}
               A:\; \mathbb{R}^{n}\to \mathbb{R}^{n} 
            .\end{align*}
            Geometrically, $A$ can
            \begin{itemize}
                \item stretch or compress space,
                \item reflect it,
                \item shear it,
                \item rotate it,
                \item or combine several of these effects.
            \end{itemize}
            Most vectors change both direction and length under $A$. Eigenvectors are the exception.
        \item \textbf{Invariant directions}: A nonzero vector $v$ is an eigenvector of $A$ if
            \begin{align*}
                Av=\lambda v
            \end{align*} 
            for some scalar $\lambda$. The vector $v$ lies along a direction that is preserved by the transformation, applying $A$ does not rotate or shear $v$; it only rescales it.
        \item \textbf{Eigenvalues}: 
            The eigenvalue $\lambda$ tells you how the transformation acts along its eigenvector.
            \begin{itemize}
                \item $\left\lvert \lambda \right\rvert >1$: stretching along that direction
                \item $0< \left\lvert \lambda \right\rvert <1$: compression along that direction
                \item $\lambda=1$: direction unchanged
                \item $\lambda=0$: collapse onto a lower-dimensional space
                \item $\lambda<0$: reflection plus scaling
            \end{itemize}
            In short, eigenvalues measure the factor by which space is expanded or contracted along the associated eigenvector.
    \end{itemize}



    \pagebreak 
    \unsect{Julia}
    \bigbreak \noindent 
    \subsection{Types}
    \bigbreak \noindent 
    \fig{.5}{./figures/tree.png}
    \begin{itemize}
        \item \textbf{Subtype constraint <:} $A$ <: $B$ means $A$ is a subtype of $B$
            \bigbreak \noindent 
            \begin{jlcode}
            Int <: Number #true
            \end{jlcode}
    \end{itemize}

    \pagebreak 
    \subsection{Functions}
    \begin{itemize}
        \item \relax    
    \end{itemize}

    \pagebreak 
    \subsection{Linear Algebra}
    \bigbreak \noindent 
    \subsubsection{Matrix creation and operations}
    \begin{itemize}
        \item \textbf{Array constructors}:
            \begin{itemize}
                \item Array\{T\}(undef, dims...)
                \item Vector\{T\}(undef, n)
                \item Matrix\{T\}(undef, m, n)
            \end{itemize}
        \item \textbf{Zeros/ones/fills}
            \begin{itemize}
                \item zeros(n), zeros(m,n)
                \item ones(n), ones(m,n)
                \item fill(x, dims...)
            \end{itemize}
        \item \textbf{Uniform ranges}:
            \begin{itemize}
                \item collect(1:n) $\to$ vector
                \item collect(1:m, 1:n) $\to$ matrix (grid)
            \end{itemize}
    \end{itemize}

    \unsect{Derivations}
    \bigbreak \noindent 
    \subsection{Series}
    \begin{itemize}
        \item \textbf{Finite geometric series}: A series with the form
            \begin{align*}
                \sum_{k=0}^{n} ar^{k}
            \end{align*}
            is called geometric. If we list the terms in this series, we see
            \begin{align*}
                S_{n} = a + ar + ar^{2} + ar^{3} + \ldots + ar^{n-1} + ar^{n}
            .\end{align*}
            If $r\ne 1$, notice that if we multiply this sum by $r$, we get
            \begin{align*}
                r_{n} = ar + ar^{2} + ar^{3} + ar^{4} + \ldots + ar^{n} + ar^{n+1}
            .\end{align*}
            If we subtract $rS_{n}$ from $S_{n}$, all terms will cancel except for $a$ and $ar^{n+1}$. So,
            \begin{align*}
                S_{n} - rS_{n} &= S_{n}(1-r) = a + ar + ar^{2} + ar^{3} + \ldots + ar^{n-1} + ar^{n}  \\
                &- \left(ar + ar^{2} + ar^{3} + ar^{4} + \ldots + ar^{n} + ar^{n+1}\right) \\
                &= a + ar^{n+1}
            .\end{align*}
            Thus,
            \begin{align*}
                S_{n} = \frac{S_{n}(1-r)}{1-r} = \frac{a + ar^{n+1}}{1-r} = \frac{a(1-r^{n+1})}{1-r}
            .\end{align*}
            If the sum has the form $\sum_{k=1}^{n}ar^{k-1}$, notice that it has almost the same terms as $\sum_{k=0}^{n}ar^{k}$, except it does not have the $ar^{n}$ term. So,
            \begin{align*}
                \sum_{k=1}^{n} ar^{k-1} = -ar^{n} + \sum_{k=0}^{n}ar^{k} = \sum_{k=0}^{n-1}ar^{k} = \frac{a(1-r^{(n-1)+1})}{1-r} = \frac{a(1-r^{n})}{1-r}
            .\end{align*}
            Similarly, if the sum has the form $\sum_{k=1}^{n}ar^{k}$ it has the same terms as $\sum_{k=0}^{n}ar^{k}$, except for the initial $ar^{0} = a$ term. So,
            \begin{align*}
                \sum_{k=1}^{n}ar^{k} &= -a + \sum_{k=0}^{n}ar^{k} = \frac{a(1-r^{n+1})}{1-r} - a = \frac{a - ar^{n+1} - a(1-r)}{1-r}\\
                &= \frac{a -ar^{n+1} -a +ar}{1-r} = \frac{ar-ar^{n+1}}{1-r} = \frac{ar(1-r^{n})}{1-r}
            .\end{align*}
            In all cases, we assume that $r \ne 1$. If $r = 1$, then
            \begin{align*}
                \sum_{k=0}^{n} ar^{k} = \sum_{k=0}^{n} a = a(n+1)
            .\end{align*}
            If $r = -1$, then we have
            \begin{align*}
                \sum_{k=0}^{n} a(-1)^{k} = \frac{a(1-(-1)^{n+1})}{1-(-1)} = \frac{a(1-(-1)^{n+1})}{2}
            .\end{align*}
            The sum depends on the parity of $n$. The number of terms in the sum is $n-0+1 = n+1$. If the sum has an even number of terms, all terms cancel and the sum is zero. If the sum has an add number of terms, all terms will cancel except for one, and so the sum is $a$.
            \bigbreak \noindent 
            Therefore, if $n$ is even, then $n+1$ is odd, so the sum is $a$. If $n$ is odd, then $n+1$ is even, so the sum is zero.
            \bigbreak \noindent 
            For example, let $r=-1$, and $n=2$. The sum is
            \begin{align*}
                \sum_{k=0}^{2}a(-1)^{n} = a(-1)^{0} + a(-1)^{1} + a(-1)^{2} = a -a + a = a
            .\end{align*}
            If we instead let $n = 3$, then the sum is
            \begin{align*}
                \sum_{k=0}^{3}a(-1)^{n} = a(-1)^{0} + a(-1)^{1} + a(-1)^{2} + a(-1)^{3} = a-a+a-a = 0
            .\end{align*}
        \item \textbf{Infinite geometric series}: Suppose $r\ne 1$. If we examine what happens to $\sum_{k=0}^{n}ar^{k}$ as $n\to \infty$,
            \begin{align*}
                \lim\limits_{n \to \infty}{\sum_{k=0}^{n}ar^{k}}  =  \lim\limits_{n \to \infty}{\frac{a(1-r^{n+1})}{1-r}}
            .\end{align*}
            We see that the behavior depends on $r^{n+1}$. The behavior is
            \begin{align*}
               \lim\limits_{n \to \infty}{r^{n+1}} = 
               \begin{cases}
                    0 & \text{ if } \left\lvert r \right\rvert  < 1 \\
                    \pm \infty & \text{ if } \left\lvert r \right\rvert  > 1
               \end{cases}
            .\end{align*}
            So,
            \begin{align*}
                \sum_{k=0}^{\infty}ar^{k} = \frac{a}{1-r} \quad \text{if } \left\lvert r \right\rvert < 1
            .\end{align*}
            If $r = 1$, then 
            \begin{align*}
                \sum_{k=0}^{\infty}a(1)^{k} = \sum_{k=0}^{\infty} a
            ,\end{align*}
            which diverges to infinity. If $r = -1$, then
            \begin{align*}
                \sum_{k=0}^{\infty}
            .\end{align*}
            
    \end{itemize}

    \pagebreak 
    \subsection{Quantities}
    \begin{itemize}
        \item \textbf{Time taken to travel}: Suppose you are traveling $k$ miles at $\ell$ miles per hour (mph). The time taken in minutes is given by
            \begin{align*}
                M = \frac{1}{\ell}\; \frac{hr}{m} \cdot k\; m = \frac{k}{\ell}\; hr \cdot \frac{60\; \text{min}}{1\; hr} = \frac{60k}{\ell}\; \text{min}
            .\end{align*}
            Notice that if we set $f_{k}(\ell) = \frac{1}{\ell}(60k)$ be the number of minutes it takes to travel $k$ miles at $\ell$ miles per hour, we see there is an inverse relationship between the speed traveled and the time it takes. In order to half the time it takes to travel $k$ miles, we need to double the speed. 
            \bigbreak \noindent 
            By looking at a graph of $f_{k}(\ell)$, we notice that the time saved by traveling faster approaches $0$ as $\ell \to \infty$.
            \bigbreak \noindent 
            The derivative is 
            \begin{align*}
                f^{\prime}_{k}(\ell) = -\frac{1}{\ell^{2}}(60k)
            .\end{align*}
            Notice
            \begin{itemize}
                \item $f^{\prime}_{k}(\ell) < 0$ for all $\ell$. So, increasing speed always decreases time.
                \item $\left\lvert f^{\prime}_{k}(ell) \right\rvert$ decreases as $\ell$ increases because of the $\ell^{2}$ term. This means each additional unit of speed saves less and less time that the previous one.
                    \bigbreak \noindent 
                    For example, increasing speed from 5 mph to 10 mph cuts time in half. But increasing from 100 mph to 105 mph barely changes anything.
            \end{itemize}
    \end{itemize}

    \pagebreak 
    \unsect{Ordinary differential equations}
    \subsection{Review}
    \subsubsection{Trig}
    \begin{itemize}
        \item \textbf{Unit circle}
            \begin{figure}[ht]
                \centering
                \def\svgwidth{\columnwidth}
                \incfig{unitcirce}
                \label{fig:unitcirce}
            \end{figure}

        \item \textbf{Periodicity}:
            \begin{itemize}
                \item \textbf{Sin, cos, csc, sec}: Period $2\pi $
                \item \textbf{Tan, cot}: Period $\pi $
            \end{itemize}
        \item \textbf{Even / odd trig functions}:
            \begin{itemize}
                \item \textbf{Sin, tan, csc, cot}: Even
                \item \textbf{Cos, sec}: Odd
            \end{itemize}
        \item \textbf{Transformations of trig functions}: A trig function can be transformed by four things
            \begin{enumerate}
                \item \textbf{Amplitude $A$}: The amplitude is the maximum distance the graph moves above or below its midline. Controls vertical stretch or compression.
                    \bigbreak \noindent 
                    If $A < 0$, the graph is reflected across the midline
                \item \textbf{Period $T = \frac{2\pi}{\omega}$}: The period is the horizontal length of one full cycle. Controls horizontal stretching  and compression
                \item  \textbf{Phase (horizontal) shift $c$}: The phase shift moves the graph left or right. The phase shift is given by $\frac{c}{\omega} $
                \item \textbf{Vertical shift $d$}: Moves the entire graph up or down. The new midline becomes
                    \begin{align*}
                        y = d
                    .\end{align*}
            \end{enumerate}
            A transformed trig function is of the form (using $\sin$ as an example)
            \begin{align*}
                A\sin{\left(\omega x-c\right)} + d
            .\end{align*}
        \item \textbf{Pythagorean identities}
            \begin{align*}
                \sin^{2}{\left(\theta \right)} + \cos^{2}{\left(\theta \right)} &= 1, \\
                \tan^{2}{\left(\theta \right)} +1 &= \sec^{2}{\left(\theta \right)}, \\
                \sec^{2}{\left(\theta \right)}-1 &= \tan^{2}{\left(\theta \right)}
            .\end{align*}
        \item \textbf{Product to sum}:
            \begin{align*}
                \sin A \sin B &= \frac{1}{2}\left[\cos(A - B) - \cos(A + B)\right], \\
                \cos A \cos B &= \frac{1}{2}\left[\cos(A - B) + \cos(A + B)\right], \\
                \sin A \cos B &= \frac{1}{2}\left[\sin(A + B) + \sin(A - B)\right], \\
                \cos A \sin B &= \frac{1}{2}\left[\sin(A + B) - \sin(A - B)\right]
            .\end{align*}
        \item \textbf{Sum to product}:
            \begin{align*}
                \sin A + \sin B &= 2\sin\left(\frac{A+B}{2}\right) \cos\left(\frac{A-B}{2}\right), \\
                \sin A - \sin B &= 2\cos\left(\frac{A+B}{2}\right) \sin\left(\frac{A-B}{2}\right), \\
                \cos A + \cos B &= 2\cos\left(\frac{A+B}{2}\right) \cos\left(\frac{A-B}{2}\right), \\
                \cos A - \cos B &= -2\sin\left(\frac{A+B}{2}\right) \sin\left(\frac{A-B}{2}\right)
            .\end{align*}
        \item \textbf{Sum and difference}:
            \begin{align*}
                \sin(A \pm B) &= \sin A \cos B \pm \cos A \sin B, \\
                \cos(A \pm B) &= \cos A \cos B \mp \sin A \sin B, \\
                \tan(A \pm B) &= \frac{\tan A \pm \tan B}{1 \mp \tan A \tan B}
            .\end{align*}
        \item \textbf{Double angle}:
            \begin{align*}
                \sin(2x) &= 2\sin x \cos x, \\
                \cos(2x) &= \cos^2 x - \sin^2 x, \\
                \cos(2x) &= 2\cos^2 x - 1, \\
                \cos(2x) &= 1 - 2\sin^2 x, \\
                \tan(2x) &= \frac{2\tan x}{1 - \tan^2 x}
            .\end{align*}
        \item \textbf{Half angle}:
            \begin{align*}
                \sin^2\left(\frac{x}{2}\right) &= \frac{1 - \cos x}{2}, \\
                \cos^2\left(\frac{x}{2}\right) &= \frac{1 + \cos x}{2}, \\
                \tan\left(\frac{x}{2}\right) &= \pm \sqrt{\frac{1 - \cos x}{1 + \cos x}}, \\
                \tan\left(\frac{x}{2}\right) &= \frac{\sin x}{1 + \cos x} = \frac{1 - \cos x}{\sin x}
            .\end{align*}
        \item \textbf{Domain and range of trig functions}:
            \begin{center}
                \begin{tabularx}{\textwidth}{@{}lXX@{}}
                    \toprule
                    \textbf{Function} & \textbf{Domain} & \textbf{Range} \\
                    \midrule
                    $y = \sin(x)$ & $(-\infty, \infty)$ & $[-1, 1]$ \\[2ex]
                    $y = \cos(x)$ & $(-\infty, \infty)$ & $[-1, 1]$ \\[2ex]
                    $y = \tan(x)$ & $(-\infty, \infty) \setminus \left\{ (2k+1)\frac{\pi}{2} \mid k \in \mathbb{Z} \right\}$ & $(-\infty, \infty)$ \\[2ex]
                    $y = \csc(x)$ & $(-\infty, \infty) \setminus \{ k\pi \mid k \in \mathbb{Z} \}$ & $(-\infty, -1] \cup [1, \infty)$ \\[2ex]
                    $y = \sec(x)$ & $(-\infty, \infty) \setminus \left\{ (2k+1)\frac{\pi}{2} \mid k \in \mathbb{Z} \right\}$ & $(-\infty, -1] \cup [1, \infty)$ \\[2ex]
                    $y = \cot(x)$ & $(-\infty, \infty) \setminus \{ k\pi \mid k \in \mathbb{Z} \}$ & $(-\infty, \infty)$ \\
                    \bottomrule
                \end{tabularx}
            \end{center}
        \item \textbf{Asymptotes of trig functions}:       Only Tan, Secant, cosecant and cotangent have Asymptotes, and they occur at:
            \begin{itemize}
                \item \textbf{Tan:} When $\cos{\theta } = 0$ at $\{(2k+1)\frac{\pi}{2} \mid k\in \mathbb{Z}\}$
                \item \textbf{Cosecant:} When $\sin{\theta } = 0$ at $\{\pi k \mid k\in \mathbb{Z}\}$
                \item \textbf{Secant:} When $\cos{\theta} = 0$ at $\{(2k+1)\frac{\pi}{2} \mid k \in \mathbb{Z}\}$
                \item \textbf{Cotangent:} When $\sin{\theta } = 0$ at $\{k\pi \mid k \in \mathbb{Z}\}$
            \end{itemize}
        \item \textbf{Graphs of trig functions}:
            \bigbreak \noindent 
            \fig{.8}{./figures/trigfunctions.png}
        \item \textbf{Domain and range of inverse trig functions}: Trigonometric functions are not one-to-one over their natural domains, so they cannot be inverted unless we restrict their domains. Trigonometric functions are not one-to-one over their natural domains, so they cannot be inverted unless we restrict their domains.
            \begin{center}
                \begin{tabularx}{\textwidth}{@{}lXX@{}}
                    \toprule
                    \textbf{Function} & \textbf{Domain} & \textbf{Range} \\
                    \midrule
                    $\arcsin(x) = \sin^{-1}(x)$ & $[-1,1]$ & $\left[-\dfrac{\pi}{2},\, \dfrac{\pi}{2}\right]$ \\[2ex]
                    $\arccos(x) = \cos^{-1}(x)$ & $[-1,1]$ & $[0,\pi]$ \\[2ex]
                    $\arctan(x) = \tan^{-1}(x)$ & $(-\infty,\infty)$ & $\left(-\dfrac{\pi}{2},\, \dfrac{\pi}{2}\right)$ \\[2ex]
                    $\arcsec(x) = \sec^{-1}(x)$ & $(-\infty,-1] \cup [1,\infty)$ & $[0,\pi],\; y \neq \dfrac{\pi}{2}$ \\[2ex]
                    $\arccsc(x) = \csc^{-1}(x)$ & $(-\infty,-1] \cup [1,\infty)$ & $\left[-\dfrac{\pi}{2},0\right) \cup \left(0,\dfrac{\pi}{2}\right]$ \\[2ex]
                    $\arccot(x) = \cot^{-1}(x)$ & $(-\infty,\infty)$ & $(0,\pi)$ \\
                    \bottomrule
                \end{tabularx}
            \end{center}
        \item \textbf{Asymptotes of inverse trig functions}:   
            \begin{center}
                \begin{tabularx}{\textwidth}{@{}lXl@{}}
                    \toprule
                    \textbf{Function} & \textbf{Horizontal Asymptotes}  & \textbf{Vertical Asymptotes} \\
                    \midrule
                    $\tan^{-1}{x}$ & $y=-\frac{\pi}{2},\frac{\pi}{2}$ & None \\[2ex]
                    $\csc^{-1}{x}$ & $y=0$  & None \\[2ex]
                    $\sec^{-1}{x}$ & $y=\frac{\pi}{2} $ &None \\[2ex]
                    $\cot^{-1}{x}$ & $y=0,\pi $ & None \\[2ex]
                    \bottomrule
                \end{tabularx}
            \end{center}
        \item \textbf{Graphs of inverse trig functions}:
            \bigbreak \noindent 
            \fig{.8}{./figures/inversetrigfunctions.jpg}
        \item \textbf{Hyperbolic trig}
            \begin{align}
                \sinh{x} &= \frac{e^{x}-e^{-x}}{2}, \quad \cosh{x} = \frac{e^{x}+e^{-x}}{2}, \\
                \tanh{(x)} &= \frac{\sinh{x}}{\cosh{x}}, \quad \text{csch}(x) = \frac{1}{\sinh{x}}, \\
                \text{sech}(x) &= \frac{1}{\cosh{x}}, \quad \coth{(x)} = \frac{\cosh{x}}{\sinh{x}}
            .\end{align}
        \item \textbf{Graphs of hyperbolic trig functions}:
            \begin{figure}[ht]
                \centering
                \incfig{cosh}
                \incfig{sinhx}
                \label{fig:sinhx}
            \end{figure}
            \begin{figure}[ht]
                \centering
                \incfig{tanhx}
                \incfig{coth}
                \label{fig:tanhx}
            \end{figure}
            \begin{figure}[h]
                \centering
                \incfig{csch}
                \incfig{sech}
                \label{fig:csch}
            \end{figure}


    \end{itemize}
    \pagebreak 
    \subsubsection{Calculus I}
    \begin{itemize}
        \item \textbf{Limits}: A limit describes the value that a function approaches as the input approaches a certain number.
            \begin{align*}
                \lim\limits_{x \to a}{f(x)} = L
            .\end{align*}
            As $x$ gets close to $a$, $f(x)$ gets close to $L$.
        \item \textbf{One sided limits}: The limit
            \begin{align*}
                \lim\limits_{x \to a^{-}}{f(x)}
            \end{align*}
            is the value of the function that is approached as $x$ approaches $a$ from the left. Similarly, 
            \begin{align*}
                \lim\limits_{x \to a^{+}}{f(x)}
            \end{align*}
            is the value of the function that is approached as $x$ approaches $a$ from the right
            \bigbreak \noindent 
            The limit exists if and only if 
            \begin{align*}
                \lim\limits_{x \to a^{-}}{f(x)} = \lim\limits_{x \to a^{+}}{f(x)}
            .\end{align*}
        \item \textbf{Limit laws}: Let
            \begin{align*}
                \lim\limits_{x \to a}{f(x)} = L, \quad \lim\limits_{x \to a}{g(x)} = M
            .\end{align*}
            Then,
            \begin{align*}
                \lim\limits_{x \to a}{c} &= c, \quad \lim\limits_{x \to a}{\left(f(x) + g(x)\right)} = L + M, \\
                \lim\limits_{x \to a}{cf(x)} &= cL, \quad \lim\limits_{x \to a}{f(x)g(x)} = LM, \\
                \lim\limits_{x \to a}{\frac{f(x)}{g(x)}} &= \frac{L}{M}, \quad M\ne 0, \\
                \lim\limits_{x \to a}{(f(x))^{n}} &= L^{n}, \quad \lim\limits_{x \to a}{\sqrt[n]{f(x)}} = \sqrt[n]{L}, \\
                \lim\limits_{x \to a}{x} = x, \quad \lim\limits_{x \to a}{x^{n}} = a^{n}
            .\end{align*}
        \item \textbf{Horizontal asymptotes}: If either $\lim\limits_{x \to \infty}{f(x)} = L$ or $\lim\limits_{x \to -\infty}{f(x)} = L$, there is a horizontal asymptote at $y = L$
        \item \textbf{Continuity}: Let $f(x)$. For $f$ to be continuous at $a$, the following must be true
            \begin{enumerate}
                \item $f(x)$ is defined at $a $
                \item $\lim\limits_{x \to a}{f(x)}$ exists
                \item $\lim\limits_{x \to a}{f(x)} = f(a)$
            \end{enumerate}
            Item three is a necessary and sufficient condition for $f$ to be continuous at $a$.
        \item \textbf{One sided continuity}: Continuity from the right implies
            \begin{align*}
                \lim\limits_{x \to a^{+}}{f(x)} = f(a)        
            .\end{align*}
            Similarly, continuity from the left implies that 
            \begin{align*}
                \lim\limits_{x \to a^{-}}{f(x)} = f(a)
            .\end{align*}
        \item \textbf{Properties of continuity}: If $f$ and $g$ are continuous at $a$, then $f+g$, $f-g$, $fg$, $\frac{f}{g}$ for $g\ne 0$, $cf$, and $cg$ are all continuous at $a$.
        \item \textbf{Differentiability implies continuity}: If $f(x)$ is differentiable on its domain, then it is continuous on its domain.


        \item \textbf{Basic facts}:
            \begin{itemize}
                \item \textbf{Power Rule}
                    \[
                        \frac{d}{dx} x^n = n x^{n-1}
                    \]
                \item \textbf{Exponential Functions}
                    \begin{align*}
                        &\frac{d}{dx} e^x = e^x, \\
                        &\frac{d}{dx} a^x = a^x \ln a
                    .\end{align*}
                \item \textbf{Logarithmic Functions}
                    \begin{align*}
                        &\frac{d}{dx} \ln x = \frac{1}{x}, \\
                        &\frac{d}{dx} \ln |x| = \frac{1}{x}
                    .\end{align*}
                \item \textbf{Trigonometric Functions}
                    \begin{align*}
                        &\frac{d}{dx} \sin x = \cos x, \\
                        &\frac{d}{dx} \cos x = -\sin x, \\
                        &\frac{d}{dx} \tan x = \sec^2 x, \\
                        &\frac{d}{dx} \sec x = \sec x \tan x, \\
                        &\frac{d}{dx} \csc x = -\csc x \cot x, \\
                        &\frac{d}{dx} \cot x = -\csc^2 x
                    .\end{align*}
                \item \textbf{Chain Rule}
                    \[
                        \frac{d}{dx} f(g(x)) = f'(g(x))\,g'(x)
                    \]
                \item \textbf{Product Rule}
                    \[
                        \frac{d}{dx}(uv) = u'v + uv'
                    \]
                \item \textbf{Quotient Rule}
                    \[
                        \frac{d}{dx}\left(\frac{u}{v}\right) = \frac{u'v - uv'}{v^2}
                    \]
            \end{itemize}
        \item \textbf{Indefinite integral identities}: 
            \begin{itemize}
                \item \textbf{Power Rule}
                    \[
                        \int x^n \, dx = \frac{x^{n+1}}{n+1} + C, \quad n \neq -1
                    \]
                \item \textbf{Logarithmic Integral}
                    \[
                        \int \frac{1}{x} \, dx = \ln|x| + C
                    \]
                \item \textbf{Exponential Functions}
                    \begin{align*}
                        &\int e^x \, dx = e^x + C, \\
                        &\int a^x \, dx = \frac{a^x}{\ln a} + C
                    .\end{align*}
                \item \textbf{Trigonometric Functions}
                    \begin{align*}
                        &\int \sin x \, dx = -\cos x + C, \\
                        &\int \cos x \, dx = \sin x + C, \\
                        &\int \tan x \, dx = \ln|\sec x| + C, \\
                        &\int \sec^2 x \, dx = \tan x + C, \\
                        &\int \csc^2 x \, dx = -\cot x + C, \\
                        &\int \sec x \tan x \, dx = \sec x + C, \\
                        &\int \csc x \cot x \, dx = -\csc x + C
                    .\end{align*}
                \item \textbf{Inverse Trigonometric Forms}
                    \begin{align*}
                        &\int \frac{1}{1+x^2} \, dx = \arctan x + C, \\
                        &\int \frac{1}{\sqrt{1-x^2}} \, dx = \arcsin x + C
                    .\end{align*}
            \end{itemize}
        \item \textbf{FTC}: 
            \begin{align*}
                \frac{d}{dx} \left(\int_{a}^{x} f(t)\; dt\right) = f(x), \\
                \int_{a}^{b}f(x)\; dx = F(b) - F(a)
            .\end{align*}
        \item \textbf{Chain rule in detail}: The chain rule is the rule for differentiating a composition of functions. If a quantity changes because it depends on another quantity, which itself depends on something else, then the overall rate of change is the product of the intermediate rates of change.
            \bigbreak \noindent 
            Formally, if 
            \begin{align*}
                y = f(u) \quad \text{ and } \quad u = g(x)
            ,\end{align*}
            then $y$ is a function of $x$ via the composition $y=f(g(x)) $, and 
            \begin{align*}
                \frac{dy}{dx} = \frac{dy}{du} \cdot \frac{du}{dx}
            .\end{align*}
            Equivalently,
            \begin{align*}
                (f \circ g)^{\prime}(x) = f^{\prime}(g(x)) \cdot g^{\prime}(x)
            .\end{align*}
            In $f(g(x))$, $g(x) $ is a function of $x$, and $f$ depends on this function. Therefore, $f$ is indirectly a function of $x$. $f$ is \textbf{not directly} a function of $x$. But, when you compose it with $g(x) $, the output of $f$ does become a function of $x$. This distinction is why the chain rule exists.
            \bigbreak \noindent 
            Suppose that 
            \begin{align*}
                f(u) = u^{3}, \quad g(x) = x^{2}
            .\end{align*}
            $f$ depends of $u$, while $g$ depends on $x$. At this stage, $f$ has nothing to do with $x$. If we compose the two functions, 
            \begin{align*}
                h(x) = f(g(x)) = f(x^{2}) = (x^{2})^{3} = x^{6}
            .\end{align*}
            At this point, $f$ is being fed a quantity that depends on $x$. So, the output of $f$ now depends on $x$. A function does not need to explicitly mention $x $ to depend on $x$. It only needs to depend on something that depends on $x$.
            \bigbreak \noindent 
            When we differentiate
            \begin{align*}
                \frac{d}{dx}f(g(x))
            \end{align*}
            we are asking "how fast is the output of $f$ changing as $x$ changes". But, the change happens in two stages,
            \begin{enumerate}
                \item $x$ changes affects $g(x) $
                \item $g(x)$ changes affects $f(g(x)) $
            \end{enumerate}
            So, the total change must account for both steps. This is why
            \begin{align*}
                \frac{d}{dx}f(g(x))= \frac{df}{dg} \cdot \frac{dg}{dx}
            .\end{align*}
            Consider $f(u) = u^{3}$, $g(x)  = 2x+1$. The composition is then 
            \begin{align*}
                f(g(x)) = (2x+1)^{3}
            .\end{align*}
            So, the derivative of $f$ with respect to $g$ is 
            \begin{align*}
                \frac{df}{dg} = 3g(x)^{2} = 3(2x+1)^{2}
            ,\end{align*}
            while the derivative of $g$ with respect to $x$ is
            \begin{align*}
                \frac{dg}{dx} = 2
            .\end{align*}
            Thus,
            \begin{align*}
                (f(g(x)))^{\prime} = \frac{df}{dg} \cdot \frac{dg}{dx} = 3(2x+1)^{2} \cdot 2 = 6(2x+1)^{2}
            .\end{align*}
            Thus, for 
            \begin{align*}
               \frac{d}{dx} y^{3}
            \end{align*}
            if we let $f(u) = u^{3} $, and $y = g(x)$, then
            \begin{align*}
                f(g(x)) = f(y) = y^{3}
            .\end{align*}
            Since
            \begin{align*}
                \frac{df}{dg} = 3g(x)^{2}, \quad \frac{dg}{dx} = \frac{dy}{dx}
            ,\end{align*}
            \begin{align*}
                (f(g(x)))^{\prime} = 3g(x)^{2} \cdot \frac{dy}{dx} = 3y^{2}\cdot \frac{dy}{dx}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{Note}: Another way to think about why $\frac{d}{dx}y^{3} = 3y^{2}$ is by recalling that $y = f(x)$, so
            \begin{align*}
                \frac{d}{dx} y^{2} = \frac{d}{dx}(f(x))^{2} = 2(f(x)) \cdot f^{\prime}(x) = 2yy^{\prime}
            \end{align*}
            by the chain rule.




        \item \textbf{Implicit differentiation}: Implicit differentiation is a technique used to differentiate equations in which the dependent variable $y$ is not isolated as a function of the independent variable $x$. Instead of having $y = f(x) $, we have
            \begin{align*}
                F(x,y) = 0
            .\end{align*}
            So, we differentiate both sides with respect to $x$. The fundamental idea is that whenever you differentiate a term containing $y$, multiply by $\frac{dy}{dx}$. This fact follows from the chain rule, since $y = y(x)$.
            \bigbreak \noindent 
            Suppose that we want to differentiate $y^{3}$ with respect to $x$. So, we want to find
            \begin{align*}
                \frac{d}{dx}y^{3}
            .\end{align*}
            If we let $f(u) = u^{3}$, and $u = y(x)$, then
            \begin{align*}
                f(y(x)) = y^{3}
            ,\end{align*}
            with
            \begin{align*}
                \frac{d}{dx}f(y(x)) = \frac{df}{du} \cdot \frac{dy}{dx}
            .\end{align*}
            Thus,
            \begin{align*}
                \frac{d}{dx}f(y(x)) = 3u^{2} \cdot \frac{dy}{dx}
            .\end{align*}
            But, notice that we defined $u = y(x)$. So,
            \begin{align*}
                3u^{2} \cdot \frac{dy}{dx} = 3y^{2} \cdot \frac{dy}{dx}
            .\end{align*}
            Or, more conventionally, we would set $f(u) = u^{3}$, and $y = g(x)$. Then,
            \begin{align*}
                f(g(x)) = f(y) = y^{3}
            ,\end{align*}
            and
            \begin{align*}
                \frac{d}{dx}y^{3} &= (f(g(x)))^{\prime} = f^{\prime}(g(x)) \cdot g^{\prime}(x) \\
                                  &=3u^{2} \cdot \frac{dy}{dx} = 3y^{2} \cdot \frac{dy}{dx}
            .\end{align*}
            Notice that we changed $3u^{2}$ to $3y^{2}$, since what we really have is $f^{\prime}(g(x)) $, and $g(x) = y$.
            \bigbreak \noindent 
            Now, as an example, we will implicitly differentiate 
            \begin{align*}
                x^{3}y^{3} = x^{3} + 1
            .\end{align*}
            So,
            \begin{align*}
                \frac{d}{dx}x^{3}y^{3} &= \frac{d}{dx}x^{3} + 1 \\
                \implies 3x^{2}y^{3} + 3x^{3}y^{2}\cdot \frac{dy}{dx} &= 3x^{2}
            .\end{align*}
            Now, we solve for $\frac{dy}{dx}$. So,
            \begin{align*}
                3x^{2}y^{3} + 3x^{3}y^{2}\cdot \frac{dy}{dx} &= 3x^{2} \\
                \implies y^{3} + xy^{2}\frac{dy}{dx} &= 1 \\
                \implies \frac{dy}{dx} &= \frac{1-y^{3}}{xy^{2}}
            .\end{align*}
        \item \textbf{Implicit differentiation with logarithms}: We can also implicitly differentiate using logarithms and their properties. Consider again
            \begin{align*}
                x^{3}y^{3} =x^{3} + 1
            .\end{align*}
            So, we can take the natural log of both sides,
            \begin{align*}
                \ln{\left(x^{3}y^{3}\right)} &= \ln{\left(x^{3} + 1\right)} \\
                \implies 3\ln{\left(x\right)} + 3\ln{\left(y\right)} &= \ln{\left(x^{3} + 1\right)}
            .\end{align*}
            Now, we differentiate,
            \begin{align*}
                \frac{d}{dx}\left(3\ln{\left(x\right)} + 3\ln{\left(y\right)}\right) &= \frac{d}{dx}\ln{\left(x^{3} + 1\right)} \\
                \implies \frac{3}{x} + \frac{3}{y} \cdot \frac{dy}{dx} = \frac{1}{x^{3} + 1}
            .\end{align*}
            Solving for $\frac{dy}{dx} $ gives
            \begin{align*}
                \frac{dy}{dx} = y\left(\frac{x^{2}}{x^{3}+1} - \frac{1}{x}\right)
            .\end{align*}
            If we choose, we can solve for $y$ in $x^{3}y^{3} = x^{3} + 1 $ and substitute it into the form derived above.
        \item \textbf{$\frac{dy}{dx}$ and differentials}: Formally, the derivative $\frac{dy}{dx}$ is not a ratio, it is a limit
            \begin{align*}
                \frac{dy}{dx} = \lim\limits_{\Delta x \to 0}{\frac{\Delta y}{\Delta x}}
            .\end{align*}
            $\frac{dy}{dx}$ is a single object. You cannot cancel or rearrange it algebraically at this level. 
            \bigbreak \noindent 
            Once a function is differentiable, we define
            \begin{align*}
                dy = f^{\prime}(x)\; dx
            .\end{align*}
            This is not a limit, but a linear approximation
            \begin{align*}
                \Delta y \approx f^{\prime}(x)\Delta x
            .\end{align*}
            At this point:
            \begin{itemize}
                \item dx is treated as an independent variable
                \item dy is defined in terms of it
                \item The notation behaves algebraically
            \end{itemize}
            Then, algebraically, 
            \begin{align*}
                \frac{dy}{dx} = f^{\prime}(x)
            .\end{align*}
            This is why we can treat $\frac{dy}{dx}$ as a fraction.



    \end{itemize}

    \pagebreak 
    \subsubsection{Calculus II}
    \begin{itemize}
        \item \textbf{Integration by Power rule}:  This is for handling power functions: For any real number n (whether whole number, negative number, rational or irrational number.)
            \begin{align*}
                \int x^{n}\; dx = \begin{cases}
                    \frac{x^{n+1}}{n+1} + C &\text{ if } n\ne -1 \\
                    \ln{\left(x\right)} + C &\text{ if } n=-1
                \end{cases}
            .\end{align*}
        \item \textbf{Integration by $u$ sub}: Integration by substitution (commonly called u-substitution) is a technique used to simplify integrals by reversing the chain rule from differential calculus. The core idea is to transform a complicated integral into a simpler one by changing variables.
            \bigbreak \noindent 
            Consider an integral of the form
            \begin{align*}
                \int f(g(x))g^{\prime}(x)\; dx
            .\end{align*}
            We let $u = g(x) $, so $du = g^{\prime}(x)\; dx $. Then, the integral becomes
            \begin{align*}
                \int f(u)\; du 
            .\end{align*}
            After integrating, substitute back $u=g(x)$. For example, consider the integral
            \begin{align*}
                \int 2x\cos{\left(x^{2}\right)}\; dx
            .\end{align*}
            So, we see that if $u = g(x) = x^{2}$, then $du= 2x\; dx $, and
            \begin{align*}
                \int 2x\cos{\left(x^{2}\right)}\; dx = \int \cos{\left(u\right)}\; du = \sin{\left(u\right)} + C = \sin{\left(x^{2}\right)} + C
            .\end{align*}
        \item \textbf{Integration by parts}: Integration by parts is a technique used to evaluate integrals that involve the product of two functions, where direct integration is not convenient. It is derived directly from the product rule for differentiation.
            \bigbreak \noindent 
            The product rule states that 
            \begin{align*}
                \frac{d}{dx}\left(u(x)v(x)\right) = u^{\prime}(x)v(x) + u(x)v^{\prime}(x)
            .\end{align*}
            If we integrate both sides, 
            \begin{align*}
                \int \frac{d}{dx}u(x)v(x) = uv = \int u^{\prime}(x)v(x)\; dx + \int u(x) v^{\prime}(x)\; dx \\
            .\end{align*}
            Now, notice that $du = u^{\prime}(x)\; dx $, and $dv = v^{\prime}(x)\; dx $. So, 
            \begin{align*}
                uv &= \int u^{\prime}(x)v(x)\; dx + \int u(x) v^{\prime}(x)\; dx \\ 
                   &= \int v\; du + \int u\; dv
            .\end{align*}
            Thus,
            \begin{align*}
                \int u\; dv = uv - \int v\; du
            .\end{align*}
            So, the integrand in question is precisely
            \begin{align*}
                \int u(x)v^{\prime}(x)\; dx
            .\end{align*}
            The choice in deciding what should be $u$, and what should be $dv$ used the LIATE rule, which ranks functions by how useful it is to differentiate them.
            \begin{itemize}
                \item \textbf{L:} Logarithmic
                \item \textbf{I:} Inverse trig
                \item \textbf{A:} Algebraic
                \item \textbf{T:} Trigonometric
                \item \textbf{E:} Exponential
            \end{itemize}
            Choose $u$ to be the function that appears earliest in the list
            \bigbreak \noindent 
            For example, consider
            \begin{align*}
                \int xe^{x}\; dx
            .\end{align*}
            Notice that $x$ is algebraic, and $e^{x}$ is an exponential. Since $A$ comes before $E$, we choose $x$ to be $u$, and $e^{x}\; dx $ to be $dv$.
            \bigbreak \noindent 
            With $u = x$, and $dv = e^{x}\; dx$, we have
            \begin{align*}
                du = \; dx, \quad v = \int \; dv = \int e^{x}\; dx = e^{x}
            .\end{align*}
            Thus, 
            \begin{align*}
                \int u\; dv = xe^{x} - \int e^{x}\; dx = xe^{x} - e^{x} + C 
            .\end{align*}
            Notice when finding $v$ from $dv$, we do not include a constant of integration. The constant of integration belongs to the entire integral, not to intermediate steps.
            \bigbreak \noindent 
            Note that for definite integrals,
            \begin{align*}
                \int_{a}^{b}u\; dv = uv\mid_{a}^{b} - \int_{a}^{b}v\; du
            .\end{align*}
        \item \textbf{Integrals of products of trig functions}:
            \begin{align*}
                \sin(ax) \sin(bx) &= \frac{1}{2} \cos((a-b)x) - \frac{1}{2} \cos((a+b)x), \\
                \sin(ax) \cos(bx) &= \frac{1}{2} \sin((a-b)x) + \frac{1}{2} \sin((a+b)x), \\
                \cos(ax) \cos(bx) &= \frac{1}{2} \cos((a-b)x) + \frac{1}{2} \cos((a+b)x)
            \end{align*}
        \item \textbf{Power reduction formulas}:
            \begin{align*}
                    &\int \sin^{n}{x}\ dx = -\frac{1}{n}\sin^{n-1}{x}\cos{x} + \frac{n-1}{n}\int \sin^{n-2}{x}\ dx \\
                    &\int_{0}^{\frac{\pi}{2}}\ \sin^{n}{x}\ dx = \frac{n-1}{n}\int_{0}^{\frac{\pi}{2}}\ \sin^{n-2}{x}\ dx
            .\end{align*}
            \begin{align*}
                &\int \cos^{n}{x}\ dx = \frac{1}{n}\cos^{n-1}{x}\sin{x} + \frac{n-1}{n}\int \cos^{n-2}{x}\ dx \\
                &\int_{0}^{\frac{\pi}{2}}\ \cos^{n}{x}\ dx = \frac{n-1}{n}\int_{0}^{\frac{\pi}{2}}\ \cos^{n-2}{x}\ dx
            .\end{align*}
            \begin{align*}
                \int \sec^{n}{x}\ dx &= \frac{1}{n-1}\sec^{n-1}{x}\sin{x}+\frac{n-2}{n-1}\int \sec^{n-2}{x}\ dx \\
                \int \sec^{n}{x}\ dx &= \frac{1}{n-1}\sec^{n-2}{x}\tan{x}+\frac{n-2}{n-1}\int \sec^{n-2}{x}\ dx
            \end{align*}
            \begin{align*}
                \int \tan^n x \, dx &= \frac{1}{n-1} \tan^{n-1}x - \int \tan^{n-2}x \, dx
            \end{align*}
        \item \textbf{Trigonometric substitution}: Trigonometric substitution is a technique used to evaluate integrals involving expressions of the form
            \begin{align*}
                \sqrt{a^{2} - x^{2}}, \quad \sqrt{a^{2} + x^{2}}, \quad \sqrt{x^{2} - a^{2}}
            .\end{align*}
            The method relies on the Pythagorean identities:
            \begin{align*}
                \sin^{2}{\left(\theta \right)} + \cos^{2}{\left(\theta \right)} &= 1, \\
                1+\tan^{2}{\left(\theta \right)} &= \sec^{2}{\left(\theta \right)}, \\
                \sec^{2}{\left(\theta \right)} -1 &= \tan^{2}{\left(\theta \right)}
            .\end{align*}
            If we see $\sqrt{a^{2} - x^{2}} $, use 
            \begin{align*}
                x = a\sin{\left(\theta \right)}  
            .\end{align*}
            Then,
            \begin{align*}
                dx = a\cos{\left(\theta \right)}\; d\theta 
            .\end{align*}
            So,
            \begin{align*}
                \sqrt{a^{2} - x^{2}} = \sqrt{a^{2} - (a\sin{\left(\theta \right)})^{2}} = \sqrt{a^{2}(1-\sin^{2}{\left(\theta \right)})} = \sqrt{a^{2}\cos^{2}{\left(\theta \right)}} = a\cos{\left(\theta \right)}
            .\end{align*}
            If we see $\sqrt{a^{2} + x^{2}} $, use
            \begin{align*}
                x = a\tan{\left(\theta \right)}
            .\end{align*}
            Then, 
            \begin{align*}
                dx = a\sec^{2}{\left(\theta \right)}\; d\theta 
            .\end{align*}
            So,
            \begin{align*}
                \sqrt{a^{2} + x^{2}} = \sqrt{a^{2}(1+\tan^{2}{\left(\theta \right)})} = a\sec{\left(\theta \right)}
            .\end{align*}
            If we see $ \sqrt{x^{2}-a^{2}}$, use
            \begin{align*}
                x = a\sec{\left(\theta \right)}
            .\end{align*}
            Then,
            \begin{align*}
                dx = a\sec{\left(\theta \right)}\tan{\left(\theta \right)}\; d\theta 
            .\end{align*}
            So,
            \begin{align*}
                \sqrt{x^{2} - a^{2}} = \sqrt{a^{2}(\sec^{2}{\left(\theta \right)}-1)} = a\tan{\left(\theta \right)}
            .\end{align*}
        \item \textbf{Polynomial long division}: Polynomial long division is the algebraic process used to divide one polynomial by another, in the same way that long division is used for numbers. In calculus, it is primarily used to rewrite improper rational functions so that techniques like partial fractions can be applied.
            \bigbreak \noindent 
            Polynomial division is based on the identity:
            \begin{align*}
                \frac{P(x)}{Q(x)} = D(x) + \frac{R(x)}{Q(x)}
            .\end{align*}
            Where
            \begin{itemize}
                \item $D(x)$ is the quotient,
                \item $R(x)$ is the remainder, and
                \item $\text{deg}(R) < \text{deg}(Q) $
            \end{itemize}
        \item \textbf{Integration by partial fractions}:  Partial fraction decomposition is a standard technique used primarily to evaluate rational integrals, that is, integrals of the form
            \begin{align*}
                \int \frac{P(x)}{Q(x)}\; dx
            \end{align*}
            where $P(x)$ and $Q(x)$ are polynomials, and 
            \begin{align*}
                \text{deg}(P) < \text{deg}(Q)
            .\end{align*}
            The core idea is to rewrite a complicated rational expression as a sum of simpler rational terms whose integrals are known. The method relies on a key algebraic fact... Any rational function with a factorable denominator can be expressed as a sum of simpler rational functions. These simpler terms correspond to the factors of the denominator, and each produces an integral you already know how to compute (logarithms or inverse trigonometric functions).
            \bigbreak \noindent 
            If $\text{deg}(P) \geq \text{deg}(Q)$, If this is not true, perform polynomial division first.
            \bigbreak \noindent 
            To perform partial fraction decomposition, we must ensure that the degree requirement holds. Then, we factor the denominator completely (over the real numbers). The possible factor types are
            \begin{enumerate}
                \item \textbf{Distinct linear factors}:
                    \begin{align*}
                        (x-a)(x-b)
                    .\end{align*}
                \item \textbf{Repeated linear factors}:
                    \begin{align*}
                        (x-a)^{2}, \quad (x-a)^{3}
                    .\end{align*}
                \item \textbf{Irreducible quadratics}:
                    \begin{align*}
                        x^{2} + bx + c, \quad (b^{2}-4ac < 0)
                    .\end{align*}
            \end{enumerate}
            One we have factored the denominator, we can write in partial fraction form.
            \begin{itemize}
                \item \textbf{Distinct linear factors}:
                    \begin{align*}
                        \frac{P(x)}{(x-a)(x-b)} = \frac{A}{(x-a)} + \frac{B}{(x-b)}
                    .\end{align*}
                \item \textbf{Repeated linear factors}:
                    \begin{align*}
                        \frac{P(x)}{(x-a)^{n}} = \frac{A_{1}}{(x-a)} + \frac{A_{2}}{(x-a)^{2}} + \cdots + \frac{A_{n}}{(x-a)^{n}}
                    .\end{align*}
                \item \textbf{Irreducible quadratic}:
                    \begin{align*}
                        \frac{P(x)}{ax^{2} + bx + c} = \frac{Ax+B}{ax^{2}+bx+c}
                    .\end{align*}
                    If repeated,
                    \begin{align*}
                        \frac{P(x)}{(ax^{2}+bx+c)^{2}} = \frac{Ax+B}{ax^{2}+bx+c} + \frac{Cx+D}{(ax^{2}+bx+c)^{2}}
                    .\end{align*}
            \end{itemize}
    \end{itemize}

    \pagebreak 
    \subsubsection{Calculus III}
    \begin{itemize}
        \item \textbf{Multivariable chain rule for one independent variable ($t$)}: For a differentiable function $z(x,y)$ of $x$ and $y$, where $x = g(t)$, $y = h(t) $  are differentiable functions of $t$, then $z(x(t), y(t)$ is a differentiable function of $t$, and 
            \begin{align*}
                \frac{dz}{dt} = \frac{\delta z}{\delta x} \cdot  \frac{dx}{dt} + \frac{\delta z}{\delta y} \cdot \frac{dy}{dt}
            .\end{align*}
    \end{itemize}



    \pagebreak 
    \subsection{First order differential equations and mathematical models}
    \subsubsection{First order differential equations}
    \begin{itemize}
        \item \textbf{Intro to differential equations}: A differential equation is an equation that relates
            \begin{itemize}
                \item an unknown function, and
                \item one or more of its derivatives.
            \end{itemize}
            Instead of solving for a number, we solve for a \textbf{function}. For example, 
            \begin{align*}
                \frac{dy}{dx} = 3x^{2}
            .\end{align*}
            This equation asks for a function $y(x)$ whose derivative equals $3x^{2}$.
        \item \textbf{Independent and dependant variables}: This distinction is fundamental.
            \begin{itemize}
                \item \textbf{Independent variable}: The variable you control or choose freely, does not depend on another variable. For example, the time $t$, position $x$, or angle $\theta$
                \item \textbf{Dependent variable}: The variable whose value depends on the independent variable. Usually written as a function, e.g. $y(x)$. For example, position as a function of time $x(t)$.
            \end{itemize}
            If 
            \begin{align*}
                y = x^{2}
            ,\end{align*}
            $x$ is the independent variable, and $y$ is the dependent variable. Changing $x$ causes $y$ to change. In a differential equation, 
            \begin{align*}
                \frac{dy}{dx} = 2x
            ,\end{align*}
            you are describing how fast the dependent variable changes with respect to the independent variable.
        \item \textbf{What a differential equation represents}: A differential equation describes a relationship between a quantity and how it changes.
            \bigbreak \noindent 
            For example, 
            \begin{align*}
                \frac{dx}{dt} = v
            \end{align*}
            says the rate of change of position with respect to time is velocity, since the unknown function is $x(t)$, which represents position as a function of time, and $x^{\prime}(t)$ is the rate of change of position with respect to time, which equals velocity $v$. 
        \item \textbf{The order of differential equations}: The order is determined by the highest derivative appearing.
            \begin{itemize}
                \item \textbf{First order}:
                    \begin{align*}
                        \frac{dy}{dx} = x
                    .\end{align*}
                \item \textbf{Second order}:
                    \begin{align*}
                        \frac{d^{2}y}{dx^{2}} + y = 0
                    .\end{align*}
                \item \textbf{Third order}:
                    \begin{align*}
                        \frac{d^{3}y}{dx^{3}} = t
                    .\end{align*}
                    Higher-order equations usually require more initial conditions.
            \end{itemize}
        \item \textbf{General vs particular solutions}: 
            \begin{itemize}
                \item \textbf{General solutions}: Contains constants
                    \begin{align*}
                        y = x^{3} + C 
                    .\end{align*}
                \item \textbf{Particular solutions}: Uses initial conditions to find constants
                    \begin{align*}
                        y(0) = 2 \implies y = x^{3} + 2
                    .\end{align*}
            \end{itemize}
            This reflects the idea that many functions can satisfy the same differential equation, but only one satisfies a given physical situation. A differential equation describes a family of curves, not a single curve. The constant $C$ is determined only if you specify a condition like:
            \begin{align*}
                y(1) = 3
            .\end{align*}
        \item \textbf{Goals of differential equations}: The study of differential equations has three principal goals
            \begin{enumerate}
                \item To discover the differential equation that describes a specified physical situation.
                \item To find—either exactly or approximately—the appropriate solution of that equation.
                \item To interpret the solution that is found.
            \end{enumerate}
        \item \textbf{Solutions}: In algebra, we typically seek the unknown \emph{numbers} that satisfy an equation
            such as
            \[
                x^{3} + 7x^{2} - 11x + 41 = 0.
            \]
            By contrast, in solving a differential equation, we are challenged to find the
            unknown \emph{functions} \( y = y(x) \) for which an identity such as
            \[
                y'(x) = 2xy(x)
            \]
            holds.
            \bigbreak \noindent 
            \textbf{Note:} The solution to a differential equation is a continuous function, since it is differentiable.
        \item \textbf{Interval of definition}: Corresponding to any solution of a differential equation is its interval of definition; also called interval of existence, interval of validity or domain of the solution. This can be an open, closed, bounded or unbounded interval.
            \bigbreak \noindent 
            If a differential equation has a solution
            \begin{align*}
                y = f(x)
            .\end{align*}
            then the interval of definition is the interval of $x$-values where
            \begin{itemize}
                \item $f(x)$ is defined
                \item $f(x)$ is differentiable
                \item The original differential equation makes sense
                \item No division by zero or undefined expressions occur
            \end{itemize}
            Consider the equation
            \begin{align*}
                \frac{dy}{dx} = \frac{1}{x}
            .\end{align*}
            A solution is
            \begin{align*}
                y = \ln\left\lvert x \right\rvert + C
            .\end{align*}
            Then, the \textbf{interval of definition} is 
            \begin{align*}
                (-\infty,0) \cup (0,\infty)
            .\end{align*}
            Because The function is undefined at $x=0$, and the solution cannot cross $x=0$
            \bigbreak \noindent 
            As a general solution, this is acceptable because:
            \begin{itemize}
                \item It represents two possible families of solutions
                \item One on $(-\infty,0)$
                \item One on $(0,\infty)$
            \end{itemize}
            At this stage, no single interval has been chosen yet. So,
            \begin{align*}
                y = \ln\left\lvert x \right\rvert + C
            \end{align*}
            is a formal solution that represents \textbf{both possibilities}. However, a particular solution chooses a specific function form this family. Since a solution to a differential equation must 
            \begin{itemize}
                \item Be defined on an interval
                \item Be continuous on that interval
                \item Satisfy the differential equation everywhere on that interval
            \end{itemize}
            The differential equation
            \begin{align*}
                \frac{dy}{dx} = \frac{1}{x}
            \end{align*}
            is undefined at $x=0$. That point splits the real line into two disconnected intervals
            \begin{align*}
                (-\infty, 0) \quad \text{ and } \quad (0,\infty)
            .\end{align*}
            A particular solution \textbf{cannot cross this singularity}.
            \bigbreak \noindent 
            Suppose that 
            \begin{align*}
                \frac{dy}{dx} = \frac{1}{x}, \quad y(1) = 0
            .\end{align*}
            Then,
            \begin{align*}
                y = \ln\left\lvert x \right\rvert
            .\end{align*}
            Notice that since $y(1) = 0$, the point $(1,0)$ must live in the domain of the solution. Thus, this fact forces the domain of the solution to be $(0,\infty)$, since it must be one, but not both. It cannot be both because a particular solution cannot 
            \begin{itemize}
                \item cross a point where the DE is undefined,
                \item be discontinuous,
                \item or “jump” from one interval to another.
            \end{itemize}
             Therefore, once the solution is fixed at $x=1$, it is locked into $(0,\infty)$. In fact, since this must be the domain, the solution becomes simply
             \begin{align*}
                 y = \ln{\left(x\right)}
             .\end{align*}
             If instead $y(-1) = 0$, then the particular solution is defined at $(-1,0)$. Thus, the domain is the left side of the singularity $(-\infty,0)$. In this case, 
             \begin{align*}
                 y = \ln{\left(-x\right)}
             .\end{align*}
             The key takeaway is that a general solution may span multiple disjoint intervals, but a particular solution must live on one continuous interval where the differential equation is defined. This is why the general solution is 
             \begin{align*}
                 y = \ln\left\lvert x \right\rvert + C
             ,\end{align*}
             but a particular solution must be either
             \begin{align*}
                 y = \ln{\left(x\right)} \quad \text{ or } \quad y = \ln{\left(-x\right)}
             \end{align*}
             depending on the initial condition.
             \bigbreak \noindent 
             Another key point arises when you recall that
             \begin{align*}
                 y = \ln{\left\lvert x \right\rvert}
             \end{align*}
             with domain
             \begin{align*}
                 (-\infty,0)\cup (0,\infty)
             \end{align*}
             is in fact differentiable across the entire domain, since the discontinuity at $x=0$ is not included in the domain. However, In differential equations, \textbf{a solution is not just any differentiable function.} A solution must
             \begin{itemize}
                 \item Satisfy the DE
                 \item Be differentiable
                 \item be defined on a single interval 
                 \item That interval must be connected
             \end{itemize}
             This last condition is key.
        \item \textbf{Why must a particular solution to a DE be defined on a single interval}:  A differential equation describes how a function changes locally. That means if you know the value of the function at one point, the equation tells you how it behaves near that point. That only makes sense if "near that point" actually exists. That's why a solution must live on one continuous interval.
            \bigbreak \noindent 
            Consider again the solution
            \begin{align*}
                y = \ln\left\lvert x \right\rvert                
            .\end{align*}
            Its algebraic domain is 
            \begin{align*}
                (-\infty,0) \cup (0,\infty)
            .\end{align*}
            This is two separate pieces. Now ask yourself... If I stand at $x=1 $, what does the differential equation tell me about what happens at $x=-1 $? The answer is nothing, there is no path from $1$ to $-1$ that stays inside the domain. So the DE gives no relationship at all between the two sides. This means
            \begin{itemize}
                \item The behavior on the left side is completely independent
                \item The behavior on the right side is completely independent
                \item They are not part of the same solution
            \end{itemize}
            Imagine a particle moving along a line. A differential equation gives its velocity
            \begin{align*}
                \frac{dy}{dx} = f(x)
            .\end{align*}
            Now, suppose the road has a cliff at $x=0$. You can
            \begin{itemize}
                \item Walk on the left side
                \item Walk on the right side
            \end{itemize}
            But, you \textbf{cannot} cross the cliff. So, motion on the left and right sides are \textbf{two different journeys}, not one. That's exactly what happens with singularities.
            \bigbreak \noindent 
            The key fact is that a solution to a DE is not just a differentiable function. The DE determines the function everywhere on its domain by \textit{local behavior}. This only works if the domain is connected.
            \bigbreak \noindent 
            If disconnected domains were allowed, then:
            \begin{itemize}
                \item Solutions wouldn’t be unique
                \item Initial conditions wouldn’t determine behavior
                \item Existence–uniqueness theorems would fail
                \item Physical interpretations would break
                \item You could literally “glue together” unrelated functions and call them a solution
            \end{itemize}
            This is why mathematics forbids it.
        \item \textbf{Singularities}: A singularity is a point where a mathematical expression or equation breaks down - meaning it is
            \begin{itemize}
                \item Undefined,
                \item Infinite,
                \item Or not well behaved
            \end{itemize}
            In differential equations, a singularity is a point where the right-hand side of the equation is not defined or not continuous.
            \bigbreak \noindent 
            Recall for
            \begin{align*}
                \frac{dy}{dx} = \frac{1}{x}
            ,\end{align*}
            the singularity is at $x=0 $, since division by zero is undefined. Hence, the slope is not defined at that point. The equation literally stops making sense there.
        \item \textbf{Families of solutions}: A solution of the first order DE $y = f(x, y)$ containing a single constant is called a one parameter family of solutions. An $n$th order DE has an $n$-parameter family of solutions.
        \item \textbf{Implicit solution}: Sometimes it may not be conducive or feasible to write the solution explicitly, as in, $y = f(x)$, Thus a relation $G(x, y) = 0$ between $x$ and $y$ is said to be an implicit solution of a DE if it satisfies the DE. That is, the solution can be given as an equation involving $x$ and $y$ instead of a function $y$ of $x$.
            \bigbreak \noindent 
            For example, we can show that the function $x^{3}y^{3} = x^{3} +1 $ is an implicit solution to the DE $xy^{\prime} + y = y^{-2} $
        \item \textbf{Integrating both sides of an equation}: Consider the equation
            \begin{align*}
                f(x) = k
            .\end{align*}
            If we integrate both sides, we get
            \begin{align*}
                \int f(x)\; dx = \int k\; dx
            .\end{align*}
            We write the integral with respect to $x$, which is denoted by $dx$. We are not adding a $dx$ algebraically, we are simply specifying the variable of integration. If our equation is instead.
            \begin{align*}
                \frac{dy}{dx} = f(x)
            .\end{align*}
            Then, integrating both sides yields
            \begin{align*}
                \int \frac{dy}{dx}\; dx = \int f(x)\; dx
            .\end{align*}
            Since derivatives and integrals are inverse operators, 
            \begin{align*}
                \int \frac{dy}{dx}\; dx = y + C
            .\end{align*}
            Thus,
            \begin{align*}
                \int \frac{dy}{dx}\; dx = \int f(x)\; dx \implies y = \int f(x)\; dx = F(x)
            ,\end{align*}
            where $F^{\prime}(x) = f(x)$.
        \item \textbf{Higher order derivatives}: Consider a higher order derivative
            \begin{align*}
                \frac{d^{3}y}{dx^{3}} = f(x)
            .\end{align*}
            To undo the third derivative, we must integrate three times. So,
            \begin{align*}
                \int \int \int \frac{d^{3}y}{dx^{3}}\; dx\;dx\; dx &= \int \int \int f(x)\; dx\; dx\; dx \\
            .\end{align*}
            Note that
            \begin{align*}
                \int \frac{d^{3}y}{dx^{3}}\; dx = \frac{d^{2}y}{dx^{2}}
            .\end{align*}
            Thus,
            \begin{align*}
                \int \int \int \frac{d^{3}y}{dx^{3}}\; dx\;dx\; dx &= y
            ,\end{align*}
            and 
            \begin{align*}
                \int \int \int f(x)\; dx\; dx\; dx = H(x) + Ax^2 + Bx + C
            ,\end{align*}
            where we can say
            \begin{align*}
                F^{\prime}(x) &= f(x), \\
                G^{\prime\prime}(x) &= f(x), \\
                H^{\prime\prime\prime}(x) &= f(x)
            .\end{align*}

        \item \textbf{Integrals as solutions}: A derivative tells you how something changes, an integral tells you what the original quantity must have been.
            \bigbreak \noindent 
            If a differential equation tells you 
            \begin{align*}
                \frac{dy}{dx} = f(x)
            ,\end{align*}
            then an integral gives you the function $y(x)$ whose derivative equals $f(x)$.
            \begin{align*}
                y(x) = \int f(x) dx
            .\end{align*}
            This is why integrals are best understood as solutions to differential equations, not just geometric areas.
            \bigbreak \noindent 
            For example, consider the statement "the rate of change of a quantity is proportional to time". So,
            \begin{align*}
                \frac{dy}{dt} = kt
            .\end{align*}
            To find the quantity itself, we integrate
            \begin{align*}
                y(t) = \int kt\; dt = \frac{k}{2}t^{2} + C
            .\end{align*}
            The differential equation describes how the system evolves, the integral gives the actual behavior
        \item \textbf{Integrals for higher order differential equations}: Consider the differential equation
            \begin{align}
                \frac{d^{3}y}{dx^{3}} = e^{4x}
            .\end{align}
            So, 
            \begin{align*}
                y = \int \int \int e^{4x}\; dx\;dx\; dx
            .\end{align*}
            Since $\int e^{rx}\; dx = \frac{1}{r}e^{rx} + C$,
            \begin{align*}
                y = \frac{1}{4^{3}}e^{4x} + Ax^{2} + Bx + C
            .\end{align*}
            
        \item \textbf{Verifying solutions to differential equations}: The solution to a differential equation is any function that satisfies the differential equation on the given interval
            \bigbreak \noindent 
            Suppose we want to verify that 
            \begin{align*}
                y(x) = \frac{1}{16}x^{4}
            \end{align*}
            is a solution to the differential equation 
            \begin{align*}
                \frac{dy}{dx} = xy^{\frac{1}{2}}
            \end{align*}
            over the interval $(-\infty, \infty)$.
            \bigbreak \noindent 
            So,
            \begin{align*}
                \frac{dy}{dx} = \frac{1}{4}x^{3}
            .\end{align*}
            Then,
            \begin{align*}
                \frac{1}{4}x^{3} = xy^{\frac{1}{2}} \implies y = \left(\frac{1}{4}x^{2}\right)^2 = \frac{1}{16}x^{4}
            .\end{align*}
            Thus, $\frac{1}{16}x^{4}$ is a solution to the differential equation $\frac{dy}{dx} = xy^{\frac{1}{2}} $. Observe that
            \begin{align*}
                \frac{dy}{dx} = xy^{\frac{1}{2}} = x\left(\frac{1}{16}x^{4}\right)^{\frac{1}{2}} = x \left(\frac{1}{4}x^{2}\right) = \frac{1}{4}x^{3}
            .\end{align*}
            Next, suppose that we want to verify that 
            \begin{align*}
                y(x) = 4\cos{\left(2x\right)} + 6\sin{\left(2x\right)}
            \end{align*}
            is a solution to the differential equation
            \begin{align*}
                y^{\prime\prime} + 4y = 0
            \end{align*}
            on the interval $(-\infty, \infty)$. So, we have that
            \begin{align*}
                y^{\prime}(x) = \frac{d}{dx}\left(4\cos{\left(2x\right)} + 6\sin{\left(2x\right)}\right) = -8\sin{\left(2x\right)} + 12\cos{\left(2x\right)}, \\
                y^{\prime\prime}(x) = \frac{d}{dx}\left(-8\sin{\left(2x\right)} + 12\cos{\left(2x\right)}\right) = -16\cos{\left(2x\right)} - 24 \sin{\left(2x\right)}
            .\end{align*}
            So, since $y^{\prime\prime}  = -4y $,
            \begin{align*}
                -16\cos{\left(2x\right)} - 24 \sin{\left(2x\right)} = -4y \implies y = 4\cos{\left(2x\right)} + 6\sin{\left(2x\right)}
            .\end{align*}
            Thus, it is verified. Alternatively, with $y^{\prime\prime} + 4y = 0 $, we have
            \begin{align*}
               -16\cos{\left(2x\right)}  -24\sin{\left(2x\right)} + 4\left(4\cos{\left(2x\right)} + 6\sin{\left(2x\right)}\right) = 0, \\
               \implies 0 = 0
            .\end{align*}
            Again, verified.
        \item \textbf{Separable differential equation}: A differential equation is separable if it can be written in the form
            \begin{align*}
                \frac{dy}{dx} = g(x)h(y)
            .\end{align*}
            or equivalently,
            \begin{align*}
                \frac{1}{h(y)}dy = g(x)dx
            .\end{align*}
            This structure allows the variables to be separated and integrated independently. Thus,
            \begin{align*}
                \int \frac{1}{h(y)}\; dy &= \int g(x)\; dx \implies F(y) + C_1 = G(x) + C_2, \\
               \implies F(y) &= G(x) + C_2 - C_1 = G(x) + C 
            .\end{align*}
            For example, consider 
            \begin{align*}
                \frac{dy}{dx} = xy
            .\end{align*}
            So,
            \begin{align*}
                \frac{1}{y}dy &= xdx \implies \int \frac{1}{y}\; dy = \int x\; dx \\
                \implies \ln\left\lvert y \right\rvert + C_1 &= \frac{1}{2}x^{2} + C_2 \\
                \implies e^{\ln{\left\lvert y \right\rvert}} &= e^{\frac{1}{2}x^{2} + C_2 - C_1}\\
                \implies e^{\ln{\left\lvert y \right\rvert}} &= e^{\frac{1}{2}x^{2} + C}\\
                \implies \left\lvert y \right\rvert &= e^{\frac{1}{2}x^{2}}e^{C}  \\
                \implies y &= \pm e^{\frac{1}{2}x^{2}}e^{C} = Ce^{\frac{1}{2}x^{2}}
            .\end{align*}
            A differential equation is separable if
            \begin{enumerate}
                \item It is first order
                \item Variables can be isolated on opposite sides
                \item No mixed terms remain after separation
                \item Integration is straightforward 
            \end{enumerate}
            An example of a DE that is \textbf{not} separable is
            \begin{align*}
                \frac{dy}{dx} = x + y
            .\end{align*}
            If we try to treat this as separable, we get
            \begin{align*}
                dy = (x+y)dx 
            .\end{align*}
            So,
            \begin{align*}
                \frac{1}{x+y}dy = dx
            .\end{align*}
            Since the left side is a function of both $x$ and $y$, instead of strictly $y$, we have not separated variables.

        \item \textbf{Dealing with $\pm$}: When solving differential equations, you often reach a point like:
            \begin{align*}
                \left\lvert y \right\rvert = e^{f(x)}
            .\end{align*}
            So,
            \begin{align*}
                y = \pm e^{f(x)}
            .\end{align*}
            Rather than writing $\pm$, we write
            \begin{align*}
                y = Ce^{f(x)}
            ,\end{align*}
            with
            \begin{align*}
                C \in \mathbb{R} \setminus \{0\}
            .\end{align*}
        \item \textbf{Newton's law of cooling}: Newton’s Law of Cooling describes how the temperature of an object changes over time as it exchanges heat with its surrounding environment
            \bigbreak \noindent 
            Newton’s Law of Cooling states that the rate of change of the temperature of an object is proportional to the difference between the object’s temperature and the ambient (surrounding) temperature.
            \bigbreak \noindent 
            If the object is hotter than its surroundings, it cools down. If it is colder, it warms up. The greater the temperature difference, the faster the rate of change.
            \bigbreak \noindent 
            Let
            \begin{itemize}
                \item $T(t)$ = temperature of the object at time  $t$
                \item $T_{a}$ = ambient (constant) temperature
                \item $k>0$ = cooling constant (depends on material and environment)
            \end{itemize}
            Then, the law of cooling states
            \begin{align*}
                \frac{dT}{dt} = -k(T - T_{a})
            .\end{align*}
            The negative sign ensures:
            \begin{itemize}
                \item Cooling when $T > T_{a}$
                \item Heating when $T<T_{a}$
            \end{itemize}
            Notice that we can use separation to solve this differential equation. We have
            \begin{align*}
                \frac{1}{T - T_{a}}dT = -kdt
            .\end{align*}
            So,
            \begin{align*}
                \int \frac{1}{T-T_{a}}\; dT &= -\int k\; dt \\
                \implies \ln\left\lvert T-T_{a} \right\rvert &= -kt + C \\
                \implies T-T_{a} &= e^{-kt + C} = e^{-kt}e^{C} = Ce^{-kt}
            .\end{align*}
            Thus,
            \begin{align*}
                T(t) = T_{a} + Ce^{-kt}
            .\end{align*}
            This is the general solution to the cooling problem. If we let $T(0) = T_0 $ be the initial temperature of the object at time $t = 0$, then
            \begin{align*}
                T_{0} = T_{a} + Ce^{0} = T_{a} + C
            .\end{align*}
            Thus,
            \begin{align*}
                C = T_{0} - T_{a}
            .\end{align*}
            Plugging this into the general form yields
            \begin{align*}
                T(t) = T_{a} + (T_{0} - T_{a})e^{-kt}
            .\end{align*}
            This is the standard form.




    \end{itemize}

    \pagebreak 
    \subsubsection{Mathematical models with first order differential equations}:
    \begin{itemize}
        \item \textbf{Tools we might need}: A quantity $A$ is proportional to another quantity $B $ if the ratio between them is a constant. We write $A \propto B \iff A = kB$ where $k$ is the proportionality constant.
            \bigbreak \noindent 
            Next, if $A$ and $B$ are two groups, then the product $AB$ represents the mathematical model of interaction between the two groups
        \item \textbf{Mathematical model}: The mathematical description of a system or phenomenon is called a mathematical model .
            \bigbreak \noindent 
            Mathematical modeling involves the following:
            \begin{itemize}
                \item Translating a real-world problem into mathematics using differential equations;
                \item Analysing or solving the resulting differential equation;
                \item Interpreting the results in the context of the original situation, answering the question originally posed and checking whether our answer actually makes logical sense
            \end{itemize}
            In mathematical modeling, we make assumptions and consider the simplest cases to get a ’feasible’ model that may only work in very rare circumstances; then we seek to improve the model by modifying some of our assumptions (like modifying the constant growth rate of the exponential model to the more realistic one in the logistic model)
            \bigbreak \noindent 
            For example, the basic population model (below) states
            \begin{align*}
                \frac{dP}{dt} = kP(t)
            .\end{align*}
            This model has some drawbacks because it projects exponential growth, which is unrealistic in several scenarios. It claims a population’s per capita (per individual) growth rate remains constant irrespective of population size, making the population grow faster as it gets larger.
            \bigbreak \noindent 
            Consequently, The quest for a more realistic model led to the logistic model
            \begin{align*}
                \frac{dP}{dt} = kP\left(1-\frac{P}{M}\right)
            .\end{align*}
            which proposes that a population’s per capita growth rate gets smaller as population size approaches a maximum imposed by limited resources, where $M$ denotes the environmental carrying capacity (the number of individuals the environment can contain).
        \item \textbf{Basic population model}:  Thomas Malthus, the English clergyman and economist proposed the earliest mathematical model of population growth. This model claims that the rate of change of a population $(P(t))$ with time is proportional to the existing population.
            \bigbreak \noindent 
            Thus, the model is
            \begin{align*}
                \frac{dP}{dt} = kP(t)
            .\end{align*}
        \item \textbf{Newton's law of cooling and warming}: Let $T(t)$ be the temperature of an object at time $t$, and let $A$ be the temperature of the surrounding environment (usually a constant). Newton’s law of cooling/warming states that the rate at which the temperature of an object changes is proportional to the difference between the temperature of the object and the temperature of the surrounding environment.
            \bigbreak \noindent 
            Thus, the model is 
            \begin{align*}
                \frac{dT}{dt} = k(T-A)
            .\end{align*}
        \item \textbf{A third model example}: Suppose a student carrying a flu virus returns to an isolated college campus of 1000 students. Determine a differential equation for the number of people $x(t)$ who have contracted the flu if the rate at which the disease spreads is proportional to the number of interactions between the number of students who have the flu and the number of students who have not yet been exposed to it.
            \bigbreak \noindent 
            The number of people who have contacted the flu is given by $x(t)$, so the number of people who have \textbf{not} contacted the flu is given by
            \begin{align*}
                1000 - x(t)
            .\end{align*}
            Because we are interested in the interaction between these two quantities, the interaction is their product 
            \begin{align*}
                x(t)(1000- x(t))
            .\end{align*}
            Thus, the rate at which the disease spreads is the rate at which the number of people who have contacted the flu $x(t)$ increases with respect to time, $\frac{dx}{dt}$, which is proportional to the interaction. Thus, the differential equation is
            \begin{align*}
                \frac{dx}{dt}= kx(t)(1000-x(t))
            .\end{align*}
            Note that $x(0) = 1$. A single student is infected at time $t=0$.






    \end{itemize}

    \pagebreak 
    \subsubsection{Slope fields, solution curves, and the existence / uniqueness theorem}
    \begin{itemize}
        \item \textbf{Slope fields}: A slope field (also called a direction field) is a graphical tool used in differential equations to visualize the behavior of solutions without explicitly solving the equation.
            \bigbreak \noindent 
            A slope field corresponds to a first-order differential equation of the form
            \begin{align*}
                \frac{dy}{dx} = f(x,y)
            .\end{align*}
            At each point $(x,y)$ in the plane,
            \begin{itemize}
                \item The value $f(x,y)$ gives the slope of the solution curve at that point.
                \item A short line segment with that slope is drawn.
                \item Collectively, these small segments form the slope field.
            \end{itemize}
            Each segment shows the direction a solution curve would follow if it passed through that point.
            \bigbreak \noindent 
            Slope fields are used to:
            \begin{itemize}
                \item Visualize solutions without solving the differential equation.
                \item Understand qualitative behavior (growth, decay, equilibrium).
                \item Estimate solutions given an initial condition.
                \item Analyze stability and long-term behavior.
            \end{itemize}
            They are especially useful when:
            \begin{itemize}
                \item The equation cannot be solved analytically.
                \item You want geometric intuition before solving.
            \end{itemize}
        \item \textbf{Solution curves}: A solution curve:
            \begin{itemize}
                \item Is a smooth curve that follows the slope field everywhere.
                \item Is tangent to each segment it passes through.
                \item Represents a specific solution $y(x)$.
            \end{itemize}
            An initial condition, such as:
            \begin{align*}
                y(0) = 2
            \end{align*}
            selects one specific solution from infinitely many possible ones.
        \item \textbf{Sketching solutions with direction fields}: If we write a first order ODE in standard form as $\frac{dy}{dx} = f(x, y)$ Then we can use the fact that derivative at a point gives the slope of the tangent line at that point to sketch line segments depicting these slopes. These line segments gives us a visual depiction of the shape of solutions; thus we can use them to sketch the solution passing through a given point because the graph of the solutions are tangent to the lineal elements or equivalently the direction field.
            \bigbreak \noindent 
            For example, consider
            \begin{align*}
                \frac{dy}{dx} = 1-xy
            .\end{align*}
            The direction field is then
            \bigbreak \noindent 
            \fig{.6}{./figures/dir1.png}
            \bigbreak \noindent 
            \textbf{Note:} To actually draw a curve, we must solve the DE. There are infinitely many possible curves, each one coming from a different initial point.
        \item \textbf{Approximate solution curve}: If we cannot solve the DE, we can instead
            \begin{enumerate}
                \item Pick a starting point $(x_{0}, y_{0}) $
                \item Use the slope at that point
                \item Move a small step in that direction
                \item Repeat
            \end{enumerate}
            This is called \textbf{Euler's method}. That is how software draws solution curves when no closed form solution is known.
            
        \item \textbf{Equilibrium (constant) solutions}: An equilibrium occurs when
            \begin{align*}
                \frac{dy}{dx} = 0
            .\end{align*}
            This happens when
            \begin{align*}
                f(x,y = 0)
            .\end{align*}
            These appear as horizontal lines in the slope field. For example, if 
            \begin{align*}
                \frac{dy}{dx}= y(1-y)
            ,\end{align*}
            then the equilibria occurs when
            \begin{align*}
                y(1-y) = 0
            .\end{align*}
            So, $y=0$ or $y=1 $
            \bigbreak \noindent 
            These lines often represent:
            \begin{itemize}
                \item Stable equilibrium (solutions approach it)
                \item Unstable equilibrium (solutions move away)
            \end{itemize}
        \item \textbf{Existence / uniqueness theorem}: Consider the IVP
            \begin{align*}
                \begin{cases}
                    \frac{dy}{dx} &= f(x,y), \\
                    y(x_{0}) &= y_{0}
                \end{cases}
            .\end{align*}
            \begin{enumerate}
                \item If $f(x,y)$ is continuous \textbf{around} $(x_{0}, y_{0}) $, then the IVP has a solution on an open interval containing $x_{0}$
                \item If in addition, $\frac{\delta f}{\delta y} $ is continuous around $(x_{0}, y_{0})$, then the solution is unique on that interval.
            \end{enumerate}
            \textbf{Note:} This is a sufficient but not necessary condition for existence. Also, A solution exists and is unique on some open interval containing the initial point.
            \bigbreak \noindent 
            Consider an example,
            \begin{align*}
                \begin{cases}
                    \frac{dy}{dx} &= x \ln{\left(y\right)}     , \\
                    y(1) &= 1
                \end{cases}
            .\end{align*}
            Since the natural log is continuous on its domain $(0,\infty)$, $x\ln{\left(y\right)} $ is continuous around $(1,1)$. Thus, a solution exists.
            \bigbreak \noindent 
            The partial derivative of $f(x,y) $ with respect to $y $ is
            \begin{align*}
                \frac{\delta f}{\delta y} = \frac{x}{y}
            ,\end{align*}
            which has a discontinuity at $y=0$. Thus, since $y\ne 0$, $\frac{x}{y}$ is continuous around $(1,1)$.
            \bigbreak \noindent 
            Therefore, there is a unique solution around $x_{0}$.
            \bigbreak \noindent 
            Next, consider 
            \begin{align*}
                \begin{cases}
                    \frac{dy}{dx} &= \sqrt{x-y}, \\
                    y(2) &= 2
                \end{cases}
            .\end{align*}
            Recall that $\sqrt{x-y}$  is only defined for real $x,y$ if $x-y \geq 0$. Since $x_{0} - y_{0} = 2-2 = 0$, $\sqrt{x-y}$ is not continuous around $(x_{0}, y_{0})$. Thus, no solution exists.
            \bigbreak \noindent 
            Consider 
            \begin{align*}
                \begin{cases}
                    \frac{dy}{dx} = \frac{y}{x}, \\
                    y(0) = 0
                \end{cases}
            .\end{align*}
            So
            \begin{align*}
                \frac{1}{y}dy &= \frac{1}{x}dx \\ 
                \implies \int \frac{1}{y}\; dy &= \int \frac{1}{x}\; dx \\
                \implies \ln{\left\lvert y \right\rvert} &= \ln{\left\lvert x \right\rvert} + C_{0} \\
                \implies \left\lvert y \right\rvert &= e^{\ln{\left\lvert x \right\rvert} + C_{0}} \\
                \implies \left\lvert y \right\rvert &= C\left\lvert x \right\rvert \\
                \implies y &= \pm C x = Kx
            .\end{align*}
            Notice that $f(x,y) = \frac{y}{x}$, which is not continuous around $(0,0)$. Thus, the theorem does not guarantee a solution on an open interval containing $(0,0)$. In fact, 
            \begin{align*}
                y &= Kx
            \end{align*}
            satisfies the DE for any $x\ne 0$, and $y(0) = 0$ holds for any value of $K$. Thus, infinitely many solutions satisfy the DE, so we see that uniqueness fails. The theorem does not apply at $(0,0)$, so it gives no information about solutions near $x=0$. However, even though the theorem does not apply, solutions do exist.
            \bigbreak \noindent 
            

    \end{itemize}

    \pagebreak 
    \subsubsection{Linear differential equations}
    \begin{itemize}
        \item \textbf{Linear DE}: A DE is linear in $y$ if it is linear in $y$ and its derivatives. Thus, no products of $y$ and itself or its derivatives, and no nonlinear function of $y$ or its derivatives. Consider the following functions
            \begin{enumerate}[label=(\alph*)]
                \item $y^{\prime} + y = x^{2} $: Linear
                \item $y^{\prime} + y^{2} = x $: Non-linear, problem is $y^{2}$
                \item $2y^{\prime} = (y^{2} + 1)(y+1)$: Non-linear, problem is $y^{2}$ and $y^{3}$
                \item $y^{\prime}(1+y) +3y = 4x$: Non-linear, problem is $y^{\prime} y $
                \item $\frac{d^{4}y}{dx^{4}} + y^{2} = 0$: Non-linear, $y^{2} $
                \item $x^{3} \frac{d^{3}y}{dx^{3}}+ x \frac{dy}{dx} -5y = e^{x}$: Linear
                \item $\frac{d^{2}y}{dx^{2}} + \sin{\left(y\right)}  = 0$: Non-linear, $\sin{\left(y\right)} $
            \end{enumerate}
            Notice that the linearity in $y$ of a DE does not say anything about linearity of functions of $x$, all we care about is $y$ and its derivatives.
        \item \textbf{Linear DEs (formal)}: A linear differential equation is one in which the dependent variable and all its derivatives appear linearly (i.e., no products, powers, or nonlinear functions of the dependent variable). An $n^{\text{th}}$ order linear differential equation has the form
            \begin{align*}
                a_{n}(x)y^{(n)} + a_{n-1}(x)y^{(n-1)} + \cdots + a_{1}(x)y^{\prime} + a_{0}(x)y = g(x)
            .\end{align*}
            Where
            \begin{itemize}
                \item $y=y(x)$ is the unknown function
                \item $a_{i}(x), g(x)$ are given functions of $x$
                \item The coefficients depend only on $x$, not on $y$ or its derivatives
            \end{itemize}
        \item \textbf{First order differential equations}: The standard form is
            \begin{align*}
                \frac{dy}{dx} + P(x)y = Q(x)
            .\end{align*}
            This form is essential because it allows solution via an integrating factor.
            \bigbreak \noindent 
            If we take a first order linear equation,
            \begin{align*}
                a_{1}(x)y^{\prime} + a_{0}(x)y = g(x)
            .\end{align*}
            Then, we see that
            \begin{align*}
                y^{\prime} + \frac{a_{0}(x)}{a_{1}(x)}y = \frac{g(x)}{a_{1}(x)}
            .\end{align*}
            Now, let $\frac{a_{0}(x)}{a_{1}(x)} = P(x)$, and $\frac{g(x)}{a_{1}(x)} = Q(x) $, this gives the standard form
            \begin{align*}
                \frac{dy}{dx} + P(x)y = Q(x)
            .\end{align*}
            Note that we are assuming here that $a_{1}(x) \ne 0 $ on the interval of interest.
            \bigbreak \noindent 
            Consider the first order linear differential equation
            \begin{align*}
                (2x-1)\frac{dy}{dx} +3y = \sin{\left(x\right)}
            .\end{align*}
            Then,
            \begin{align*}
                \frac{dy}{dx} + \frac{3}{2x-1}y = \frac{\sin{\left(x\right)}}{2x-1}
            ,\end{align*}
            now it is in standard form.
        \item \textbf{Integrating factor method (First order)}: Define
            \begin{align*}
                \mu(x) = e^{\int P(x)\; dx}
            .\end{align*}
            Multiply the standard form of the differential equation by $\mu(x) $,
            \begin{align*}
                \mu(x)\frac{dy}{dx} + \mu(x)P(x)y = \mu(x)Q(x)
            .\end{align*}
            Then, the left hand side becomes
            \begin{align*}
                \frac{d}{dx}\left(\mu(x)y\right)
            .\end{align*}
            Thus,
            \begin{align*}
                \frac{d}{dx}\left(\mu(x)y\right) = \mu(x)Q(x)
            .\end{align*}
            Then, we integrate
            \begin{align*}
                \mu(x)y = \int \mu(x)Q(x)\;  \dx + C
            .\end{align*}
            Finally, solve for $y$,
            \begin{align*}
                y = \frac{1}{\mu(x)}\left(\int \mu(x)Q(x)\; dx + C\right)
            .\end{align*}
            Consider an example,
            \begin{align*}
                \frac{dy}{dt} - 5y = te^{4t}
            .\end{align*}
            So, $P(t) = -5$, and $Q(t) = te^{4t}$. Define 
            \begin{align*}
                \mu(t) = e^{\int P(t)\; dt} = e^{\int -5\; dt} = e^{-5t}
            .\end{align*}
            Now,
            \begin{align*}
                y(t) = \frac{1}{\mu(t)}\left(\int \mu(t)Q(t)\; dt + C\right)
            .\end{align*}
            So,
            \begin{align*}
                y(t) = \frac{1}{e^{-5t}}\left(\int te^{-5t}e^{4t}\; dt + C\right) = \frac{1}{e^{-5t}}\left(\int te^{-t}\; dt + C\right)
            .\end{align*}
            Using integration by parts, let $u = t$, so $du = dt$, and $dv = e^{-t}$, so $v = -e^{-t}$. Then,
            \begin{align*}
                \int te^{-t}\; dt = -te^{-t} - \int -e^{-t}\; dt = -te^{-t} - e^{-t}
            .\end{align*}
            Thus,
            \begin{align*}
                y(t) = \frac{1}{e^{-5t}}\left(-te^{-t}-e^{-t} + C\right)
            .\end{align*}
            Now, consider
            \begin{align*}
                \frac{dy}{dt} = - \frac{y}{t} + 7
            .\end{align*}
            In standard form,
            \begin{align*}
                \frac{dy}{dt} + \frac{1}{t}y = 7
            .\end{align*}
            Thus, $P(t) = \frac{1}{t} $, and $Q(t)  = 7$. Define
            \begin{align*}
                \mu(t) = e^{\int \frac{1}{t}\; dt} = e^{\ln{\left\lvert t \right\rvert}} = \left\lvert t \right\rvert
            .\end{align*}
            On any interval not containing zero (because $\frac{1}{t}$ in the differential equation is not defined at $t=0$), we may take
            \begin{align*}
                \mu(t) = t \quad \text{or} \quad \mu(t) = -t
            .\end{align*}
            Take $\mu(t) = t$. Then,
            \begin{align*}
                y(t) = \frac{1}{t}\left(\int 7t + C\right) = \frac{1}{t}\left(\frac{7}{2}t^{2} + C\right)
            .\end{align*}
        \item \textbf{The integrating factor is not unique}: Any nonzero constant multiple of an integrating factor is also an integrating factor. Suppose $\mu(t)$ is an integrating factor. Then, for any $C \ne 0 $, 
            \begin{align*}
                C\mu(t)
            \end{align*}
            also works. This is because
            \begin{align*}
                \frac{d}{dt}\left(C\mu(t)y\right) = C \frac{d}{dt}\left(\mu(t)y\right)
            .\end{align*}
            Consider $k\mu(x)$ for $k\ne 0$, we would then have
            \begin{align*}
                k\mu(x)\frac{dy}{dx} + k\mu(x)P(x)y = k\mu(x)Q(x) \implies k \frac{d}{dx}\left(\mu(x)y\right) = k\mu(x)Q(x)
            .\end{align*}
            Thus, we get the same
            \begin{align*}
                \frac{d}{dx}\left(\mu(x)y\right) = \mu(x)Q(x)
            ,\end{align*}
            which yields the same expression for $y$,
            \begin{align*}
                y(x) = \frac{1}{\mu(x)}\left(\int \mu(x)Q(x)\; dx + C\right)
            .\end{align*}
            This is why for $\mu(t) = \left\lvert t \right\rvert $, we can choose either $\mu(t) = t$ or $\mu(t) = -t$, because both integrating factors yield the same solution set.



        \item \textbf{Homogeneous and non-homogeneous linear first order DEs}: A first order linear DE of the form
            \begin{align*}
                \frac{dy}{dx} + P(x)y = 0
            \end{align*}
            is called \textbf{homogeneous}, and the solution is
            \begin{align*}
                y = Ce^{-\int P(x)\; dx}
            .\end{align*}
            If $Q(x) \ne 0$, then
            \begin{align*}
                \frac{dy}{dx} + P(x)y = Q(x)
            \end{align*}
            is said to be \textbf{non-homogeneous}, with solution
            \begin{align*}
                y = y_{h} + y_{p}
            ,\end{align*}
            where
            \begin{itemize}
                \item $y_{h} = $ solution to homogeneous equation
                \item $y_{p} = $ particular solution
            \end{itemize}
        \item \textbf{Model example with first order linear DE}: A 30-gallon tank initially contains 15 gallons of salt water containing 3 pounds of salt. Suppose salt water containing 1 pound of salt per gallon is pumped into the top of the tank at the rate of 2 gallons per minute, while a well-mixed solution leaves the bottom of the tank at a rate of 1 gallon per minute. How much salt is in the tank when the tank is full?
            \bigbreak \noindent 
            Notice that we are interested in the change of salt. If $S(t)$ denotes the amount of salt in the tank at time $t$, and $V(t)$ denotes the amount of water in the tank at time $t$, then we are interested in $\frac{dS}{dt}$.
            \bigbreak \noindent 
            The initial amount of water in the tank is $15$ gallons. The inflow of water into the tank is $2$ gallons per minute, while the outflow is $1$ gallon per minute. So, the net change in the amount of water per unit time is $2-1$ gallons per minute. Thus,
            \begin{align*}
                V(t) = 15 + \text{net change per unit time} = 15 + (2-1)t = 15 + t
            .\end{align*}
            From this, if $t_{f}$ is the time when the tank is full (at 30 gallons), 
            \begin{align*}
                V(t_{f}) = 30 = 15 + t_{f}
            .\end{align*}
            So, $t_{f} = 15$ minutes.
            \bigbreak \noindent 
            Since $S(t)$ is the unknown function, $S(0) = 3$ is the initial condition. Observe that a well-mixed solution implies 
            \begin{align*}
                \frac{S(t)}{V(t)} \frac{\text{lb}}{\text{gal}}
            .\end{align*}
            We require the rate of salt in minus the rate of salt out, since we are interesting in only the amount of salt at the end. First, we can find the rate of salt into the tank. If 1 lb of salt per gallon is pumped into the tank at the rate of 2 gallons per minute, then the rate of salt in is given by
            \begin{align*}
                1 \frac{\text{lb}}{\text{gal}} \cdot 2 \frac{\text{gal}}{\text{min}} = 2 \frac{\text{lb}}{\text{min}}
            .\end{align*}
            Now for the rate of salt out of the tank. Recall that there are $\frac{S(t)}{V(t)}$ pounds of salt water per gallon of water. So, if the amount of salt water that leaves the tank per minute is one, then the rate of salt out is given by
            \begin{align*}
                \frac{S(t)}{V(t)} \frac{\text{lb}}{\text{gal}} \cdot 1 \frac{\text{gal}}{\text{min}} = \frac{S(t)}{V(t)} \frac{\text{lb}}{\text{min}}
            .\end{align*}
            So, the rate of change in salt is given by
            \begin{align*}
                \frac{dS}{dt} = \text{rate in } - \text{ rate out} = \left(2 - \frac{S(t)}{15 + t}\right) \frac{\text{lb}}{\text{min}}
            .\end{align*}
            Notice that this is a first order linear differential equation, which has standard form
            \begin{align*}
                \frac{dS}{dt} + \frac{1}{15+t}S = 2
            .\end{align*}
            Now, we can solve. Define 
            \begin{align*}
                \mu(t) = e^{\int \frac{1}{15+t}\; dt} = e^{\ln\left\lvert 15+t \right\rvert} = 15+t
            .\end{align*}
            Thus,
            \begin{align*}
                S(t) = \frac{1}{15+t}\left(\int (2(15+t))\; dt + C\right) = \frac{1}{15+t}\left(30t + t^{2} + C\right)
            .\end{align*}
            With the initial condition $S(0) = 3$, 
            \begin{align*}
                3 = \frac{1}{15+0}(30(0) + 0^{2} + C) \implies C = 45
            .\end{align*}
            So,
            \begin{align*}
                S(t) = \frac{1}{15+t}\left(t^{2} + 30t + 45\right) = \frac{t^{2} + 30t + 45}{15+t}
            .\end{align*}
            When the tank is full, $t = 15$, so the amount of salt in the tank when it is full is given by
            \begin{align*}
                S(15) = \frac{15^{2} + 30(15) + 45}{30} = 24
            .\end{align*}


    \end{itemize}

    \pagebreak 
    \subsection{Substitution methods and exact solutions}
    \subsubsection{Substitution methods}
    \begin{itemize}
        \item \textbf{Multivariate polynomials}: When a polynomial depends on more than one independent variable, it is called a multivariate polynomial. Let $x_{1}, x_{2}, \dots, x_{n}$ be independent variables. A \textbf{polynomial} in $n$ variables over a field $\mathbb{F}$ has the form
            \begin{align*}
                p(x_{1}, \dots, x_{n}) = \sum_{\alpha \in \mathbb{N}^{n}} c_{\alpha}x_{1}^{\alpha_{1}}x_{2}^{\alpha_{2}} \cdots x_{n}^{\alpha_{n}}
            \end{align*}
            where
            \begin{itemize}
                \item Each $c_{\alpha} \in \mathbb{F}$
                \item The multi-index $\alpha = (\alpha_{1}, \dots, \alpha_{n}) $ has only finitely many nonzero coefficients
                \item All exponents are non-negative integers
            \end{itemize}
            Each term $c_{\alpha}x^{\alpha} $ is called a \textbf{monomial}. For a monomial $x_{1}^{\alpha_{1}} \cdots x_{n}^{\alpha_{n}}$, the \textbf{total degree} is 
            \begin{align*}
                \left\lvert \alpha \right\rvert = \alpha_{1} + \cdots + \alpha_{n}
            .\end{align*}
            The degree of the polynomial is the maximum total degree among its monomials.
            \bigbreak \noindent 
            Consider
            \begin{align*}
                p(x,y) = 3x^{2}y + 5y^{3} - 7
            .\end{align*}
            Here, $p$ has degree $3$.
        \item \textbf{Homogeneous polynomials}: A polynomial is \textbf{homogeneous of degree $d$} if \textit{every} monomial has total degree $d$. For example,
            \begin{align*}
                q(x,y,z) = x^{2} + y^{2} + z^{2}
            \end{align*}
            is homogeneous of degree $2$.
        \item \textbf{Homogeneous functions}: $f$ is homogeneous of degree $n$ if
            \begin{align*}
                f(tx) = t^{n}f(x)
            .\end{align*}
            For example, if $f(x) = x^{2}$, then $f(tx) = t^{2}x^{2}$, so $f$ is homogeneous of degree $2$. Linear functions are homogeneous of degree $1$.
        \item \textbf{First order DE differential form}: For any first order differential equation, we can write it in the differential form
            \begin{align*}
                M(x,y)dx + N(x,y)dy = 0
            .\end{align*}
        \item \textbf{Coefficient functions of a differential equation}: In the context of differential equations, coefficient functions are the functions that multiply the unknown function or its derivatives. They play the same structural role as numerical coefficients in algebraic equations, but they are allowed to vary with the independent variable(s). Consider a differential equation for a unknown function $y(x)$. A typical form is 
            \begin{align*}
                a_{n}(x)y^{(n)}(x) + a_{n-1}(x)y^{(n-1)}(x) + \cdots + a_{1}(x)y^{\prime}(x) + a_{0}(x)y(x) = g(x)
            .\end{align*}
            Here, $a_{0}(x), a_{1}(x), \dots, a_{n}(x) $ are coefficient functions.
        \item \textbf{Homogeneous first order DE}: When written in differential form, we can say that the first order differential equation is homogeneous if the coefficient functions $M$ and $N$ are homogeneous of the same degree. That is, for some real number $k$,
            \begin{align*}
                M(\lambda x, \lambda y) = \lambda^{k}M(x,y), \quad N(\lambda x, \lambda y) = \lambda^{k}N(x,y)
            \end{align*}
            for all $\lambda > 0$. Suppose $M$ and $N$ are homogeneous of the same degree, we have
            \begin{align*}
                M(x,y)\; dx + N(x,y)\; dy = 0 \implies \frac{dy}{dx} = - \frac{M(x,y)}{N(x,y)} 
            .\end{align*}
            If we let $F(x,y) = - \frac{M(x,y)}{N(x,y)}$, then we can see that 
            \begin{align*}
                F(\lambda x, \lambda y) = -\frac{M(\lambda x, \lambda y)}{N(\lambda x, \lambda y)} = -\frac{\lambda^{k}M(x,y)}{\lambda^{k}N(x,y)} = -\frac{M(x,y)}{N(x,y)} = F(x,y)
            .\end{align*}
            Thus, $F$ is homogeneous of degree zero. Now, let's let $\lambda = \frac{1}{x}$, then
            \begin{align*}
                F(\lambda x, \lambda y) = F\left(\frac{x}{x}, \frac{y}{x}\right) = F\left(1,\frac{y}{x}\right)
            .\end{align*}
            We see that $F$ depends only on the ratio $\frac{y}{x}$, scaling has no effect. Define 
            \begin{align*}
                f(t) := F(1,t)
            ,\end{align*}
            then $f(t) = f\left(\frac{y}{x}\right)$. In a homogeneous first order DE, 
            \begin{align*}
                \frac{dy}{dx} = F(x,y)
            ,\end{align*}
            this structure guarantees that 
            \begin{align*}
                \frac{dy}{dx} = f\left(\frac{y}{x}\right)
            .\end{align*}
            If we make the substitution $y = xv$, then
            \begin{align*}
                \frac{dy}{dx} = f\left(\frac{xv}{x}\right) = f(v)
            .\end{align*}
            So, we can solve using separability. Note that $v = v(x)$ is a function of $x$, since $y$ is a function of $x$, and $v = \frac{y}{x}$.
        \item \textbf{Bernoulli first order ODEs}: Consider an ODE of the form
            \begin{align*}
                \frac{dy}{dx} + P(x)y = Q(x)y^{n}
            ,\end{align*}
            where $P(x), Q(x)$ are continuous functions on some interval, $n \in \mathbb{R}$, and $n \ne 0,1 $. If $n =0$ or $n=1$, the equation reduces to a first order linear ODE. In the form above, we can divide by $y^{n}$ to get
            \begin{align*}
                \frac{1}{y^{n}}\frac{dy}{dx} + P(x)y^{1-n} = Q(x)
            .\end{align*}
            Now, let $u = y^{1-n}$, where $u = u(x)$ is a function of $x$, then
            \begin{align*}
               \frac{du}{dx} = (1-n)y^{-n}\frac{dy}{dx} \implies \frac{1}{y^{n}}\frac{dy}{dx} = \frac{1}{1-n}\frac{du}{dx}
            .\end{align*}
            So,
            \begin{align*}
                \frac{1}{y^{n}}\frac{dy}{dx} + P(x)y^{1-n} &= Q(x) \implies \frac{1}{1-n}\frac{du}{dx} + P(x)u = Q(x) \\
                \implies \frac{du}{dx} + (1-n)P(x)u &= (1-n)Q(x)
            .\end{align*}
            Notice that we now have a first-order linear differential equation in $u$, which can be solved with an integration factor.
            \bigbreak \noindent 
            Consider an example, 
            \begin{align*}
                y^{2}\frac{dy}{dx} + 2xy^{3} = 6x
            .\end{align*}
            The Bernoulli form is then
            \begin{align*}
                \frac{dy}{dx} + 2xy = 6xy^{-2}
            .\end{align*}
            So, $n=-2$, and $u = y^{1-n} = y^{1+2} = y^{3}$. Thus,
            \begin{align*}
               \frac{du}{dx} = 3y^{2}\frac{dy}{dx} \implies \frac{dy}{dx} = \frac{1}{3y^{2}}\frac{du}{dx} 
            .\end{align*}
            From this,
            \begin{align*}
                \frac{dy}{dx} + 2xy &= 6xy^{-2} \implies \frac{1}{3y^{2}}\frac{du}{dx} + 2xy = 6xy^{-2} \implies \frac{du}{dx} + 6xu = 18x
            .\end{align*}
        \item \textbf{Substitution of the dependent variable}: It could be that we can convert a DE to a linear DE by changing the dependent variable. Consider
            \begin{align*}
                g^{\prime}(y)y^{\prime} + p(x)g(y) = f(x)
            .\end{align*}
            Let $z = g(y(x))$, so $y$ is a function of $x$ and $g$ is a function of $y$, and $z$ is a function of $x$, $z(x)$.
            \begin{align*}
                z^{\prime} = g^{\prime}(y(x))y^{\prime}(x)
            .\end{align*}
            Thus,
            \begin{align*}
                y^{\prime} = \frac{z^{\prime}}{g^{\prime}}
            .\end{align*}
            Now,
            \begin{align*}
                g^{\prime}(y)y^{\prime} + p(x)g(y) = f(x) \implies z^{\prime} + p(x)z = f(x)
            ,\end{align*}
            which is linear in $z$.
        \item \textbf{General substitutions}: We can also make substitutions by choosing a new variable that simplifies the expression appearing in the ODE. Consider
            \begin{align*}
                \frac{dy}{dx} = 2 + e^{y-2x+7}
            .\end{align*}
            If we let $v= y-2x+7$, then $\frac{dy}{dx} = v^{\prime} + 2$, and DE becomes
            \begin{align*}
                v^{\prime} + 2 = 2 + e^{v} \implies v^{\prime} = e^{v} \implies \frac{1}{e^{v}} dv = dx
            .\end{align*}
            Which we can solve by integrating both sides.



    \end{itemize}

    \pagebreak 
    \subsubsection{Exact equations}
    \begin{itemize}
        \item \textbf{Exact equations}: 
            An exact differential equation is a first-order ODE that arises from the total differential of a scalar potential function. Conceptually, instead of solving directly for $y(x)$, you identify a function $F(x,y)$ whose level curves $F(x,y)=C$ are the solutions.
            \bigbreak \noindent 
            An equation written in differential form as 
            \begin{align*}
                M(x,y)\; dx + N(x,y)\; dy = 0
            .\end{align*}
            where $M$ and $N$ are functions with continuous partial derivatives on some region.
            \bigbreak \noindent 
            The equation is exact if there exists a function $F(x,y)$ such that
            \begin{align*}
                dF = M\; dx + N\; dy
            .\end{align*}
            By the multivariable chain rule,
            \begin{align*}
                dF = \frac{\delta F }{\delta x }\; dx + \frac{\delta F }{\delta y}\; dy
            .\end{align*}
            Therefore, exactness means 
            \begin{align*}
                M = F_{x}, \quad N = F_{y}
            .\end{align*}
        \item \textbf{Necessary and sufficient condition}: If $M$ and $N$ have continuous first partial derivatives on a simply connected region, the equation is exact iff
            \begin{align*}
                \frac{\delta M }{\delta y} = \frac{\delta N }{\delta x} 
            .\end{align*}
            This follows from equality of mixed partials
            \begin{align*}
                F_{xy} = F_{yx}
            .\end{align*}
        \item \textbf{Solving exact equations}: First, verify exactness, so compute
            \begin{align*}
                M_{y}, N_{x}
            .\end{align*}
            If they match, proceed. Then, integrate $M$ with respect to $x$.
            \begin{align*}
                F(x,y) = \int M(x,y)\; dx + g(y)
            .\end{align*}
            where $g(y)$ is an unknown “constant” of integration that may depend on $y$. All we need to do is determine $g(y)$. So, we differentiate the expression for $F$ with respect to $y$ and match it to $N$.
            \begin{align*}
                F_{y}(x,y) = N(x,y)
            .\end{align*}
            Then, we can solve for $g^{\prime}(y)$ and integrate to get $g(y)$. The implicit solution is then
            \begin{align*}
                F(x,y) = C
            .\end{align*}
        \item \textbf{Why is $F(x,y) = C$}: Notice that since 
            \begin{align*}
                dF = M\; dx + N\; dy
            ,\end{align*}
            and 
            \begin{align*}
                M(x,y)\; dx + N(x,y)\; dy = 0
            ,\end{align*}
            we have $dF = 0$. Since the differential of $F$ is zero, the function does not change along the solution curves. Thus,
            \begin{align*}
                dF = 0 \iff F(x,y) = \text{constant}
            .\end{align*}
            Thus, the solution set consists of level curves of $F$:
            \begin{align*}
                F(x,y) = C
            .\end{align*}
            Consider a solution curve, moving along a solution curve, output does not change. Thus, the curve lies on one contour line $F = C$.
            \bigbreak \noindent 
            \textbf{Note:} The “constant of integration” that appears while constructing $F(x,y)$ is not the same as the constant that appears in the final solution. They combine into a single arbitrary constant.

    \end{itemize}



















    
\end{document}
