\documentclass{report}

\input{~/dev/latex/template/preamble.tex}
\input{~/dev/latex/template/macros.tex}

\title{\Huge{}}
\author{\huge{Nathan Warner}}
\date{\huge{}}
\fancyhf{}
\rhead{}
\fancyhead[R]{\itshape Warner} % Left header: Section name
\fancyhead[L]{\itshape\leftmark}  % Right header: Page number
\cfoot{\thepage}
\renewcommand{\headrulewidth}{0pt} % Optional: Removes the header line
%\pagestyle{fancy}
%\fancyhf{}
%\lhead{Warner \thepage}
%\rhead{}
% \lhead{\leftmark}
%\cfoot{\thepage}
%\setborder
% \usepackage[default]{sourcecodepro}
% \usepackage[T1]{fontenc}

% Change the title
\hypersetup{
    pdftitle={Math 3}
}

\begin{document}
    % \maketitle
        \begin{titlepage}
       \begin{center}
           \vspace*{1cm}
    
           \textbf{Undergraduate Topics in Mathematics (4)} \\
           Proof writing, The theory of sets, Axiomatic geometry, Numerical analysis
    
           \vspace{0.5cm}
            
                
           \vspace{1.5cm}
    
           \textbf{Nathan Warner}
    
           \vfill
                
                
           \vspace{0.8cm}
         
           \includegraphics[width=0.4\textwidth]{~/niu/seal.png}
                
           Computer Science \\
           Northern Illinois University\\
           United States\\
           
                
       \end{center}
    \end{titlepage}
    \tableofcontents
    \pagebreak 
    \unsect{Proofs}
    \bigbreak \noindent 
    \subsection{Intro to proof writing, intuitive proofs}
    \begin{itemize}
        \item \textbf{Intro to definitions, propositions and proofs: the chessboard problem}: Suppose you have a chessboard (8$\times$8 grid of squares) and a bunch of dominoes (2$\times$1 block of squares), so each domino can perfectly cover two squares of the chessboard.
            \bigbreak \noindent 
            Note that with 32 dominoes you can cover all 64 squares of the chessboard. There are many different ways you can place the dominoes to do this, but one way is to cover the first column by 4 dominoes end-to-end, cover the second column by 4 dominoes, and so on
            \bigbreak \noindent 
            Math runs on definitions, so let’s give a name to this idea of covering all the squares. Moreover, let’s not define it just for 8 $\times$ 8 boards — let’s allow the definition to apply to boards of other dimensions
            \bigbreak \noindent 
            \textbf{Definition.} A perfect cover of an $m\times n$ board with 2 $\times$ 1 dominoes is an arrangement of those dominoes on the chessboard with no squares left uncovered, and no dominoes stacked or left hanging off the end.
            \bigbreak \noindent 
            As we demonstrated above, there exist perfect covers of the 8 $\times$ 8 chessboard. This is a book about proofs, so let’s write this out as a proposition (something which is true and requires proof) and then let’s write out a formal proof of this fact.
            \bigbreak \noindent 
            \textbf{Proposition.} There exists a perfect cover of an 8 $\times$ 8 chessboard.
            \bigbreak \noindent 
            This proposition is asserting that “there exists” a perfect cover. To say “there exists” something means that there is at least one example of it. Therefore, any proposition like this can be proven by simply presenting an example which satisfies the statement.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Observe that the following is a perfect cover.
            \bigbreak \noindent 
            \fig{.7}{./figures/1.png}
            \bigbreak \noindent 
            We have shown by example that a perfect cover exists, completing the proof. $\blacksquare$
            \bigbreak \noindent 
            We typically put a small box at the end of a proof, indicating that we have completed our argument. This practice was brought into mathematics by Paul Halmos, and it is sometimes called the Halmos tombstone
            \bigbreak \noindent 
            One apocryphal story is that Halmos regarded proofs as living until proven. Once proven, they have been defeated — killed. And so he wrote a little tombstone to conclude his proof
            \bigbreak \noindent 
            What if I cross out the bottom-left and top-left squares, can we still perfectly cover the 62 remaining squares?
            \bigbreak \noindent 
            As you can probably already see, the answer is yes. For example, the first column can now be covered by 3 dominoes and the other columns can be covered by 4 dominoes each.
            \bigbreak \noindent 
            What if I cross out just one square, like the top-left square? Can this be perfectly covered? 
            \bigbreak \noindent 
            The answer is no
            \bigbreak \noindent 
            \textbf{Proposition.} If one crosses out the top-left square of an 8 $\times$ 8 chessboard, the remaining squares can not be perfectly covered by dominoes.
            \bigbreak \noindent 
            \textbf{Proof Idea}. The idea behind this proof is that one domino, wherever it is placed, covers two squares. And two dominoes must cover four squares. And three cover six. In general, the number of squares covered — 2, 4, 6, 8, 10, etc. — is always an even number. This insight is the key, because the number of squares left on this chessboard is 63— an odd number
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Since each domino covers 2 squares and the dominoes are non-overlapping, if one places our k dominoes on the board, then they will cover $2k$ squares, which is always an even number. Therefore, a perfect cover can only cover an even number of squares. Notice, though, that the board has 63 remaining squares, which is an odd number. Thus, it can not be perfectly covered.
            \bigbreak \noindent 
            What if I take an 8$\times$8 chessboard and cross out the top-left and the bottom-right squares? Then can it be covered by dominoes?
            \bigbreak \noindent 
            \textbf{Proposition.} If one crosses out the top-left and bottom-right squares of an 8 $\times$ 8 chessboard, the remaining squares can not be perfectly covered by dominoes.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Observe that the chessboard has 62 remaining squares, and since every domino covers two squares, if a perfect cover did exist it would require
            \begin{align*}
                \frac{62}{2} = 31 \text{ dominoes}
            .\end{align*}
            \bigbreak \noindent 
            Also observe that every domino on the chessboard covers exactly one white square and exactly one black square
            \bigbreak \noindent 
            Thus, whenever you place 31 non-overlapping dominoes on a chessboard, they will collectively cover 31 white squares and 31 black squares.
            \bigbreak \noindent 
            Next observe that since both of the crossed-out squares are white squares, the remaining squares consist of 30 white squares and 32 black squares. Therefore, it is impossible to have 31 dominoes cover these 62 squares. $\blacksquare$
        \item \textbf{Naming Results}: So far, all of our results have been called “propositions.” Here’s the run-down on the naming of results:
            \begin{itemize}
                \item A theorem is an important result that has been proved.
                \item A proposition is a result that is less important than a theorem. It has also been proved.
                \item A lemma is typically a small result that is proved before a proposition or a theorem, and is used to prove the following proposition or theorem.
                \item A corollary is a result that is proved after a proposition or a theorem, and which follows quickly from the proposition or theorem. It is often a special case of the proposition or theorem.
            \end{itemize}
            All of the above are results that have been proved — a conjecture, though, has not.
            \begin{itemize}
                \item A conjecture is a statement that someone guesses to be true, although they are not yet able to prove or disprove it.
            \end{itemize}
        \item \textbf{Conjectures and counterexamples}: As an example of a conjecture, suppose you were investigating how many regions are formed if one places $n$ dots randomly on a circle and then connects them with lines.
            \bigbreak \noindent 
            \fig{.7}{./figures/2.png}
            \bigbreak \noindent 
            At this point, if you were to conjecture how many regions there will be for the $n = 6$ case, your guess would probably be 32 regions — the number of regions certainly seems to be doubling at every step. In fact, if it kept doubling, then with a little more thought you might even conjecture a general answer: that n randomly placed dots form $2^{n-1}$ regions;
            \bigbreak \noindent 
            Surprisingly, this conjecture would be incorrect. One way to disprove a conjecture is to find a counterexample to it. And as it turns out, the $n = 6$ case is such a counterexample
            \bigbreak \noindent 
            \fig{.8}{./figures/3.png}
            \bigbreak \noindent 
            This counterexample also underscores the reason why we prove things in math. Sometimes math is surprising. We need proofs to ensure that we aren’t just guessing at what seems reasonable. Proofs ensure we are always on solid ground. Further, proofs help us understand why something is true — and that understanding is what makes math so fun
            \bigbreak \noindent 
            Lastly, we study proofs because they are what mathematicians do
        \item \textbf{The pingeonhole principle}
            \bigbreak \noindent 
            \textbf{Principle}. The principle has a simple form and a general form. Assume $k$ and $n$ are positive integers
            \bigbreak \noindent 
            \textbf{Simple form:} If $n + 1$ objects are placed into $n$ boxes, then at least one box has at least two objects in it.
            \bigbreak \noindent 
        \textbf{General form:} If $kn + 1$ objects are placed into $n$ boxes, then at least one box has at least $k + 1$ objects in it.
            \bigbreak \noindent 
            \textbf{Birthday example}: If there are 330 million people in the united states, how many U.S. residents are guaranteed to have the same birthday according to the pigeonhole principle?
            \bigbreak \noindent 
            To determine this, let’s see what would happen if each date of the year had exactly the same number of people born on it
            \begin{align*}
                \frac{330\times10^{6}}{366} = 901,639.344
            .\end{align*}
            \bigbreak \noindent 
            Since 901,639.344 people are born on an average day of the year, we should be able round up and say that at least one day of the year has had at least 901,640 people born on it. That is, with the pigeonhole principle we should be able to prove that there are at least 901,640 people in the USA with the same birthday
            \bigbreak \noindent 
            \textbf{Solution.} Imagine you have one box for each of the 366 dates of the (leap) year, and each person in the U.S. is considered an object. Put each person in the box corresponding to their birthday. By the general form of the pigeonhole principle (with $n = 366$ and $k = 901, 639$ and thus $k + 1 = 901, 640$), any group of
            \begin{align*}
                (901, 639)(366) + 1
            .\end{align*}
            \bigbreak \noindent 
            people is guaranteed to contain 901,640 people which have the same birthday.
        \item \textbf{Another pingeonhole example}:
            \bigbreak \noindent 
            \textbf{Proposition.} Given any five numbers from the set $\{1, 2, 3, 4, 5, 6, 7, 8\}$, two of the chosen numbers will add up to 9.
            \bigbreak \noindent 
            We may think to start by listing the pairs that sum to 9. We have
            \begin{align*}
                1 &+ 8 \\ 
                2 &+ 7 \\
                3 &+ 6 \\
                4 &+ 5 
            .\end{align*}
            And of course $8+1,7+2,..$ etc. We see we have four sums, we choose these sums as our boxes. If each of the four sums is a box, and each number is an object, then we are placing five objects into four boxes 
            \bigbreak \noindent 
            \textbf{Proof.} Let one box correspond to the numbers 1 and 8, a second box correspond to 2 and 7, another to 3 and 6, and a final box to 4 and 5. Notice that each of these pairs adds up to 9.
            \bigbreak \noindent 
            Given any five numbers from $\{1, 2, 3, 4, 5, 6, 7, 8\}$, place each of these five numbers in the box to which it corresponds; for example, if your first number is a 6, then place it in the box labeled “3 and 6.” Notice that we just placed five numbers into four boxes. Thus, by the simple form of the pigeonhole principle, there must be some box which contains two numbers in it. These two numbers add up to 9, as desired
        \item \textbf{Another pingeonhole example}:
            \bigbreak \noindent 
            \textbf{Proposition.} Given any collection of 10 points from inside the following square (of side-length 3), there must be at least two of these points which are of distance at most $\sqrt{2}$
            \bigbreak \noindent 
            \fig{1}{./figures/4.png}
            \bigbreak \noindent 
            \textbf{Proof.} Divide the $3\times 3$ square into nine $1\times 1$ boxes. Placing 10 arbitrary points amongst the boxes gaurantees that at least one box will have at least two points. We observe that the farthest these two points can be from each other is when they sit in two corners such that a diagonal line through the box hits both points. The length of this line is given by
            \begin{align*}
                \sqrt{1^{2} + 1^{2}} = \sqrt{2}
            .\end{align*}
            Thus, we observe that the maximum distance of these two points is $\sqrt{2}$ $\blacksquare$
        \item \textbf{Another pingeonhole example}:
            \bigbreak \noindent 
            \textbf{Proposition.} Given any 101 integers from $\{1, 2, 3, . . . , 200\}$, at least one of these numbers will divide another
            \bigbreak \noindent 
            \textbf{Solution.} As we ponder about how to construct 100 boxes from the properties of the set, we may wonder how the even and odd members partition this set. Call $S = \{1,2,3,...,200\} $, $E=\{2,4,6,...,200\} $, and $O = \{1,3,5,...,199\} $. Note that $E \cup O = S$. We notice that these two sets are arithmetic sequences, each with difference two. If $a_{n} = a_{1} +  (n-1)d$, then 
            \begin{align*}
                n &= \frac{a_{n} - a_{1}}{2} + 1 \\
                \implies n&= 100
            .\end{align*}
            \bigbreak \noindent 
            Let's make the odd numbers are boxes. We note that any even number $\ell$ can be written as $\ell = 2^{k}m$, where $m$ is odd, and $k$ is the highest power of two that divides $\ell$. Thus, in box $m$, we place any number of the form $2^{k}m$
            \bigbreak \noindent 
            \fig{.5}{./figures/5.png}
            \bigbreak \noindent 
            For any pair of numbers in the same box, the smaller divides the larger. Picking 101 numbers from the set $S$, and only 100 boxes... by the pigeonhole principle we must have atleast two numbers in the same box, and thus the smaller divides the larger. $\blacksquare$.
            \bigbreak \noindent 
            \textbf{Formal proof.} 
            \textbf{Proof.} For each number $n$ from the set $\{1, 2, 3, \dots, 200\}$, factor out as many 2's as possible, and then write it as $n = 2^k \cdot m$, where $m$ is an odd number. So, for example, $56 = 2^3 \cdot 7$, and $25 = 2^0 \cdot 25$. Now, create a box for each odd number from 1 to 199; there are 100 such boxes.
            \bigbreak \noindent 
            Remember that we are given 101 integers and we want to find a pair for which one divides the other. Place each of these 101 integers into boxes based on this rule:
            \bigbreak \noindent 
            \begin{quote}
                If the integer is $n$, then place it in Box $m$ if $n = 2^k \cdot m$ for some $k$.
            \end{quote}
            \bigbreak \noindent 
            For example, $72 = 2^3 \cdot 9$ would go into Box 9, because that's the largest odd number inside it.
            \bigbreak \noindent 
            Since 101 integers are placed in 100 boxes, by the pigeonhole principle (Principle 1.5) some box must have at least 2 integers placed into it; suppose it is Box $m$. And suppose these two numbers are $n_1 = 2^k \cdot m$ and $n_2 = 2^\ell \cdot m$, and let’s assume the second one is the larger one, meaning $\ell > k$. Then we have now found two integers where one divides the other; in particular $n_1$ divides $n_2$, because:
            \[
                \frac{n_2}{n_1} = \frac{2^\ell \cdot m}{2^k \cdot m} = 2^{\ell - k}.
            \]
            This completes the proof.$\blacksquare$
        \item \textbf{Another pigeonhole example}
            \bigbreak \noindent 
            \textbf{Proposition}. Suppose $G$ is a graph with $n \geq 2$ vertices. Then $G$ contains two vertices which have the same degree.
            \bigbreak \noindent 
            We start by observing that the minimum degree is zero, and the maxmium is $n-1$. It could happen that a vertex is connected to no other vertices, and a vertex could be connected to all other vertices. If a vertex is connected to all other vertices, than it has degree $n-1$, because it has an edge going to all vertices but itself. Thus, we have our boxes. But you may notice that we have $n$ boxes for $n$ vertices. This may seem like a problem, but after some thought you may see that it is not possible for the zero box and the $n-1$ box to both be used for a specific graph $G$. Thus, we have only $n-1$ boxes for $n$ vertices.
            \bigbreak \noindent 
            The rest of the proof is left as an exercise for the reader.
        \item \textbf{Classic Geometry Theorem}. Given any two points on the sphere, there is a great circle that passes through those two points. 
            \bigbreak \noindent 
            Given a sphere, there are infinitely many ways to cut it in half, and each of these paths of the knife is called a great circle
            \bigbreak \noindent 
            \fig{.5}{./figures/6.png}
        \item \textbf{Final pigeonhole example}
            \bigbreak \noindent 
            \textbf{Proposition}. If you draw five points on the surface of an orange in marker, then there is always a way to cut the orange in half so that four points (or some part of the point) all lie on one of the halves.
            \bigbreak \noindent 
            \textbf{\textit{Proof}}. Consider an orange with five points drawn on it. Pick any two of these points, and call them $p$ and $q$. By the Classic Geometry Theorem, there exists a great circle passing through these points; angle your knife to cut along this great circle. Because the points are drawn in marker, they are wide enough so that part of these two points appear on both halves.
            \bigbreak \noindent 
            Now consider the remaining three points and the two halves that you just cut the orange into. Consider these three points to be objects and the halves to be boxes; by the simple form of the pigeonhole principle, at least two of these three points are on the same orange half. These two, as well a portion of $p$ and of $q$, give four points or partial points, as desired $\quad \blacksquare $



    \end{itemize}

    \pagebreak 
    \subsection{Direct proofs}
    \begin{itemize}
        \item \textbf{Fact about integers}: The sum of integers is an integer, the difference of integers is an integer, and the product of integers is an integer. Also, every integer is either even or odd.
            \bigbreak \noindent 
            We are calling these facts because, while they are true and one could prove them, we will not be proving them here
        \item \textbf{Even and odd integers}: An integer $n$ is \textit{even} if $n=2k$ for some integer $k $
            \bigbreak \noindent 
            An integer $n$ is \textit{odd} if $n=2k+1$ for some integer $k$
        \item \textbf{Sum of two even integers}
            \bigbreak \noindent 
            \textbf{Proposition.} The sum of two even integers is even
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $n$ and $m$ are even integers, then $n = 2a$, and $m = 2b$ for some integers $a$ and $b$. Furthermore,
            \begin{align*}
                n + m &= 2a + 2b = 2(a+b)
            .\end{align*}
            \bigbreak \noindent 
            Since the sum of two integers is itself an integer, then we have two times an integer, which satisfies the definition of an even number. Hence, the sum $n + m$ is even, where $n$ and $m$ are even. $\int$
        \item \textbf{More on propositions}: We can rewrite our propositions to take the form
            \begin{quote}
               if \textit{statement} is true, then \textit{other statement} is also true 
            \end{quote}
            For example, 
            \begin{quote}
               if $m$ and $n$ are even, then $m+n$ is also even
            \end{quote}
            \bigbreak \noindent 
            Another way to summarize such statements is this:
            \begin{quote}
               \textit{some statement} is true implies \textit{some other statement} is true. 
            \end{quote}
            Which allows us to use the implies symbol $\implies$. For example, 
            \begin{quote}
               $m$ and $n$ being even $\implies$ $m+n$ is even 
            \end{quote}
            We have the general form $P \implies Q$, where $P$  and $Q$ are statements
            \bigbreak \noindent 
             However, when writing formally, like when writing up the final draft of your homework, these symbols are rarely used. You should write out solutions with words, complete sentences, and proper grammar. Pick up any of your math textbooks, or look online at math research articles, and you will find that such practices are standard.
        \item \textbf{The structure of direct proofs}: A direct proof is a way to prove a “$P \Rightarrow Q$” proposition by starting with $P$ and working your way to $Q$. The “working your way to $Q$” stage often involves applying definitions, previous results, algebra, logic, and techniques. Here is the general structure of a direct proof:
            \bigbreak \noindent 
            \begin{mdframed}
                \textbf{Proposition}. $P\implies Q$
                \bigbreak \noindent 
                \textbf{\textit{Proof.}} Assume $P$
                \bigbreak \noindent 
                \hspace{1cm}\textit{Explain what $P $ means by applying definitions and/or other results}
                \begin{align*}
                    &\vdots \quad \text{Apply algebra,} \\
                    &\vdots \quad \text{logic techniques}
                .\end{align*}
                \bigbreak \noindent 
                \hspace{1cm} \textit{Hey look, that's what $Q$ means}
                \bigbreak \noindent 
                Therefore $Q$ \hspace{10cm} $\blacksquare $
            \end{mdframed}
        \item \textbf{Proof by cases}: A related proof strategy is proof by cases. This is a “divide and conquer” strategy where one breaks up their work into two or more cases 
            \bigbreak \noindent 
            The below example of proof by cases will also give us more practice with direct proofs involving definitions. Indeed, when you break up a problem in two parts, those two parts still need to be proven, and a direct proof is often the way to tackle each of those parts
            \bigbreak \noindent 
            \textbf{Proposition.} If $n$ is an integer, then $n^{2} + n + 6$ is even.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $n$ is an integer, then either $n$ is even or it is odd.
            \begin{tcolorbox}[penv]
                \textit{Case I}. Assume $n$ is even, then $n=2m$ for some integer $m$. Thus, we have
                \begin{align*}
                    n^{2} + n + 6 &= (2m)^{2} + 2m + 6 \\
                      &=4m^{2} + 2m + 6 \\
                      &= 2 (2m^{2} + m + 3)
              .\end{align*}
              \bigbreak \noindent 
              Observe that $2m^{2} + m + 3 \in \mathbb{Z}$. Thus, we have two times an integer, which satisfies the definition of an even number.
              \bigbreak \noindent 
              \textit{Case 2.} Assume $n$ is odd, then $n=2m+1$ for some integer $m$. Thus,
              \begin{align*}
                  n^{2} + n + 6 &= (2m+1)^{2} + 2m + 1 + 6 \\
                                &=4m^{2} + 4m + 1 + 2m + 7 \\
                                &= 4m^{2} + 6m + 8 \\
                                &= 2(2m^{2} + 3m + 4)
              .\end{align*}
              \bigbreak \noindent 
              Since $m$ is an integer, $2m^{2} + 3m +4$ is an integer, and we again have two times an integer, which is an even integer.
              \bigbreak \noindent 
              We have shown that $n^{2} + n  + 6 $ is even whether $n$ is even or odd. Combined, this shows that $n^{2} + n + 6$ is even for all integers $n$ $\quad \blacksquare$
                
            \end{tcolorbox}
        \item \textbf{Proof by exhaustion (brute force proof)}: A proof by cases cuts up the possibilities into more manageable chunks. If the theorem refers to a collection of elements and your proof is simply checking each element individually, then it is called a \textit{proof by exhaustion} or a \textit{brute force proof}
        \item \textbf{Divisibility}: An integer \(a\) is said to divide an integer \(b\) if \(b = ak\) for some integer \(k\). When \(a\) does divide \(b\), we write \(a \mid b\), and when \(a\) does not divide \(b\), we write \(a \nmid b\).
            \bigbreak \noindent 
            \textbf{Note:} A common mistake is to see something like “$2 \mid 8$” and think that this equals 4. The expression “$a \mid  b$” is either true or false
            \bigbreak \noindent 
            \textbf{Remark.} $a\mid 0$ for any integer $a$, because $0 = a \cdot 0$ for every such $a$
            \bigbreak \noindent 
            $0\nmid b$ for any nonzero integer $b$, because for any such $b$, we have $b\ne 0 \cdot k $ for any integer $k$
        \item \textbf{The transitive property of divisibility}:
            \bigbreak \noindent 
            \textbf{Proposition}. Let $a,b$, and $c$ be integers, if $a\mid b$ and $b \mid c$, then $a\mid c$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $a,b$, and $c$ are integers. Further assume that $a\mid b$, and $b\mid c$
            \penv {
                By the definition of divisibility, $a\mid b$ and $b \mid c$ implies $b = ak$ for some integer $k$, and $c = bs$ for some integer $s$
                \bigbreak \noindent 
                If $a\mid c$, we require that $c = ar$ for some integer $r$
                \bigbreak \noindent 
                \begin{align*}
                    b &= ak  \\
                    \implies c &= (ak)s \\
                    \implies c&= a(ks)
                .\end{align*}
                \bigbreak \noindent 
            }
            Since $k$ and $s$ are integers, then their product $ks$ is itself an integer. Let $r = ks$. Then $c  = ar$, which is precisely the definition of divisiblity, and we conclude that $a\mid c$. $\quad \blacksquare$
        \item \textbf{The division algorithm}:
            \bigbreak \noindent 
            \textbf{Theorem.} For all integers $a$ and $m $ with $m>0 $, there exist unique integers $q $ and $r $ such that
            \begin{align*}
                a = mq + r
            .\end{align*}
            Where $0 \leq r < m$. We call $q$ the \textit{quotient} and $r$ the \textit{remainder}
        \item \textbf{Common divisor, greatest common divisor}:
            Let $a$ and $b$ be integers. If $c \mid a$ and $c \mid b$, then $c$ is said to be a common divisor of $a$ and $b$.
            \bigbreak \noindent 
            The greatest common divisor of $a$ and $b$ is the largest integer $d$ such that $d \mid a$ and $d \mid b$. This number is denoted $\text{gcd}(a, b)$.
            \bigbreak \noindent 
            Note that there is one pair of integers that does not have a greatest common divisor; if $a = 0$ and $b = 0$, then every positive integer $d$ is a common divisor of $a$ and $b$. This means that no divisor is the greatest divisor, since you can always find a bigger one. Thus, in this one case, $gcd(a, b)$ does not exist
        \item \textbf{Bezout's identity}: If $a$ and $b$ are positive integers, then there exist integers $k$ and $\ell$ such that
            \begin{align*}
                \gcd{(a, b)} = ak + b\ell
            .\end{align*}
            \bigbreak \noindent 
            As an example, suppose $a=12$ and $b=20$, then $\gcd{(12,20)} =4$, and we have
            \begin{align*}
                4 &= 12k + 20 \ell  \\
                \implies \ell &= \frac{1}{5}-\frac{3}{5}k
            .\end{align*}
            Let $k=2$, then we see $\ell = -1$. We see that there are infinitely many solutions, $k=2, \ell = -1$ is just one of them. Nevertheless, this theorem simply says that at least one solution must exist. 
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $a$ and $b$ are fixed positive integers, notice that the expression $ax + by$ can take many values for integers $x$ and $y$. Let $d$ be the \textit{smallest positive integer} that $ax + by$ can be equal. Let $k$ and $\ell$ be the $x$ and $y$ that obtain this $d$. That is, 
            \begin{align*}
                d = ak + b\ell
            .\end{align*}
            \penv{
               We now must show that $d$ is a common divisor of $a$ and $b$, and then that it is the \textit{greatest common divisor}
               \bigbreak \noindent 
               \textit{Part 1 (common divisor)}. $d$ is a common divisor of $a$ and $b$ if $d\mid a$ and $d\mid b$. To see that $d \mid a$, we examine the division algorithm. We know that there exsits unique integers $q $ and $r $ such that
               \begin{align*}
                   a = dq + r
               .\end{align*}
               With $0 \leq r < d$. We have
               \begin{align*}
                   r &= a-dq \\
                     &=a-(ak + b\ell)q \\
                     &=a-akq -b\ell q \\
                     &= a(1-kq) + b(-\ell q)
               .\end{align*}
               Observe that $1-kq$, and $-\ell q$ are both integers, Since $r$ is written in the form $ax + by$, $0 \leq r < d$, and $d$ is the smallest positive integer that this form can produce (with the given $a,b$), it must be that $r=0$. Thus,
               \begin{align*}
                   a = dq + 0 = dq
               .\end{align*}
               And we see that $d\mid a$. A similar argument will show that $d\mid b$ as well. This proves that $d$ is a common divisor of $a$ and $b$.
               \bigbreak \noindent 
           }
           \penv{
               \textit{Part 2 (gcd)}. Assume that $d^{\prime}$ is some other common divisor of $a$ and $b$. We must show that $d^{\prime} \leq d$. If $d^{\prime}$ is a common divisor of $a$ and $b$, then $d^{\prime} \mid a$ and $d^{\prime} \mid b$, which implies $a = d^{\prime}n$, and $b = d^{\prime} m$, for some integers $n$ and $m$. If $d = ak + b\ell$, then
               \begin{align*}
                   d &= d^{\prime}nk + d^{\prime}m\ell \\
                   &=d^{\prime}(nk + m\ell) \\
                   \implies d^{\prime} &=\frac{d}{nk + m\ell}
               .\end{align*}
               Since $n,k,m,\ell \in \mathbb{Z}$, it follows that $nk +m\ell \in \mathbb{Z}$. Thus, $d^{\prime} \leq d$.
           }
           \bigbreak \noindent 
           Therefore, we have shown that $d$ is not only a common divisor of $a$ and $b$, but that it is also the largest, and hence the $gcd$. Thus,
           \begin{align*}
               \gcd{(a,b)} = d = ak + b \ell
           .\end{align*}
           $\blacksquare$
           \bigbreak \noindent 
           A corollary from this result is that $\gcd{(ma, mb)} = m \gcd{(a,b)}$. If $\gcd{(a,b)} = ak + b\ell$, we have
           \begin{align*}
               \gcd{(ma,mb)} &= mak + mb\ell  \\
                             &=m(ak + b\ell) \\
                             &=m\gcd{(a,b)}
           .\end{align*}
       \item \textbf{Modulo and congruence}: 
           For integers \(a\), \(r\), and \(m\), we say that \(a\) is congruent to \(r\) modulo \(m\) and we write \(a \equiv r \pmod{m}\) if \(m \mid (a - r)\).
           \bigbreak \noindent 
           For example, $18 \equiv  4 \pmod{7}$ because $18 = 7(2) +4 $, we see that $7 \mid (18-4)$
           \bigbreak \noindent 
           If \(a\) divided by \(m\) leaves a remainder of \(r\), then \(a \equiv r \pmod{m}\). However, this is not the only way to have \(a \equiv r \pmod{m}\) — it is not required that \(r\) be the remainder when \(a\) is divided by \(m\); all that is required is that \(a\) and \(r\) have the same remainder when divided by \(m\). For example:
           \begin{align*}
               18 =11 \pmod{7}
           .\end{align*}
        \item \textbf{Properties of modular congruence}: Assume that $a, b, c, d$
            and $m$ are integers, $a \equiv b \pmod{m}$ and $c \equiv d\pmod{m}$. Then
            \begin{enumerate}[label=(\roman*)]
                \item $a + c  \equiv b + d \pmod{m} $ 
                \item $a - c  \equiv b - d \pmod{m} $ 
                \item $a \cdot  c  \equiv b \cdot  d \pmod{m} $ 
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof of property $i$}}. Assume that $a \equiv b \pmod{m}$, and $c \equiv d \pmod{m}$, we must show that $a + c \equiv b + d \pmod{m}$
            \penv{
                If $a\equiv b \pmod{m}$, then $m \mid a-b$, which implies $a-b = mk$ for some $k\in \mathbb{Z}$. Similarly, $c \equiv d \pmod{m} \implies m \mid c-d \implies c-d = m\ell$, for some $\ell \in \mathbb{Z}$. Adding these two equations yields
                \begin{align*}
                    (a-b) + (c-d) &= mk + m\ell \\
                    \implies (a+c) - (b + d) &= m(k+\ell)
                .\end{align*}
        }
        Since $k+\ell \in \mathbb{Z}$, then by the definition of divisibility
        \begin{align*}
            m \mid (a+c) - (b+d)
        .\end{align*}
        Which then by the definition of congruence
        \begin{align*}
            a+c \equiv b+d \pmod{m}
        .\end{align*}
        $\blacksquare$
        \bigbreak \noindent 
        \textbf{\textit{Proof of property $iii$}}. Assume $a \equiv b \pmod{m}$, and $c \equiv d \pmod{m}$
        \penv{
            From above we know it follows that $a - b = mk $, and $c-d = m\ell$, for $k,\ell \in \mathbb{Z}$. If $ ac \equiv bd \pmod{m}$, it must be that $ac -bd = ms$, for some $s\in \mathbb{Z}$. Let's see if we can derive $ac-bd$ in terms of what we know, namely $a-b$ and $c-d$. Amazingly,
            \begin{align*}
                ac -bd &= (a-b)c + (c-d)b \\
                &= mkc + m\ell b \\
                &= m(kc +\ell b)
            .\end{align*}
        }
        It then follows that
        \begin{align*}
            m \mid ac-bd
        .\end{align*}
        Thus,
        \begin{align*}
            ac \equiv bd \pmod{m}
        .\end{align*}
        $\blacksquare$
    \item \textbf{Prime and composite integers}: An integer $p \geq 2$ is prime if its only positive divisors are 1 and $p$. An integer $n \geq 2$ is composite if it is not prime. Equivalently, $n$ is composite if it can be written as $n = st$, where $s$ and $t$ are integers and $1 < s, t < n$.
        \bigbreak \noindent 
        \textbf{Note:} To be clear, “$1 < s, t < n$” means that both $s$ and $t$ are between 1 and $n$.
    \item \textbf{Properties of primes and divisibility}:
        \bigbreak \noindent 
        \textbf{Lemma}. Let \( a, b \) and \( c \) be integers, and let \( p \) be a prime:
        \begin{enumerate}[label=(\roman*)]
            \item If \( p \nmid a \), then \( \gcd(p, a) = 1 \).
            \item If \( a \mid bc \) and \( \gcd(a, b) = 1 \), then \( a \mid c \).
            \item If \( p \mid bc \), then \( p \mid b \) or \( p \mid c \) (or both).
        \end{enumerate}
        \bigbreak \noindent 
        \textbf{\textit{Proof of property $i$}}. Assume that $p$ does not divide $a$, then $p$ cannot possibly be a common divisor of $a$ and $p$, because it is not a divisor of $a$. 
        \bigbreak \noindent 
        Since $p \in \mathbb{P}\footnote{Where $\mathbb{P}$ is the family of primes}$, then the only divisors of $p$ are one and itself. Thus, the only option left is one. Hence, the greatest common divisor is one. $\blacksquare$
        \pagebreak \bigbreak \noindent 
        \textbf{\textit{Proof of property $ii$}}. Assume $a\mid bc$, and $\gcd{(a,b)} = 1$. Then, $bc = ar$ for some integer $r$, and by Bezout's identity, there exist some integers $k, \ell$ such that
        \begin{align*}
            \gcd{(a,b)} &= ak + b\ell \\
            \implies 1&= ak + b\ell 
        .\end{align*}
        If $a\mid c$, we require $c = as$, for some integer $s$. If we multiply the above expression by c, we get
        \begin{align*}
            c &= cak + cb\ell
        .\end{align*}
        Since we assumed $a\mid bc$, then it must be that $bc = ar$, for $r\in \mathbb{Z}$. Thus, we have
        \begin{align*}
            c &= cak + ar\ell \\
              &= a(ck + r\ell)
        .\end{align*}
        Since $c,k,r,\ell \in \mathbb{Z}$, the expression $ck+r\ell$ is also an integer, and by the definition of divisibility, it must be that $a\mid c$  $\quad \blacksquare $
        \bigbreak \noindent 
        \textbf{\textit{Proof of property $iii$}}. Assume that $p \mid bc$. Then there are two cases, either $p\mid b$, or $p\nmid b$.
        \bigbreak \noindent 
        \textit{Case I}. If $p\mid b$, then the statement is true and we are done
        \bigbreak \noindent 
        \textit{Case II}. If $p\nmid b$, then by property $i$, it must be that $\gcd{(p,b)} = 1$. By property $ii$, if $p \mid bc$, and $\gcd{(p,b)} = 1$, then it must be that $p \mid c$. $\quad \blacksquare$.
    \item \textbf{More on properties of congruence}: We return to congruence to examine the statement
        \begin{align*}
            ak \equiv bk \pmod{m} \stackrel{?}{\implies} a\equiv b \pmod{m}
        .\end{align*}
        \bigbreak \noindent 
        \textbf{Proposition (\textit{modular cancellation law})}. Let $a,b,k,m$ be integers. If $ak \equiv bk \pmod{m}$, and $\gcd{(m,k)} = 1$, then $a \equiv b \pmod{m}$
        \bigbreak \noindent 
        \textbf{\textit{Proof}}. Assume $ak \equiv bk\pmod{m}$, and $\gcd{(m,k)} =1$, then $m \mid ak-bk$, and $ak-bk = m\ell$, for some integer $\ell$. 
        \bigbreak \noindent 
        \penv{
            If $a\equiv b\pmod{m}$, then $m\mid a-b$, and $a-b = mr$, for some integer $r$. Since $ak \equiv bk\pmod{m}$, then it must be that
            \begin{align*}
                ak-bk &= m\ell \\
                \implies k(a-b) &= m\ell \\
                \implies a-b &= \frac{m\ell}{k}
            .\end{align*}
            Thus, we require $\frac{\ell}{k}$ to be an integer, it then follows that the proposition holds true.
            \bigbreak \noindent 
            We know that if $a\mid bc$, and $\gcd{(a,b)} = 1$, then $a\mid c$. Thus, since $k\mid m\ell$, and $\gcd{(m,k)} = 1$, it must be that $k\mid \ell$. Hence, $ \frac{\ell}{k} \in \mathbb{Z}$, and 
            \begin{align*}
                a-b = m\left(\frac{\ell}{k}\right)
            .\end{align*}
            And by the definition of divisibility, $m\mid a-b$, which implies $a \equiv b \pmod{m}$ $\quad \blacksquare$.
        }
    \item \textbf{Fermat's little theorem}: If $a$ is an integer and $p$ is a prime which does not divide $a$, then
        \begin{align*}
            a^{p-1} \equiv 1 \pmod{p}
        .\end{align*}
        \bigbreak \noindent 
        \textbf{\textit{Proof.}} 
        Assume that $a$ is an integer and $p$ is a prime which does not divide $a$. We begin by proving that when taken modulo $p$,
        \[
            \{a, 2a, 3a, \dots, (p-1)a\} \equiv \{1, 2, 3, \dots, p-1\}.
        \]
        To do this, observe that the set on the right has every residue modulo $p$ except $0$, and each such residue appears exactly once. Therefore, since both sets have $p-1$ elements listed, in order to prove that the left set is the same as the right set, it suffices to prove this:
        \begin{enumerate}
            \item No element in the left set is congruent to $0$, and
            \item Each element in the left set appears exactly once.
        \end{enumerate}
        In doing so, we will twice use the modular cancellation law (Proposition 2.18) to cancel out an $a$, and so we note at the start that by Lemma 2.17 part (i) we have $\gcd(p, a) = 1$.
        \bigbreak \noindent 
        \textbf{Step 1.} First we show that none of the terms in $\{a, 2a, 3a, \dots, (p-1)a\}$, when considered modulo $p$, are congruent to $0$. To do this, we will consider an arbitrary term $ia$, where $i$ is anything in $\{1, 2, 3, \dots, p-1\}$. Indeed, if we did have some
        \[
            ia \equiv 0 \pmod{p},
        \]
        which is equivalent to
        \[
            ia \equiv 0a \pmod{p},
        \]
        then by the modular cancellation law (Proposition 2.18) we would have
        \[
            i \equiv 0 \pmod{p}.
        \]
        That is, in order to have $ia \equiv 0 \pmod{p}$, that would have to have $i \equiv 0 \pmod{p}$. Therefore we are done with Step 1, since no $i$ from $\{1, 2, 3, \dots, p-1\}$ is congruent to $0$ modulo $p$.
        \bigbreak \noindent 
        \textbf{Step 2.} Next we show that every term in $\{a, 2a, 3a, \dots, (p-1)a\}$, when considered modulo $p$, does not appear more than once in that set. Indeed, if we did have
        \[
            ia \equiv ja \pmod{p},
        \]
        for $i$ and $j$ from $\{1, 2, 3, \dots, p-1\}$, then by the modular cancellation law (Proposition 2.18) we have
        \[
            i \equiv j \pmod{p}.
        \]
        And since $i$ and $j$ are both from the set $\{1, 2, 3, \dots, p-1\}$, this means that $i = j$. In other words, each term in $\{a, 2a, 3a, \dots, (p-1)a\}$ is not congruent to any other term from that set — it is only congruent to itself. This completes Step 2.
        \bigbreak \noindent 
        We have succeeded in proving that when taken modulo $p$,
        \[
            \{a, 2a, 3a, \dots, (p-1)a\} \equiv \{1, 2, 3, \dots, p-1\},
        \]
        even though the numbers in these sets may be in a different order. But since the order does not matter when multiplying numbers, we see that
        \[
            a \cdot 2a \cdot 3a \cdot 4a \cdot \dots \cdot (p-1)a \equiv 1 \cdot 2 \cdot 3 \cdot 4 \cdot \dots \cdot (p-1) \pmod{p}.
        \]
        Then, since $\gcd(2, p) = 1$ by Lemma 2.17 part (i), by the modular cancellation law (Proposition 2.18) we may cancel a $2$ from both sides:
        \[
            a \cdot 3a \cdot 4a \cdot \dots \cdot (p-1)a \equiv 1 \cdot 3 \cdot 4 \cdot \dots \cdot (p-1) \pmod{p}.
        \]
        Then, since $\gcd(3, p) = 1$ by Lemma 2.17 part (i), by the modular cancellation law (Proposition 2.18) we may cancel a $3$ from both sides:
        \[
            a \cdot a \cdot 4a \cdot \dots \cdot (p-1)a \equiv 1 \cdot 4 \cdot \dots \cdot (p-1) \pmod{p}.
        \]
        Continuing to do this for the $4, 5, \dots, (p-1)$ on each side (each of which has a greatest common divisor of $1$ with $p$, by Lemma 2.17 part (i)), by the modular cancellation law (Proposition 2.18) we obtain
        \[
            \underbrace{a \cdot a \cdot a \cdot \dots \cdot a}_{p-1 \text{ copies}} \equiv 1 \pmod{p},
        \]
        which is equivalent to what we sought to prove:
        \[
            a^{p-1} \equiv 1 \pmod{p}.
        \]
    \item \textbf{Bonus proof}:
        \bigbreak \noindent 
        \textbf{Proposition.} If $x$ and $y$ are positive integers, and $x \geq y$, then $\sqrt{x} \geq \sqrt{y} $
        \bigbreak \noindent 
        \textbf{\textit{Proof.}} Assume $x$ and $y$ are positive integers, and $x \geq y$. Then
        \begin{align*}
            x &\geq y \\
            \implies x -y & \geq 0  \\
        .\end{align*}
        Since $x,y \geq 0$, $\sqrt{x^{2}} = \abs{x} = x$, and $\sqrt{y^{2}} = \abs{y} = y $. Thus,
        \begin{align*}
            x-y &\geq 0 \\
            \implies \sqrt{x^{2}} - \sqrt{y^{2}} &\geq 0  \\
            \implies (\sqrt{x} - \sqrt{y})(\sqrt{x} + \sqrt{y}) &\geq 0 \\
            \implies \sqrt{x} - \sqrt{y} &\geq 0  \quad \quad \blacksquare
        .\end{align*}
    \item \textbf{The AM-GM inequality}:
        \bigbreak \noindent 
        \textbf{Theorem (\textit{AM-GM inequality})}. If $x,y \geq 0 \in \mathbb{Z}$, then $\sqrt{xy} \leq \frac{x+y}{2} $
        \bigbreak \noindent 
        \textbf{\textit{Proof.}} Assume $x,y \geq 0 \in \mathbb{Z}$. Consider
        \begin{align*}
            0 \leq (x-y)^{2}
        .\end{align*}
        Which we know to be true, squaring an integer is always positive, and we know $x-y$ to be an integer. It then follows that
        \begin{align*}
            0 \leq x^{2} -2xy + y^{2}
        .\end{align*}
        If we add $4xy$ to both sides, we get
        \begin{align*}
            4xy &\leq x^{2} + 2xy + y^{2} \\
            \implies 4xy &\leq (x + y)^{2} \\
        .\end{align*}
        Now let's take the square root of both sides
        \begin{align*}
            2\sqrt{xy} \leq \abs{x+y}
        .\end{align*}
        Since $x,y \geq 0$, $\abs{x+y} = x+y$. Thus,
        \begin{align*}
            2\sqrt{xy} \leq x + y \\
            \therefore \sqrt{xy} \leq \frac{x+y}{2}
        .\end{align*}
        \bigbreak \noindent 
        \textbf{Note:} Some of the steps taken in this proof may seem a bit random, but if we start at the proposition $\sqrt{xy} \leq \frac{x+y}{2}$ and work backwards algebraically, we see
        \begin{align*}
            \sqrt{xy} &\leq \frac{x+y}{2} \\
            2\sqrt{xy} &\leq x+y \\
            4xy &\leq (x+y)^{2} \\
            4xy &\leq x^{2} + 2xy + y^{2} \\
            0 &\leq x^{2} + 2xy + y^{2} - 4xy \\
            0 &\leq x^{2} - 2xy + y^{2} \\
            0 &\leq (x-y)^{2}
        .\end{align*}
        \bigbreak \noindent 
        We see that we have derived a starting point, and were just working backwards in the proof.
            
    \end{itemize}

    \pagebreak 
    \subsection{Sets}
    \begin{itemize}
        \item \textbf{Vacuous truth}: a vacuous truth is a conditional or universal statement (a universal statement that can be converted to a conditional statement) that is true because the antecedent cannot be satisfied.[1] It is sometimes said that a statement is vacuously true because it does not really say anything. For example, the statement "all cell phones in the room are turned off" will be true when no cell phones are present in the room. In this case, the statement "all cell phones in the room are turned on" would also be vacuously true, as would the conjunction of the two: "all cell phones in the room are turned on and turned off", which would otherwise be incoherent and false.
        \item \textbf{Review: Proper subset}: If $A = B$, then $A \subseteq B$. In the case that $A \subseteq B$ and $A \ne B$, we say that $A$ is a proper subset of $B$. the correct notation for this is “$A \subset B$.”
        \item \textbf{Proving $A \subseteq B $}
            \bigbreak \noindent 
            \textbf{Definition}. Suppose $A$ and $B$ are sets. If every element in $A$ is also an element of $B$, then $A$ is a subset of $B $, which is denoted $A \subseteq B$
            \bigbreak \noindent 
            \textbf{Note:} For every set $B$, it is true that $\varnothing \subseteq B $. 
            To see it, first note that, because there are no elements in $\varnothing$, it would be true to say  
            "for any $x \in \varnothing$, $x$ is a purple elephant that speaks German.'' It’s vacuously\footnote{A statement is vacuously true if it asserts something about all elements of the empty set.} true!  
            You certainly can’t disprove it, right? You can’t present to me any element in $\varnothing$ that is not a purple elephant that speaks German.
            \bigbreak \noindent 
            By this reasoning, I could switch out "is a purple elephant that speaks German" for any other statement, and it would still be true! And this includes the subset criteria: if $x \in \varnothing$, then $x \in B$, which by definition means that $\varnothing \subseteq B$.  
            Again, you certainly can not present to me any $x \in \varnothing$ which is not also an element of $B$, can you?
            \bigbreak \noindent 
            in order to prove that $A \subseteq B$, what we would have to show is this:
            \begin{align*}
                \text{If } x\in A, \text{ then } x\in B 
            .\end{align*}
            In other words, for any arbitrary element in $A$, that same element is also in $B$
            \bigbreak \noindent 
            \textbf{Proposition.} It is the case that 
            \begin{align*}
                \{n \in \mathbb{Z}:\ 12 \mid n\} \subseteq \{n\in\mathbb{Z}:\ 3\mid n\}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Let $A = \{n\in\mathbb{Z}:\ 12\mid n\} $, and $B =\{n\in\mathbb{Z}:\ 3\mid n\} $. Assume $a\in A$
            \penv{
                Since $a\in A$, then $12 \mid a$, which implies $a = 12k$, for some $k\in \mathbb{Z}$. If $a\in B$, then $3\mid a \implies a = 3\ell$
                \bigbreak \noindent 
                Since $a =12k$, and $a=3\ell$, then $12k=3\ell \implies \ell = 4k$. Thus, we have
                \begin{align*}
                    a = 3(4k)
                .\end{align*}
                Which by the definition of divisiblity, and since $4k \in \mathbb{Z}$, we have $3\mid a$. 
                \bigbreak \noindent 
                Therefore, $a \in B \quad \blacksquare$
            }
        \item \textbf{Proving $A = B$}:
            Recall that, for sets $A$ and $B$, to say that ``$A = B$'' is to say that these two sets contain \textit{exactly} the same elements. Said differently, it means these two things:
            \begin{enumerate}
                \item Every element in $A$ is also in $B$ (which means $A \subseteq B$), and
                \item Every element in $B$ is also in $A$ (which means $B \subseteq A$).
            \end{enumerate}
            Indeed, a slick way to prove that $A = B$ is to prove both $A \subseteq B$ and $B \subseteq A$, both of which can be done using the approach discussed above.
        \item \textbf{Review of set operations}:
            \begin{itemize}
                \item The \textit{union} of sets $A$ and $B$ is the set $A \cup B = \{x : x \in A \text{ or } x \in B\}$.
                \item The \textit{intersection} of sets $A$ and $B$ is the set $A \cap B = \{x : x \in A \text{ and } x \in B\}$.
                \item Likewise, if $A_1, A_2, A_3, \dots, A_n$ are all sets, then the union of all of them is the set
                    \[
                        A_1 \cup A_2 \cup \cdots \cup A_n = \{x : x \in A_i \text{ for some } i\}.
                    \]
                    This set is also denoted
                    \[
                        \bigcup_{i=1}^n A_i.
                    \]
                \item Likewise, if $A_1, A_2, A_3, \dots, A_n$ are all sets, then the intersection of all of them is the set
                    \[
                        A_1 \cap A_2 \cap \cdots \cap A_n = \{x : x \in A_i \text{ for all } i\}.
                    \]
                    This set is also denoted
                    \[
                        \bigcap_{i=1}^n A_i.
                    \]
            \end{itemize}
            \bigbreak \noindent 
            Assume $A$ and $B$ are sets and ``$x \notin B$'' means that $x$ is not an element of $B$.
            \begin{itemize}
                \item The \textit{subtraction} of $B$ from $A$ is $A \setminus B = \{x : x \in A \text{ and } x \notin B\}$.
                \item If $A \subseteq U$, then $U$ is called a \textit{universal set} of $A$. The \textit{complement} of $A$ in $U$ is $A^c = U \setminus A$.
            \end{itemize}
            \bigbreak \noindent 
            Furthermore, 
            \begin{itemize}
                \item The \textit{power set} of a set $A$ is $\mathcal{P}(A) = \{X : X \subseteq A\}$.
                \item The \textit{cardinality} of a set $A$ is the number of elements in the set, and it is denoted $|A|$.
            \end{itemize}
            \bigbreak \noindent 
            Assume $A$ and $B$ are sets, The Cartesian product of A and B is 
            \begin{align*}
                A \times B = \{(a, b):\  a \in A and b \in B\}.
            .\end{align*}
            \pagebreak \bigbreak \noindent 
        \item \textbf{More on power sets}: 
            \bigbreak \noindent 
            \textbf{Proposition.} Suppose $A$ and $B $ are sets. If $\mathcal{P}(A)\subseteq \mathcal{P}(B)$, then $A\subseteq B$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A$ and $B$ are sets, and $\mathcal{P}(A) \subseteq \mathcal{P}(B)$.
            \bigbreak \noindent 
            \penv{
                Choose $x\in \mathcal{P}(A)$, which means $x \subseteq A$. Since $\mathcal{P}(A) \subseteq \mathcal{P}(B)$, it follows that $x \in \mathcal{P}(B)$, which means $x \subseteq B$. Let $x=A$, since $A\in\mathcal{P}(A)$. Since $x \subseteq B$, then $A \subseteq B $
            }
            \bigbreak \noindent 
            Therefore, $A\subseteq B \quad \blacksquare$
        \item \textbf{De Morgan's law}:
            \bigbreak \noindent 
            \textbf{Theorem}. Suppose $A$ and $B$ are subsets of a universal set $U$. Then,
            \begin{align*}
                (A \cup B)^{C} &= A^{C} \cap B^{C} \tag{1}
            .\end{align*}
            And
            \begin{align*}
                (A \cap B)^{C} &= A^{C} \cup B^{C} \tag{2}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof (1)}}. Assume $A$ and $B$ are subsets of a universal set $U$, since $(A \cup B)^{C}$, and $A^{C} \cap B^{C} $ are sets, we show equality by showing $(A\cup B)^{C} \subseteq A^{C}\cap B^{C}$, and $A^{C} \cap B^{C} \subseteq (A\cup B)^{C}$. It then follows that $(A \cup B)^{C} = A^{C} \cap B^{C} $
            \penv{
                Choose $x\in (A\cup B)^{C} $, by the definition of the complement, we have $x\not\in(A\cup B)$, which by the definition of the union means $x$ cannot be in $A$, and it cannot be in $B$. In other words, $x\not\in A$ and $x\not\in B \implies x \in A^{C}$ and $x\in B^{C} $. Therefore,
                \begin{align*}
                    x\in A^{C} \cap B^{C}
                .\end{align*}
                Which by the definition of the subset, means $(A\cup B)^{C} \subseteq A^{C} \cap B^{C}$
                \bigbreak \noindent
                Next, let $x\in A^{C} \cap B^{C}$, then $x \in A^{C}$ and $x\in B^{C}$, which means $x\not\in A$ and $x\not\in B$, which implies $x\not\in (A\cup B) \implies x\in (A\cup B)^{C}$.
                \bigbreak \noindent 
                Therefore, since $x\in A^{C} \cap B^{C} \implies x\in (A\cup B)^{C}$, by the definition of a subset, we have $A^{C} \cap B^{C} \subseteq (A\cup B)^{C} $
            }
            Since both $(A\cup B)^{C} \subseteq A^{C} \cap B^{C}$, and $A^{C} \cap B^{C} \subseteq (A \cup B)^{C}$, it must be the case that $(A\cup B)^{C} = A^{C} \cap B^{C} \quad \blacksquare$
            \bigbreak \noindent 
            It should be addressed that this proof can be done by simply manipulating the set builder notation. We have
            \begin{align*}
                A^{C} \cap B^{C} &= \{x \in \mathbb{R}:\ x \in A^{C} \text{ and } x\in B^{C}\} \\
                                 &=\{x\in\mathbb{R}:\ x\not\in A \text{ and } x\not\in B\} \\
                                 &=\{x\in\mathbb{R}:\ x\not\in (A\cup B)\}  \\
                                 &=\{x\in\mathbb{R}:\ x\in (A\cup B)^{C}\}
            .\end{align*}
            $\blacksquare$
        \item \textbf{Proving $a\in A$}: Consider the set $\{x\in S:\ P(x)\}$, where $P(x)$ is some condition on $x$
            \bigbreak \noindent 
            Given a set of this form, if you are presented with a specific $a$ and you wish to prove that $a \in A$, then you must show that
            \begin{enumerate}
                \item $a\in S$
                \item $P(a)$ is true
            \end{enumerate}
            \bigbreak \noindent 
            For example, Let $A = \{(x,y) \in \mathbb{Z} \times \mathbb{N}:\ x\equiv y\pmod{5}\} $, then $(17,2) \in A$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} First, note that $(17,2) \in\mathbb{Z} \times \mathbb{N}$ because $17\in \mathbb{Z}$, and $2 \in \mathbb{N} $, Next, observe that
            \begin{align*}
                17 \equiv 2 \pmod{5}
            .\end{align*}
            Because $5\mid (17-2)$
        \item \textbf{Indexed Families of Sets}: Consider a set $\mathcal{F}$, If every element of $\mathcal{F} $ is itself a set, then $\mathcal{F}$ is called a \textit{family of sets}. Then, one can ask questions about such a family, — like, what is the union of all of the sets in $\mathcal{F}$. That is,
            \begin{align*}
                \bigcup_{S \in \mathcal{F}} S &= \{x:\ x\in S \text{ for some } S \in \mathcal{F}\}
            .\end{align*}
            Likewise, 
            \begin{align*}
                \bigcap_{S\in \mathcal{F}} S &= \{x:\ x\in S \text{ for every } S \in \mathcal{F}\}
            .\end{align*}
        \item \textbf{Bonus example I}.
            \bigbreak \noindent 
            \textbf{Proposition}. It is the case that 
            \begin{align*}
                \{n \in \mathbb{Z}:\ 12\mid n\} = \{n\in\mathbb{Z}:\ 3\mid n\} \cap \{n\in \mathbb{Z}:\ 4\mid n\}
            .\end{align*}
            \textbf{\textit{Proof.}} Let $A = \{n \in \mathbb{Z}:\ 12\mid n\}$, $B =\{n\in\mathbb{Z}:\ 3\mid n\}$, and $C= \{n\in \mathbb{Z}:\ 4\mid n\}$
            \penv{
                \textit{Part i.)} Choose $x\in A$, we then have $ 12\mid x$, and $x = 12k$, for some $k\in \mathbb{Z}$. Thus,
                \begin{align*}
                    x = 12k = 3(4k) = 4(3k)
                .\end{align*}
                Which by the definition of divisibility implies both $3\mid x $ and $4\mid x$, since both $4k$ and $3k \in \mathbb{Z}$. Hence, $x\in B \cap C$
                \bigbreak \noindent 
                \textit{Part ii.)} Choose $x\in B\cap C$, then both $x = 3r$ and $x=4s$, for $r,s\in\mathbb{Z} $. We have
                \begin{align*}
                    3r = 4s
                .\end{align*}
                Which implies $3\mid 4s$, since $r \in \mathbb{Z}$. Because $3\in \mathbb{P}$, we know that either $3\mid 4$ or $3\mid s$. Since it is clear that $3\nmid 4$, it must be the case that $3\mid s$, and thus $s = 3\ell$ for an integer $\ell$. It then follows that
                \begin{align*}
                    x=4s = 4(3\ell) = 12\ell
                .\end{align*}
                Which by the definition of divisibility implies $12\mid x$, and thus $x\in A$
            }
            Since choosing an $x\in A \implies x\in B\cap C$, it must be that $A\subseteq B\cap C$, and choosing an $x\in B\cap C \implies x\in A$, it must also be that $B\cap C \subseteq A$. With these two facts, we can assert that $A = B \cap C \quad \blacksquare$
        \item \textbf{The Cardinality of the Power Set}: Suppose $A$ is a set with $n$ elements. How many subsets of $A$ are there? Said differently, what is $\abs{P(A)}$?
            \bigbreak \noindent 
            We could check the first few cases by hand
            \begin{center}
                \begin{tabular}{c|c|c}
                    $A$& $\abs{A} = n$ & $\abs{\mathcal{P}(A)}$ \\
                    \hline
                    $\{1\}$ & $1$ & 2 \\
                    $\{1,2\}$ & 2 & 4 \\
                    $\{1,2,3\}$ & 3 & 8 \\
                    $\{1,2,3,4\}$ & 4 & 16
                \end{tabular}
            \end{center}
            \bigbreak \noindent 
            It sure looks like if $|A| = n$, then $|P(A)| = 2^n$.  Why would this be true? There is actually a pretty slick way to see it. Every subset  of $\{1, 2, 3\}$ can be thought of by asking whether or not each element is included in the  subset. For example, $\{1, 3\}$ can be thought of as $\langle \text{yes, no, yes} \rangle$, since 1 was included,  2 was not, and 3 was.
            \bigbreak \noindent 
            Suppose you’re trying to generate a subset of $\{1, 2, 3\}$. You could think about  doing so by asking three yes/no questions, the answers to which uniquely determine  your set. With 2 options for the first element, 2 for the second, and 2 for the third, in  total there are $2 \times 2 \times 2 = 8$ ways to answer the three questions, and hence 8 subsets!
            \bigbreak \noindent 
            With $n$ straight yes/no questions, there are $2 \times 2 \times \cdots \times 2 = 2^n$ ways to answer  the questions, each corresponding uniquely to a subset of $A$. Thus, if $|A| = n$, then  $|P(A)| = 2^n$.
        \item \textbf{A consequence of the above fact}:
            \bigbreak \noindent 
            \textbf{Proposition}. Given any $A \subseteq \{1, 2, 3, \ldots, 100\}$ for which $|A| = 10$, there  exist two different subsets $X \subseteq A$ and $Y \subseteq A$ for which the sum of the elements  in $X$ is equal to the sum of the elements in $Y$.
            \bigbreak \noindent 
            For example, consider the set $\{6, 23, 30, 39, 44, 46, 62, 73, 90, 91\}$, If we let 
            \begin{align*}
                X = \{6, 23, 46, 73, 90\} \text{ and } Y = \{30, 44, 73, 91\}
            .\end{align*}
            then the elements in both sets sum to $238$:
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We prove this fact using the pigeonhole principle. Consider the smallest and largest possible subset sums. If $A = \varnothing \subseteq \{1,2,3,...,100\} $, then the sum is $0$. If $A = \{91,92,93,94,95,96,97,98,99,100\} $, then the subset sum is $955$. Thus, there are no more than $956$ possible subset sums for the set $A \subseteq \{1,2,3,...,100\} $, for which $\abs{A} = 10$.
            \bigbreak \noindent 
            Consider $956$ boxes, each representing a unique subset sum. Since we have $2^{\abs{A}} = 2^{10} = 1024$ subsets and only $956$ boxes to place each subset in, there must be a box containing two subsets $A$, which means they must have the same sum $\quad \blacksquare$.
        \item \textbf{The symmetric difference of sets}. The \textit{symmetric difference} of two sets $A$ and $B$, denoted $A \Delta B $, or $A \ominus B$, is the set which contains the elements which are either in set $A$ or in set $B$ but not in both 

    \end{itemize}

    \pagebreak 
    \subsection{Induction}
    \begin{itemize}
        \item \textbf{Dominoes}: Consider a line of dominoes, perfectly arranged, just waiting to be knocked over. Dominoes stacked up like this have the following properties:
            \begin{enumerate}
                \item If you give the first domino a push, it will fall (in particular, it will fall into the second domino, knocking it over).
                \item Moreover, every domino, when it’s knocked over, falls into the next one and knocks it over.
            \end{enumerate}
            Given these two properties, it must be the case that if you knock over the first domino, then every domino will eventually fall. The first premise gets the process going, as it implies that the first domino will fall. And then the second premise keeps it going: Applying the second premise means that the falling first domino will cause the second domino to fall. Applying the second premise again means that the second falling domino will cause the third domino to fall. Applying the second premise again means that the third falling domino will cause the fourth domino to fall. And so on.
        \item \textbf{Sum of the first $n$  odd numbers}: Take a look at the following
            \begin{align*}
                1 = 1 &= 1^{2} \\
                1 + 3 = 4 &= 2^{2}\\
                1 + 3 + 5 = 9 &= 3^{2}\\
                1 + 3 + 5 + 7 = 16 &= 4^{2}\\
                1 + 3 + 5 + 7 + 9 = 25 &= 5^{2}\\
                1 + 3 + 5 + 7 + 9 + 11 = 36 &= 6^{2}\\
                1 + 3 + 5 + 7 + 9 + 11 + 13 = 49 &= 7^{2}
            .\end{align*}
            \bigbreak \noindent 
            It sure looks like the sum of the first $n$ odd numbers is $n^{2}$. But how can we prove that it’s true for every one of the infinitely many $n$? The trick is to use the domino idea. Imagine one domino for each of the above statements.
            \bigbreak \noindent 
            \fig{.7}{./figures/7.png}
            \bigbreak \noindent 
            Suppose we do the following:
            \begin{itemize}
                \item Show that the first domino is true (this is trivial, since obviously $1=1^{2} $).
                \item Show that any domino, if true, implies that the following domino is true too
            \end{itemize}
            Given these two, we may conclude that all the dominoes are true. It’s exactly the same as noting that all the dominoes from earlier will fall. This is a slick way to prove infinitely many statements all at once, and it is called the \textit{principle of mathematical induction}, or, when among friends, it is simply called \textit{induction}.
        \item \textbf{Induction}: Consider a sequence of mathematical statements, $S_{1}, S_{2}, S_{3}, . . . .$
            \begin{itemize}
                \item Suppose $S_{1}$ is true, and
                \item Suppose, for each $k \in \mathbb{N}$, if $S_{k}$ is true then $S_{k+1}$ is true.
            \end{itemize}
            Then, $S_{n} $ is true for every $n\in \mathbb{N}$.
        \item \textbf{Induction framework}:
            \bigbreak \noindent 
            \textbf{Proposition}. $S_{1}, S_{2}, S_{3},... $ are all true
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} \textit{General setup or assumptions if needed}
            \penv{
                \textit{Base case.} $\left\langle\left\langle \text{Demonstration that $S_{1}$ is true} \right\rangle\right\rangle$
                \bigbreak \noindent 
                \textit{Inductive hypothesis}. Assume that $S_{k}$ is true
                \bigbreak \noindent 
                \textit{Induction step}. $\left\langle \left\langle \text{Proof that $S_{k}$ implies $S_{k+1} $} \right\rangle \right\rangle $
            }
            \textit{Conclusion}. Therefore, by induction, all the $S_{n}$ are true. \hspace{5cm} $\blacksquare $
        \item \textbf{Induction example 1}: Let’s simply sum the first $n$ natural numbers: $1 + 2 + 3 + 4 + · · · + n$. These sums are called the triangular numbers since they can be pictured as the number of balls in the following triangles.
            \bigbreak \noindent 
            \fig{.6}{./figures/8.png}
            \bigbreak \noindent 
            \textbf{Proposition.} For any $n\in \mathbb{N}$, $\sum_{i=1}^{n} i = 1 + 2 + 3 + \ldots + n = \frac{n(n+1)}{2} $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by induction
            \penv{
                \underline{Base case:} The base case is when $n=1$, and
                \begin{align*}
                    1 = \frac{1(1+1)}{2} = 1
                .\end{align*}
                \bigbreak \noindent 
                \underline{Inductive hypothesis}: Let $k\in \mathbb{N}$, assume 
                \begin{align*}
                    1 + 2 + 3 + ... + k = \frac{k(k+1)}{2}
                .\end{align*}
                \bigbreak \noindent 
                \underline{Inductive step}: We aim to show that the result holds for $k+1$. Thus,
                \begin{align*}
                    1+ 2 + 3 + ... + k+k+1 = \frac{(k+1)((k+1)+1)}{2} 
                .\end{align*}
                We have
                \begin{align*}
                    1 + 2 + 3 + ... + k + k+1 &= \frac{(k+1)(k+2)}{2}  \\
                    \implies \frac{k(k+1)}{2} + k+1 &= \frac{(k+1)(k+2)}{2} \\
                    \implies \frac{k^{2} + k + 2k + 1}{2} &= \frac{k^{2} + 2k + k + 2}{2}
                .\end{align*}
            }
            Therefore, by induction, $1+2+3+...+n = \frac{n(n+1)}{2} $ for all $n\in \mathbb{N} \quad \blacksquare$
        \item \textbf{Induction example 2}: 
            \bigbreak \noindent 
            \textbf{Proposition}. Let $S_{n}$ be the sum of the first $n$ natural numbers. Then, for any $n \in \mathbb{N}$,
            \begin{align*}
                S_{n} + S_{n+1} = (n+1)^{2}
            .\end{align*}
            \bigbreak \noindent 
            We will prove this proposition twice. The first proof is a direct proof, the second will be by induction.
            \bigbreak \noindent 
            \textbf{\textit{Direct proof.}} We have
            \begin{align*}
                S_{n} + S_{n+1} &= \frac{n(n+1)}{2} + \frac{(n+1)((n+1)+1)}{2} \\
                                &= \frac{n^{2} + n}{2} + \frac{n^{2} + 2n + n + 2}{2} \\
                                &= \frac{n^{2} + n + n^{2} + 3n + 2}{2} \\
                                &= \frac{2n^{2} + 4n + 2}{2} \\
                                &= \frac{2(n^{2} + 2n + 1)}{2} \\
                                &= n^{2} + 2n + 1 \\
                                &= (n+1)^{2} \quad \blacksquare
            .\end{align*}
            \pagebreak \bigbreak \noindent 
            \textbf{\textit{Proof by induction}}. We proceed by induction
            \penv{
                \underline{Base case}: The base case is when $n=1$, and 
                \begin{align*}
                    S_{1} + S_{2} = 1 + 3 = 4 = (1+1)^{2}
                .\end{align*}
                as desired
                \bigbreak \noindent 
                \underline{Inductive hypothesis}. Let $k\in\mathbb{N}$, and assume that 
                \begin{align*}
                    S_{k} + S_{k+1} = ( k+1)^{2}
                .\end{align*}
                \bigbreak \noindent 
                \underline{Inductive step}. We aim to prove that the result holds for $k+1$. That is, 
                \begin{align*}
                    S_{k+1} + S_{k+2} = (k+2)^{2}
                .\end{align*}
                For this, we use the fact that $S_{k+1} $ is the sum of the first $k+1$ natural numbers, thus we can write it as $S_{k} + (k+1)$. Likewise, $S_{k+2} = S_{k+1} + (k+2)$. Thus,
                \begin{align*}
                    S_{k+1} + S_{k+2} &= S_{k} + (k+1) + S_{k+1} + (k+2) \\
                                      &= S_{k} + S_{k+1} + 2k+3 \\
                                      &=(k+1)^{2} + 2k + 3\\
                                      &= k^{2} + 2k + 1 + 2k + 3 \\
                                      &= k^{2} + 4k + 4 \\
                                      &= (k+2)^{2}
                .\end{align*}
            }
            \underline{Conclusion.} Therefore, by induction, the proposition holds for all $n\in \mathbb{N} \quad \blacksquare$
        \item \textbf{A quick note about induction}: For some proof techniques, adding a sentence at the end of your proof is nice but not required. For induction, though, it really is required. You can prove that the first domino will fall, and you can prove that each domino — if fallen— will knock over the next domino, but why does this mean they all fall? Because induction says so! Until you say “by induction. . . ” your work will not officially prove the result
        \item \textbf{Induction example 3.}
            \bigbreak \noindent 
            \textbf{Proposition.} For every $n \in N$, the product of the first $n$ odd natural numbers equals $\frac{(2n)!}{2^{n}n!} $. That is, 
            \begin{align*}
                1 \cdot  3 \cdot 5 \cdot ... \cdot (2n-1) = \frac{(2n)!}{2^{n}n!}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by induction.
            \bigbreak \noindent 
            \underline{Base case:} The base case occurs when $n=1$, 
            \begin{align*}
                1 = \frac{(2(1))!}{2^{1}1!} = 1
            .\end{align*}
            As desired
            \bigbreak \noindent 
            \underline{Inductive hypothesis}. Let $k\in \mathbb{N}$, assume
            \begin{align*}
                1 \cdot 3 \cdot 5 \cdot ... \cdot (2k-1) = \frac{(2k)!}{2^{k}k!}
            .\end{align*}
            \bigbreak \noindent 
            \underline{Inductive step}. We aim to prove that the result holds for $k+1$. Thus, we wish to show
            \begin{align*}
                1 \cdot 3 \cdot 5 \cdot ... \cdot (2k-1) \cdot (2(k+1)-1) &= \frac{(2(k+1))!}{2^{k+1}(k+1)!}\\
                                                                          &=\frac{(2k+2)!}{2^{k+1}(k+1)!}
            .\end{align*}
            By the inductive hypothesis, we have
            \begin{align*}
                1 \cdot 3 \cdot 5 \cdot ... \cdot (2k-1) \cdot (2k+1) &= \frac{(2k)!}{2^{k}k!}(2k+1) \\
                                                                      &= \frac{(2k)!(2k+1)}{2^{k}k!} \\
                                                                      &= \frac{(2k+1)!}{2^{k}k!} \\
                                                                      &=\frac{(2k+1)!}{2^{k}k!} \cdot \frac{(2k+2)}{(2k+2)} \\
                                                                      &= \frac{(2k+2)!}{2^{k}k!(2k+2)} \\
                                                                      &= \frac{(2k+2)!}{2^{k}k! \cdot 2(k+1)} \\
                                                                      &= \frac{(2k+2)!}{2^{k+1}(k+1)!}
            .\end{align*}
            Therefore, by induction, the proposition holds for all $n\in \mathbb{N} \quad \blacksquare$
        \item \textbf{Induction example 4}. 
            \bigbreak \noindent 
            \textbf{Proposition.} For every $n \in \mathbb{N}$, if any one square is removed from a $2^n \times 2^n$ chessboard, the result can be perfectly covered with $\text{L}$-shaped tiles.
            \bigbreak \noindent 
            The tiles cover three squares and look like this:
            \bigbreak \noindent 
            \fig{1}{./figures/9.png}
            \bigbreak \noindent 
            Since the proposition refers to something being true “for every \( n \in \mathbb{N} \),” that’s a pretty good indication that induction is the way to proceed. The base case (when \( n = 1 \)) will be fine. For the inductive hypothesis, we will be assuming that any \( 2^k \times 2^k \) board, with one square removed, can be perfectly covered by L-shaped tiles.
            \bigbreak \noindent 
            In the induction step we are going to consider a $2^{k+1} \times 2^{k+1}$ board — a board that is twice as big in each dimension— with one square missing.
            \pagebreak \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by induction
            \bigbreak \noindent 
            \penv{
                \underline{Base Case}. The base case is when $n = 1$, and among the four possible squares that one can remove from a $2 \times 2$ chessboard, each leaves a chessboard which can be perfectly covered by a single $L$-shaped tile:
                \bigbreak \noindent 
                \fig{.9}{./figures/10.png}
                \bigbreak \noindent 
                \underline{Inductive Hypothesis}. Let $k \in \mathbf{N}$, and assume that if any one square is removed from a $2^{k} \times 2^{k}$ chessboard, the result can be perfectly covered with $L$–shaped tiles.
                \bigbreak \noindent 
                \underline{Induction Step.} Consider a $2^{k+1} \times 2^{k+1}$ chessboard with any one square removed.  Cut this chessboard in half vertically and horizontally to form four $2^k \times 2^k$ chessboards.  One of these four will have a square removed, and hence, by the induction hypothesis, can be perfectly covered.
                \bigbreak \noindent 
                Next, place a single $L$-shaped tile so that it covers one square from each of the other three $2^{k} × 2^{k}$ chessboards, as shown in the picture below.
                \bigbreak \noindent 
                \fig{.7}{./figures/11.png}
                \bigbreak \noindent 
                Each of these other three $2^k \times 2^k$ chessboards can be perfectly covered by the  inductive hypothesis, and hence the entire $2^{k+1} \times 2^{k+1}$ chessboard can be perfectly covered.
                \bigbreak \noindent 
            }
            \textbf{Conclusion.} By induction, for every $n \in \mathbb{N}$, if any one square is removed from a  $2^n \times 2^n$ chessboard, the result can be perfectly covered with L-shaped tiles.
        \item \textbf{Another note about induction}: So far, in all of our examples we proved that a statement holds from all $n \in \mathbb{N}$.  
            The base case was $n = 1$ and in the inductive hypothesis we assumed that the result holds for some $k \in \mathbb{N}$.  
            \bigbreak \noindent 
            There are times where one instead wants to prove that a statement holds for only the natural numbers past some point.  
            For example, it is possible to prove the $p$-test by induction, a result that you might remember from your calculus class:
            \[
                \sum_{i=1}^\infty \frac{1}{i^n} \text{ converges for all integers } n \geq 2.
            \]
            To prove this result, the base case would be $n = 2$ and in the inductive hypothesis we would assume that the result holds for some $k \in \{2, 3, 4, 5, \ldots\}$.  
            \bigbreak \noindent 
            At other times, you may want to prove that a result holds for more than just the natural numbers.  
            For example, a result from combinatorics is that
            \[
                \sum_{i=1}^n \binom{n}{i} = 2^n \text{ holds for all integers } n \geq 0.
            \]
            Here, the base case is $n = 0$, and the inductive hypothesis is the assumption that this holds for some $k \in \{0, 1, 2, 3, \ldots\}$.
        \item \textbf{Strong induction idea}: The idea behind strong induction is that at the point when the 100th domino is the  next to get knocked down, you know for sure that all of the first 99 dominoes have  fallen, not just the 99th. Likewise, when you are proving some sequence of statements  $S_1, S_2, S_3, S_4, \ldots$, instead of just assuming that $S_k$ is true in order to prove $S_{k+1}$,  why not just assume that $S_1, S_2, \ldots, S_k$ are all true in order to prove $S_{k+1}$ — because  by the time you are proving $S_{k+1}$, you have shown them all to be true!
        \item \textbf{Strong induction}: Consider a sequence of mathematical statements, $S_{1}, S_{2}, S_{3}, ...$
            \begin{itemize}
                \item Suppose $S_1$ is true, and  
                \item Suppose, for any $k \in \mathbb{N}$, if $S_1, S_2, \ldots, S_k$ are all true, then $S_{k+1}$ is true.
            \end{itemize}
            Then $S_n$ is true for every $n \in \mathbb{N}$.
            \bigbreak \noindent 
            \textbf{Note:} In regular induction, you essentially use $S_1$ to prove $S_2$, and then $S_2$ to prove $S_3$,  and then $S_3$ to prove $S_4$, and so on. With strong induction, you use $S_1$ to prove $S_2$,  and then $S_1$ and $S_2$ to prove $S_3$, and then $S_1, S_2$, and $S_3$ to prove $S_4$, and so on.
        \item \textbf{Fundemental theorem of arithmetic}: If $n$ is an integer and $n \geq 2$,  then $n$ is either prime or composite. An integer $p$ is prime if $p \geq 2$ and its only  positive divisors are $1$ and $p$. A positive integer $n \geq 2$ that is not prime is called  composite, and is therefore one that can be written as $n = st$, where $s$ and $t$ are  integers smaller than $n$ but larger than $1$. And with that, it is time for a really big  and important result.
            \bigbreak \noindent 
            \textbf{Theorem 4.8 (Fundamental Theorem of Arithmetic).}  Every integer $n \geq 2$ is either prime or a product of primes.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by strong induction
            \pagebreak \bigbreak \noindent 
            \penv{
                \underline{Base case.} The base case occurs when $n=2$. Observe that $2\in \mathbb{P} $
                \bigbreak \noindent 
                \underline{Inductive hypothesis}. Let $k\in \mathbb{N}$ such that $k \geq 2$. Assume that the integers $2,3,4,...,k$ are either prime or a product of primes.
                \bigbreak \noindent 
                \underline{Induction step}. Next, we consider $k+1$. We aim to show that $k+1$ is either prime or a product of primes. Since $k+1$ is larger than one, it is either prime or composite. Consider these two cases separately. Case 1 is that $k+1$ is prime. In this case, our goal is achieved.
                \bigbreak \noindent 
                Case 2 is that $k+1$ is composite; that is, $k+1$ has positive factors other than one and itself. Say, $k+1 = st$, where $s,t$ are positive integers greater than zero, and  
                \begin{align*}
                    1 < s < k+1 \quad 1<t<k+1
                .\end{align*}
                By the inductive hypothesis, both $s$ and $t$ can be written as a product of primes, say
                \begin{align*}
                    s &= p_{1} \cdot p_{2} \cdot ... \cdot p_{m} \\
                    t &= q_{1} \cdot q_{2} \cdot  ... \cdot q_{\ell}
                .\end{align*}
                Where each $p_{i}, q_{j} \in \mathbb{P}$, then 
                \begin{align*}
                    k + 1 = st = (p_{1} \cdot p_{2} \cdot ... \cdot p_{m})(q_{1} \cdot q_{2} \cdot  ... \cdot q_{\ell})
                .\end{align*}
                \bigbreak \noindent 
                Is written as a product of primes
                \bigbreak \noindent 
                Note that if $s$ or $t$ where prime, then $m$ or $\ell$ would be one. Say $s$ was prime, then $s = p_{1} $
                \bigbreak \noindent 
                \textbf{Conclusion}. By strong induction, every positive integer larger than 2 can be written as a product of primes.
            }
        \item \textbf{Chocolate bar example}:
            \bigbreak \noindent 
            \textbf{Proposition.} Suppose you have a chocolate bar that is an $m \times n$ grid of squares. The entire bar, or any smaller rectangular piece of that bar, can be broken along the vertical or horizontal lines separating the squares. 
             
            The number of breaks to break up that chocolate bar into individual squares is precisely $mn - 1$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by strong induction
            \penv{
                \underline{Base case}: The base case occurs when $n=1$, which is an $1\times 1$ chocolate bar. Since the number of breaks needed to break the bar into individual squares is clearly zero, we have
                \begin{align*}
                    0 = 1(1) -1 = 0
                .\end{align*}
                As desired
                \bigbreak \noindent 
                \underline{Inductive hypothesis}: Let $k\in\mathbb{N}$, assume that all bars with at most $k$ squares satisfy the proposition.
                \bigbreak \noindent 
                \underline{Induction step}: Consider now any bar with $k+1$ squares, suppose this bar has dimensions $m\times n $. Consider an arbitrary first break, and suppose the two smaller bars have $a$ squares and $b$ squares, respectively. Note that we must have $a + b = mn$, because the number of squares in the smaller bars must add up to the number of squares in the original $m \times n$ bar.
                \bigbreak \noindent 
                By the inductive hypothesis, the bar with $a$ squares will require $a − 1$ breaks to completely break it up, and the bar with $b$ breaks will require $b−1$ breaks. Therefore, to break up the $m \times n$ bar, we must make a first break, followed by $(a − 1) + (b − 1)$ additional breaks. The total number of breaks is then
                \begin{align*}
                    1 + (a-1) + (b-1) &= a+b-1 \\
                                      &=mn - 1
                .\end{align*}
                And $mn − 1$ is indeed one less than the number of squares in the $m \times n$ bar.
                \bigbreak \noindent 
            }
            \underline{Conclusion}. By strong induction, a chocolate bar of any size requires one break less than its number of squares to break it up into individual squares $\quad \blacksquare $
            \bigbreak \noindent 
            \textbf{Note:} What if the pieces were in the shape of a triangle? If it had $T$ squares would it still require $T - 1$ breaks?
            \bigbreak \noindent 
            What about other shapes? What if there are pieces missing in the middle? Interestingly, the answer is $T - 1$ no matter the bar’s shape, and even if pieces are missing! As long as each of your “breaks” divides one chunk into two, that’s the answer.
            \bigbreak \noindent 
            Here is some intuition for that: No matter the shape, the bar starts out as a  
            single “chunk” of chocolate, and after your sequence of breaks the bar is broken into  
            $T$ chunks of chocolate — the $T$ individual squares. How many breaks does it take to  
            move from 1 chunk to $T$ chunks? Notice that every break increases the number of  
            chunks by 1. So after 1 break, there will be 2 chunks. After 2 breaks, there will be 3  
            chunks. And so on. Thus, after $T - 1$ breaks there will be $T$ chunks, which is why  
            $T - 1$ breaks is guaranteed to be the answer, no matter which shape you started with.

        \item \textbf{Multiple base cases}: When proving the $(k + 1)$st case within the induction step, strong induction allows  you to apply not just the $k$th step, but any of the steps $1, 2, 3, \ldots, k$. In the previous  two examples, you had no idea which earlier steps you will need, so it was vital that  you assumed them all. At times, though, you really only need, say, the previous two  steps. The $k$th step is perhaps not enough, but the $(k - 1)$st step and the $k$th step is  guaranteed to be enough.
            \bigbreak \noindent 
            If you rely on the two previous steps, then that is analogous to saying that it takes the previous two dominoes to knock over the next one. Thus, if you knock over dominoes 1 and 2, then they will collectively knock over the third. Then, since the second and third have fallen, those two will collectively knock over the fourth. Then the third and fourth will knock over the fifth. And so on. Thus, the induction relies on two base cases, because without knocking over the first two the third won’t fall and the process won’t begin
            \bigbreak \noindent 
            \textbf{Example:} 
            \bigbreak \noindent 
            \textbf{Proposition.} Every $n \in N$ with $n \geq 11$ can be written as $2a + 5b$ for some natural numbers $a$ and $b$.
            \bigbreak \noindent 
            \textbf{Base Cases.} In the induction step, we will need two cases prior, so we show two base  
            cases here: $n = 11$ and $n = 12$. Both of these can be written as asserted:
            \[
                11 = 2 \cdot 3 + 5 \cdot 1 \\
                12 = 2 \cdot 1 + 5 \cdot 2.
            \]
            \textbf{Inductive Hypothesis.} Assume that for some integer $k \geq 12$, the results hold for  
            \[
                n = 11, 12, 13, \ldots, k.
            \]
            \textbf{Induction Step.} We aim to prove the result for $k + 1$. By the inductive hypothesis,  
            \[
                k - 1 = 2a + 5b
            \]
            for some $a, b \in \mathbb{N}$. Adding 2 to both sides,
            \[
                k + 1 = 2(a + 1) + 5b.
            \]
            Observe that $(a + 1) \in \mathbb{N}$ and $b \in \mathbb{N}$, proving that this is indeed a representation of  
            $(k + 1)$ in the desired form.
            \bigbreak \noindent 
            \textbf{Conclusion.} Therefore, by strong induction, every integer $n \geq 11$ can be written as  
            the proposition asserts. \(\blacksquare\)
            \pagebreak 
        \item \textbf{False proofs with induction}: 
            \bigbreak \noindent 
            \textbf{Proposition}. Everyone on Earth has the same name
            \bigbreak \noindent 
            \textit{Fake Proof.} We will consider groups of $n$ people at a time, and by induction we will  
            ``prove'' that for every $n \in \mathbb{N}$, every group of $n$ people must have everyone with the  
            same name.
            \penv{
                \textbf{Base Case.} If $n = 1$, then of course everyone in the group has the same name, since  
                there’s only one person in the group!
                \bigbreak \noindent 
                \textbf{Inductive Hypothesis.} Let $k \in \mathbb{N}$, and assume that any group of $k$ people all have  
                the same name.
                \bigbreak \noindent 
                \textbf{Induction Step.} Consider a group of $k + 1$ people.
                \bigbreak \noindent 
                \fig{.7}{./figures/12.png}
                \bigbreak \noindent 
                But notice that we can look at the first $k$ of these people and then the last $k$ of these people, and to each of these groups we can apply the inductive hypothesis:
                \bigbreak \noindent 
                \fig{.7}{./figures/13.png}
                \bigbreak \noindent 
                And the only way that this can all happen, is if all $k + 1$ people have the same name.
            }
            Conclusion. This “proves” by induction that for every $n \in N$, every group of $n$ people must have the same name. So if you let $n$ be equal to the number of people on Earth, this “proves” that everyone has the same name.
            \bigbreak \noindent 
            For $k+1$ people, the proof assumes that you can take the first $k$ people and the last  
            $k$ people, and both of these subsets must have the same name because the induction  
            hypothesis applies to them individually.  
            \bigbreak \noindent 
            However, this reasoning fails when $k+1 = 2$. For $k+1 = 2$, the first subset has one  
            person, and the second subset also has one person. These subsets do not overlap, so  
            there is no logical connection ensuring that these two people share the same name.
            \bigbreak \noindent 
            The induction relies on overlapping subsets of $k$ people to conclude that all $k+1$ people  must have the same name. However, this overlap only works if $k+1 > 2$, meaning the proof  doesn't actually establish the result for $k+1 = 2$, which breaks the induction chain.  Without the foundation for $n = 2$, the argument fails for all larger $n$.
        \item \textbf{Induction bonus example 1}.
            \bigbreak \noindent 
            \textbf{Lemma 4.13}. For every $n\in \mathbb{N}_{0} $,
            \begin{align*}
                1 + 2 + 4 + 8 + ... + 2^{n} = 2^{n+1}-1
            .\end{align*}
            For example, 
            \begin{align*}
                1 &= 2^{1}-1 \\
                1 + 2 &= 2^{2}-1 \\
                1 + 2 + 4 &= 2^{3}-1 \\
                1 + 2 + 4 + 8 &= 2^{4}-1
            .\end{align*}
            \penv{
                \underline{Base case}. The base case occurs when $n=1$, we have
                \begin{align*}
                    1 = 2^{1}-1 = 1
                .\end{align*}
                As desired
                \bigbreak \noindent 
                \underline{Inductive hypothesis}. Let $k\in \mathbb{N}_{0}$, assume that
                \begin{align*}
                    1 + 2 + 4 +... + 2^{k} = 2^{k+1}-1
                .\end{align*}
                \bigbreak \noindent 
                \underline{Induction step}. We wish to show that the result holds for $k+1$. That is, 
                \begin{align*}
                    1 + 2 + 4+ ... + 2^{k} + 2^{k+1} = 2^{(k+1)+1}-1 = 2^{k+2} -1
                .\end{align*}
                By the inductive hypothesis, we have
                \begin{align*}
                    1 + 2 + 4 + ... + 2^{k} + 2^{k+1} &= 2^{k+1}-1 + 2^{k+1} \\
                                                      &=2(2^{k+1})-1 \\
                                                      &=2^{k+2} -1
                .\end{align*}
                As desired

            }
            \bigbreak \noindent 
            Therefore, by induction, the proposition holds for all $n\in \mathbb{N}_{0} $
            \bigbreak \noindent 
        \item \textbf{Induction bonus example 2}. \textbf{Proof.} We proceed by strong induction.
            \textbf{Base Case.} Our base case is when \( n = 1 \). Note that 1 can be written as \( 2^0 \), and this is the only way to write 1 as a sum of distinct powers of 2, because all other powers of 2 are larger than 1.
            \bigbreak \noindent 
            \textbf{Inductive Hypothesis.} Let \( k \in \mathbb{N} \), and assume that each of the integers \( 1, 2, 3, \dots, k \) can be expressed as a sum of distinct powers of 2 in precisely one way.
            \bigbreak \noindent 
            \textbf{Induction Step.} We now aim to show that \( k+1 \) can be expressed as a sum of distinct powers of 2 in precisely one way.
            \bigbreak \noindent 
            Let \( 2^m \) be the largest power of 2 such that \( 2^m \leq k+1 \). We now consider two cases: the first is if \( 2^m = k+1 \), and the second is if \( 2^m < k+1 \).
            \bigbreak \noindent 
            \textbf{Case 1:} \( 2^m = k+1 \). If this occurs, then \( 2^m \) itself is a way to express \( k+1 \) as a (one-term) sum of distinct powers of 2. Moreover, there is no other way to express \( k+1 \) as a sum of distinct powers of 2, because by Lemma 4.13 all smaller powers of 2 sum to \( 2^m - 1 = k \). Thus, even by including all smaller powers of 2, we are unable to reach \( k+1 \). So, in Case 1, there is precisely one such expression for \( k+1 \).
            \bigbreak \noindent 
            \textbf{Case 2:} \( 2^m < k+1 \). In order to apply the inductive hypothesis, we will consider \( (k+1) - 2^m \). First, note that \( (k+1) - 2^m \) is less than \( 2^m \), because otherwise \( k+1 \) would have two copies of \( 2^m \) within it, implying that \( 2^m + 2^m \leq k+1 \). However, since \( 2^m + 2^m = 2 \cdot 2^m = 2^{m+1} \), this would mean \( 2^{m+1} \leq k+1 \). This can't be, since \( 2^m \) was chosen to be the largest power of 2 that is at most \( k+1 \). Thus, it must be the case that \( (k+1) - 2^m < 2^m \).
            \bigbreak \noindent 
            Next, by the inductive hypothesis, \( (k+1) - 2^m \) can be expressed as a sum of distinct powers of 2 in precisely one way, and since \( (k+1) - 2^m < 2^m \), this unique expression for \( (k+1) - 2^m \) will not contain a \( 2^m \). Thus, by adding a \( 2^m \) to it, we obtain an expression for \( k+1 \) as a sum of powers of 2. And this expression is unique because \( (k+1) - 2^m \) is unique according to the inductive hypothesis, and the \( 2^m \) portion is unique because, again by Lemma 4.13, even if you summed all of the smaller powers of 2, you will not reach \( 2^m \).
            \bigbreak \noindent 
            \textbf{Conclusion.} By strong induction, every \( n \in \mathbb{N} \) can be expressed as a sum of distinct powers of 2 in precisely one way. \(\Box\)
        \item \textbf{Induction bonus example 3.}
            \bigbreak \noindent 
            \textbf{Theorem 4.15 (\textit{The binomial theorem})}. For $x,y \in \mathbb{R}$, and $n\in \mathbb{N}_{0} $
            \begin{align*}
                (x+y)^{n} = \sum_{m=0}^{n}\binom{n}{m} x^{n-m}y^{m}
            .\end{align*}
            Here, when $n \geq m$, the binomial coefficient $\binom{n}{m}$ is defined to be 
            \[
                \binom{n}{m} = \frac{n!}{m!(n-m)!},
            \]
            which one can show is always an integer. The binomial coefficients can also be defined combinatorially: $\binom{n}{m}$ is equal to the number of ways to choose $m$ elements from an $n$-element set; in fact, $\binom{n}{m}$ is read "n choose m." For example, 
            \[
                \binom{4}{2} = 6
            \]
            because there are six subsets of the set $\{1, 2, 3, 4\}$ containing two elements:
            \[
                \{1, 2\}, \{1, 3\}, \{1, 4\}, \{2, 3\}, \{2, 4\}, \{3, 4\}.
            \]
            Binomial coefficients can be computed iteratively using \textit{Pascal's rule}, which says that
            \[
                \binom{n}{r} = \binom{n-1}{r-1} + \binom{n-1}{r},
            \]
            as well as the fact that
            \[
                \binom{n}{0} = 1 \quad \text{and} \quad \binom{n}{n} = 1 \quad \text{for all } n \in \mathbb{N}_0.
            \]
            A beautiful way to combine these facts is called \textit{Pascal's triangle}:
            \bigbreak \noindent 
            \fig{.6}{./figures/15.png}
            \bigbreak \noindent 
            Indeed, we can even prove the binomial theorem by induction, by making use of Pascal’s rule. Here is a sketch of that proof:
            \bigbreak \noindent 
            \textbf{\textit{Proof sketch}}. The base case is when $n = 0$, and indeed $(x + y)^0 = 1$. The next couple cases are more interesting, and you can check that $(x + y)^1 = x + y$ and $(x + y)^2 = x^2 + 2xy + y^2$ do indeed match the theorem. The inductive hypothesis will be
            \[
                (x + y)^k = x^k + \binom{k}{1}x^{k-1}y + \binom{k}{2}x^{k-2}y^2 + \cdots + \binom{k}{k-1}xy^{k-1} + y^k.
            \]
            For the induction step, we perform easy algebra, then apply the inductive hypothesis, then perform hard algebra, then apply Pascal's rule:
            \[
                (x + y)^{k+1} = (x + y)(x + y)^k
            \]
            \[
                = (x + y) \left[ x^k + \binom{k}{1}x^{k-1}y + \binom{k}{2}x^{k-2}y^2 + \cdots + \binom{k}{k-1}xy^{k-1} + y^k \right]
            \]
            \[
                = x^{k+1} + \left[\binom{k}{0}\right]x^k y + \left[\binom{k}{1}\right]x^{k-1}y^2 + \cdots + \left[\binom{k}{k}\right]xy^k + y^{k+1}
            \]
            \[
                = x^{k+1} + \binom{k+1}{1}x^k y + \binom{k+1}{2}x^{k-1}y^2 + \cdots + \binom{k+1}{k}xy^k + y^{k+1}.
            \]
            And that—a few boring algebraic details omitted—is the proof.
            \bigbreak \noindent 
            The binomial theorem tells us that in order to expand $(x + y)^5$ you can just look at the 5th row of Pascal’s triangle (where the top element counts as the $0$th row, so the 5th row is $1 \ 5 \ 10 \ 10 \ 5 \ 1$):
            \[
                (x + y)^5 = 1x^5 + 5x^4y + 10x^3y^2 + 10x^2y^3 + 5xy^4 + 1y^5.
            \]
            Moreover, by plugging in special values for $x$ and $y$, all sorts of neat identities pop out. There are loads of examples of this, but here are just three:
            \begin{itemize}
                \item By plugging in $x = 1$, $y = 1$, we prove $\sum_{k=0}^n \binom{n}{k} = 2^n$.
                \item By plugging in $x = 2$, $y = 1$, we prove $3^n = \sum_{k=0}^n \binom{n}{k}2^k$.
                \item By plugging in $x = -1$, $y = 1$, we prove $0 = \sum_{k=0}^n (-1)^k \binom{n}{k}$.
            \end{itemize}
        % \item \textbf{Fermat's little theorem with 4.15}:
        %     \bigbreak \noindent 
        %     \textbf{Theorem}. If $a$ is a natural number and $p$ is a prime which does not divide $a$, then
        %     \begin{align*}
        %         a^{p} \equiv a \pmod{p}
        %     .\end{align*}
        %     \textbf{Note: } Written just slightly differently by multiplying each side of the congruence by a, which can also be undone by using the cancellation law



    \end{itemize}

    \pagebreak 
    \subsection{Logic}
    \begin{itemize}
        \item \textbf{Statements}: A statement is a sentence or mathematical expression that is either true or false. If the logic is valid and the statements are true, then it is called sound
            \bigbreak \noindent 
            Every theorem/proposition/lemma/corollary is a (true) statement; Every conjecture is a statement (of unknown truth value); and Every incorrect calculation is a (false) statement.
        \item \textbf{Open sentence}: 
            A related notion is that of an \textit{open sentence}, which refers to sentences or mathematical expressions that:
            \begin{enumerate}
                \item do not have a truth value,
                \item depend on some unknown, like a variable $x$ or an arbitrary function $f$, and
                \item when the unknown is specified, the open sentence becomes a statement (and thus has a truth value).
            \end{enumerate}
            Their truth value depends on the specific value of $x$ or $f$ that is chosen.
            \bigbreak \noindent 
            Typically, we use capital letters for statements, like $P$, $Q$ and $R $. Open sentences are often written the same, or perhaps like $P(x)$, $Q(x)$ or $R(x)$ when one wishes to emphasize the variabl
        \item \textbf{And, or, not}: Let $P$ and $Q$ be statements or open sentences.
            \begin{enumerate}
                \item $P \land Q$ means "P and Q".
                \item $P \lor Q$ means "P or Q (or both)".
                \item $\sim P$ means "not P".
            \end{enumerate}
        \item \textbf{Implies, iff}:
            Let $P$ and $Q$ be statements or open sentences.
            \begin{enumerate}
                \item $P \implies Q$ means "P implies Q".
                \item $P \iff Q$ means "P if and only if Q".
            \end{enumerate}
            \bigbreak \noindent 
            Let’s now discuss a subtle aspect of implications: Translating them to and from English. Language can be complicated,\footnote{Language nuances can make logical translation challenging.} and we in fact have many different ways in English to say “$P$ implies $Q$.” Here are some examples:
            \begin{itemize}
                \item If $P$, then $Q$
                \item $Q$ if $P$
                \item $P$ only if $Q$
                \item $Q$ whenever $P$
                \item $Q$, provided that $P$
                \item Whenever $P$, then also $Q$
                \item $P$ is a sufficient condition for $Q$
                \item For $Q$, it is sufficient that $P$
                \item For $P$, it is necessary that $Q$
            \end{itemize}
            For example, “If it is raining, then the grass is wet” has the same meaning as “The grass is wet if it is raining.” These also mean the same as “The grass is wet whenever it is raining” or “For the grass to be wet, it is sufficient that it is raining.”
            \bigbreak \noindent 
            Next, here are some ways to say “$P$ if and only if $Q$”:
            \begin{itemize}
                \item $P$ is a necessary and sufficient condition for $Q$.
                \item For $P$, it is necessary and sufficient that $Q$.
                \item $P$ is equivalent to $Q$.
                \item If $P$, then $Q$, and conversely.
                \item $P$ implies $Q$ and $Q$ implies $P$.
                \item Shorthand: $P$ iff $Q$.
                \item Symbolically: $(P \implies Q) \land (Q \implies P)$.
            \end{itemize}
            The fact that ``$P$ implies $Q$'' is the same as ``If $P$, then $Q$'' or ``$Q$ if $P$'' is sometimes intuitive to students. But the fact that these are all the same as ``$P$ only if $Q$'' is often confusing. Most people's guts tell them that ``$P$ implies $Q$'' should be the same as ``$Q$ only if $P$.''
            \bigbreak \noindent 
            The answer is ``$P$ only if $Q$'', and the way to think about it is that ``$P$ implies $Q$'' means that whenever $P$ is true, $Q$ must also be true. And ``$P$ only if $Q$'' means that $P$ can only be true if $Q$ is true\ldots that is, whenever $P$ is true, it must be the case that $Q$ is also true\ldots that is, $P \implies Q$.
        \item \textbf{Conditional, biconditional statements}: Now, if $P$ and $Q$ are statements, then ``$P \implies Q$'' and ``$P \iff Q$'' are also statements, meaning they must also be either true or false. The statement $P \implies Q$ is called a conditional statement, whereas $P \iff Q$ is called a biconditional statement. These are minor definitions, but the following is an important definition.

        \item \textbf{Converse}: The \textit{converse} of $P \implies Q$ is $Q\implies P $
            \bigbreak \noindent 
            \textbf{Note:} If $P \implies Q$, it is not necessarily the case that $Q \implies P$
        \item \textbf{Truth tables for and, or, and not}: A truth table models the relationship between the truth values of one or more statements, and that of another
            \bigbreak \noindent 
            \begin{center}
                \begin{tabular}{c|c|c}
                    $P$& $Q$ & $P\land Q$ \\
                    \hline
                    True & True  & True \\
                    True & False & False \\
                    False &  True & False \\
                    False & False & False
                \end{tabular}
            \end{center}
            For for “$P$ and $Q$” to be a true statement, both $P$ and $Q$ must be independently true
            \bigbreak \noindent 
            Here’s how the truth values for $P$ and for $Q$ affect the truth value for $P \lor Q$.
            \begin{center}
                \begin{tabular}{c|c|c}
                    $P$ & $Q$ & $P \lor Q$ \\
                    \hline
                    True  & True & True \\
                    True  & False & True \\
                    False  & True  & True \\
                    False & False & False
                \end{tabular}
            \end{center}
            It is sufficient that either $P$ is true or that $Q$ is true (or both).
            \bigbreak \noindent 
            Finally, here is how the truth values for $P$ affects that of $\neg P$.
            \begin{center}
                \begin{tabular}{c|c}
                    $P$ &  $\neg P$ \\
                    \hline
                    True & False\\
                    False & True
                \end{tabular}
            \end{center}
            In order for ``not $P$'' to be true, it is required that $P$ be false. By applying this reasoning twice, this also implies that $\sim\sim P$ and $P$ always have the same truth value.
            \bigbreak \noindent 
            One last example shows how we proceed with more complicated statements
            \[
                \begin{array}{c|c|c|c|c|c}
                    \hline
                    P & Q & P \vee Q & P \wedge Q & \neg (P \wedge Q) & (P \vee Q) \wedge \neg (P \wedge Q) \\
                    \hline
                    \text{True} & \text{True} & \text{True} & \text{True} & \text{False} & \text{False} \\
                    \text{True} & \text{False} & \text{True} & \text{False} & \text{True} & \text{True} \\
                    \text{False} & \text{True} & \text{True} & \text{False} & \text{True} & \text{True} \\
                    \text{False} & \text{False} & \text{False} & \text{False} & \text{True} & \text{False} \\
                \end{array}
            \]
        \item \textbf{De Morgan’s Logic Laws}: Take a loot at the truth tables for $\neg(P \land Q)$ and $\neg P \lor \neg Q$, side by side:
            \begin{multicols}{2}
                \[
                    \begin{array}{c|c|c|c}
                        P & Q & P \land Q & \neg(P \land Q) \\
                        \hline
                        \text{True} & \text{True} & \text{True} & \text{False} \\
                        \text{True} & \text{False} & \text{False} & \text{True} \\
                        \text{False} & \text{True} & \text{False} & \text{True} \\
                        \text{False} & \text{False} & \text{False} & \text{True} \\
                    \end{array}
                \]

                \[
                    \begin{array}{c|c|c|c|c}
                        P & Q & \neg P & \neg Q & \neg P \lor \neg Q \\
                        \hline
                        \text{True} & \text{True} & \text{False} & \text{False} & \text{False} \\
                        \text{True} & \text{False} & \text{False} & \text{True} & \text{True} \\
                        \text{False} & \text{True} & \text{True} & \text{False} & \text{True} \\
                        \text{False} & \text{False} & \text{True} & \text{True} & \text{True} \\
                    \end{array}
                \]
            \end{multicols}
            Since the final columns are the same, if one is true, the other is true; if one is false, the other is false; that is, there is no way to select $P$ and $Q$ without these two agreeing. When two statements have the same final column in their truth tables, like in the example above, they are said to be logically equivalent (one is true if and only if the other is true), which we denote with an ``$\iff$'' symbol. De Morgan’s logic law, for example, can be written like this:
            \[
                \neg(P \land Q) \iff (\neg P \lor \neg Q)
            \]
            \bigbreak \noindent 
            “$P$ and $Q$ are not both true” is the same as “$P$ is false or $Q$ is false.”
            \bigbreak \noindent 
            \textbf{Theorem}: If $P$ and $Q$ are statements, then
            \[
                \neg(P \land Q) \iff \neg P \lor \neg Q \quad \text{and} \quad \neg(P \lor Q) \iff \neg P \land \neg Q.
            \]
        \item \textbf{$P$, $Q$, and their names}:
            In logical statements involving \( P \) and \( Q \), the terms \( P \) and \( Q \) are referred to as propositions or statements. Depending on the logical operator used, they may also have more specific names:
            \begin{enumerate}
                \item \textbf{In a conjunction (\( P \land Q \)):}
                    \begin{itemize}
                        \item \( P \) and \( Q \) are called \textbf{conjuncts}.
                    \end{itemize}
                \item \textbf{In a disjunction (\( P \lor Q \)):}
                    \begin{itemize}
                        \item \( P \) and \( Q \) are called \textbf{disjuncts}.
                    \end{itemize}
                \item \textbf{In an implication (\( P \implies Q \)):}
                    \begin{itemize}
                        \item \( P \) is called the \textbf{antecedent} (or \textbf{hypothesis}, \textbf{premise}).
                        \item \( Q \) is called the \textbf{consequent} (or \textbf{conclusion}).
                    \end{itemize}
                \item \textbf{In a biconditional (\( P \iff Q \)):}
                    \begin{itemize}
                        \item \( P \) and \( Q \) are called \textbf{equivalents} (since \( P \iff Q \) means \( P \) and \( Q \) are logically equivalent).
                    \end{itemize}
                \item \textbf{In negation (\( \neg P \)):}
                    \begin{itemize}
                        \item \( P \) is simply the proposition being negated.
                    \end{itemize}
            \end{enumerate}

        \item \textbf{Implications}: We call the conditional statemests, $P \implies Q$ \textit{implications}. They are called implications because they express a logical relationship where one statement (the premise, $P$) ``implies'' or leads to another statement (the conclusion, $Q$). The word ``implication'' comes from the Latin root \textit{implicare}, meaning ``to entwine'' or ``to involve,'' reflecting the idea that $P$ is connected to $Q$.
            \bigbreak \noindent 
            A biconditional statement combines two implications, $P \implies Q$ AND $Q\implies P $
        \item \textbf{Truth Tables with Implications}: Consider the truth table for the implication $P\implies Q$
            \begin{center}
                \begin{tabular}{c|c|c}
                    $P$& $Q$ & $P\implies Q$ \\
                    \hline 
                    True & True  & True \\
                    True  & False & False \\
                    False & True & True \\
                    False & False & True
                \end{tabular}
            \end{center}
            The results of the first two rows are trivial, but the last two may be hard to grasp.
            \bigbreak \noindent 
            Why is the implication true if the assumption, $P$, is false? It’s kind of like how we said that this is true: “If $x \in \varnothing$, then $x$ is a purple elephant that speaks German.” Since there is nothing in the empty set, if you suppose $x \in \varnothing$, you can then claim anything you want about $x$ and it is inherently true — you certainly cannot present to me any element in the empty set that is not a purple elephant that speaks German. In the set theory chapter, we called such a claim \textit{vacuously true}. 
            \bigbreak \noindent 
            Likewise, in a universe where $P$ is true, the statement $P \implies Q$ has some real meaning that needs to be proven or disproven: Does $P$ being true imply $Q$ is true, or not? But in a universe where $P$ is not true, it claims nothing, and hence $P \implies Q$ is \textit{vacuously true}.
            \bigbreak \noindent 
            “If unicorns exist, then they can fly” can certainly not be considered false, because unicorns do not exist, so any claim about them is considered vacuously true. Indeed, the way to falsify that proposition would be to locate a unicorn that cannot fly, which is impossible to do. Every unicorn in existence can indeed fly! Also, every unicorn in existence cannot fly! Neither can be disproven!
        \bigbreak \noindent 
        Let's now consider the truth table for the statement $P \iff Q $
        \begin{center}
            \begin{tabular}{c|c|c}
                $P$& $Q$ & $P\iff Q$ \\
                \hline
                True &True & True \\
                True & False & False \\
                False & True & False \\
                False & False & True
            \end{tabular}
        \end{center}
        We can see this by writing $P\iff Q $ as $(P\implies Q) \land (Q\implies P)$
    \item \textbf{Quantifiers}: Consider the sentence
        \begin{center}
           $n$ is even 
        \end{center}
        Which is not a statement because it is neither true nor false. One way to turn a sentence like this into a statement is to give n a value. For example,
        \begin{center}
           If $n=5$, then $n$ is even 
        \end{center}
        What I’d like to discuss now are two other basic ways to turn “$n$ is even” into a statement: add quantifiers. A quantifier is an expression which indicates the number (or quantity) of our objects
        \begin{center}
          $\forall \ n\in \mathbb{N}$, $n$ is even \\
          $\exists \ n \in \mathbb{N}$ such that $n$ is even
        \end{center}
        Where $\forall$ means "for all", and $\exists$ means "there exists". The symbol $\forall$ is known as the \textit{universal quantifer}. Whereas $\exists$ is known as the \textit{existential quantifier.}
        \bigbreak \noindent 
        \textbf{Note}: We also have $\not\exists $ "there does not exist", and $\exists! $ "there exists a unique"
    \item \textbf{Rules of negating}: We have the following rules for negating statements
        \begin{itemize}
            \item $\neg\land = \lor $ 
            \item $\neg\lor = \land $
            \item $\neg\forall = \exists $ 
            \item $\neg\exists = \forall $ 
        \end{itemize}
        Consider the statement, $R: $ for every real number $x$, there is some real number $y$ such that $y^{3} = x $. Symbolically, we have
        \begin{align*}
            \forall\ x\in \mathbb{R},\ \exists \ y\in \mathbb{R} \text{ such that } y^{3} = x
        .\end{align*}
        Then,
        \begin{align*}
            \neg(\forall\ x\in \mathbb{R},\ \exists \ y\in \mathbb{R} \text{ such that } y^{3} = x)
        .\end{align*}
        Is equivalent to the statement
        \begin{align*}
            \exists \ x\in \mathbb{R}, \text{ such that } \forall \ y\in \mathbb{R},\ y^{3} \ne x
        .\end{align*}
    \item \textbf{Negations with implications}: First, recall the truth table for $P\implies Q$
        \begin{center}
            \begin{tabular}{c|c|c}
                $P$& $Q$ & $P\implies Q $ \\
                \hline
                True  & True & True \\
                True & False & False \\
                False & True & True \\
                False & False & True
            \end{tabular}
        \end{center}
        \bigbreak \noindent 
        The only way for $P \implies Q$ to be false is for both $P$ to be true and for $Q$ to be false. This shows that
        \begin{align*}
            \neg(P \implies Q) \Leftrightarrow P \land \neg Q
        .\end{align*}
        Consider the statement
        \begin{align*}
            S:\ \forall \ n \in \mathbb{N}, (3\mid n) \implies (6\mid n)
        .\end{align*}
        Then,
        \begin{align*}
            \neg S:\ &\neg( \forall \ n \in \mathbb{N}, (3\mid n) \implies (6\mid n)) \\
                     &\eq \exists \ n \in \mathbb{N} \text{ such that } (3\mid n) \land (6\nmid n)
        .\end{align*}
    \item \textbf{The contrapositive (and the inverse)}: The \textit{contrapositive} of $P\implies Q$ is $\neg Q \implies \neg P $
        \bigbreak \noindent 
        \textbf{Note:} The \textit{inverse} of $P \implies Q$ is $\neg P \implies \neg Q $
        \bigbreak \noindent 
        \textbf{Theorem}: An implication is logically equivalent to its contrapositive. That is,
        \begin{align*}
            P \implies Q \eq \neg Q \implies \neg P
        .\end{align*}
        The truth table easily verifys this
    \item \textbf{Proving quantified statements: Existential proofs}: To prove an existence statement, it suffices to exhibit an example satisfying the criteria. The above strategy is called a constructive proof — you literally construct an example. There are also non-constructive ways to prove something exists. Often (but not always!) non-constructive proofs make use of some other theorem. 
    \item \textbf{Proving quantified statements: Universal proofs}: To prove a universal statement, it suffices to choose an arbitrary case and prove it works there. We have seen several examples of this. For example, if you were asked to prove that “For every odd number $n$, it follows that $n + 1$ is even,” your proof wouldn’t explicitly check 1 and 3 and 5 and so on. Rather, you would say “Since $n$ is odd, $n = 2a + 1$ for some $a \in \mathbb{Z}$.” Then you would note that 
        \[
            n + 1 = (2a + 1) + 1 = 2(a + 1)
        \]
        is even. The point here is that by letting $n = 2a + 1$, you were essentially selecting an arbitrary odd number, and operating on that. Every odd number can be written in that form, and every odd number can have 1 added to it and then factored like we did. Since our $n$ was completely arbitrary, everything we did could be applied to any particular odd number. Proving something holds for an arbitrary element of a set, proves that it in turn holds for every element in that set.
    \item \textbf{Proving biconditional statements}: In order to prove a statement in the form $P\implies Q$, we must prove both directions. That is, $P\implies Q$ and $Q\implies P $


    \end{itemize}

    \pagebreak 
    \subsection{Proof using the contrapositive}
    \begin{itemize}
        \item \textbf{Proof outline}:
            \bigbreak \noindent 
            \textbf{Proposition.} $P\implies Q$
            \bigbreak \noindent 
            \textbf{\textit{Proof}}. We will use the contrapositive. Assume not-$Q$
            \penv{
                $\left\langle \left\langle \text{ An explanation of what not-$Q$ means } \right\rangle \right\rangle $, use definitions, and/or other results
                \begin{align*}
                    &\vdots  \quad \text{ Apply algebra,}\\
                    &\vdots  \quad \text{ logic, techniques}
                .\end{align*}
                $\left\langle \left\langle \text{ Hey look, that's what not-$P$  means } \right\rangle \right\rangle $
                \bigbreak \noindent 
                Therefore not-$P$
            }
            Since not-$Q \implies $ not-$P$, by the contrapositive $P\implies Q $ \hspace{2.5cm} $\blacksquare $
        \item \textbf{Contrapositive proof 1.}
            \bigbreak \noindent 
            \textbf{Proposition}. Suppose $n\in \mathbb{N}$, if $n^{2}$ is odd, then $n$ is odd.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We will use the contrapositive. The statement, $\forall \ n \in \mathbb{N},\ n^{2} = 2k+1 \implies n = 2\ell + 1,\ k,\ell \in \mathbb{Z}$ has the logically equivalent contrapositive $\forall n \in \mathbb{N},\ n \ne 2\ell + 1 \implies n^{2}\ne 2k+1$. Since $n\in \mathbb{N}$, if $n, n^{2}$  is not odd, then it must be even. Thus, the statement becomes $\forall n \in \mathbb{N},\ n = 2\ell \implies n^{2} = 2k,\ k,\ell \in \mathbb{N}$ which becomes much easier to proof. For some extra practice negating statements, here is the negation
            \begin{align*}
                \neg(&\forall n \in \mathbb{N},\ n^{2} = 2k+1 \implies n  = 2\ell  + 1,\ k,\ell \in \mathbb{N}) \\
                =\ &\exists n \in \mathbb{N} \text{ such that } n^{2}= 2k+1 \land n \ne 2\ell + 1
            .\end{align*}
            Recall $\neg(P\implies Q) = P \land \neg Q $
            \bigbreak \noindent 
            Assume $n\in \mathbb{N}$, and that $n$ is even. Since $n$ is even, it must be that $n = 2\ell$, for some integer $\ell$. Squaring both sides, we get
            \begin{align*}
                n^{2} &= (2\ell)^{2} \\
                      &=4\ell^{2} =2(2\ell^{2})
            .\end{align*}
            Since $\ell \in \mathbb{Z}$, we know $2\ell^{2} \in \mathbb{Z} $, and thus $n^{2}$ is even.
            \bigbreak \noindent 
            Therefore, since $n$ not being odd implies $n^{2}$ is also not odd, we have shown by the contrapositive that if $n^{2}$ is odd, $n$ is also odd $\quad \blacksquare $
        \item \textbf{Contrapositive proof 2.} 
            \bigbreak \noindent 
            \textbf{Proposition}. Suppose $n \in N$. Then, $n$ is odd if and only if $3n + 5$ is even
            \pagebreak \bigbreak \noindent 
            \textbf{\textit{Proof.}} We will prove this in two parts
            \penv{
                \underline{Part 1: If $n$ is odd then $3n+5$ is even}. Assume $n\in \mathbb{N}$ is odd, then $n = 2k+1$, for $k\in \mathbb{N}_{0}$. Thus,
                \begin{align*}
                    3n+5 &= 3(2k+1) + 5 \\
                         &= 6k + 3 + 5 = 6k + 8\\
                         &= 2(3k+4)
                     .\end{align*}
                     Thus even.
                     \bigbreak \noindent 
                     \underline{Part 2: $3n+5$ being even implies $n$ is odd}. We prove this by use of the contrapositive. The given statement has the following contrapositive...
                     \begin{align*}
                         n = 2k \implies 3n+5 = 2\ell + 1,\ k,\ell \in \mathbb{N}_{0}
                     .\end{align*}
                     Thus,
                     \begin{align*}
                         3n+5 &= 3(2k) + 5 \\
                              &= 6k+5 = 6k + 4 + 1 \\
                              &= 2(3k+2) + 1
                    .\end{align*}
                    Thus odd.
                    \bigbreak \noindent 
            }
            Since $P \implies Q$, and $Q\implies P$, it must be that $P \iff Q$ is true. Thus, we assert for $n\in \mathbb{N}$, $n$ is odd if and only if $3n+5$ is even.
        \item \textbf{Contrapositive proof 3.}:
            \bigbreak \noindent 
            \textbf{Proposition}. Let $a,b\in \mathbb{Z}$, and $p \in \mathbb{P}$. If $p\nmid ab$, then $p\nmid a$ and $p\nmid b $
            \textbf{Proof.} Suppose $a, b \in \mathbb{Z}$ and $p$ is a prime. We will use the contrapositive. Suppose that it is not true that $p \nmid a$ and $p \nmid b$. By the logic form of De Morgan’s law (Theorem 5.9), this is equivalent to saying it is not true that $p \nmid a$ \textit{or} it is not true that $p \nmid b$. That is, $p \mid a$ \textit{or} $p \mid b$. Let’s consider these two cases separately.
            \penv{
                \textbf{Case 1.} Suppose $p \mid a$, which by the definition of divisibility (Definition 2.8) means that $a = pk$ for some $k \in \mathbb{Z}$. Thus,
                \[
                    ab = (pk)b = p(kb).
                \]
                Since $k, b \in \mathbb{Z}$, also $(kb) \in \mathbb{Z}$. And so, by the definition of divisibility (Definition 2.8), $p \mid ab$.
                \bigbreak \noindent 
                \textbf{Case 2.} Suppose $p \mid b$, which by the definition of divisibility (Definition 2.8) means that $b = p\ell$ for some $\ell \in \mathbb{Z}$. Thus,
                \[
                    ab = a(p\ell) = b(a\ell).
                \]
                Since $a, \ell \in \mathbb{Z}$, also $(a\ell) \in \mathbb{Z}$. And so, by the definition of divisibility (Definition 2.8), $p \mid ab$.
                \bigbreak \noindent 
                In either case, we concluded that $p \mid ab$, which is equivalent to saying that it is not true that $p \nmid ab$.
                \bigbreak \noindent 

            }
            We proved that if it is not true that $p \nmid a$ and $p \nmid b$, then it is not true that $p \nmid ab$. Hence, by the contrapositive, this implies that if $p \mid ab$, then $p \mid a$ and $p \mid b$. \(\square\)
            \bigbreak \noindent 
            \textbf{Note:} Mathematicians have agreed that we should be allowed to skip essentially-identical cases
            \bigbreak \noindent 
            If you have two cases, like $p \mid a$ and $p \mid b$, and there is literally no mathematical distinction between them, then you are allowed to say “without loss of generality, assume $p \mid a$.” This allows you to skip the “$p \mid b$” case entirely.
            \bigbreak \noindent 
            \textbf{Condensed, Elder-Approved Proof.} Suppose $a, b \in \mathbb{Z}$ and $p$ is a prime. We will use the contrapositive. Suppose that it is not true that $p \nmid a$ and $p \nmid b$. By the logic form of De Morgan’s law (Theorem 5.9), this is equivalent to saying it is not true that $p \nmid a$ \textit{or} it is not true that $p \nmid b$. That is, $p \mid a$ \textit{or} $p \mid b$. Without loss of generality, assume $p \mid a$.
            \bigbreak \noindent 
            By the definition of divisibility (Definition 2.8), this means that $a = pk$ for some $k \in \mathbb{Z}$. Thus,
            \[
                ab = (pk)b = p(kb).
            \]
            Since $k, b \in \mathbb{Z}$, also $(kb) \in \mathbb{Z}$. And so, by the definition of divisibility (Definition 2.8), $p \mid ab$.
            \bigbreak \noindent 
            We proved that if it is not true that $p \nmid a$ and $p \nmid b$, then it is not true that $p \nmid ab$. Hence, by the contrapositive, this implies that if $p \mid ab$, then $p \mid a$ and $p \mid b$. \(\square\)
        \item \textbf{Contrapositive proof 4.}
            \bigbreak \noindent 
            \textbf{Proposition}. Let $a,b,n \in \mathbb{N}$. If $36a \not\equiv 36b \pmod{n} $, then $n\nmid 36 $
            \bigbreak \noindent 
            \textbf{Proof idea}. The fact that this proposition says a lot of things are not happening is one indication that the contrapositive could be worthwhile. The contrapositive states For $a,b,n\in \mathbb{N}$,  If $ n\mid 36$, then $36a\equiv 36b \pmod{n}$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $a,b,n\in \mathbb{N}$, and $n\mid36$. In this case, we have $36 = nk$, for $k\in \mathbb{Z}$. We require $36a-36b = n\ell$, for $\ell \in \mathbb{Z}$. We then examine the quantity $36a-36b$. Since $36 = nk$, we have
            \begin{align*}
                36a - 36b &= nka - nkb \\
                          &=n(ka-kb)
            .\end{align*}
            Which is precisely the definition of divisibility, since it is clear that $ka-kb \in \mathbb{Z}$. Thus, we have $n \mid 36a -36b $, and by the definition of modular congruence $36a  \equiv 36b \pmod{n}$.
            \bigbreak \noindent 
            Therefore, by the contrapositive, $36a \not\equiv 36b \pmod{n}$ implies that $n\nmid 36 \quad \blacksquare $
        \item \textbf{Lemma 6.6} This lemma has two parts
            \begin{enumerate}[label=(\roman*)]
                \item If $m\in\mathbb{Z} $, then $m^{2}  + m $ is even 
                \item If $a\in \mathbb{Z}$, and $a^{2}$ is even, then $a$ is even
            \end{enumerate}
            This proof is trivial and will not be shown. Proving $i$ is simply a proof by cases. To prove $ii$, we can use the contrapositive, instead proving that if $a$ is odd, then $a^{2}$ is odd. Which, by the contrapositive shows that if $a^{2}$ is even, then $a$ must also be even.
        \item \textbf{Contrapositive proof 5.} 
            \bigbreak \noindent 
            \textbf{Proposition}. If $a$ is an odd integer, then $x^{2} + x - a^{2}=  0$ has no integer solution.
            \bigbreak \noindent 
            \textbf{Proof idea.} We will use the contrapositive, which states if $x^{2} + x - a^{2} = 0$ has an integer solution, then $a$ is even.
            \bigbreak \noindent 
            \textbf{Note:} Negating $Q$ in this case ($x^{2} + x - a^{2} = 0 $ has no integer solution) does not given $x^{2} +x - a^{2} \ne 0 $... It is important to question what it means for the given statement to be false in order to properly negate. The negation of the statement is "it is false that $x^{2} + x  -a^{2} = 0 $ has no integer solutions", which must mean that some integer $m$ exists such that $m^{2} + m -a^{2} = 0$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose that \(a\) is an odd integer. We will use the contrapositive. Assume that it is false that \(x^2 + x - a^2 = 0\) has no integer solutions; that is, assume that there is some integer \(m\) such that
            \begin{align*}
                m^2 + m - a^2 = 0
            .\end{align*}
            By the quadratic formula\(^9\) and then some algebra,
            \begin{align*}
                m &= \frac{-1 \pm \sqrt{1^2 - 4(1)(-a^2)}}{2(1)} \\
                m &= \frac{-1 \pm \sqrt{1 + 4a^2}}{2} \\
                2m &= -1 \pm \sqrt{1 + 4a^2} \\
                2m + 1 &= \pm \sqrt{1 + 4a^2} \\
                4m^2 + 4m + 1 &= 1 + 4a^2 \\
                m^2 + m &= a^2.
            .\end{align*}
            Next, observe that \(m^2 + m\) is guaranteed to be even, by Lemma 6.6 part (i). Thus, since we just deduced that \(m^2 + m = a^2\), this means that \(a^2\) must be even. And since \(a\) is an integer, \(a^2\) being even implies that \(a\) is even, by Lemma 6.6 part (ii). In particular, this means that \(a\) is not odd.

            We have shown that if it is false that \(x^2 + x - a^2 = 0\) has no integer solutions, then it is also false that \(a\) is an odd integer. By the contrapositive, if \(a\) is an odd integer, then \(x^2 + x - a^2 = 0\) has no integer solution. \(\Box\)







    \end{itemize}

    \pagebreak 
    \subsection{Contradiction}
    \begin{itemize}
        \item \textbf{The idea}: The big idea is this: If you start with something true and apply correct logic to it, you will never arrive at something false. So it can’t be true that Carmen stole the bag, if that would imply the falsity that she can be in two places at once. Indeed, if your assumptions imply something false, then something you assumed had to be false as well.
            \bigbreak \noindent 
            Suppose we had a theorem $P \implies Q$. Throughout the problem, we assume $P$ to be true. The goal is to show that $Q$ is also true. By the truth tables, either $Q$ is true or $\neg Q$ is true, not both. This gives two options.
            \begin{enumerate}
                \item $P$ is true and $Q$ is true $(P \land Q) $
                \item $P$ is true and $\neg Q$ is true $(P \land \neg Q) $
            \end{enumerate}
            If $P \land \neg Q $ implies anything false, that can't be the correct option. That is, it must be $P \land Q$. Thus, we have shown $P\implies Q $
            \bigbreak \noindent 
            Notice that the only way that \(P \implies Q\) can be false is if \(P\) is true and \(Q\) is false.
            \bigbreak \noindent 
            \begin{center}
                \begin{tabular}{c|c|c}
                    $P$ &$Q$ &$P \implies  Q$ \\
                    \hline
                    True &True &True \\
                    True &False &False \\
                    False &True &True \\
                    False &False &True
                \end{tabular}
            \end{center}
            Thus, this is the only case we have to rule out in order to prove our theorem: that \(P \implies Q\) is true. So, if you assume that \(P\) is true and \(Q\) is false, and manage to use that to deduce a contradiction, then you will have ruled out the one and only bad case, which in turn means that the theorem must be true!
            \bigbreak \noindent 
            In other words, if $P \land \neg Q$ cannot be, then it must be that $P \implies Q$
        \item \textbf{Contradiction example 1.} 
            \bigbreak \noindent 
            \textbf{Proposition.} There does not exist a largest natural number
            \bigbreak \noindent 
            \textbf{Proof Idea.} One quick note: This proposition is not phrased explicitly as 
            ``\(P \implies Q\),'' but you are probably starting to see how to rephrase propositions 
            in this form. For example, this proposition could instead be stated as: 
            ``If \(N\) is the set of natural numbers, then \(N\) does not have a largest element.'' 
            Or, equivalently: ``If \(N\) is larger than every natural number, then \(N \notin \mathbb{N}\)'' 
            Or, equivalently: ``If \(N\) is a natural number, then there exists a natural number 
            larger than \(N\).''
            \bigbreak \noindent 
            For our proof by contradiction, we will assume that there \emph{is} a largest natural number, 
            and then deduce a contradiction. There are several ways to do this, but one way is to assume 
            that \(N\) is the largest and then show that \(N + 1\) must be larger—if it weren’t, we could 
            deduce that \(0 \geq 1\), which is clearly a contradiction. Here’s that:
            \bigbreak \noindent 
            \textbf{Proof.} Assume for a contradiction that there is a largest element of \(\mathbb{N}\), and call this number \(N\). Being larger than every other natural number, \(N\) has the property that \(N \geq m\) for all \(m \in \mathbb{N}\).
            \bigbreak \noindent 
            Observe that since \(N \in \mathbb{N}\), also \((N + 1) \in \mathbb{N}\). And so, by assumption,
            \[
                N \geq N + 1.
            \]
            Subtracting \(N\) from both sides,
            \[
                0 \geq 1.
            \]
            This is a contradiction\(^1\) since we know that \(0 < 1\), and therefore there must not be a largest element of \(\mathbb{N}\). \(\Box\)

        \item \textbf{Contradiction example 2.}
            \bigbreak \noindent 
            \textbf{Proposition}. There does not exist a smallest positive rational number.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume for the sake of contradiction that there does exist a smallest positive rational number. Call this number $q$. Since $q\in \mathbb{Q}$, we have
            \begin{align*}
                q = \frac{a}{b}
            .\end{align*}
            Where $a,b \in \mathbb{Z}$, and $a,b > 0$. Since $q$ is the smallest, than for all $r \in \mathbb{Q}$, we have $q \leq r$. Let $r = \frac{a}{2b} $. Then,
            \begin{align*}
                \frac{a}{b} &\leq \frac{a}{2b} \\
                \implies 2ab &\leq ab \\
                \implies 2 &\leq 1
            .\end{align*}
            This is a contradiction, since we know $2 > 1$. It must be that there is no smallest positive rational number.
        \item \textbf{Proof by contradiction general form}: 
            \bigbreak \noindent 
            \textbf{Proposition.} $P\implies Q$
            \bigbreak \noindent 
            \textbf{Proof.} Assume for the sake of contradiction $P$ and $\neg Q$
            \penv{
                $\left\langle \left\langle \text{ An explanation of what these mean } \right\rangle \right\rangle $
                \begin{align*}
                    &\vdots \quad \text{ Apply algebra,} \\
                    &\vdots \quad \text{ logic, techniques} 
                .\end{align*}
                $\left\langle \left\langle \text{ Hey look, that contradicts something we know to be true } \right\rangle \right\rangle $
            }
            We obtained a contradiction, therefore $P\implies Q \quad \blacksquare$
        \item \textbf{Proof by contradiction example 3.}
            \bigbreak \noindent 
            \textbf{Proposition.} If $A,B$ are sets, then $A \cap (B \setminus A) = \varnothing $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume for the sake of contradiction, that $A \cap (B\setminus A) \ne \varnothing $
            \penv{
                Since $A\cap (B \setminus A) \ne \varnothing$, then $\exists x \in A \cap (B \setminus A) $. Thus, $x\in A \ \land \ x\in (B\setminus A) $. Rewrite $B\setminus A$ as $B \cap A^{C}$. Thus, $x\in B \ \land \ x\in A^{C}$. Since $x\in A^{C}$, it must be that $x \not\in A$. Thus, we have $x\in A$, $x\in B$, and $x\not\in A $
            }
            Therefore, since $x \in A $ and $x \not\in A$ is a contradiction, it must be that if $A$, and $B$ are sets, then $A \cap (B \setminus A) = \varnothing $ $\quad \blacksquare $.
        \item \textbf{Proof by contradiction example 4.}
            \bigbreak \noindent 
            \textbf{Proposition.} There does not exists integers $m,n$ such that $15m + 35n = 1 $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume for the sake of contradiction there does exist integers $m,n $ such that $15m + 35n = 1$, since $m,n \in \mathbb{Z}$, $3m + 7n \in \mathbb{Z} $, but
            \begin{align*}
                15m + 35n &=  1\\
                \implies 3m + 7n &= \frac{1}{5}
            .\end{align*}
            Since $3m+7n \not\in \mathbb{Z} $, we have a contradiction. Thus, it must be that there does not exist integers $m,n$ such that $15m + 35n = 1$.
            \bigbreak \noindent 
            Alternatively, we could have done
            \begin{align*}
                15m + 35n &= 1 \\
                \implies 5(3m + 7n) &= 1
            .\end{align*}
            Which implies $5\mid 1$. But it is clearly the case that $5\nmid 1$, since there exists no $k\in \mathbb{Z}$ such that $1 = 5k$. Thus, another way to arrive at a contradiction. $\quad \blacksquare $
        \item \textbf{Proof by contradiction example 5.}
            \bigbreak \noindent 
            \textbf{Proposition.} There are infinitely many primes.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose for the sake of contradiction that there are finitely many primes, say $k$ in total. Let $p_{1}, p_{2},p_{3},...,p_{k}$ be the complete list. Consider the number $N = p_{1} \cdot p_{2} \cdot p_{3} \cdot ...\cdot p_{k}$. Next, consider $N + 1 $. That is, $p_{1}p_{2}p_{3}...p_{k} + 1$. Either $N + 1 $ is prime or it is composite, we consider both cases separately
            \bigbreak \noindent 
            \underline{Case 1: $N+1$ is prime.} In this case, $N+1$ is prime and greater than all the $p_{i}$s we have previously considered. Thus, we have found a new prime.
            \bigbreak \noindent 
            \underline{Case 2: $N+1$ is composite}. We begin by showing that no such $p_{i}$ divides $N+ 1$. Because we know that $p_{i} \mid N$, we have
            \begin{align*}
                N \equiv 0 \pmod{p_{i}}
            .\end{align*}
            Adding one to both sides, we get
            \begin{align*}
                N+1 \equiv 1 \pmod{p_{i}}
            .\end{align*}
            Hence, it must be that $p_{i}\nmid N+1$. Since $p_{i}$ was arbitrary, this shows that none of our $k$ primes divide $N+1 $
            \bigbreak \noindent 
            We assumed that \( p_1, p_2, \ldots, p_k \) was the complete list of prime numbers. 
            And recall that \( N + 1 \) is assumed to be composite, which means it is a product of primes. 
            But since none of the \( p_i \) divide \( N + 1 \), there must be some other prime number, \( q \),
            which divides \( N + 1 \). And hence, we have again found a new prime.
            \bigbreak \noindent 
            In either case, we have contradicted the claim that \( p_1, p_2, \ldots, p_k \) was an exhaustive
            list of the prime numbers. Therefore, there must be infinitely many primes. $\quad \blacksquare $
        \item \textbf{Proof by contradiction example 6.}
            \bigbreak \noindent 
            \textbf{Proposition} The number $\sqrt{2}$ is irrational
            \bigbreak \noindent 
            \textbf{Proof.} Assume for a contradiction that $\sqrt{2}$ is rational. Then there must be some non-zero integers $p$ and $q$ where
            \[
                \sqrt{2} = \frac{p}{q}.
            \]
            Moreover, we may assume that this fraction is written in \textit{lowest terms}, meaning that $p$ and $q$ have no common divisors. Then,
            \[
                \sqrt{2}q = p.
            \]
            By squaring both sides,
            \[
                2q^2 = p^2.
            \]
            Since $q^2 \in \mathbb{Z}$, by the definition of divisibility, this implies that $2 \mid p^2$, and hence $2 \mid p$ by Lemma 2.17 part (iii). By a second application of the definition of divisibility, this means that $p = 2k$ for some non-zero integer $k$. Plugging this in:
            \begin{align*}
                2q^2 &= p^2,\\
                2q^2 &= (2k)^2,\\
                2q^2 &= 4k^2,\\
                q^2 &= 2k^2
            \end{align*}
            Therefore, $2 \mid q^2$, and hence $2 \mid q$, again by Lemma 2.17 part (iii). But this is a contradiction: We had assumed that $p$ and $q$ had no common factors, and yet we proved that $2$ divides each. Therefore, $\sqrt{2}$ cannot be rational, meaning it is irrational.
            \bigbreak \noindent 
            The following is a geometric proof that $\sqrt{2} \in \bar{\mathbb{Q}}$. Recall that $\bar{\mathbf{Q}}$ is the set of irrational numbers.
            \bigbreak \noindent 
            Assume for a contradiction that $\sqrt{2} = \frac{p}{q}$ where $p, q \in \mathbb{N}$ and the fraction is written in lowest terms. This implies that 
            \[
                2q^2 = p^2,
            \]
            but this time let’s think about this as 
            \[
                p^2 = 2q^2.
            \]
            Or, better yet,
            \[
                p^2 = q^2 + q^2.
            \]
            Since $p$ and $q$ are integers, $p^2$ represents the area of a square with side length $p$, and each $q^2$ represents the area of a square with side length $q$.
            \bigbreak \noindent 
            \fig{.6}{./figures/15.png}
            \bigbreak \noindent 
            Recall that $\sqrt{2} = \frac{p}{q}$ was written in lowest terms. In particular, this means that there do not exist any smaller integers $a$ and $b$ for which $\sqrt{2} = \frac{a}{b}$. Our contradiction will be to find such $a$ and $b$.
            \bigbreak \noindent 
            Getting back to the squares above, we are now going to imagine each square is a piece of paper and we are going to place the two $q^{2}$ squares on top of the $p^{2}$ square. If one $q^{2}$ square is placed in the lower-left, and the other is placed in the upper-right, this happens
            \bigbreak \noindent 
            \fig{.6}{./figures/17.png}
            \bigbreak \noindent 
            Notice that there is one square region in the middle that was covered twice, and two small squares in the upper-left and lower-right that were not covered at all. And remember: The amount of area in the $p^2$ square is equal to the amount of area in the two $q^2$ squares. Therefore, the area that was covered twice must equal the area that was not covered at all! Let’s suppose the middle square has dimensions $a \times a$, and the two corner squares have dimensions $b \times b$. Then, this reasoning shows that
            \bigbreak \noindent 
            \fig{.8}{./figures/18.png}
            \bigbreak \noindent 
            And those $a$ and $b$ must also be integers, since they are the difference of integers from the overlap picture:
            \bigbreak \noindent 
            \fig{.8}{./figures/19.png}
            \bigbreak \noindent 
            We had assumed that $p$ and $q$ were the smallest integers for which $\sqrt{2} = \frac{p}{q}$, and yet the above image shows that $a$ and $b$ are also integers, and since $a^2 = b^2 + b^2$, which implies $2b^2 = a^2$, we have $2 = \frac{a^2}{b^2}$. And so, finally, by taking the square root of each side, we see that
            \[
                \sqrt{2} = \frac{a}{b}.
            \]
            We have shown that $a$ and $b$ are integers with the above property. The picture above also shows that $a$ is smaller than $p$, and $b$ is smaller than $q$. Combined, this contradicts our assumption that $p$ and $q$ are the smallest integers where $\sqrt{2} = \frac{p}{q}$.
        \item \textbf{The irrational numbers}:
            The fact that irrational numbers exist explains why we need the real numbers $\mathbb{R}$—the rational numbers $\mathbb{Q}$ are clearly not enough! Next, note that while $\sqrt{2}$ is not a ratio of integers, it is a root of $x^2 - 2 = 0$, which is a polynomial with integer coefficients.
            \bigbreak \noindent 
            \textbf{Big Question:} Is every irrational number a root of a polynomial with integer coefficients? 
            \bigbreak \noindent 
            \textbf{Big Answer:} Nope! In 1844, Joseph Liouville proved that
            \[
                \sum_{k=1}^\infty \frac{1}{10^{k!}} = 0.11000100000000000000000100\ldots
            \]
            is not the root of any polynomial with integer coefficients.
            \bigbreak \noindent 
            The irrational numbers were thus partitioned into \textit{algebraic numbers}, which are the roots of such polynomials, and \textit{transcendental numbers}, which are not. Today, $\pi$ and $e$ are the most famous numbers which have been proved to be transcendental.
        \item \textbf{Proof of the halting problem}:
            \bigbreak \noindent 
            \textbf{Theorem}. Assume that $P$ is an arbitrary program and $i$ is a possible input of $P$; we write $P(i)$ to be the result of plugging input $i$ into the program $P$. There does not exist a program $H(P(i))$ which determines whether $P(i)$ will eventually halt.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume for a contradiction that such a program $H$ did exist. Create a new program $T(x)$; its input, $x$, is itself a program with some input. Now, we define the program $T(x)$ as follows:
            \bigbreak \noindent 
            \begin{cppcode}
            Input: A program |$x$|, with its own input
            Run |$H(x)$|
            if |$H(x)$| answers |\textit{Program $x$ will halt} \textbf{then}|
                begin an infinite loop
            else halt
            \end{cppcode}
            \bigbreak \noindent 
            The program $T$ is designed to run counter to $x$: If the input program $x $ was going to halt, then $T$ begins an infinite loop. And if the input program was going to run forever, then $T$ says to halt
            \bigbreak \noindent 
            The program $T$ accepts as input any program. And since $T$ is itself a program, we are allowed to \textit{plug $T$ into itself!} What is the result? Well, since $T(T)$ is a program, like any program either $T(T)$ contains an infinite loop or it does not. Let’s consider each of these two cases.
            \bigbreak \noindent 
            \underline{Case 1:} Observe that if $T(T)$ has an infinite loop, then like all programs with infinite loops, it will not halt — but by looking at the above pseudocode for $T$, it is clear that if $T(T)$ has an infinite loop, then it will halt! This is a contradiction.
            \bigbreak \noindent 
            \underline{Case 2:} Conversely, if $T(T)$ does not have an infinite loop, then like all programs without an infinite loop it must eventually halt — but by looking at the above pseudocode for $T$, it is clear that if $T(T)$ will eventually halt, then it will begin an infinite loop which will prevent it from halting! This is again a contradiction.
            \bigbreak \noindent 
            Whether $T$ does or does not have an infinite loop, we have reached a contradiction. And since $T$ was built from $H $, our assumption that there exists a halting program $H$ must have been incorrect. This concludes the proof. $\quad \blacksquare $
        \item \textbf{Proof by contradiction example 7}:
            \bigbreak \noindent 
            \textbf{Proposition.} Every natural number is interesting
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume for a contradiction that not every natural number is interesting. Then, there must be a smallest uninteresting number, which we call $n$. But being the smallest uninteresting number is a very interesting property for a number to have! So $n$ is both uninteresting and interesting, which gives the contradiction. Therefore, every natural number must be interesting. $\quad \blacksquare $
        \item \textbf{Proof by minimal counterexample}: We proved that every natural number is interesting. The way we did this was by assuming for a contradiction that not every number is interesting. Under this assumption, there exist uninteresting natural numbers, and so there must exist a smallest uninteresting natural number.
            \bigbreak \noindent 
            Despite it being a silly example, there is an important idea behind it which is sometimes called \textit{proof by minimal counterexample}. Consider a theorem which asserts something is true for every natural number, and you are attempting to prove it by contradiction. Then you would assume for a contradiction not every natural number satisfies the result — that is, you’re assuming there is at least one counterexample. Well, among all of the counterexamples, one of them must be the smallest. And thinking about that smallest counterexample — such as the smallest uninteresting number — can at times be a powerful variant of proof by contradiction.
            \bigbreak \noindent 
            We used strong induction to prove the fundamental theorem of arithmetic. But there’s another slick proof of this theorem that uses a proof by minimal counterexample
            \bigbreak \noindent 
            \textbf{Theorem (\textit{Fundemental theorem of arithmetic})}. Every integer $n \geq 2 $ is either prime or a product of primes.
            \bigbreak \noindent 
            Recall that every integer $n \geq 2$ is either prime or composite, and being composite means it is a product of smaller integers
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} 
            Assume for a contradiction that this is not true. Then there must be a minimal counterexample; let’s say $N$ is the smallest natural number at least 2 which is neither prime nor the product of primes. The fact that it is not prime means that it is composite: $N = ab$ for some $a, b \in \{2, 3, \ldots, N - 1\}$.
            \bigbreak \noindent 
            We now make use of the fact that $N$ is assumed to be the minimal counterexample to this result — which means that everything smaller than $N$ must satisfy the result. In particular, since $a$ and $b$ are smaller than this smallest counterexample, $a$ and $b$ must each be prime or a product of primes.
            \bigbreak \noindent 
            And this gives us a contradiction: Since $N = ab$, if $a$ and $b$ are each prime or a product of primes, then their product — which equals $N$ — must be as well. This contradicts our assumption that $N$ was a counterexample, completing the proof.
            \bigbreak \noindent 
            Another way to think about this proof is that it argues that if $N$ were a counterexample, then since $N = ab$, it can’t possibly be that both $a$ and $b$ are primes or a product of primes, since as we just saw, that would produce a contradiction. And therefore, it must be the case that either $a$ or $b$ is also a counterexample. This implies that every counterexample produces a smaller counterexample — every $N$ produces an $a$ or a $b$. But this is a contradiction, since you can not repeatedly find smaller and smaller natural numbers — at some point you reach the bottom.
        \item \textbf{Proof of the division algorithm}
            \bigbreak \noindent 
            \textbf{Theorem (\textit{The division algorithm})}: For all integers $a$ and $m$ with $m > 0$, there exist unique integers $q$ and $r$ such that
            \[
                a = mq + r,
            \]
            where $0 \leq r < m$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} 
            \textbf{Existence.} First, note that if $a = 0$, then by simply choosing $q = 0$ and $r = 0$, the theorem follows. Thus, we may assume that $a \neq 0$.
            \bigbreak \noindent 
            Next, we will argue that if the theorem holds for all positive $a$, then it also holds for all negative $a$. Indeed, assume that $a > 0$, and suppose $a$ and $m$ can be expressed as
            \[
                a = mq + r,
            \]
            where $0 \leq r < m$. Then, $-a$ has an expression as well. In particular, if we let $q' = -q - 1$ and $r' = m - r$, then
            \[
                mq' + r' = m(-q - 1) + (m - r) = -mq - m + m - r = -(mq + r) = -a.
            \]
            Therefore, for these integers $q'$ and $r'$,
            \[
                -a = mq' + r',
            \]
            where $0 \leq r' < m$. Because of this, any expression for $a > 0$ immediately produces one for $-a$. Thus, we need only prove the case where $a$ is a positive integer.
            \bigbreak \noindent 
            We will implement a proof by minimal counterexample in order to prove the case where $a$ is positive. Fix any $m > 0$, and assume for a contradiction that not every $a \in \mathbb{N}$ satisfies the theorem, which in turn means that there is a smallest $a$ for which the theorem fails. Consider three cases.
            \bigbreak \noindent 
            \textbf{Case 1:} $a < m$. In this case, we can simply let $q = 0$ and $r = a$, and we have obtained
            \[
                a = m \cdot q + r,
            \]
            with $0 \leq r < m$, and the theorem is satisfied.
            \bigbreak \noindent 
            \textbf{Case 2:} $a = m$. In this case, we can simply let $q = 1$ and $r = 0$, and we have obtained
            \[
                a = m \cdot q + r,
            \]
            with $0 \leq r < m$, and the theorem is satisfied.
            \bigbreak \noindent 
            \textbf{Case 3:} $a > m$. Recall that the theorem assumes that $m > 0$, and so in this case we have $a > m > 0$. In particular, note that $a > a - m$ and also $a - m > 0$.
            \bigbreak \noindent 
            Since $a$ is the smallest positive counterexample to this theorem, and $a - m$ is both positive and less than $a$, the integer $a' = a - m$ must satisfy this theorem! That is, there must exist integers $d$ and $s$ for which
            \[
                (a - m) = m \cdot d + s,
            \]
            with $0 \leq s < m$. By moving the $m$ on the left side over,
            \[
                a = m \cdot d + s + m.
            \]
            By factoring,
            \[
                a = m \cdot (d + 1) + s.
            \]
            Thus, by letting $q = d + 1$ and $r = s$, we have shown that our smallest counterexample is not a counterexample at all:
            \[
                a = m \cdot q + r,
            \]
            with $0 \leq r < m$. Since there cannot exist a smallest counterexample, there cannot exist any counterexample. Thus, for each $a$ and $m$, there must exist a $q$ and $r$ as the theorem asserts.
            \bigbreak \noindent 
            \textbf{Uniqueness.} Assume for a contradiction that for our fixed $a$ and $m$, the $q$ and $r$ are not unique. That is, assume there exist two different representations of $a$:
            \[
                a = mq + r \quad \text{and} \quad a = mq' + r',
            \]
            where $q, r, q', r' \in \mathbb{Z}$ and $0 \leq r, r' < m$. Then,
            \[
                mq + r = mq' + r'.
            \]

            By some algebra, we find:
            \[
                r - r' = mq' - mq,
            \]
            which means
            \[
                r - r' = m(q' - q).
            \]
            \bigbreak \noindent 
            Since $q$ and $q'$ are integers, so is $q - q'$ (by Fact 2.1), which means the above expression matches the definition of divisibility (Definition 2.8)! That is, $m \mid (r - r')$.
            \bigbreak \noindent 
            Notice that since $0 \leq r, r' < m$, the difference $r - r'$ would have these restrictions:
            \[
                -m < r - r' < m.
            \]
            And the only number in this range which is divisible by $m$ is zero. That is, $r - r' = 0$, or $r = r'$.
            \bigbreak \noindent 
            Next, since $r = r'$, the fact that $r - r' = m(q - q')$ implies that
            \[
                0 = m(q - q').
            \]
            Since $m > 0$, we may divide both sides by $m$, which means $0 = q - q'$, or $q = q'$.
            \bigbreak \noindent 
            We assumed that
            \[
                a = mq + r \quad \text{and} \quad a = mq' + r'
            \]
            were two different representations of $a$ and $m$, but we have proven that $q = q'$ and $r = r'$, proving that they are in fact the same representation, giving the contradiction and concluding the proof.


    \end{itemize}

    \pagebreak 
    \subsection{Functions}
    \begin{itemize}
        \item \textbf{The definition of a function}: Given a pair of sets \( A \) and \( B \), suppose that each element \( x \in A \)
            is associated, in some way, to a unique element of \( B \), which we denote \( f(x) \). Then
            \( f \) is said to be a function from \( A \) to \( B \). This is often denoted
            \( f : A \to B \).
            \bigbreak \noindent 
            Furthermore, \( A \) is called the \textbf{domain} of \( f \), and \( B \) is called the \textbf{codomain} of \( f \).
            \bigbreak \noindent 
            The set \( \{f(x) : x \in A\} \) is called the \textbf{range} of \( f \).
        \item \textbf{The \textit{Existence}, and \textit{uniqueness} property of functions}: When discussing functions, the ideas of existence and uniqueness will come up repeatedly. We defined a function \( f : A \to B \) to be a rule which sends each \( x \in A \) to some \( f(x) \in B \). What this means is that \( f(x) \) must exist (it must be equal to some \( b \in B \)), and it must be unique (it must be equal to only one \( b \in B \)).
            \bigbreak \noindent 
            For example, defining $f: \mathbb{R} \to \mathbb{R}$, $f(x) = \ln{(x)}$ fails the \textit{existence} requirement of functions, because the natural logarithm function $\ln{(x)}$ is not defined for negative values of $x$ or $x=0 $. his means that the function $\ln(x)$ would fail the requirement of existence for all elements in the domain $\mathbb{R}$.
            \bigbreak \noindent 
            To make $f(x) = \ln(x) $ a valid function, we must adjust the domain to only include values for which $\ln(x)$ is defined. The correct domain is $(0,\infty)$, the set of positive real numbers. Thus, we would write
            \begin{align*}
                f: (0, \infty) \to \mathbb{R}
            .\end{align*}
            A "function" that fails the uniqueness requirement of functions would assign a single element in the domain to more than one element in the codomain.
            \bigbreak \noindent 
            Consider a rule $f: A \to B $ defined as 
            \begin{align*}
                f(x) = \begin{cases}
                    b_{1} & \text{ if } x= a \\     
                    b_{2} & \text{ if } x= a 
                \end{cases}
            .\end{align*}
            Where $b_{1} \ne b_{2}$, and $a\in A $. This rule clearly violates the \textit{uniqueness} criterion, and is therefore not a function.
            \bigbreak \noindent 
            In high school you were probably taught the \textit{vertical line test} to check whether a graph corresponds to a function. The vertical line test says that if every vertical line hits the graph in one (existence) and only one (uniqueness) spot, then the graph corresponds to a function
        \item \textbf{Injections, Surjections and Bijections}: A function $f : A \to B$ is injective (or one-to-one) if $f(a_{1}) = f(a_{2})$ implies that $a_{1} = a_{2}$.
            \bigbreak \noindent 
            The contrapositive of the second half states, A function $f: A \to B$ is \textit{injective} if $a_{1} \ne a_{2}$ implies that $f(a_{1}) \ne f(a_{2}) $
            \bigbreak \noindent 
            A function $f:\  A \to B$ is surjective (or onto) if, for every $b \in B$, there exists some $a \in A$ such that $f(a) = b$
            \bigbreak \noindent 
            Let’s take a look at another way to define this same idea, by again applying the contrapositive (and doing a little rearranging).
            \bigbreak \noindent 
            A function $f:\ A \to B$ is surjective (or onto) if there does not exist any $b \in B$ for which $f(a) \ne b$ for all $a \in A$.
            \bigbreak \noindent 
            When defining a function \( f : A \to B \), the ideas of existence and uniqueness were focused on \( A \) — for every \( x \in A \), we demanded that \( f(x) \) exist and be unique. To be injective and surjective, the attention shifts to \( B \). To be surjective means that \( B \) has an existence criterion (for every \( b \in B \), there exists some \( a \in A \) that maps to it). And to be injective means that \( B \) has a uniqueness-type criterion (for every \( b \in B \), there is at most one \( a \in A \) that maps to it).
            \bigbreak \noindent 
            A function $f:\  A \to B$ is \textit{bijective} if it is both injective and surjective.
            \bigbreak \noindent 
            Defining a function \( f : A \to B \) placed existence and uniqueness criteria on \( A \). If \( f \) is both injective and surjective, then this adds existence and uniqueness criteria to \( B \). Thus, if \( f \) is a bijection, then it has these criteria on both sides: Every \( a \in A \) is mapped to precisely one \( b \in B \), and every \( b \in B \) is mapped to by precisely one \( a \in A \). In effect, this pairs up each element of \( A \) with an element of \( B \); namely, \( a \) is paired with \( f(a) \) in this way.
        \item \textbf{Proving $x$jectiveness for $x\in \{\text{in,sur,bi}\}$}: Based on its definition, this is the outline to prove a function is injective.
            \bigbreak \noindent 
            \begin{mdframed}
                \textbf{Proposition}. $f:\ A \to B$ is an injection
                \bigbreak \noindent 
                \textbf{\textit{Proof.}} Assume $x,y \in A $, and $f(x) = f(y)$
                \begin{align*}
                    &\vdots \quad \text{ Apply algebra}, \\
                     &\vdots \quad \text{ logic, techniques}
                .\end{align*}
                Therefore, $x=y $
                \bigbreak \noindent 
                Since $f(x) =f(y)$ implies $x=y$, $f$ is injective $\quad \blacksquare $
            \end{mdframed}
            \bigbreak \noindent 
            Alternatively, one could use the contrapositive, which would mean one starts by assuming $x \ne y$, and then concludes that $f(x) \ne f(y)$.
            \bigbreak \noindent 
            Next, here’s the outline for a surjective proof.
            \begin{mdframed}
                \textbf{Proposition.} $f:\ A \to B$ is a surjection
                \bigbreak \noindent 
                \textbf{\textit{Proof.}} Assume $b\in B $
                \begin{align*}
                    &\vdots \quad \text{ Magic  to find an $a\in A$}\\
                    &\vdots \quad \text{ where $f(a) = b $}
                .\end{align*}
                Since every $b\in B$ has an $a\in A$ where $f(a) = b $, $f$ is surjective $\quad \blacksquare $
            \end{mdframed}
        \item \textbf{Proving jectiveness examples}
            \begin{itemize}
                \item \( f : \mathbb{R} \to \mathbb{R} \) where \( f(x) = x^2 \) is not injective, surjective, or bijective.
                \item \( g : \mathbb{R}^+ \to \mathbb{R} \) where \( g(x) = x^2 \) is injective, but not surjective or bijective.
                \item \( h : \mathbb{R} \to \mathbb{R}^+ \) where \( h(x) = x^2 \) is surjective, but not injective or bijective.
                \item \( k : \mathbb{R}^+ \to \mathbb{R}^+ \) where \( k(x) = x^2 \) is injective, surjective, and bijective.
            \end{itemize}
            \bigbreak \noindent 
            \textbf{\textit{Proof (part a).}} Observe that $f(-2) = f(2) =4 $, while $-2 \ne 2 $. Thus, $f$ is not injective. Next, notice that $f(x) = x^{2} > 0$. Thus, there is no such $a\in \mathbb{R}$ such that $f(a) = -4$. Since $-4$ is in the codomain and is not hit, $f$ is not surjective. Since $f$ is not both injective and surjective, it is therefore not bijective. 
            \bigbreak \noindent 
            \textbf{Part b}. Let $a_{1}, a_{2} \in \mathbb{R}^{+}$, assume $g(a_{1}) = g(a_{2})$. Thus,
            \begin{align*}
                a_{1}^{2} &= a_{2}^{2} \\
                \implies a_{1} &= \pm a_{2}
            .\end{align*}
            But, for all $a\in \mathbb{R}^{+}$, $a >0$. Thus, $a_{1} = a_{2}$ and $g $ is injective. Observe that again there is no such value in the domain of $g$ such that $g(x) = -4$. Since $-4$ is in the codomain of $g$, it is not surjective, and is therefore not bijective.
            \bigbreak \noindent 
            \textbf{Part c.} Observe that $h(-2) = h(2) = 4$, while $-2 \ne 2$. Thus, $ h$ is not injective. Further, let $b\in \mathbb{R}^{+}$, then
            \begin{align*}
                h(a) &= b \\
                \implies a^{2} &= b \\
                \implies a &= \pm b
            .\end{align*}
            But, the codomain is restricted to positive values, thus $a=b$ and $h $ is surjective. Since $h$ is not injective, it is not bijective.
            \bigbreak \noindent 
            \textbf{Part d.} Let $a_{1}, a_{2} \in \mathbb{R}^{+}$, assume $f(a_{1}) = f(a_{2}) $, which implies
            \begin{align*}
                a_{1}^{2} &= a_{2}^{2} \\
                \implies a_{1} &= \pm a_{2}
            .\end{align*}
            Again, since the domain is restricted to positive values, we have $a_{1} = a_{2}$ and $f$ is injective. Next, let $b\in \mathbb{R}^{+}$, then
            \begin{align*}
                f(a) &= b \\
                \implies a^{2} &= b \\
                \implies a &= \pm b
            .\end{align*}
            But since the codomain is restricted to positive values, $a=b$ and the function is surjective. Since the function is both onto and one-to-one, the function is bijective (invertible). $\quad \blacksquare $
        \item \textbf{Proving jectiveness example 2.} Show $f: (\mathbb{Z} \times \mathbb{Z}) \to (\mathbb{Z} \times \mathbb{Z})$, with $f(x,y) = (x+2y, 2x+3y) $ is a bijection.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} First, we show injectiveness. Let $(a,b), (c,d) \in \mathbb{Z}^{2}$. Assume $f(a,b) = f(c,d) $. Thus,
            \begin{align*}
                &(a+2b,2a+3b) = (c+2d, 2c+3d) \\
                \implies &\begin{cases} a+2b &=c+2d \\ 2a+3b &=2c+3d \end{cases} \\
                \implies &\begin{cases} a+2b-2a-3b &=0 \\ 2a+3b-2c-3d &=0 \end{cases} 
            .\end{align*}
            We then solve this system,
            \begin{align*}
                \begin{array}{cccc|c} 1 & 2 & -1 & -2 & 0\\ 2 & 3 & -2 & -3 & 0 \end{array} \implies \begin{array}{cccc|c} 1 & 0 & -1 & 0 & 0 \\ 0 &1 & 0 & -1 & 0\end{array}
            .\end{align*}
            Which implies 
            \begin{align*}
                \begin{cases}
                    a &= c \\
                    b &=d
                \end{cases}
           \end{align*}
            As desired. Thus, $f$ is injective. Next, let $(c,d) \in \mathbb{Z}^{2}$. Require $f(a,b) = (c,d)$ for some $(a,b) \in \mathbb{Z}^{2} $. Thus,
            \begin{align*}
                &(a+2b, 2a+3b) = (c,d) \\
                \implies &\begin{cases} a + 2b &= c\\ 2a+3b &=d \end{cases}
            .\end{align*}
            Solving this system yields
            \begin{align*}
                \begin{array}{cc|c} 1 & 2 & c \\ 2 & 3 & d \end{array} \implies \begin{array}{cc|c} 1 & 0 & -3c + 2d \\0&1 &2c-d \end{array}
            .\end{align*}
            Thus, $(a,b) = (-3c +2d, 2c-d)$ and the function is surjective. Because the function is both injective and surjective, it is therefore bijective.
            \bigbreak \noindent 
            Alternatively, observe that $f:\ \mathbb{Z}^{2} \to \mathbb{Z}^{2}$, $f(x,y) = (x+2y, 2x+3y) $ is given by the matrix representation $A\vec{\mathbf{x}} = \vec{\mathbf{b}} $
            \begin{align*}
                \begin{pmatrix} 1 & 2\\2&3 \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix} &= \begin{pmatrix} a \\b \end{pmatrix}
            .\end{align*}
            Thus, since $A$ is square, we can simply check its determinant. \footnote{Common linear algebra $W$} 
            \begin{align*}
                \det\begin{pmatrix} 1 & 2 \\ 2 & 3 \end{pmatrix} &= 1(2)-2(3) = -1
            .\end{align*}
            Since $\det(A) \ne 0$, the function is invertible
        \item \textbf{The func-y pigeonhole principle}:
            \bigbreak \noindent 
            \textbf{Theorem 8.10 (The func-y pigeonhole principle)}: Suppose $A$ and $B$ are finite sets and $f:\  A \to B$ is any function.
            \begin{enumerate}[label=(\alph*)]
                \item If $|A| > |B|$, then $f$ is not injective.
                \item If $|A| < |B|$, then $f$ is not surjective.
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} \textbf{Part (a).} Consider each element in \( A \) to be an object and each element of
            \( B \) to be a box. Given an \( a \in A \), place object \( a \) into box \( b \) if \( f(a) = b \). 
            Since there are more objects than boxes, by the pigeonhole principle at least one box has at least
            two objects in it. That is, \( f(a_1) = f(a_2) \) for some distinct \( a_1 \) and \( a_2 \), implying that
            \( f \) is not injective.
            \bigbreak \noindent 
            \textbf{Part (b).} Since \( f \) is a function, each \( a \in A \) is mapped to only one \( b \in B \). 
            Thus, \( k \) elements in \( A \) can map to at most \( k \) elements of \( B \). 
            And so the \( |A| \) elements in \( A \) can map to at most \( |A| \) elements in \( B \). 
            However, since \( |A| < |B| \), there must be some elements not hit, meaning that \( f \) is not surjective.
            \bigbreak \noindent 
            It is again useful to think about what the contrapositive tells us:
            \begin{itemize}
                \item[(a)] If \( f \) is injective, then \( |A| \leq |B| \).
                \item[(b)] If \( f \) is surjective, then \( |A| \geq |B| \).
            \end{itemize}
            Viewing the statements this way is beneficial for another reason: It demonstrates
            clearly that in order for \( f \) to be a bijection—meaning an injection and a surjection—we
            would need \( |A| = |B| \).
            \bigbreak \noindent 
            It is also worth mentioning that this theorem still holds true in the case that \( |A| \)
            and/or \( |B| \) are infinite.\footnote{But proving this to be the case would take us too far afield.}
        \item \textbf{The Composition}: Let \( A \), \( B \), and \( C \) be sets, \( g : A \to B \), and \( f : B \to C \). Then the
            composition function is denoted \( f \circ g \) and is defined as follows:
            \[
                (f \circ g) : A \to C \quad \text{where} \quad (f \circ g)(a) = f(g(a)).
            \]
            Suppose 
            \begin{align*}
                &g:\ \mathbb{R} \to \mathbb{R},\ g(x) = x+1 \\
                &f:\ \mathbb{R} \to \mathbb{R}^{+},\ f(x) = x^{2}
            .\end{align*}
            Then,
            \begin{align*}
                (f\circ g):\ \mathbb{R} \to \mathbb{R}^{+},\ (f\circ g)(x) = (x+1)^{2}
            .\end{align*}
        \item \textbf{Property of injective functions under composition}:
            \bigbreak \noindent 
            \textbf{Theorem 8.13}. Suppose $A, B$ and $C$ are sets, $g:\ A \to B$ is injective, and $f:\ B \to C$ is injective. Then $f \circ g$ is injective
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Since $(f\circ g):\ A \to C$, to show that is an injection we must show that for all $a_{1}, a_{2}\in A$, $(f\circ g)(a_{1}) = (f\circ g)(a_{2}) $ implies $a_{1} = a_{2}$. Assume $a_{1}, a_{2} \in A$, and $(f\circ g)(a_{1}) = (f\circ g)(a_{2})$. Using the definition of the composition, we have
            \begin{align*}
                f(g(a_{1})) = f(g(a_{2}))
            .\end{align*}
            Since $f$ is injective, we know that for any $b_{1}, b_{2} \in B$, $f(b_{1}) = f(b_{2}) $ implies $b_{1} = b_{2}$. Since $g(a_{1}), g(a_{2}) \in B$, we have
            \begin{align*}
                g(a_{1}) = g(a_{2})
            .\end{align*}
            Likewise, since $g$ is injective, it must be that $a_{1}  = a_{2}$
            \bigbreak \noindent 
            Thus, we have shown that for any $a_{1}, a_{2} \in A$, if $(f\circ g)(a_{1}) = (f\circ g)(a_{2})$, then $a_{1} = a_{2}$. Therefore, $(f\circ g)$ is an injection. $\quad \blacksquare $
        \item \textbf{Property of surjective functions under composition}:
            \bigbreak \noindent 
            \textbf{Theorem 8.14}: Suppose $A$, $B$ and $C$ are sets, $g:\ A \to B$ is surjective, and $f:\ B \to C$ is surjective. Then $f \circ g$ is surjective.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Since $(f\circ g):\ A \to C$, to show that $f\circ g$ is surjective, we must show that for all $c\in C$, there exists some $a\in A$ such that $(f\circ g)(a) = c$. To start, since $f$ is surjective, then for all $c\in C$, there exists some $b\in B$ such that $f(b) = c$. Further, we know that $g$ is surjective. Thus, for all $b\in B$, there exists some $a\in A$ such that $g(a) = b$. 
            \bigbreak \noindent 
            Thus, for an arbitrary $c\in C$, we have found an $a\in A$ such that
            \begin{align*}
                (f\circ g)(a) = f(g(a)) = f(b) = c
            .\end{align*}
            Completing the proof $\quad \blacksquare $
        \item \textbf{A corollary from the above two results}: Suppose $A$, $B$ and $C$ are sets, $g:\  A \to B$ is bijective, and $f:\ B \to C$ is bijective. Then $f \circ g$ is bijective.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} By Theorem 8.13, \( f \circ g \) is an injection. By Theorem 8.14, \( f \circ g \) is a surjection. Thus, by the definition of a bijection (Definition 8.7), \( f \circ g \) is a bijection.
        \item \textbf{Note about compositions}: Notice that in our definition of function composition (Definition 8.11) we had functions \( g \) and \( f \) where \( g : A \to B \), and \( f : B \to C \). Notice that we don’t really need the codomain of \( g \) to equal the domain of \( f \). If we had \( g : A \to B \) and \( f : D \to C \) where \( B \subseteq D \), that would be enough (for the definition, and for these last two theorems). As long as \( g(a) \) is a part of \( f \)’s domain, then \( f(g(a)) \) will make sense, which is all we need.
        \item \textbf{Identity function and invertibility}: For a set \( A \), the identity function on \( A \) is the function 
            \begin{align*}
                i_A : A \to A  \text{ where } i_A(x) = x  \text{ for every }  x \in A 
            \end{align*}
            \bigbreak \noindent 
            The inverse of a function \( f : A \to B \), if it exists, is the function \( f^{-1} : B \to A \) such that \( f^{-1} \circ f = i_A \) and \( f \circ f^{-1} = i_B \).
            \bigbreak \noindent 
            For example, if \( f : \mathbb{R} \to \mathbb{R} \) where \( f(x) = x + 1 \), then \( f^{-1} : \mathbb{R} \to \mathbb{R} \) is the function
            \( f^{-1}(x) = x - 1 \). To see this, simply note that
            \[
                (f \circ f^{-1})(x) = f(f^{-1}(x)) = f(x - 1) = (x - 1) + 1 = x
            \]
            and
            \[
                (f^{-1} \circ f)(x) = f^{-1}(f(x)) = f^{-1}(x + 1) = (x + 1) - 1 = x.
            \]
        \item \textbf{Arctan and the natural logarithm}: this is a great opportunity to mention a couple important functions — $\text{arctan}(x)$ and $\ln(x)$ — which are defined as the inverses to other important function.
            \begin{itemize}
                \item If \( \tan : (-\pi/2, \pi/2) \to \mathbb{R} \) is the tangent function, then its inverse is defined to be \( \arctan : \mathbb{R} \to (-\pi/2, \pi/2) \), and is called the arctangent function.\footnote{}
                \item If \( \exp : \mathbb{R} \to \mathbb{R}^+ \) is the exponential function (that is, \( \exp(x) = e^x \)), then its inverse is defined to be \( \ln : \mathbb{R}^+ \to \mathbb{R} \), and is called the natural logarithm function.
            \end{itemize}
        \item \textbf{When does an inverse exist}:
            \bigbreak \noindent 
            \textbf{Theorem}: A function $f:\ A \to B$ is invertible if and only if $f$ is a bijection.
            \bigbreak \noindent 
            \textbf{Proof.} First, suppose that \( f : A \to B \) is invertible. We will prove that \( f \) is both
            an injection and a surjection, which will prove that \( f \) is a bijection. To see that \( f \)
            is a surjection, choose any \( b \in B \). We aim to find an \( a \in A \) such that \( f(a) = b \). To 
            this end, let \( a = f^{-1}(b) \), which exists and is in \( A \) because \( f^{-1} : B \to A \). Now simply
            observe that the definition of an invertible function (Definition 8.16) implies
            \[
                f(a) = f(f^{-1}(b)) = b.
            \]
            This proves that \( f \) is a surjection.
            \bigbreak \noindent 
            To see that \( f \) is an injection, let \( a_1, a_2 \in A \) and assume \( f(a_1) = f(a_2) \). Note that 
            \( f(a_1) \) (and hence \( f(a_2) \), since they're equal) is an element of \( B \) due to the fact that 
            \( f : A \to B \). And so, since \( f^{-1} : B \to A \), we may apply \( f^{-1} \) to both sides:
            \[
                f(a_1) = f(a_2)
            \]
            \[
                f^{-1}(f(a_1)) = f^{-1}(f(a_2))
            \]
            \[
                a_1 = a_2,
            \]
            by the definition of the inverse. Thus, \( f \) is an injection. And since we already showed 
            that \( f \) is a surjection, it must be a bijection. This concludes the forward direction of 
            the theorem.
            \bigbreak \noindent 
            As for the backwards direction, assume that \( f \) is a bijection. For \( b \in B \), we will 
            now define \( f^{-1}(b) \) like this:
            \[
                f^{-1}(b) = a \quad \text{if} \quad f(a) = b.
            \]
            That is, we are defining \( f^{-1} \) to act as an inverse from \( B \) to \( A \) should act, without yet 
            claiming that \( f^{-1} \) is a function. Our goal now is to demonstrate that this definition 
            of \( f^{-1} \) satisfies the conditions to be a function, which would prove that \( f \) is invertible. 
            To do so, recall that to be a function there is an existence condition (\( f^{-1}(b) \) must be 
            equal to some \( a \in A \)) and a uniqueness condition (\( f^{-1}(b) \) must be equal to only one 
            \( a \in A \)). We will check these separately.
            \bigbreak \noindent 
            \textbf{Existence:} Let \( b \in B \). Since \( f \) is surjective, there must be some \( a \in A \) such that 
            \( f(a) = b \). Hence, by our definition of \( f^{-1} \), we have \( f^{-1}(b) = a \). We have shown that 
            for every \( b \in B \) there exists at least one \( a \in A \) for which \( f^{-1}(b) = a \), which concludes 
            the existence portion of this argument.
            \bigbreak \noindent 
            \textbf{Uniqueness:} Suppose \( f^{-1}(b) = a_1 \) and \( f^{-1}(b) = a_2 \), for some \( b \in B \) and \( a_1, a_2 \in A \). 
            By the definition of \( f^{-1} \), this means that \( f(a_1) = b \) and \( f(a_2) = b \). But since \( f \) is 
            injective, this means that \( a_1 = a_2 \). We have shown that \( f^{-1}(b) \) can not be equal to 
            two different elements of \( A \), which concludes the uniqueness portion of this argument.
            \bigbreak \noindent 
            Combined, these two parts show that \( f^{-1} : B \to A \) is a function, hence proving 
            that \( f \) is invertible.
            \bigbreak \noindent 
            We have proved the forwards and backwards directions of Theorem 8.17, which 
            completes its proof. \(\Box\)
        \item \textbf{The image and inverse image}: Let \( f : A \to B \) be a function, and assume \( X \subseteq A \) and \( Y \subseteq B \).
            The \textit{image} of \( A \) is
            \[
                f(X) = \{y \in B : y = f(x) \text{ for some } x \in X\},
            \]
            and the \textit{inverse image} of \( Y \) is
            \[
                f^{-1}(Y) = \{x \in A : f(x) \in Y\}.
            \]
        \item \textbf{The bijection principle}:
            \bigbreak \noindent 
            \textbf{Principle (\textit{The bijection principle.})} Two sets have the same size if and only if there is a bijection between them.
        \item \textbf{Hilbert's hotel}: We begin by talking about the set of problems related to the so-called Hilbert’s Hotel. Assume that there is a hotel, called Hilbert’s Hotel, which has infinitely many rooms in a row.
            \bigbreak \noindent 
            \fig{.7}{./figures/20.png}
            \begin{itemize}
                \item Assume every room has someone in it, and so the “No Vacancy” sign has been
                    turned on. With most hotels, this would mean that if someone else arrives at
                    the hotel, they will not be given a room. But this isn’t the case with Hilbert’s
                    Hotel. If, for \( n \in \mathbb{N} \), the patron in room \( n \) moves to room \( n + 1 \), then nobody
                    is left without a room and suddenly room 1 is completely open! So the new
                    customer can go to room 1. We created a room out of nothing!
                \item Now imagine 2 people arrived at the hotel. Can we accommodate them?
                    Certainly! Now, just have everyone move from room \( n \) to room \( n + 2 \). This
                    leaves rooms 1 and 2 open to the newcomers, and we are again good-to-go.

                \item What if, however, we have infinitely many people lined up wanting a room?
                    Can we accommodate all of them? Yes! We still can! Just have the person in
                    room \( n \) move to room \( 2n \). Then all of the odd-numbered rooms are vacant and
                    the infinite line of people can take these rooms.
            \end{itemize}
            The first point of this exercise is to simply realize that weird stuff can happen
            when dealing with the infinite. The second point, though, is to realize that each time
            the people switched rooms, those same exact people got new rooms. So in the first
            example when they each just moved one room down, that should mean that there
            are just as many rooms from 1 to $\infty$ as there are from 2 to $\infty$. . . And likewise for the
            others.
        \item \textbf{Cardinality and infinite sets}:
            \bigbreak \noindent 
            \textbf{Example} There are the same number of natural numbers as there are natural
            numbers larger than 1 (that is, \( |\mathbb{N}| = |\{2, 3, 4, \dots \}| \)). What’s the bijection that shows
            this? Let
            \[
                f : \mathbb{N} \to \{2, 3, 4, \dots \} \quad \text{where} \quad f(n) = n + 1.
            \]

            In other (non-)words, this is the pairing
            \[
                1 \leftrightarrow 2 \quad 2 \leftrightarrow 3 \quad 3 \leftrightarrow 4 \quad 4 \leftrightarrow 5 \quad \dots
            \]
            \bigbreak \noindent 
            \textbf{The Moral}. Two sets can have the same size even though one is a proper subset of the other.
            \bigbreak \noindent 
            \textbf{Example}. There are the same number of natural numbers as even natural
            numbers (that is, \( |\mathbb{N}| = |2\mathbb{N}| \)). What’s the bijection that shows this? Let
            \[
                f : \mathbb{N} \to \{2, 4, 6, 8, \dots\} \quad \text{where} \quad f(n) = 2n.
            \]
            In other (non-)words, this is the pairing
            \[
                1 \leftrightarrow 2 \quad 2 \leftrightarrow 4 \quad 3 \leftrightarrow 6 \quad 4 \leftrightarrow 8 \quad \dots
            \]
            \textbf{The Moral.} Two sets can have the same size even though one is a proper subset of the other 
            and the larger one even has \textit{infinitely many more elements} than the smaller one.
            \bigbreak \noindent 
            And in a similar way, one can prove that \( |\mathbb{N}| = |\mathbb{Z}| \). Indeed, a bijection 
            \( f : \mathbb{N} \to \mathbb{Z} \) can be given by following this pattern:
            \[
                f(1) = 0, \quad f(2) = 1, \quad f(3) = -1, \quad f(4) = 2, \quad f(5) = -2, \quad f(6) = 3, \quad \dots
            \]
            \bigbreak \noindent 
            One way to write such a function is this:
            \[
                f : \mathbb{N} \to \mathbb{Z} \quad \text{where} \quad 
                f(n) = 
                \begin{cases} 
                    \frac{n}{2} & \text{if } n \text{ is even}; \\
                    -\frac{(n-1)}{2} & \text{if } n \text{ is odd}.
                \end{cases}
            \]


    \end{itemize}

    \pagebreak 
    \subsection{Relations}
    \begin{itemize}
        \item \textbf{Set partitions}: A partition of a set $A$ is a collection of non-empty subsets of $A$ for which each element of $A$ is in one and only one of the subsets.
            \bigbreak \noindent 
            Formally, a partition is a collection of non-empty sets $\{P_{i}\}_{i\in S} $ such that
            \begin{enumerate}
                \item $P_{i} \subseteq A $ for all $i$
                \item $\bigcup_{i\in S} P_{i} = A$
                \item $P_{i} \cap P_{j} = \varnothing$ for all $i\ne j $
            \end{enumerate}
            \bigbreak \noindent 
            A partition of \( \mathbb{Z} \) is the set of evens and the set of odds. Another partition of \( \mathbb{Z} \) is the positive integers, the negative integers, and \(\{0\}\). Another is the non-\(17\) integers and \(\{17\}\). Another is the five sets in the Mod-5 Property section on the previous page. And the simplest partition of \( \mathbb{Z} \) is simply \( \mathbb{Z} \) — a partition with only one part.
        \item \textbf{Index sets}: In the formal definition of a partition, $S$ is the index set that labels or indexes the subsets $P_{i}$ in the partition. 
            \bigbreak \noindent 
            $S$ can be any set (e.g., $N,\{1,2,...,n\}$, or any other index set), as long as it provides unique labels for each subset $P_{i}$
        \item \textbf{Equivalence Relations}: An \emph{equivalence relation} on a set \( A \) is an ordered relationship between pairs of elements of \( A \) for which the pair is either \emph{related} or is \emph{not related}. If \( a, b \in A \), we denote \( a \sim b \) if \( a \) is related to \( b \), and \( a \not\sim b \) if \( a \) is not related to \( b \).
            \bigbreak \noindent 
            For \( \sim \) to be an equivalence relation, it also must satisfy the following three properties:
            \begin{itemize}
                \item \textbf{Reflexive:} \( a \sim a \) for all \( a \in A \);
                \item \textbf{Symmetric:} If \( a \sim b \), then \( b \sim a \) for all \( a, b \in A \); and
                \item \textbf{Transitive:} If \( a \sim b \) and \( b \sim c \), then \( a \sim c \) for all \( a, b, c \in A \).
            \end{itemize}
            Lastly, if \( \sim \) is an equivalence relation and \( a \in A \), define the \emph{equivalence class} containing \( a \) to be the set
            \[
                \{ b \in A : a \sim b \}.
            \] 
        \item \textbf{Relations}: A relation on a set \( A \) is any ordered relationship between pairs of elements of \( A \) for which the pair is either \emph{related} or is \emph{not related}. If \( a, b \in A \), we denote \( a \sim b \) if \( a \) is related to \( b \), and \( a \not\sim b \) if \( a \) is not related to \( b \).
            \bigbreak \noindent 
            Lastly, if \( \sim \) is a relation and \( a \in A \), define the class containing \( a \) to be the set
            \[
                \{ b \in A : a \sim b \}.
            \]
        \item \textbf{Equivalence relations and partitions}:
            \bigbreak \noindent 
            \textbf{Theorem 9.5.} Assume $\sim$ is a relation on $A$. The relation $\sim$ partitions the elements of $A$ into classes if and only if $\sim$ is an equivalence relation.
            \bigbreak \noindent 
            Before we prove this theorem, we first define some notation. We denote the equivalence class of an element $a\in A$, $\{x\in A:\ a \sim x\} $ by $[a]$. 
            \bigbreak \noindent 
            Next, a lemma.
            \bigbreak \noindent 
            \textbf{Lemma 9.10}. Suppose $\sim$ is an equivalence relation on a set $A$, and let $a, b \in A$. Then,
            \begin{align*}
                [a] = [b] \text{ if and only if } a\sim b
            \end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof of lemma 9.10}}. For the (straight)forward direction, assume that \([a] = [b]\). Observe that since \( \sim \) is reflexive, \( b \sim b \) and so \( b \in [b] \). And since \([a] = [b]\), this in turn means that \( b \in [a] \), which by Notation 9.9 implies \( a \sim b \). This concludes the forward direction.
            \bigbreak \noindent 
            As for the backward direction, we begin by assuming \( a \sim b \), and we aim to prove that \([a] = [b]\). This will be accomplished by demonstrating that \([a] \subseteq [b]\) and \([b] \subseteq [a]\). To prove the former, choose any \( x \in [a] \); we will show that \( x \in [b] \). By assumption we have \( a \sim b \), and because \( x \in [a] \) we have \( a \sim x \). That is,
            \[
                a \sim b \quad \text{and} \quad a \sim x.
            \]
            By the symmetry property of \( \sim \),
            \[
                b \sim a \quad \text{and} \quad a \sim x.
            \]
            By the transitivity property of \( \sim \),
            \[
                b \sim x.
            \]
            And so, by Notation 9.9,
            \[
                x \in [b].
            \]
            We have shown that \( x \in [a] \) implies \( x \in [b] \), and hence \([a] \subseteq [b]\).
            \bigbreak \noindent 
            The reverse direction is nearly the same. Let \( x \in [b] \), which means \( b \sim x \). Combining this, the transitivity of \( \sim \), and our assumption that \( a \sim b \), we get \( a \sim x \), which means \( x \in [a] \). And since \( x \in [b] \) implies \( x \in [a] \), we have \([b] \subseteq [a]\).
            \bigbreak \noindent 
            We have shown that \([a] \subseteq [b]\) and \([b] \subseteq [a]\), which proves that \([a] = [b]\). This concludes the backward direction, and hence the proof.
            \qed
            \bigbreak \noindent 
            We now proceed to the proof of theorem 9.5

        \item \textbf{Equivalence relation example 1}: Let $\sim$ be the relation on $\mathbb{R}$ where
            \begin{align*}
                a \sim b \text{ if } \floor{a} = \floor{b}
            \end{align*}
            We can verify that \( \sim \) is an equivalence relation by checking that it satisfies the three criteria. It is reflexive because certainly \( \floor{a}= \floor{a} \) for any \( a \in \mathbb{R} \); it is symmetric because if \( \floor{a} = \floor{b} \), then certainly \( \floor{b} = \floor{a} \); and it is transitive because if \( \floor{a} = \floor{b} \) and \( \floor{b} = \floor{c} \), then \( \floor{a} = \floor{c} \). Each of these is immediate because the equal sign already has these properties.
            \bigbreak \noindent 
            This means that the equivalence classes must then partition all of $\mathbb{R}$, and indeed they do.
            The class of all numbers that are equivalent to \( 12.4 \) is the set of numbers in the interval \([12, 13)\); that is, all numbers \( x \) such that \( 12 \leq x < 13 \). Indeed, the equivalence classes for \( \sim \) are all intervals of the form \([n, n+1)\) for \( n \in \mathbb{Z} \). 
            \bigbreak \noindent 
            Moreover, by Theorem 9.5 this means that the equivalence classes must then partition all of \( \mathbb{R} \), and they do: every \( x \in \mathbb{R} \) is in precisely one of these intervals:
            \[
                \ldots, [2, 3), [3, 4), [4, 5), [5, 6), [6, 7), \ldots.
            \]
            \qed
    \end{itemize}

    \pagebreak 
    \unsect{Elementary fields, groups, and rings}
    \begin{itemize}
        \item \textbf{Modular congruence and congruence classes}: Recall that two integers $a$ and $b$ are said to be congruent modulo $n$ if they leave the same remainder when divided by $n$. Mathematically, this is written as
            \begin{align*}
                a\equiv b \pmod{n}
            .\end{align*}
            Which means
            \begin{align*}
                n \mid a-b
            .\end{align*}
            When an integer $a$ is divided by $n$
            \begin{align*}
                a = q_{1}n + r_{1} \quad \text{ with} 0 \leq r_{1} < n
            .\end{align*}
            Similarly, for an integer $b$ divided by $n$
            \begin{align*}
                b = q_{2}n + r_{} \quad \text{ with} 0 \leq r_{2} < n
            .\end{align*}
            Subtracting $b$ from $a$
            \begin{align*}
                a - b &= (q_{1} - q_{2})n + (r_{1} - r_{2}) \tag{1}
            .\end{align*}
            If $n\mid (a-b)$, 
            \begin{align*}
                a-b=nk, \quad k\in \mathbb{Z}
            .\end{align*}
            By (1) above, we have
            \begin{align*}
                (q_{1} - q_{2})n + (r_{1} - r_{2}) &= kn
            .\end{align*}
            For this to hold, we require $r_{1}-r_{2}$ to be a multiple of $n$, since $q_{1} - q_{2}$ is already a multiple of $n$. Since $r_{1}, r_{2}$ satisfy $0 \leq r_{1}, r_{2} < n$. It must be that $-n < r_{1}- r_{2} < n$. In this case, for $n$ to divide $r_{1} - r_{2}$. It must be that
            \begin{align*}
                r_{1} - r_{2} &= 0 
            .\end{align*}
            Which implies $r_{1} = r_{2}$. Hence, $a$ and $b$ have the same remainder when divided by $n$ when $n\mid a-b$.
            \bigbreak \noindent 
            A congruence class modulo $n$ is the set of all integers that are congruent to a particular integer $a$ modulo $n$. This set is denoted as
            \begin{align*}
                [a]_{n} = \{x\in \mathbb{Z} \mid x \equiv a \pmod{n}\}
            .\end{align*}
            For example, $[0]_{3}$ is 
            \begin{align*}
                \{x\in \mathbb{Z}:\ x \equiv 0 \pmod{3}\} \\
            .\end{align*}
            Which is the integers $x$ such that $3 \mid x-0  $. In other words, it describes the set of integers that are divisible by 3.
            \bigbreak \noindent 
            The set $[1]_{3}$ is the set
            \begin{align*}
                [1]_{3} = \{x\in \mathbb{Z}:\ x \equiv 1 \pmod{3}\}
            .\end{align*}
            Which implies $3\mid x-1$, and thus $x = 3k + 1$, for $k\in \mathbb{Z}$. In words, it is the set of integers that leave a remainder of one when divided by three.
            \bigbreak \noindent 
            The modulus $n$ partitions the integers into $n$ distinct congruence classes:
            \begin{align*}
                [0]_{n}, [1]_{n}, ...,[n-1]_{n}
            .\end{align*}
            Every integer belongs to exactly one of these classes.
            \bigbreak \noindent 
            Arithmetic operations can be performed within the framework of congruence classes
            \begin{itemize}
                \item \textbf{Addition}: If $a\equiv b \pmod{n}$ and $c \equiv d \pmod{n}$, then  
                    \begin{align*}
                        a + c \equiv b + d \pmod{n}
                    .\end{align*}
                \item \textbf{Multiplication}: If $a\equiv b \pmod{n}$ and $c \equiv d \pmod{n}$, then  
                    \begin{align*}
                        ac \equiv bd \pmod{n}
                    .\end{align*}
            \end{itemize}
        \item \textbf{Groups}: A group is a collection of objects $G$, together with one operation $\oplus$, which has the following properties:
            \begin{itemize}
                \item \textbf{Associativity}: $a \oplus (b\oplus c) = (a\oplus b) \oplus c$
                \item \textbf{Identity}: There is an element $e\in G$ such that $e \oplus g = g \oplus e = g$ for all $g \in G $
                \item \textbf{Inverse}: For every $g\in G$, there exists $g^{-1} \in G$ such that $g \oplus g^{-1} = g^{-1}\oplus g = e $
            \end{itemize}
            For example, $\mathbb{Z}$ is a group under addition.
            \begin{itemize}
                \item \textbf{Associativity}: Two integers $a,b$ are associative, $a + (b + c)  = (a+b) +c $
                \item \textbf{Identity}: Zero is the identity element, since $0 \in \mathbb{Z}$ and $0 + a = a+ 0 = a $
                \item \textbf{Inverse}: $a + (-a) = (-a) + a = 0$
            \end{itemize}
            \textbf{Note:} A group is said to be \textit{abelian} if it is commutative under its operation. In other words, $x \oplus y = y\oplus x$ for all $x,y \in G $
        \item \textbf{Rings}: A ring is a set $R$, together with two operations $\oplus $ and $* $, which has the following properties
            \begin{itemize}
                \item $R$ is an abelian group under $\oplus $
                \item $R$ is associative under $*$
                % \item There exists an element 1 such that $r * 1 =  1 * r  = r $ for all $r\in R $
                \item The operation $*$ distributes over $\oplus$
                    \begin{align*}
                        a * (b\oplus c) &= (a*b) \oplus a * c \\
                        (a\oplus b) * c &= (a*c) \oplus (b*c)
                    .\end{align*}
            \end{itemize}
            For example, $\mathbb{Z}$ is a ring under addition and multiplication. First note that $\mathbb{Z}$ is an abelian group under addition. Further, for $a,b\in \mathbb{Z}$, $a\cdot b = b\cdot a$. 
            \bigbreak \noindent 
            $1\in \mathbb{Z}$ is the identity, $1 \cdot a = a \cdot 1 =a$ for all $a\in \mathbb{Z} $, and we know that multiplication distributes over addition
            \begin{align*}
                a \cdot (b+c) &= a\cdot b + a\cdot c \\
                (a+b) \cdot c &= a\cdot c + b\cdot c
            .\end{align*}
        \item \textbf{Fields}: A field is a set $F$, together with two operations $\oplus$ and $* $, which has the following properties
            \begin{itemize}
                \item $F$ is a commutative ring under $\oplus$ and $* $ 
                \item Every nonzero $f\in F$ has a multplicative inverse, that is, some element $g\in F$ for which
                    \begin{align*}
                        f*g = g*f = 1
                    .\end{align*}
            \end{itemize}
            The sets $\mathbb{Q}, \mathbb{R}$, and $\mathbb{C}$ under addition and multiplication are examples of fields. The set of integers $\mathbb{Z}$ is not. Although it is a commutative ring under addition and multiplication, not every element has a multiplicative inverse. For example, there is no such $a\in \mathbb{Z}$ such that $2 \cdot  g = 1 $
        \item \textbf{Vector spaces}: A vector space is a set of vectors $V$, together with a set of scalars $F$, with the following properties
            \begin{itemize}
                \item $V$ is a abelian group under vector addition
                \item  $F$ is a field under multiplication
                \item For each $s\in F$, and $\mathbf{v}\in V$, scalar multiplication gives a unique element $s\cdot \mathbf{v} \in V $
                \item Additional properties
                    \begin{align*}
                        1\mathbf{v} &= \mathbf{v} \\
                        a(b\mathbf{v}) &= (ab)\mathbf{v} \\
                        a(\mathbf{u} + \mathbf{v}) &= a\mathbf{u} + a\mathbf{v} \\
                        (a+b) \mathbf{v} &= a\mathbf{v} + b\mathbf{v}
                    .\end{align*}
            \end{itemize}



    \end{itemize}


    \pagebreak 
    \unsect{Combinatorics}
    \bigbreak \noindent 
    \subsection{Introduction}
    \begin{itemize}
        \item \textbf{What is combinatorics?}: Combinatorics is a collection of techniques and a language for the study of finite or countably infinite discrete structures. Given a set of elements and possibly some structure on that set, typical questions are
            \begin{itemize}
                \item Does a specific arrangement of the elements exists?
                \item How many such arrangemets are there?
                \item What properties do these arrangements have?
                \item Which one of the arrangemetns is maximal, minimal, or optimal according to some criterion?
            \end{itemize}
        \item \textbf{Counting the number of subsets for a set}: Let $[n] = \{1,2,...,n\} $, and let $f(n)$ be the number of subsets of $[n]$. Then $f(n) = 2^{n}$. For any particular subset of $[n]$, each element is either in that subset or not. Thus, to construct a subset, we have to make one of two choices for each element of $[n]$. Furthermore, these choices are independent of each other. Hence, the total number of choices, and consequently the total number of subsets is 
            \begin{align*}
                \underbrace{2\times2\times...\times2}_{n} = 2^{n}
            .\end{align*}
        \item \textbf{Number of subsets without consecutive integers}: For a sequence $[n] = \{1,...,n\}$ we can count the number of subsets given by $f(n)$, that do not contain consecutive integers with the recurrence relation
            \begin{align*}
                f(n) = f(n-1) + f(n-2)
            .\end{align*}
            We consider two cases
            \begin{enumerate}
                \item $n$ in not included in the subsets
                \item $n$ is included in the subsets. In this case, we build the subsets considering the subsequence $[n-2]  = \{1,...,n-2\}$. Note that if we include $n$, we must exclude $n-1$, because $n-1$ and $n$ are consecutive, this will become cleare in the upcoming example.
            \end{enumerate}
            \bigbreak \noindent 
            Consider the sequence $[n] = \{1,2,3,4\}$. By the relation above, 
            \begin{align*}
                f(4) &= f(3) + f(2) 
            .\end{align*}
            Before we are able to compute this, we must define our base cases. 
            \begin{align*}
                f(n) &= \begin{cases}
                    3 & \text{if } n = 2 \\
                    2 & \text{if } n =1
                \end{cases}
            .\end{align*}
            If $n=2$, we have $\{1,2\}$, and the allowed subsets are $\varnothing, \{1\}, \{2\} $. If we have $n=1$, the subsets are $\{\varnothing, \{1\}\} $. Thus
            \begin{align*}
                f(4) &= f(3) + f(2) = f(2) + f(1) + f(2)  \\
                     &= 3 + 2 + 3 = 8               
            .\end{align*}
            Let's explicitly break up the given sequence so we can see whats going on. In the first case, $n$ is excluded, thus the sequence becomes $\{1,2,3\}$. If $n$ is included, the sequence becomes $\{1,2\}$, where we build the subsets of $\{1,2\}$, and then add 4 to each one. Thus,
            \begin{align*}
                \{1,2,3\} + \{1,2\} &= \{1,2,3\}  + \varnothing + \{1\} + \{2\} \\
                                    &= \{1,2,3\} + \{4\} + \{1,4\} + \{2,4\}
            .\end{align*}
            Since the sequence $\{1,2,3\}$ in not a base case, we must split this one up aswell, we have
            \begin{align*}
                \{1,2,3\} &= \{1,2\} + \{1\}  + \{4\} + \{1,4\} + \{2,4\} \\
                          &=  \varnothing + \{1\} + \{2\} + \varnothing + \{1\} + \{4\} + \{1,4\} + \{2,4\} \\
                          &= \varnothing + \{1\} + \{2\} + \{3\} + \{1,3\} + \{4\} + \{1,4\} + \{2,4\} 
            .\end{align*}
            Thus, we conclude all "good" subsets of $[n]$ either have $n$ or don't have $n$. The ones that don't have $n$ are exactly the "good" subsets of $[n-1]$. The "good" subsets of $[n]$ that include $n$ are exactly the "good" subsets of $[n-2]$ together with $n$. Thus $f(n) = f(n-1) + f(n-2) $ $\blacksquare$
            
    \end{itemize}

    \pagebreak 
    \subsection{Induction and recurrence relations}
    \begin{itemize}
        \item \textbf{Principal of Mathematical Induction}: Given an infinite sequence of propositions
            \begin{align*}
                P_{1}, P_{2}, P_{3},...P_{n},...,
            .\end{align*}
            In order to prove that all of them are true, it is enough to show two things
            \begin{enumerate}
                \item \textbf{The base case:} $P_{1}$ is true
                \item \textbf{The inductive step}: For all positive integers $k$, if $P_{k}$ is true, then so is $P_{k+1}$
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{Example}: Show that 
            \begin{align*}
                1 + 2 + 3 + ... + n = \frac{n(n+1)}{2}
            .\end{align*}
            \textbf{Base case}:
            \begin{align*}
                1 &= \frac{1(1+1)}{2} = \frac{2}{2} = 1
            .\end{align*}
            \bigbreak \noindent 
            \textbf{Inductive step}: $P_{k}$ is given by
            \begin{align*}
                1 + 2 + 3 + ... + k = \frac{k(k+1)}{2}
            .\end{align*}
            \bigbreak \noindent 
            $P_{k+1}$ is given by
            \begin{align*}
                1 + 2 + 3 + ... + k + k+1 = \frac{k+1(k+2)}{2}
            .\end{align*}
            If $1+2+3+...+k  = \frac{k(k+1)}{2}$, then
            \begin{align*}
                1 + 2 + 3 + ... + k + k+1 &= \frac{k+1(k+2)}{2} \\
                \frac{k(k+1)}{2} + k + 1 &= \frac{k+1(k+2)}{2} \\
                \frac{k(k+1) + 2k + 2}{2} &= \frac{k^{2} + 3k + 2}{2} \\
                \frac{k^{2} + 3k  + 2}{2} &= \frac{k^{2} + 3k + 2}{2}
            .\end{align*}
            Thus, we have showed that $P_{k} \implies P_{k+1}$ $\blacksquare$.
            \bigbreak \noindent 
            \textbf{Note}: Our aim is not to directly prove $P_{k+1}$, but to prove that $P_{k}$ implies $P_{k+1}$. In the inductive step we assume $P_{k}$ to be true, then show under this assumption, $P_{k+1}$ is also true.
        \item \textbf{Understanding gauss's formula for the sum of the first $n$ natural numbers}: Suppose we want to find the sum $1+2+3+...+(n-1)+n$. We could have discovered the formula that we proved above by first writing the sum twice
            \begin{align*}
                &1 + 2  + 3 + ... + (n-1) + n \\
                &n + (n-1) + (n-2) + ... + 2 + 1
            .\end{align*}
            The sum of the two numbres in each column is $n+1$, and there are $n$ columns, so the total sum is $n(n+1)$, it then follows that the actual sum is $\frac{1}{2}n(n+1)$
        \item \textbf{Trianglular numbers}: The sequence of integers
            \begin{align*}
                &1
                &3 = 1+2 \\
                &6 = 1 + 2  + 3 \\
                &10 = 1 + 2 + 3 + 4 \\
                &15  = 1 + 2 + 3 + 4 + 5  \\
                &...
            .\end{align*}
            Are called \textit{triangular numbers}. If you were to make a triangle of dots out of the sum, where the highest number is the base, the second highest is the layer ontop of the base, etc, you would form a triangle.
        \item \textbf{Strong induction}: Given an infinite sequence of propositions
            \begin{align*}
                P_{1}, P_{2}, P_{3}, ..., P_{n}
            .\end{align*}
            In order to demonstrate that all of them are true, it is enough to know two things.
            \begin{enumerate}
                \item \textbf{The base case}: $P_{1}$ is true
                \item \textbf{The inductive step}: For all integers $k \geq 1$, if $P_{1}, P_{2}, P_{3},...,P_{k}$ are true, then so is $P_{k+1}$
            \end{enumerate}
        \item \textbf{Pingala-fibonacci numbers}: Define a sequence of positive integers as follows: $F_{0} = 0, F_{1} = 1$, and for $n=2,3,... $ we have
            \begin{align*}
                F_{n} = F_{n-2} + F_{n-1}
            .\end{align*}
            This sequence is also known as \textit{the fibonacci sequence}.
        \item \textbf{Lucas numbers}: Change the initial values on the fibonacci sequence. Let $L_{0} = 2, L_{1} = 1$, and $L_{n} = L_{n-2} + L_{n-1}$. Then, we get the \textit{Lucas numbers}
            \begin{align*}
                2,1,3,4,7,11,18,29,47,...
            .\end{align*}
        \begin{align*}
            \mathcal{L}
        .\end{align*}

    \end{itemize}

    \pagebreak 
    \unsect{Axiomatic geometry}
    \subsection{Euclids elements and the question of parallels}
    \begin{itemize}
        \item \textbf{Mathematical axioms and postulates}: Axioms are general truths or statements accepted without proof. Postulates are assumptions specific to a particular mathematical framework, often geometry. They serve as starting points for reasoning within that system.
            \bigbreak \noindent 
            In short, axioms are universal truths in mathematics. Postulates are subject-specific assumptions.
        \item \textbf{Euclids definitions}:
            \begin{enumerate}
                \item \textbf{Point:} That which has no part.
                \item \textbf{Line:} Breadthless length.
                \item The ends of a line are points.
                \item \textbf{Straight line:} A line which lies evenly with the points on itself.
                \item \textbf{Surface:} That which has length and breadth only.
                \item The edges of a surface are lines.
                \item \textbf{Plane surface:} A surface which lies evenly with the straight lines on itself.
                \item \textbf{Angle:} The inclination to one another of two lines in a plane which meet one another and do not lie in a straight line.
                \item \textbf{Right angle:} When a straight line set up on another straight line makes the adjacent angles equal to one another, each of the equal angles is a right angle.
                \item \textbf{Perpendicular:} A straight line standing on another straight line to form right angles with it.
                \item \textbf{Obtuse angle:} An angle greater than a right angle.
                \item \textbf{Acute angle:} An angle less than a right angle.
                \item \textbf{Boundary:} That which is the extremity of anything.
                \item \textbf{Figure:} That which is contained by any boundary or boundaries.
                \item \textbf{Circle:} A plane figure contained by one line (the circumference) such that all straight lines falling upon it from one point among those lying within the figure are equal to one another.
                \item \textbf{Center of a circle:} The point from which all straight lines drawn to the circumference are equal.
                \item \textbf{Diameter of a circle:} Any straight line drawn through the center and terminated in both directions by the circumference.
                \item \textbf{Semicircle:} The figure contained by the diameter and the circumference cut off by it. The center of the semicircle is the same as that of the circle.
                \item \textbf{Segment of a circle:} The figure contained by a straight line and the circumference it cuts off.
                \item \textbf{Rectilineal figure:} A figure contained by straight lines.
                \item \textbf{Trilateral figure:} A rectilineal figure contained by three straight lines (a triangle).
                \item \textbf{Quadrilateral figure:} A rectilineal figure contained by four straight lines.
                \item \textbf{Multilateral figure (polygon):} A rectilineal figure contained by more than four straight lines.
                \item \textbf{Equilateral triangle:} A triangle with three equal sides.
                \item \textbf{Isosceles triangle:} A triangle with two equal sides.
                \item \textbf{Scalene triangle:} A triangle with three unequal sides.
                \item \textbf{Right-angled triangle:} A triangle with one right angle.
                \item \textbf{Obtuse-angled triangle:} A triangle with one obtuse angle.
                \item \textbf{Acute-angled triangle:} A triangle with three acute angles.
                \item \textbf{Parallel lines:} Straight lines which, being in the same plane and being produced indefinitely in both directions, do not meet one another in either direction.
            \end{enumerate}
        \item \textbf{Euclids postulates}
            \begin{enumerate}
                \item To draw a straight line from any point to any point
                \item To produce a finite straight line continuously in a straight line
                \item To describe a circle with any center and distance
                \item That all right angles are equal to one another
                \item That, if a straight line falling on two straight lines makes the interior angles on the same side less than two right angles, the two straight lines, if produced indefinitely, meet on that side on which are the angles less than the two right angels
            \end{enumerate}
        \item \textbf{Euclids axioms}:
            \begin{enumerate}
                \item Things which are equal to the same thing are also equal to one another
                \item If equals be added to equals, the wholes are equal
                \item If equals be subtracted from equals, the remainders are equal.
                \item Things which coincide with one another are equal to one another
                \item The whole is greater than the part
            \end{enumerate}
        \item \textbf{Definitions rephrased}:
            \begin{enumerate}
                \item \textbf{Point:} A location that has no size or dimension.
                \item \textbf{Line:} A one-dimensional object that has length but no width.
                \item \textbf{Endpoints of a line:} The points where a line begins or ends.
                \item \textbf{Straight line:} A line that does not curve and lies evenly between its endpoints.
                \item \textbf{Surface:} A two-dimensional object that has length and width but no thickness.
                \item \textbf{Edges of a surface:} The boundaries of a surface are lines.
                \item \textbf{Plane surface:} A flat surface where any straight line connecting two points on it lies entirely on the surface.
                \item \textbf{Angle:} The measure of the inclination or separation between two lines that meet at a point but are not aligned.
                \item \textbf{Right angle:} An angle formed when one line meets another to create two equal angles (90 degrees each).
                \item \textbf{Perpendicular lines:} Two lines that meet to form a right angle.
                \item \textbf{Obtuse angle:} An angle larger than a right angle (greater than 90 degrees).
                \item \textbf{Acute angle:} An angle smaller than a right angle (less than 90 degrees).
                \item \textbf{Boundary:} The edge or limit of an object.
                \item \textbf{Figure:} A shape that is enclosed by boundaries.
                \item \textbf{Circle:} A shape where all points on the boundary (the circumference) are the same distance from a central point.
                \item \textbf{Center of a circle:} The point that is equidistant from every point on the circle’s boundary.
                \item \textbf{Diameter of a circle:} A straight line passing through the center of a circle that touches the boundary on both sides.
                \item \textbf{Semicircle:} Half of a circle, defined by dividing a circle along its diameter.
                \item \textbf{Segment of a circle:} A region of a circle bounded by a chord (a straight line) and the arc it cuts off.
                \item \textbf{Polygon (rectilinear figure):} A shape enclosed by straight lines.
                \item \textbf{Triangle:} A polygon with three sides.
                \item \textbf{Quadrilateral:} A polygon with four sides.
                \item \textbf{Polygon (multilateral figure):} A shape with more than four sides.
                \item \textbf{Equilateral triangle:} A triangle where all three sides are equal in length.
                \item \textbf{Isosceles triangle:} A triangle where two sides are equal in length.
                \item \textbf{Scalene triangle:} A triangle where all three sides are of different lengths.
                \item \textbf{Right triangle:} A triangle with one right angle (90 degrees).
                \item \textbf{Obtuse triangle:} A triangle with one obtuse angle (greater than 90 degrees).
                \item \textbf{Acute triangle:} A triangle where all angles are acute (less than 90 degrees).
                \item \textbf{Parallel lines:} Two straight lines in the same plane that, no matter how far extended, will never meet
            \end{enumerate}
        \item \textbf{Postulates rephrased}
            \begin{enumerate}
                \item It is possible to draw a straight line connecting any two points.
                \item A finite straight line can be extended indefinitely in a straight line.
                \item A circle can be drawn with any center and any radius.
                \item All right angles are equal to each other.
                \item If a straight line intersects two straight lines such that the interior angles on one side add up to less than two right angles, then the two straight lines, if extended indefinitely, will meet on the side where the angles are less than two right angles.
            \end{enumerate}
        \item \textbf{Axioms rephrased}:
            \begin{enumerate}
                \item Things equal to the same thing are equal to each other.
                \item If equals are added to equals, the results are equal.
                \item If equals are subtracted from equals, the remainders are equal.
                \item Things that overlap or coincide exactly are equal.
                \item The whole is greater than any of its parts.
            \end{enumerate}
        \item \textbf{More on Euclids 5th postulate}: Unlike the other four postulates, the 5th postulate is more complex and less intuitive. It essentially describes the behavior of parallel lines, but its wording led mathematicians to wonder if it could be derived from the other postulates.
            \bigbreak \noindent 
            For centuries, mathematicians like Proclus, Ptolemy, and others tried to prove the 5th postulate as a theorem based on the other four postulates. These attempts were unsuccessful, as the postulate is independent.
            \bigbreak \noindent 
            In the 19th century, mathematicians like Lobachevsky, Bolyai, and Gauss explored what happens if the 5th postulate is replaced with different assumptions. This led to the development of non-Euclidean geometries:
            \begin{itemize}
                \item \textbf{Hyperbolic geometry:} There are infinitely many parallel lines through a point not on a given line.
                \item \textbf{Elliptic geometry:} No parallel lines exist.
            \end{itemize}
            The questioning of the 5th postulate revolutionized mathematics, leading to a broader understanding of geometry and the realization that Euclidean geometry is just one of many possible systems.
            \bigbreak \noindent 
            Observe Euclids 5th postulate
            \bigbreak \noindent 
            \fig{.2}{./figures/21.png}
        \item \textbf{ Playfair's Postulate}: Is an equivalent form of Euclid's 5th postulate which states 
            \begin{quote}
                "Through a given point not on a line, there is exactly one line parallel to the given line"
            \end{quote}
    \end{itemize}

    \pagebreak 
    \subsection{Five examples}
    \begin{itemize}
        \item \textbf{The Euclidean plane}: The Euclidean plane is a two-dimensional geometric space that forms the foundation of Euclidean geometry, as described in Euclid's Elements. It is characterized by the following properties
            \begin{enumerate}
                \item \textbf{Flat Surface:} The Euclidean plane is flat, meaning it has no curvature.
                \item \textbf{Points and Lines:} It consists of an infinite set of points. Straight lines can be drawn to connect any two points, and these lines extend infinitely in both directions.
                \item \textbf{Distance and Angles:} Distance between points is measured using the Euclidean distance formula. Angles are measured in degrees or radians.
                \item \textbf{Postulates:} The plane follows Euclid’s postulates, including the 5th (parallel postulate), which ensures the uniqueness of parallel lines.
                \item \textbf{Coordinate Representation:} Often represented using the Cartesian coordinate system, where every point is defined by an ordered pair $(x,y)$
                \item \textbf{Dimensions:} It has two dimensions: length and width.
            \end{enumerate}
            Note that the 2-dimensional cartesian plane is a mathematical representation of the Euclidean plane using a coordinate system.
            The Euclidean plane is a more general geometric concept, while the Cartesian plane provides a numerical framework (coordinates) for working with Euclidean geometry. In practical applications, the Cartesian plane is often used to model the Euclidean plane
            \bigbreak \noindent 
            Let $\mathbb{E}$ denote the Euclidean plane. 
            \bigbreak \noindent 
            \textbf{Coordinates}: The points in $\mathbb{E}$ are in one-to-one correspondence with the ordered pairs of real numbers. Each point $A$ corresponds to a pair of real numbers $(x,y)$, called the \textit{coordinates} of $A$, where the pair is assigned in the familiar way
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{e1}
                \label{fig:e1}
            \end{figure}
            We often identify $A$ with its pair of coordinates $(x,y)$
            \bigbreak \noindent 
            \textbf{Equations of lines}: Each \textit{nonvertical line} $\ell$ in $\mathbb{E}$ consists of all points $(x,y)$, where $y = mx + b$ for some fixed $m$ and $b$. each \textit{vertical line} $\ell$ consists of all $(x,y)$, where $x=a$ for some fixed $a$
            \bigbreak \noindent 
            For any two points $A(x_{1}, y_{1})$ and $B(x_{2}, y_{2})$, the \textit{slope} of the line $\ell$ through $A$ and $B$ is 
            \begin{align*}
                m  = \frac{y_{2} - y_{1}}{x_{2} - x_{1}} \quad (\text{if } x_{2} \ne x_{1})
            \end{align*}
            And an equation for $\ell$ is given by 
            \begin{align*}
                y-y_{1} = m(x - x_{1}) \quad (\text{if } x_{2} \ne x_{1})
            \end{align*}
            The \textit{Euclidean distance} $e(AB)$ between $A$ and $B$ satisfies the formula 
            \begin{align*}
                e(AB) = \sqrt{(x_{2} - x_{1})^{2} + (y_{2} - y_{1})^{2}}
            \end{align*}
            \begin{figure}[ht]
                \centering
                \incfig{e2}
                \label{fig:e2}
            \end{figure}
            \bigbreak \noindent 
            Then 
            \begin{align*}
                (e(AB))^{2} &= (x_{2} -x_{1})^{2} + (y_{2} - y_{1})^{2} \\
                e(AB) &= \sqrt{(x_{2} - x_{1})^{2} + (y_{2} - y_{1})^{2}}
            \end{align*}
        \item \textbf{More on Euclidean distance}
            \bigbreak \noindent 
            \textbf{Proposition 1.1} If $A(x_{1}, y_{1})$ and $B(x_{2}, y_{2}) $ are on the line $y=mx+b$, then $e(AB) = \abs{x_{1} - x_{2}}\sqrt{m^{2} + 1}$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A(x_{1}, y_{1})$ and $B(x_{2}, y_{2}) $ are on the line $y=mx+b$, and $e(AB) = \sqrt{(x_{2} - x_{1})^{2} + (y_{2} - y_{1})^{2}}$. Observe that the slope $m$ of the line is given by
            \begin{align*}
                m = \frac{y_{2} - y_{1}}{x_{2} - x_{1}}
            \end{align*}
            Which implies 
            \begin{align*}
                y_{2} - y_{1} = m(x_{2} - x_{1})
            \end{align*}
            Plugging this expression for $y_{2} -y_{1}$ into $e(AB)$ yields
            \begin{align*}
                e(AB) &= \sqrt{(x_{2} - x_{1})^{2} + (m(x_{2}-x_{1}))^{2}} \\
                      &= \sqrt{(x_{2} - x_{1})^{2} + (m^{2}(x_{2}-x_{1})^{2})} \\
                      &= \sqrt{(x_{2}-x_{1})^{2}[1 + m^{2}]} \\
                      &= \sqrt{(x_{2} - x_{1})^{2}} \cdot \sqrt{m^{2} + 1} \\
                      &= \abs{x_{2} - x_{1}} \sqrt{m^{2} + 1} 
            \end{align*}
            As desired \hspace*{\fill}$\blacksquare$ 
        \item \textbf{The Minkowski plane, or taxicab plane}: Let $\mathbb{M}$ denote the Minkowski plane. $\mathbb{M}$ has the same points, lines, and coordinates as $\mathbb{E}$, but distance is different. For any $A(x_{1}, y_{1})$ and $B(x_{2}, y_{2})$, define the \textit{Minkowski distance} $d_{\mathbb{M}}$ as
            \begin{align*}
                d_{\mathbb{M}} = \abs{x_{2} - x_{1}} + \abs{y_{2} - y_{1}}
            \end{align*}
            Thus, the \textit{Minkowski distance} $d_{\mathbb{M}}(AB)$ is defined as the sum of the horizontal and vertical "ordinary distances"
            \bigbreak \noindent 
            For example, consider $A(1,2), B(-1,-3)$, then 
            \begin{align*}
                d_{\mathbb{M}}(AB) &= \abs{-1-1} + \abs{-3-2} = 7
            \end{align*}
        \item \textbf{More on Minkowski distance}:
            \bigbreak \noindent 
            \textbf{Proposition 1.2} If $A(x_{1}, y_{1})$ and $B(x_{2}, y_{2}) $ are on the line $y=mx+b$, then $d_{\mathbb{M}}(AB) = \abs{x_{1} - x_{2}}(1+\abs{m})$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A(x_{1}, y_{1})$ and $B(x_{2}, y_{2}) $ are on the line $y=mx+b$, and $d_{\mathbb{M}} = \abs{x_2-x_1} + \abs{y_{2} - y_{1}}$. Observe that the slope $m$ of the line is given by
            \begin{align*}
                m = \frac{y_{2}-y_{1}}{x_{2} - x_{1}}
            \end{align*}
            Which implies 
            \begin{align*}
                y_{2} - y_{1} = m(x_{2} - x_{1})
            \end{align*}
            Plugging this expression for $y_{2} -y_{1}$ into $d_{\mathbb{M}}$ yields
            \begin{align*}
                d_{\mathbb{M}} &= \abs{x_{2} - x_{1}} + \abs{y_{2} - y_{1}} \\
                               &= \abs{x_{2} - x_{1}} + \abs{m(x_{2} - x_{1})} \\
                               &= \abs{x_{2} - x_{1}} + \abs{m}\abs{x_{2} - x_{1}} \\
                               &= \abs{x_{2} - x_{1}}(1 + \abs{m}) \\
                               &= \abs{-(x_{1} - x_{2})} (1 + \abs{m}) \\
                               &= \abs{-1}\abs{x_{1} - x_{2}} (1 + \abs{m}) \\
                               &= \abs{x_{1} - x_{2}} (1 + \abs{m}) \\
            \end{align*}
            As desired \hspace*{\fill} $\blacksquare$
        \item \textbf{The spherical plane}: Let $\mathbb{S}(r)$ denote the surface of the sphere of radius $r$; that is, the \textit{spherical plane}.
            \bigbreak \noindent 
            Once $r$ is fixed, we shorten the notation to $\mathbb{S}$. We shall assume that our spheres are centered at the origin $(0,0,0)$ in three-dimensional space. Then $\mathbb{S}$ is the set of all $(x,y,z)$ such that $x^{2} + y^{2} + z^{2} = r^{2} $. Points are as usual, and lines on $\mathbb{S}$ are defined to be the \textit{great circles}. A great circle is the intersection of the sphere with a plane that cuts the sphere in half. Then, any two points have a unique line joining them, unless they are oppoosite (antipodes). In this case, they have infinitely many lines joining them.
            \bigbreak \noindent 
            \textbf{Distance in $\mathbb{S}$}: For points $A,B$ on $\mathbb{S}$, define distance
            \begin{align*}
                d_{\mathbb{S}}(AB) = &\text{ length of the minor (shorter) arc of the} \\
                                     &\text{ great circle (line) through $A$ and $B$}
            \end{align*}
            To compute $d_{\mathbb{S}}(AB)$ more easily, we must recall the forumula for the \textit{arc length in a circle of radius $r$}. Let $\theta$ be the radian measure of $\angle POQ$. The angle that sweeps out the full circle has measure $2\pi$, and the circumference is $2\pi r $. The sector formed by $\angle POQ$ makes up $\frac{\theta}{2\pi}$ of the full circle, so
            \begin{align*}
                \text{arc length } PQ = \frac{\theta }{2\pi} \cdot 2\pi r = \theta  r
            \end{align*}
            \bigbreak \noindent 
            An explicit formula for the spherical distance between two points, in terms of their coordinates, is given next. It follows from the distance formula for three-dimensional space and the Law of Cosines.
            \bigbreak \noindent 
            If $P(a,b,c)$ and $Q(x,y,z)$ are points on the surface of the sphere of radius $r$ centered at $(0,0,0)$ then
            \begin{align*}
                d_{\mathbb{S}} = r\cos^{-1}{\left(\frac{ax+by+cz}{r^{2}}\right)}
            \end{align*}
            \bigbreak \noindent 
            First, recall the law of cosines
            \begin{remark}
               \textit{(Law of Cosines.)} 
            \end{remark}
            \begin{figure}[ht]
                \centering
                \incfig{loc}
                \label{fig:loc}
            \end{figure}
            \bigbreak \noindent 
            In trigonometry, the \textbf{law of cosines} (also known as the \textit{cosine formula} or \textit{cosine rule}) relates the lengths of the sides of a triangle to the cosine of one of its angles. For a triangle with sides $a$, $b$, and $c$, opposite respective angles $\alpha$, $\beta$, and $\gamma$ (see Fig.~1), the law of cosines states:
            \[
                c^2 = a^2 + b^2 - 2ab \cos \gamma,
            \]
            \[
                a^2 = b^2 + c^2 - 2bc \cos \alpha,
            \]
            \[
                b^2 = a^2 + c^2 - 2ac \cos \beta.
            \]
            The law of cosines generalizes the Pythagorean theorem, which holds only for \textbf{right triangles}: if $\gamma$ is a right angle then $\cos \gamma = 0$, and the law of cosines reduces to:
            \[
                c^2 = a^2 + b^2.
            \]
            The law of cosines is useful for solving a triangle when all three sides or two sides and their included angle are given. $\qed $
            \bigbreak \noindent 
            Consider the points $P(a,b,c)$ and $Q(x,y,z)$ and the line (great circle) connecting them
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{gc}
                \label{fig:gc}
            \end{figure}
            \bigbreak \noindent 
            Let $d$ be the Euclidean distance $PQ$ and $\theta$ be the radian measure of $\angle POQ$. By the law of cosines,
            \begin{align*}
                d^{2} &= r^{2} + r^{2} - 2r^{2}\cos{\left(\theta \right)} \\
                \implies \cos{\left(\theta \right)} &= \frac{d^{2} - r^{2} - r^{2}}{-2r^{2}} = \frac{d^{2} - 2r^{2}}{-2r^{2}} = \frac{2r^{2}-d^{2}}{2r^{2}}
            \end{align*}
            The Euclidean distance $d$ is given by
            \begin{align*}
                d &= \sqrt{(x-a)^{2} + (y-b)^{2} + (z-c)^{2}} \\
                  &= \sqrt{x^{2} + y^{2} + z^{2} + a^{2} + b^{2} + c^{2} - 2ax -2by - 2cz}
            \end{align*}
            Thus,
            \begin{align*}
                \cos{\left(\theta \right)} &= \frac{2r^{2} - \left(\sqrt{x^{2} + y^{2} + z^{2} + a^{2} + b^{2} + c^{2} - 2ax -2by - 2cz}\right)^{2}}{2r^{2}} \\
                                           &= \frac{2r^{2} -x^{2}-y^{2}-z^{2}-a^{2}-b^{2}-c^{2}+2ax+2by+2cz}{2r^{2}}
            \end{align*}
            Observe that since points $P,Q$ lie on a sphere, they must obey the equations
            \begin{align*}
                x^{2} + y^{2} + z^{2} = r^{2}
            \end{align*}
            Thus, since $P$ is given by the pair $(a,b,c)$, and $Q$ is given by $(x,y,z)$, we have
            \begin{align*}
                a^{2} +b^{2} + c^{2} &=r^{2} \\
                x^{2} + y^{2} + z^{2} &= r^{2}
            \end{align*}
            Thus,
            \begin{align*}
                \cos{\left(\theta \right)}  &= \frac{2r^{2} -x^{2}-y^{2}-z^{2}-a^{2}-b^{2}-c^{2}+2ax+2by+2cz}{2r^{2}} \\
                                        &= \frac{r^{2} + r^{2} -x^{2}-y^{2}-z^{2}-a^{2}-b^{2}-c^{2}+2ax+2by+2cz}{2r^{2}} \\
                                        &= \frac{a^{2} + b^{2} + c^{2} + x^{2} + y^{2} + z^{2} -x^{2}-y^{2}-z^{2}-a^{2}-b^{2}-c^{2}+2ax+2by+2cz}{2r^{2}} \\
                                        &= \frac{2ax+2by+2cz}{2r^{2}} \\
                                        &=\frac{2(ax+by+cz)}{2r^{2}} \\
                                        &= \frac{ax+by+cz}{r^{2}}
            \end{align*}
            Since $d_{\mathbb{S}} = r\theta$, we finally arrive at the expression
            \begin{align*}
                d_{\mathbb{S}} &= r\theta  = r\cos^{-1}{\left(\frac{ax+by+cz}{r^{2}}\right)}
            \end{align*}
            As desired \hspace*{\fill} $\blacksquare$
            \bigbreak \noindent 
            \textbf{Note:} There are no parallel lines in $\mathbb{S}$, any two great circles meet at a pair of antipodes.
        \item \textbf{The chords of a circle}: A chord of a circle is a straight line segment whose endpoints lie on the circle. In other words, it is a line segment that connects two points on the circumference of a circle
        \item \textbf{The hyperbolic plane (Poincare disk model)}: Let $\mathbb{H}$ denote the hypebolic plane, which is the set of all points inside (but not on) the unit circle in $\mathbb{E}$. That is, all $(x,y)$ with $x^{2} + y^{2} < 1 $
            \bigbreak \noindent 
            Lines in $\mathbb{H}$ are defined to be the chords of the circle.
            \bigbreak \noindent 
            \textbf{Distance:} If $A,B$ are two points in $\mathbb{H}$, define $d_{\mathbb{H}}(AB)$, the distance between them in $\mathbb{H}$ as follows: Draw the chord $AB$, and let $M,N$ be the points where the chord meets the unit circle ($M,N$ are in $\mathbb{E}$ but not $\mathbb{H}$). label so that $B $ separates $A$ and $N$.
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{hyper}
                \label{fig:hyper}
            \end{figure}
            \bigbreak \noindent 
            Let $e(PQ)$ denote the usual Euclidean distance between points, and define
            \begin{align*}
                d_{\mathbb{H}}(AB) = \ln{\left(\frac{e(AN)e(BM)}{e(AM)e(BN)}\right)}
            \end{align*}
            Since $e(AN)>e(BN)$ and $e(BM) > e(AM)$, we have $\frac{e(AN)}{e(BN)} > 1$ and $\frac{e(BM)}{e(AM)} > 1$. Hence $\frac{e(AN)e(BM)}{e(AM)e(BN)}  = \frac{e(AN)}{e(BN)} \cdot \frac{e(BM)}{e(AM)}> 1$. It follows from a property of ln that $d_{\mathbb{H}}(AB) > 0$. Note that $d_{\mathbb{H}}(AB) = d_{\mathbb{H}(BA)}$. Also,
            \begin{align*}
                d_{\mathbb{H}}(AB) = \bigg\lvert \ln{\left(\frac{e(AN)e(BM)}{e(AM)e(BN)}\right)} \bigg\rvert = \bigg\lvert \ln{\left(\frac{e(AM)e(BN)}{e(AN)e(BM)}\right)} \bigg\rvert
            \end{align*}
            So if absolute value is used in this way, then we need not worry about which point on the unit circle is marked $M$ and which is marked $N$.
            \bigbreak \noindent 
            If $A=B$ in $\mathbb{H}$, take any chord through $A$ and let $M,N$ be as previously. Since $\frac{e(AN)e(AM)}{e(AM)e(AN)} =1$, it is consistent with the preceding definition to set $d_{\mathbb{H}}(AA) = 0$.
            \bigbreak \noindent 
            We note that $N$ using the distance formula above is always the point from $A$ through $B$, and the point $M$ is the point from $B$ through $A$. With this in mind, it is clear that $\frac{e(AN)e(BM)}{e(AM)e(BN)} \to \infty$ as we move $A$ and $B$ closer to the opposing sides of the unit circle. Since $\ln:\ (0,\infty) \to \mathbb{R}$, and we noted earlier that $\frac{e(AN)e(BM)}{e(AM)e(BN)} > 1$, distances in the hyperbolic plane can get arbitrary large or small, without bound.
            \bigbreak \noindent 
            Further, Euclids 5th postulate/Playfairs postulate is  false on the hyperbolic plane. Observe
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{e5}
                \label{fig:e5}
            \end{figure}
            \fc{Euclids fifth postulate does not hold on the hyperbolic plane}
            \bigbreak \noindent 
            These lines will never meet, because they are stopped by the unit circle boundary. Further, they will in a sense continue on forever, because distances can get arbitrarily large
            \bigbreak \noindent 
            Also,
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{play}
                \label{fig:play}
            \end{figure}
            \bigbreak \noindent 
            We see that given a point $P$ not on the line $\ell$, there are many lines through $P$ that are parallel to $\ell$. All of these lines are parallel to $\ell$, because they will never intersect with $\ell$
        \item \textbf{The gap plane}: Let $\mathbb{G}$ denote the \textit{gap}, or \textit{missing strip} plane. The points of $\mathbb{G}$ are all those of $\mathbb{E}$ except those $(x,y)$ with $0< x \leq 1$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{gap}
                \label{fig:gap}
            \end{figure}
            So the $y$-axis is part of $\mathbb{G}$, but the line $x=1$ is not (and neither is any vertical line $x=a$ for $0 < a < 1$)
            \bigbreak \noindent 
            Lines in $\mathbb{G}$ are defined to be the same as in $\mathbb{E}$, except that for any nonvertical line $y=mx+b$, the part in the missing strip is deleted. So a typical nonvertical line $\ell$ consists of all $(x,y)$ with $y=mx+b$ ($m,b$ fixed) and with $x \leq 0$ or $x > 1$
            \bigbreak \noindent 
            Behold a line in $\mathbb{G}$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{behold}
                \label{fig:behold}
            \end{figure}
            \bigbreak \noindent 
            \textbf{Distance:} For points $A,B$ in $\mathbb{G}$, we define $d_{\mathbb{G}}(AB)$ as follows. First; if $A$ and $B$ lie on opposite sides of the gap, let $C$ be the point where segment $\overline{AB} $ meets the $y$-axis, and $D$ the point where $\overline{AB}$ meets the vertical line $x=1$ ($D$ is not in $\mathbb{G}$)
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{ex1}
                \label{fig:ex1}
            \end{figure}
            \bigbreak \noindent 
            Now define
            \begin{align*}
                d_{\mathbb{G}}(AB) = \begin{cases}
                    e(AB) & \text{ for $A,B$ on the same side of the gap} \\     
                    e(AB) - e(CD) & \text{ for $A,B$ on the opposite sides of the gap} 
                \end{cases}
            \end{align*}
        \item \textbf{Interior and Exterior angles}: Interior angles are the angles inside the triangle. Each vertex of the triangle has one interior angle. The sum of the interior angles of a triangle is always $180^{\circ}$
            \bigbreak \noindent 
            Exterior angles are the angles formed outside the triangle when one side of the triangle is extended.
            At each vertex, an exterior angle is supplementary to the interior angle (they add up to $180^{\circ} $
            \bigbreak \noindent 
            If an interior angle at a vertex is $A$, the corresponding exterior angle $E$ is:
            \begin{align*}
                E = 180^{\circ} - A
            \end{align*}
            \bigbreak \noindent 
            The sum of the exterior angles of a triangle (one at each vertex) is always $360^{\circ}$ , regardless of the shape of the triangle.
            \bigbreak \noindent 
            \fig{.8}{./figures/23.png}
        \item \textbf{Remote angles}: Remote angles refer to the interior angles of a triangle that are not adjacent to a given exterior angle
        \item \textbf{More on points}:
            \begin{itemize}
                \item \textbf{Collinear points}: Points that lie on the same straight line.
                \item \textbf{Noncollinear points}: Points that do not lie on the same straight line.
                \item \textbf{Coplanar points}: Points that lie on the same plane.
                \item \textbf{Concurrent Points}: Points where three or more lines intersect.
                \item \textbf{Equidistant Points}: Points that are all the same distance from a particular point or object.
                \item \textbf{Lattice Points}:  Points with integer coordinates.
                \item \textbf{Interior points:} Points that lie inside a given shape.
                \item \textbf{Exterior points:} Points that lie outside a given shape.
            \end{itemize}
        \item \textbf{Congruent triangles}: Congruent triangles are triangles that are exactly the same in shape and size. This means that all corresponding sides and angles of one triangle are equal to those of the other triangle.
        \item \textbf{Vertical (opposite) angles}: Vertical angles (also called opposite angles) are the angles that are formed by two intersecting lines and are opposite to each other
        \item \textbf{Reading angle notation}: Suppose you have an angle $\angle ABC$. This angle refers to the angle formed at vertex $B$ by the two line segments or rays:
            \bigbreak \noindent 
            One extending from $B$ to $A$, the other extending from $B$ to $C$. The middle letter, $B$, always represents the vertex of the angle (the point where the two lines meet).
            \bigbreak \noindent 
            \textbf{Note:} If there’s no ambiguity about which angle is being referred to, the angle might simply be denoted as $\angle B$.
        \item \textbf{Potential dangers and the exterior angle inequality}:
            \bigbreak \noindent 
            \textbf{Theorem (\textit{Exterior angle inequality})}: An exterior angle of a triangle is greater than either remote interior angle. That is, if $\triangle ABC$ is a any triangle, and point $D$ is on the extension of segment $\overline{BC}$ through $C$, then
            \begin{align*}
                \angle ACD > \text{ both } \angle A \text{ and } \angle B
            \end{align*}
            \bigbreak \noindent 
            \textbf{Background facts that are ok for both $\mathbb{E}$ and $\mathbb{S}$}
            \begin{enumerate}
                \item \textbf{Triangles:} Line segments that join any three noncollinear points
                \item \textbf{Angle measures}: Are defined for every angle
                \item \textbf{Vertical angles}: Have equal measure
                \item \textbf{side-angle-side}: Criterion for congruent triangles, If two sides and the angle between them in one triangle are equal to the corresponding parts in another triangle, the triangles are congruent.
            \end{enumerate}
            \bigbreak \noindent 
            Consider the triangle 
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{tri3}
                \label{fig:tri3}
            \end{figure}
            \bigbreak \noindent 
            \textbf{\textit{Euclid's proof of EAI}}: Let $ M$ be the midpoint of $\overline{AC}$ so $\overline{AM} = \overline{CM}$. Next, extend $\overline{BM}$ through $M$ to point $E$ such that $\overline{MB} = \overline{ME}$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{tri4}
                \label{fig:tri4}
            \end{figure}
            \bigbreak \noindent 
            Notice that since $\angle AMB$ and $\angle CME$ are vertical, they must be equal. That is, $\angle AMB = \angle CME$. Since 
            \begin{enumerate}
                \item $AM = CM $
                \item $MB = ME$
                \item $\angle AMB = \angle CME $
            \end{enumerate}
            We have met the side-angle-side criterion for congruent triangles. Thus, $\triangle AMB \cong \triangle CME$. Consequently, we have $\angle BAM = \angle ECM $. Further, notice that
            \begin{align*}
                \angle ACD &= \angle ACE + \angle ECD \\
                            &= \angle ECM + \angle ECD \\
                           &= \angle BAM + \angle ECD > \angle BAM = \angle A
            \end{align*}
            Thus, $\angle ACD > \angle A$. To show $\angle ACD > \angle B$, first, extend $AC$ through $C$ to point $F$, forming  $\angle BCF$. Notice that since $\angle ACD$ and $\angle BCF$ are vertical, they must be equal. That is, $\angle ACD = \angle BCF$ 
            \bigbreak \noindent 
            Next, let $N$ be the midpoint of $BC$ such that $BN = CN$. Extend $A$ through $N$ to point $G$ such that $AN=GN$.
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{tri5}
                \label{fig:tri5}
            \end{figure}
            \bigbreak \noindent 
            Note that since $\angle ANB$ and $\angle CNG$ are vertical, they are equal. That is, $\angle ANB = \angle CNG$. Further, since we have
            \begin{enumerate}
                \item $\angle ANB = \angle CNG $
                \item $AN = GN $
                \item $BN = CN$
            \end{enumerate}
            We have congruence, $\triangle ANB \cong \triangle CNG$. Thus, $\angle ABN = \angle NCG$. Therefore,
            \begin{align*}
                \angle ACD = \angle BCF &= \angle BCG + \angle GCF \\
                                        &= \angle NCG + \angle GCF \\
                                        &= \angle ABN + \angle GCF > \angle ABN = \angle B
            \end{align*}
            \bigbreak \noindent 
            Thus, we have shown that $\angle ACD > \angle A$ and $\angle B$ \hspace*{\fill} $\blacksquare$
            
    \end{itemize}

    \pagebreak 
    \subsection{Intro to geometric proofs and some set theory}
    \begin{itemize}
        \item \textbf{Transversal}: a transversal is a line that passes through two lines in the same plane at two distinct points.
        \item \textbf{Relationship of angles}: Consider the transversal configuration
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{tc}
                \label{fig:tc}
            \end{figure}
            \bigbreak \noindent 
            We see that we get eight formed angles.
            \begin{itemize}
                \item \textbf{Interior angles}: Interior angles are the angles that are inside the transversal configuration. Angles $a,b,c,d$ are interior
                \item \textbf{Exterior angles}: Exterior angles are the angles that are inside the transversal configuration. Angles $e,f,g,h$ are exterior
                \item \textbf{Consecutive interior angles}: Pairs of interior angles that are on the same side of the transversal. Angles $c,d$ are consecutive interior, and $a,b$ are consecutive interior
                \item \textbf{Consecutive exterior angles}: Pairs of exterior angles that are on the outside of the transversal configuration. Angles $e,g$ are consecutive exterior, angles $f,h$ are consecutive exterior
                \item \textbf{Alternate interior angles}: Pairs of interior angles that are on opposite sides but not complementary, angles $b,d$ and $a,c$ are alternate interior
                \item \textbf{Alternate exterior angles}: Pairs of exterior angles that are on opposite sides but not complementary, angles $e,h$, and $f,g$ are alternate exterior
                \item \textbf{Vertical angles}: Angles that are opposite each other, formed when two lines intersect. Vertical angles are of equal measure. Pairs $d,h$ - $a,g$ - $e,b$ - and $f,c$ are vertical
                \item \textbf{Supplementary angles}: Angle pairs that sum to 180, pairs $a,h$ - $d,g$ - $f,b$ - and $e,c$ are supplementary
                \item \textbf{Complementary angles}: Angle pairs that sum to 90, none in the transversal configuration
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Proposition (Equal alternate interior angles)}. Suppose $a + b = 180$, then $b = d$, and $c=a $.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Consider the transversal configuration shown above. Assume $a+b = 180$, then $a=180-b$. Since vertical angles are equal, we have $d=h$. But since $a,h$ are supplementary, we have $a + h = 180$, which implies $h = 180 -a$. Thus,
            \begin{align*}
                d = h = 180 - a
            \end{align*}
            Since $a+b = 180$ implies $ b = 180-a$, we have
            \begin{align*}
                 d = h = 180 - a = b
            \end{align*}
            \bigbreak \noindent 
            Thus, $d=b$. Next, we show that $c=a$. Since $c$ and $f$ are vertical, we have $c = f$. Further, since $a + b =180$, we have $a = 180 -b$. Notice that $b$ and $f$ are supplementary, which implies $b + f = 180$, or $f = 180 - b $. So, since $c=f = 180 -b$, and $a = 180-b$, we have $c = f = 180 - b = a$. Thus, $c=a$
            \bigbreak \noindent 
            Therefore, we conclude that if $a+ b =180$, $b = d$ and $c = a $ \hspace*{\fill}$\blacksquare$
        \item \textbf{Background on Euclid's plane without the fifth postulate}:
            \bigbreak \noindent 
            \textbf{Assumptions}:
            \begin{itemize}
                \item Two points determine a unique line
                \item Distances between points on a line include all positive real numbers
                \item Angles are measured
                    \bigbreak \noindent 
                    \begin{figure}[ht]
                        \centering
                        \incfig{supp}
                        \label{fig:supp}
                \end{figure}
                We say that $\alpha$ and $\beta$ are \textit{supplementary} because $\alpha + \beta = 180^{\circ}$. Note that two angles that are supplementary to each other do not have to be next to each other, only the sums of their angles must be $180^{\circ}$. 
                \bigbreak \noindent 
                As a side note, recall that \textit{complementary} angles are angles that sum to $90^{\circ}$
            \end{itemize}
            \bigbreak \noindent 
            \textbf{Definitions}:
            \begin{itemize}
                \item \textbf{Angles}: An angle is formed when two rays meet at a common endpoint, called the vertex.
                \item \textbf{Vertical angles}: Vertical angles (or opposite angles) are the angles formed when two lines intersect.
                \item \textbf{Triangle}: A triangle is a polygon with three sides, three vertices, and three angles.
                    \bigbreak \noindent 
                    The sum of the interior angles of a triangle is always $180^{\circ}$
                    \bigbreak \noindent 
                    A triangle is a closed geometric figure formed by three line segments connecting three non-collinear points
                \item \textbf{Congruent}: Congruent refers to figures or shapes that are identical in size and shape.
                    \bigbreak \noindent 
                    Two triangles are congruent if their corresponding sides and angles are equal (e.g., by SSS, SAS, ASA, or AAS congruence criteria).
                    \bigbreak \noindent 
                    We generally use the side-angle-side criterion to determine congruent triangles.
            \end{itemize}
            \bigbreak \noindent 
            Also, recall the exterior angle theorem proved above.
        \item \textbf{Example of proof by contradiction}: Suppose we are on Euclid's plane without the fifth postulate
            \bigbreak \noindent 
            \textbf{Proposition 1}. Suppose that line $\ell$ crosses $m$ and $n$ so that  the interior angles on one side of $\ell$ add to more than $180^{\circ}$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{p1}
                \label{fig:p1}
            \end{figure}
            \bigbreak \noindent 
            Then, $m,n$ do not meet on that side of $\ell$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume for the sake of contradiction that the statement is false. That is, suppose $m,n$ meet on that side of $\ell$. Then, we must have
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{p2}
                \label{fig:p2}
            \end{figure}
            \bigbreak \noindent 
            Call the point where they meet $C$, since we have three noncollinear points $A,B,C$, $\triangle ABC$ is formed.
            \bigbreak \noindent 
            Define $\angle CBD$ as the exterior angle for $\triangle ABC$, call it measure $\gamma$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{p4}
                \label{fig:p4}
            \end{figure}
            \bigbreak \noindent 
            $\beta$ and $\gamma$ are supplementary, so $\beta + \gamma = 180^{\circ}$. Thus, $\gamma = 180^{\circ} - \beta$. By the EAI, $\gamma > \alpha$, which means $180^{\circ} - \beta > \alpha$. Thus, we have $180^{\circ} > \alpha + \beta$. But, we stated that $\alpha + \beta > 180^{\circ}$, which is a contradiction. 
            \bigbreak \noindent 
            Therefore, by contradiction, are assumption that $m,n$ meet on that side is false, and therefore $m,n$ must not meet on that side.  \hspace*{\fill} $\blacksquare$
            \bigbreak \noindent
        \item \textbf{Upper bounds}: Suppose $S$ is a set of real numbers, we define $b \in \mathbb{R}$ as an \textit{upper bound} for $S$ if for all $x\in S, x \leq b$
            \bigbreak \noindent 
            The negation of this definition is, there exists $x\in S$ such that $x \nleq b$, or $x > b$. Thus, to prove some $b$ is not an upper bound for $S$, we can show that some element of $S$ is greater than $b$
            \bigbreak \noindent 
            There are of course  sets that do not have any upper bounds. Consider the set $S = \{n:\ n\in \mathbb{N} \text{ and } n>0\} $. This set has no upper bound.
            \bigbreak \noindent 
            If $S = \varnothing$, then every $b \in \mathbb{R}$ is an upper bound for $S$. This statement is vacuously true.
        \item \textbf{Least upper bound (supremum)}: $c\in \mathbb{R}$ is a \textit{least upper bound} of a set $S$ of real numbers if 
            \begin{enumerate}
                \item $c$ is an upper bound for $S$
                \item $c \leq b$ for all upper bounds $b$ of $S$
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{Note:} The supremum of a set $S$ is denoted $ b = \text{sup}(S)$, where $b$ is the supremum of the set
        \item \textbf{Least upper bound property of $\mathbb{R}$}: If $S$ is a nonempty set of real numbers that has an upper bound in $\mathbb{R}$, then $S$ has a least upper bound (l.u.b) in $\mathbb{R} $
            \bigbreak \noindent 
            This justifies, among other things, that infinite decimals exist as real numbers, since an infinite decimal can be defined as the least upper bound of the set of all its finite truncations. For example, suppose $S$ is the set of all finite decimal expansions of $\pi$.
            \begin{align*}
                S = \{3,3.1,3.14,3.141, 3.1415,...\}
            \end{align*}
            Then, $S$ as an $l.u.b$ $\pi$, and $\pi\not\in S $
        \item \textbf{Least upper bound proposition}
            \bigbreak \noindent 
            \textbf{Proposition.} Let $S$ be a nonempty set of real numbers that has a least upper bound $b \in \mathbb{R}$. Let $t \in \mathbb{R}$ such that $t < b$. Then, there exists some $s \in S$ such that $t < s \leq b$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $S$ is a nonempty subset of the real numbers with a least upper bound $b$. Let $t\in \mathbb{R}$ such that $t<b$. Since $b$ is a least upper bound of $S$, we have
            \begin{align*}
                \forall \ s \in S,\ s \leq b 
            \end{align*}
            Since $t< b$, $t$ cannot be an upper bound for $S$. If it were, then that would contradict $b$ being the least upper bound. Since $t$ is not an upper bound of $S$, then this implies the existence of some $s\in S$ such that $ t< s$. If this were not the case, then the negation which states, for all $s\in S$, $t \geq s$ would be true. Since the negation implies that $t$ is an upper bound, which we know can't be the case, there must exist some $s\in S$ such that $t < s$. 
            \bigbreak \noindent 
            Since $s \leq b$ for all $s\in S$, and we know that there exists some $s \in S$ such that $t < s$, there must be at least one $s$ that satisfies
            \begin{align*}
                t < s \leq b
            \end{align*}
            \hspace*{\fill} $\blacksquare$
        \item \textbf{Lower bounds}: Let $S$ be a nonempty set of real numbers. Then $g\in \mathbb{R}$ is a \textit{lower bound} for $S$ if $g \leq x$ for all $x\in S$.
        \item \textbf{Greater lower bounds (Infimum)}: $h\in \mathbb{R}$ is a \textit{greatest lower bound}, also called the \textit{infimum}, or \textit{inf} for $S$ if $ h$ is a lower bound for $S$ and $h \geq g$ for all lower bounds $g$ of $S$
        \item \textbf{Infimum proposition}
            \bigbreak \noindent 
            \textbf{Proposition}. Let $S$ be a nonempty set or real numbers that has a lower bound in $\mathbb{R}$. Then $S$ has a infimum in $\mathbb{R}$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $S \subseteq \mathbb{R}$, $S\ne \varnothing$ that has a lower bound in $\mathbb{R}$.
            \bigbreak \noindent 
            Let $B$ be the set of all lower bounds of $S$. Since $S$ has a lower bound, $B$ is nonempty. Define
            \begin{align*}
                B = \{b \in \mathbb{R}: b \leq s \ \forall \ s \in S\}
            \end{align*}
            \bigbreak \noindent 
            We first note that every $s \in S$ serves as an upper bound for $B$. This is because for any $b\in B,\ b \leq s$ for all $s\in S$, thus satisfying the definition of an upper bound
            \bigbreak \noindent 
            Since $B$ is nonempty and bounded above by all elements of $S$, $B$ has a least upper bound (supremum) in $\mathbb{R}$. Let $\lambda$ be this supremum. That is, $\lambda = \text{sup}\ B$. To show that this supremum is precisely the infimum for $S$ is to show two things
            \begin{enumerate}
                \item $\lambda \in B$. That is, $\lambda$ is a lower bound for $S$
                \item $\lambda \geq b$ for all lower bounds $b $ of $S$
            \end{enumerate}
            We begin by showing that $\lambda \in B$. If $\lambda \in B$, then by definition of $B$, $ \lambda \leq s \ \forall \ s \in S$. Assume for the sake of contradiction that there exists some $s \in S$ such that $\lambda > s$. This would contradict the fact that $\lambda$ is the least upper bound for $B$ because then $s$ would be an upper bound for $B$ smaller than $\lambda$. Thus, there are no such $s\in S$ such that $s < \lambda$, and $\lambda$ must therefore be in $B$
            \bigbreak \noindent 
            Next, we show that $\lambda$ is truly the greatest lower bound of $S$, that $\lambda \geq b $ for all lower bounds $b$ of $S$. Assume for the sake of contradiction that there exists some $b \in B$ such that $\lambda < b$. This would mean $\lambda$ is not actually an upper bound for $B$  which again contradicts the fact that $\lambda$ is the supremum of $B$
            \bigbreak \noindent 
            Thus, since $\lambda \in B$, and $\lambda \geq b$ for all $b\in B$. We have that $\lambda$ is the greatest lower bound of $S$, or $\lambda = \text{inf } S $ \hspace*{\fill}$\blacksquare$


    \end{itemize}

    \pagebreak 
    \subsection{An axiom system for geometry: First steps.}
    \begin{itemize}
        \item \textbf{What is projective geometry?} Projective geometry is a branch of geometry where any two distinct lines intersect in exactly one point, meaning there are no parallel lines. It extends Euclidean geometry by adding "points at infinity" to ensure this property holds. Projective geometry focuses on incidence relations (how points and lines are related) rather than distances or angles.
        \item \textbf{What is incidence?} In geometry, "incident" means that a point lies on a line (or a plane, in higher dimensions), or that a line passes through a point. More generally, it describes a fundamental relationship between geometric objects in an incidence structure.
            \bigbreak \noindent 
            For example:
            \begin{itemize}
                \item A point is incident to a line if it lies on that line.
                \item A line is incident to a point if it passes through that point.
                \item In projective geometry, two lines are incident to the same point if they intersect at that point.
            \end{itemize}
            \bigbreak \noindent 
            It is a basic, undefined term in axiomatic geometry, meaning it is taken as a fundamental concept rather than being defined in terms of simpler notions.
        \item \textbf{What is incidence geometry}: Incidence geometry is the study of geometric structures based only on points, lines, and their incidence relations (which points lie on which lines). It focuses on which objects are connected rather than distances, angles, or measurements. The main rules are typically:
            \begin{enumerate}
                \item Any two distinct points determine a unique line.
                \item Any two distinct lines intersect in at most one point.
                \item There exist at least four points, not all on the same line (to avoid trivial cases).
            \end{enumerate}
            \bigbreak \noindent 
            It includes Euclidean, affine, and projective geometries as special cases.

        \item \textbf{The Fano plane}: The Fano plane is a \textit{projective plane of order two.}
            \bigbreak \noindent 
            When we say that the Fano Plane is a projective plane of order two, we mean that
        \begin{itemize}
            \item \textbf{It is a finite projective plane}: – A projective plane is a type of incidence geometry satisfying specific axioms
                \begin{enumerate}
                    \item Any two distinct points determine a unique line.
                    \item Any two distinct lines intersect in a unique point.
                    \item There exist four points, no three of which are collinear (this ensures it is not a degenerate geometry).
                \end{enumerate}
            \item \textbf{Order two ($q = 2$)}: The order of a finite projective plane is a parameter $q$ that determines its structure. The order $q$ is defined by the number of points on each line minus one. In the Fano Plane:
                \begin{enumerate}
                    \item Every line contains exactly  $q+1=3$ points
                    \item Every point is on exactly $q+1 = 3$ lines
                    \item The total number of points is $q^{2} + q + 1 = 2^{2} + 2 + 1 = 7 $
                    \item The total number of lines is $q^{2} + q + 1 = 2^{2} + 2  + 1 = 7 $
                \end{enumerate}
        \end{itemize}
        Since the Fano Plane satisfies these properties for $q=2$, it is called a projective plane of order two.
    \item \textbf{More on the Fano plane}: There are seven points $\{A,B,C,D,E,F,G\}$, and there are seven lines $\{A,B,D\}, \{C,D,F\}, \{A,F,E\}, \{A,C,G\}, \{B,C,E\}, \{B,F,G\}, \{D,E,G\}$
        \bigbreak \noindent 
        There are three points on each line, and three points through each line
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{fano}
            \label{fig:fano}
        \end{figure}
        \bigbreak \noindent 
        Which points on which line? Write points in alphabetical order in three rows, start with $A$, then $B$, then with $D$
        \begin{align*}
            &A \ B \ C \ D \ E \ F \\
            &B \ C \ D \ E \ F \ A\\
            &D \ E \ F \ A B \ C \ \\
        \end{align*}
        Note that the columns give the lines
        \bigbreak \noindent 
        \textbf{Note:} The triangle picture is a good visual aid, but the Fano plane is not part of the Euclidean plane.
    \item \textbf{Coordinates for the Fano plane}: Each point is an ordered triple $(x,y,z) $, where $x,y,z$ are integers mod $2$
        \begin{align*}
            \begin{cases}
            0 & \text{ stands for all even numbers}     \\
            1 & \text{ stands for all odd numbers}     
            \end{cases}
        \end{align*}
        We further note that $\text{odd } + \text{ odd} = \text{ even}$. Or, $1 +1 = 0 $. Other than that it is business as usual... $0+0 =0,\ 1+0 = 0 + 1 =  1$
        \bigbreak \noindent 
        We have the points
        \begin{align*}
            &A(1,0,0) \quad B(1,1,0) \quad D(0,1,0) \quad E(0,0,1) \\
            &C(1,1,1) \quad F(1,0,1) \quad G(0,1,1) \quad \text{No point }:\ (0,0,0)
        \end{align*}
        \bigbreak \noindent 
        Given points $P,Q$, find the third point collinear with $P,Q$. We simply add the coordinate triples for $P,Q$. For example, suppose $A(1,0,0), B(1,1,0)$. Then,
        \begin{align*}
            (1,0,0) + (1,1,0) = (0,1,0) = D
        \end{align*}
    \item \textbf{Distance on the Fano plane}: We define distance for Fano points, but its not Euclidean distance
        \bigbreak \noindent 
        Given points $P,Q$,
        \begin{align*}
            d(PQ) = \text{ number of different respective coordinates}
        \end{align*}
        \bigbreak \noindent 
        For example, $B(1,1,0), G(0,1,1)$ implies $d(BG) = 2 $
    \item \textbf{General finite projective plane}:In general, for a finite projective plane of order  $q$
        \begin{enumerate}
            \item There are $q^{2} + q + 1$ points
            \item There are $q^{2} + q + 1$ lines
            \item Every line contains $q+1$ points
            \item Every point is contained in $q+1$ lines
        \end{enumerate}
        \bigbreak \noindent 
        And satisfies
        \begin{enumerate}
            \item Any two distinct points determine a unique line.
            \item Any two distinct lines intersect at a unique point.
            \item There exist at least four points, no three of which are collinear. (This ensures non-triviality.)
        \end{enumerate}
        Thus, the Fano Plane is the smallest projective plane, and it uniquely exists for order 2.
        \bigbreak \noindent 
        \textbf{Note:} The "projective" part in the name projective plane comes from its connection to projective geometry, which generalizes Euclidean geometry by removing the notion of parallel lines.
    \item \textbf{Fine projective plane with order one?}: a finite projective plane cannot have order $q=1$ because it would not satisfy the axioms of a projective plane.
        \bigbreak \noindent 
        If $q=1$:
        \begin{enumerate}
            \item \textbf{Number of points}: $1^{2} + 1 + 1 =3$
            \item \textbf{Number of lines}: $1^{2} + 1 + 1 =2$
            \item \textbf{Each line has}: $1+1 = 2$ points
            \item \textbf{Each point is on}: $1+1=2$ lines
        \end{enumerate}
        \bigbreak \noindent 
        This configuration forms a triangle, but therefore fails the requirement that a finite projective plane has at least four points (it only has three)
    \item \textbf{Some extra planes}
        \begin{itemize}
            \item \textbf{$\hat{\mathbb{E}}$: The bumpy plane}: Which is $\mathbb{E}$, but warped. Has bumps and depressions, not always flat.
            \item \textbf{$\mathbb{R}^{3}$:} Points, lines, distance of usual 3-dimensional space.
            \item \textbf{$\varnothing$}: Has the components necessary for a plane vacuously
        \end{itemize}
    \item \textbf{Define a plane}: Let's define a plane called $*$, 
        \begin{align*}
            \mathbb{P} &= \{A,B,C,D\} \quad \text{(4 points)} \\
            \mathbb{L} &= \{A,B,C\}, \{A,C,D\}, \{B,D\} \quad \text{3 lines}
        \end{align*}
        With distance function
        \begin{align*}
            \begin{array}{c|cccc}
               &A&B&C&D \\
               \hline
                A&0&1&2&\frac{1}{2} \\
                B&1&0&\frac{3}{2} &\frac{1}{2} \\
                C&2&\frac{3}{2}&0&\frac{3}{2} \\
                D&\frac{1}{2} &\frac{1}{2}&\frac{3}{2}&0
            \end{array}
        \end{align*}
    \item \textbf{Axiom system for plane geometry}: 
        \bigbreak \noindent 
        \textbf{Undefined terms:}
        \begin{itemize}
            \item \textbf{$\mathbb{P}$:} Set of elements, called \textbf{points.}
            \item \textbf{$\mathbb{L}$:} Collection of subsets of $\mathbb{P}$, called \textbf{lines}
            \item A function $d:\ \mathbb{P}\times \mathbb{P} \to \mathbb{R} $, called a \textbf{distance function}
        \end{itemize}
        \bigbreak \noindent 
        Call anything with these components a \textbf{plane}
        \bigbreak \noindent 
        \textbf{Notation, terminology}
        \begin{itemize}
            \item A line is a set of points
            \item If $P$ is on the line $m$ ($P\in m$), we say that "$P$ is on $m$", or "$m$ goes through $P$"
            \item If two or more points are on the same line, we say they are \textbf{collinear}
            \item Denote distance $d(P,Q)$, or $d(PQ)$, or just $PQ$
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Axiom of distance}: For all points $P,Q$
        \begin{enumerate}
            \item $PQ \geq 0 $
            \item $PQ = 0 \iff P=Q $
            \item $PQ = QP $
        \end{enumerate}
        These are true for all planes mentioned so far, even $*$ and $\varnothing $
        \bigbreak \noindent 
        \textbf{The distance set}: Define $\mathbb{D} = \{PQ:\ P,Q \in \mathbb{R}\}$. This is the set of all distances that occur between points of $\mathbb{P}$, with respect to the given distance function.
        \bigbreak \noindent 
        \textbf{The diameter of the plane $\mathbb{P}$, $\omega $}
        \begin{align*}
            \begin{cases}
                \omega = \text{sup}\ \mathbb{D} & \text{ if $\mathbb{D}$ has an upper bound in $\mathbb{R} $}      \\
                \omega = \infty & \text{ if $\mathbb{D}$ has no an upper bound in $\mathbb{R} $}      \\
            \end{cases}
        \end{align*}
        \bigbreak \noindent 
        Note that $\infty$ is not a real number, but we still say $r < \infty$ for all $r\in \mathbb{R} $
        \bigbreak \noindent 
        \[
            \begin{array}{|c|c|c|}
                \hline
                \mathbb{P} & \mathbb{D} & \omega \\
                \hline
                \mathbb{E} & [0, \infty) & \infty \\
                \mathbb{M} & [0, \infty) & \infty \\
                \mathbb{S}(r) & [0, \pi r] & \pi r \\
                \mathbb{H} & [0, \infty) & \infty \\
                \mathbb{G} & [0, \infty) & \infty \\
                \text{Fano} & \{0, 1, 2, 3\} & 3 \\
                \hat{\mathbb{E}} & [0, \infty) & \infty \\
                \mathbb{R}^3 & [0, \infty) & \infty \\
                \varnothing & \varnothing & \times \\
                (*) & \{0, \frac{1}{2}, 1, \frac{3}{2}, 2\} & 2 \\
                \hline
            \end{array}
        \]
        \bigbreak \noindent 
        \textbf{Note:} Whether $\omega$ is a finite number or $ \infty$, each distance $PQ$ is a nonnegative, finite real number
        \bigbreak \noindent 
        Why not assume that two points determine a unique line? That two points are together in exactly one line? The sphere $\mathbb{S}$, which we want to include as a plane, has many lines through two points, when the points are antipodes. These are the points $P,Q$ where $PQ = \pi r = \omega $.
        \bigbreak \noindent 
        Thus, our axioms will allow multiple lines through two points, but only if their distance apart is precisely $\omega$, the diameter of the plane. Note that $P,Q$, with $PQ = \omega$ \textbf{may or may not} have more than one line through them.
        \bigbreak \noindent 
        \textbf{Axioms of incidence}
        \begin{enumerate}
            \item There are at least two different lines
            \item Each line contains at least two different points
            \item Each pair of points are together in at least one line
            \item Each pair of points $P,Q$, with $PQ < \omega$ are together in at most one line
        \end{enumerate}
        \bigbreak \noindent 
        \textbf{Note:} These are true for all discussed planes except $\varnothing$. 1 and 2 are false for $\varnothing $
        \bigbreak \noindent     
    \item \textbf{So what exactly is a plane?}: Based on the provided axioms, the definition of a plane in this system is simply a structure consisting of
        \begin{itemize}
            \item A set of points $\mathbb{P}$
            \item A collection of subsets of $\mathbb{P}$ called lines $\mathbb{L}$
            \item A distance function $d:\ \mathbb{P}\times\mathbb{P}\to\mathbb{R}$.
        \end{itemize}
        \bigbreak \noindent 
        Thus, a set $\mathbb{P}$ and a set of lines $\mathbb{L}$ can be called a plane as long as they fit this definition, regardless of whether they satisfy the axioms of distance or incidence.
        \bigbreak \noindent 
        However, for a plane to behave in a meaningful way in axiomatic geometry (i.e., to be one of the discussed geometric planes like $\mathbb{E}, \mathbb{M}, \mathbb{S}(r)$, etc...) it must satisfy the axioms of distance and incidence. These axioms impose necessary geometric structure, ensuring that distances behave as expected and that lines and points interact according to the incidence rules.
        \bigbreak \noindent 
        Thus, a plane can exist without satisfying the axioms, but to be a meaningful model of geometry, it is typically expected to satisfy them.
    \item \textbf{Plane example}: Consider the plane with $\mathbb{P}:\ $ all points inside the unit circle in $\mathbb{E}$, and $\mathbb{L}$ be the set of all chords inside the circle
        \bigbreak \noindent 
        For points $P,Q$ in $\mathbb{P}$, define $d(PQ) = PQ = e(PQ)$. Ie the Euclidean distance
        \bigbreak \noindent 
        Note that the seven axioms are true statements for this example. 
        \bigbreak \noindent 
        We have $\mathbb{D} = [0,2)$, so $\omega = 2$, but $PQ < 2$ for all $P,Q\in \mathbb{P}$
    \item \textbf{Trivial discrete model (TDM)}: Let $\mathbb{P}$ be any set of at least three elements. Let $\mathbb{L}$ be the collection of all two element subsets of $\mathbb{P} $
        \bigbreak \noindent 
        Define distance as follows: For all $x\ne y \in \mathbb{P}$, 
        \begin{align*}
            \begin{cases}
                xy &= 1 \\
                xx &= 0
            \end{cases}
        \end{align*}
        The seven axioms are true for the TDM. We have $\mathbb{D} = \{0,1\}$, thus $\omega = 1 $
        \bigbreak \noindent 
        For example, if $\mathbb{P} = \{A,B,C\} $, which implies $\mathbb{L} = \{A,B\}, \{A,C\}, \{B,C\} $, which forms a triangle where all sides are of length one.
    \item \textbf{White stripes model (ws)}: Let $\ell, m$ be two parallel lines in $\mathbb{E}$
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{twolines}
            \label{fig:twolines}
        \end{figure}
        \bigbreak \noindent 
        Define $\mathbb{P} = \{\text{all points on $\ell $}\} \cup \{\text{all points on $m$}\}$, and $\mathbb{L} = \ell,m$, and all two point sets $\{P,Q\}$ where $P$ on $\ell$, $Q$ on $m$. Define distance $d = $ Euclidean distance $e(PQ)$
        \bigbreak \noindent 
        Note that the seven axioms are true statements for $ws$, and $\mathbb{D} = [0,\infty),\ \omega = \infty$
        \bigbreak \noindent 
        \begin{figure}[ht]
            \centering
            \incfig{twolines2}
            \label{fig:twolines2}
        \end{figure}





    \end{itemize}

    \pagebreak 
    \subsection{Betweenness, segements, and rays}
    \begin{itemize}
        \item \textbf{Betweenness}: Let $\mathbb{P}$ be a plane with points, lines, distance, and satisfy the seven axioms (3 distance, 4 incidence). Define
            \bigbreak \noindent 
            \textbf{Definition.} Point $B$ lies \textbf{between} points $A$ and $C$, denoted $A-B-C$ provide that
            \begin{enumerate}
                \item $A,B$, and $C$ are different and collinear
                \item $AB + BC = AC $
            \end{enumerate}
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{between2}
                \label{fig:between2}
            \end{figure}
        \item \textbf{Betweenness example 1}: \begin{align*}
                P &= \{A, B, C, D\} \\
                L &= \{\{A, B, C\}, \{A, C, D\}, \{B, D\}\}
            \end{align*}
            \textbf{Distance:}
            \[
                \begin{array}{c|cccc}
  & A & B & C & D \\
  \hline
                    A & 0 & 1 & 2 & \frac{1}{2} \\
                    B & 1 & 0 & \frac{3}{2} & \frac{1}{2} \\
                    C & 2 & \frac{3}{2} & 0 & \frac{3}{2} \\
                    D & \frac{1}{2} & \frac{1}{2} & \frac{3}{2} & 0 \\
                \end{array}
            \]
            \textbf{On line \(\{A, C, D\}\):}
            \begin{align*}
                AC &= 2, \quad AD = \frac{1}{2}, \quad DC = \frac{3}{2} \\
            \end{align*}
            $AD + DC = AC$. Thus, $A - D - C$.
            \bigbreak \noindent 
            \textbf{On line \(\{A, B, C\}\):}
            \begin{align*}
                AB &= 1, \quad AC = 2, \quad BC = \frac{3}{2} \\
            \end{align*}
            No two of these add to the third, so there is \textbf{no betweenness relation} among \(A, B, C\).
        \item \textbf{Betweenness on the Fano plane}: We have the collinear points $A(1,0,0), B(1,1,0), D(0,1,0)$, with 
            \begin{align*}
                AB =1, \quad BD = 1, \quad AD =2
            \end{align*}
            We see $AB + BD = AD$. Thus, $A-B-D$
        \item \textbf{Betweenness on the spherical plane}: Consider points $A, C$, with $A \ne C$, and distance $AC < \omega = \pi r$. So, $A,C$ determine unique great circle (line) $\overleftrightarrow{AC}$. Let $A^{*}$ be the antipode of $A$, and $C^{*}$ be the antipode of $C$. We check all points $B$ on $\overleftrightarrow{AC}$  and see in which locations there is betweenness $A-B-C$.
            \bigbreak \noindent 
            First, consider $B$ on minor arc $\overset{\frown}{AC}$. Notice that the minor arc $\overset{\frown}{AB}$ plus the minor arc $\overset{\frown}{BC}$ equals the minor arc $\overset{\frown}{AC}$. Thus,
            \begin{align*}
                d_{\mathbb{S}}(AB) + d_{\mathbb{S}}(BC) = d_{\mathbb{S}}(AC)
            \end{align*}
            Thus, $A-B-C$
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{minor1}
                \label{fig:minor1}
            \end{figure}
            \bigbreak \noindent 
            Next, let $B$ be on the minor arc $\overset{\frown}{A^{*}C}$. Observe that
            \begin{align*}
               d_{\mathbb{S}}(AC) + d_{\mathbb{S}}(CB) =  d_{\mathbb{S}}(AB)
            \end{align*}
            Thus, $A-C-B $
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{overset}
                \label{fig:overset}
            \end{figure}
            \bigbreak \noindent 
            Next, let $B$ be on the minor arc $\overset{\frown}{C^{*}A}$. Observe that
            \begin{align*}
                d_{\mathbb{S}}(BA) + d_{\mathbb{S}}(AC) = d_{\mathbb{S}}(BC)
            \end{align*}
            Thus, $B-A-C $
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{minorarc3}
                \label{fig:minorarc3}
            \end{figure}
            \bigbreak \noindent 
            Next, let $B$ be on the minor arc $\overset{\frown}{A^{*}C^{*}}$, any two of $d_{\mathbb{S}}(AB), d_{\mathbb{S}}(BC), d_{\mathbb{S}}(AC)  $ add to more than $\pi r $, hence more than any distance on $\mathbb{S} $. Therefore, no two add to the third and $A,B,C$ have no betweenness relation
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{marc1}
                \label{fig:marc1}
            \end{figure}
            \bigbreak \noindent 
            Finally, consider two points $A, A^{*}$, where $A^{*}$ is $A $'s antipode. Let $B$ be any point not equal to $A$ or $A^{*}$. Then, $B$ is collinear with $A, A^{*}$. Observe that
            \begin{align*}
                d_{\mathbb{S}}(AB) + d_{\mathbb{S}}(BA^{*}) = \pi r = d_{\mathbb{S}}(AA^{*})
            \end{align*}
            Thus, $A-B-A^{*} $
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{mior4}
                \label{fig:mior4}
            \end{figure}
        \item \textbf{Betweenness theorem 1}: 
            \bigbreak \noindent 
            \textbf{Proposition}. For a general plane $\mathbb{P}$ with points, lines, distance, and satisfy the seven axioms, $A-B-C \iff C-B-A$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Suppose that $A-B-C$, by definition, $A,B,C$ are different and collinear. Hence, $C,B,A$ are different and collinear, and $AB + BC = AC $
            \bigbreak \noindent 
            By distance axiom three, $AB = BA$, $BC = CB$, and $AC = CA$. Thus,
            \begin{align*}
                AB + BC &= AC \\
                \implies BA + CB &= CA
            \end{align*}
            But by the commutative property of $+$ in $\mathbb{R} $
            \begin{align*}
                BA + CB &= CA \\
                \implies CB + BA &= CA 
            \end{align*}
            Therefore, by the definition of betweenness, $C-B-A$. Thus, by similar steps, if $C-B-A$, then $A-B-C$ \hspace*{\fill} $\blacksquare$
        \item \textbf{Uniqueness Middle Theorem (UMT)}:
            \bigbreak \noindent 
            \textbf{Theorem}: If $A-B-C$ then $B-A-C$ and $A-C-B$ are false.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A-B-C$, then $A,B,C$ are different, collinear, and $AB + BC = AC$. We know by distance axioms $1$ and $2$ that each of $AB, BC$, and $AC$ are greater than zero. Thus,
            \begin{align*}
                AC > AB \quad \text{ and } AC > BC
            \end{align*}
            Suppose for the sake of contradiction that $B-A-C$ is also true. Thus, $BC$ would be larger than both $BA=AB$ and $AC$. 
            \bigbreak \noindent 
            Since this contradicts the fact that $AC > BC$, which must be true if $A-B-C$, it must be that $B-A-C$ is false. By similar steps, $A-C-B$ is also false. \hspace*{\fill} $\blacksquare $ 
        \item \textbf{Betweennes in $\mathbb{M}$}: Suppose $A-B-C$ is true in $\mathbb{E}$. Then, we have in the Minkowski plane
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{bet}
                \label{fig:bet}
            \end{figure}
            \bigbreak \noindent 
            So we see
            \begin{align*}
                d_{\mathbb{M}}(AB) + d_{\mathbb{M}}(BC) &= \left\lvert x_{1} -x_{2} \right\rvert + \left\lvert y_{1} - y_{2} \right\rvert + \left\lvert x_{2} - x_{3} \right\rvert + \left\lvert y_{2} - y_{3} \right\rvert
            \end{align*}
            \bigbreak \noindent 
            We can then drop the absolute value bars by examining the configuration and determining which order the subtraction needs to happen to yield a positive result. We have
            \begin{align*}
                &(x_{2} - x_{1}) + (y_{2} - y_{1}) +(x_{3} -x_{2}) + (y_{3} - y_{2}) \\
                &=(x_{3}-x_{1}) + (y_{3} - y_{1}) = d_{\mathbb{M}}(AC)
            \end{align*}
            Thus, for $ A-B-C$ in $\mathbb{E}$, $A-B-C$ in $\mathbb{M}$ holds true. Similarly, $B-A-C$ in $\mathbb{E}$ implies $B-A-C$ in $\mathbb{M}$, and $A-C-B$ in $\mathbb{E}$ implies $A-C-B$ in $\mathbb{M}$
            \bigbreak \noindent 
            So for three collinear points $A,B,C$ in $\mathbb{E} $, exactly one (by the UMT) of $A-B-C$, $B-A-C$, $A-C-B$ occurs, and each relation implies the same relation happens in $\mathbb{M}$.
            \bigbreak \noindent 
            If $A-B-C$ happens in $\mathbb{M}$, then the other two do not by the UMT,  so only $A-B-C$ will then be true in $\mathbb{E}$. We state
            \begin{align*}
                A-B-C \text{ in } \mathbb{E} \iff A-B-C \text{ in } \mathbb{M}
            \end{align*}
        \item \textbf{Betweenness among the planes}: We have
            \begin{align*}
                A\text{-}B\text{-}C \text{ in } \mathbb{E} \iff $A\text{-}B\text{-}C$ \text{ in } \mathbb{M} \\
                A\text{-}B\text{-}C \text{ in } \mathbb{E} \iff $A\text{-}B\text{-}C$ \text{ in } \mathbb{G} \\
                A\text{-}B\text{-}C \text{ in } \mathbb{E} \iff $A\text{-}B\text{-}C$ \text{ in } \mathbb{H} \\
            \end{align*}
        \item \textbf{Inside out}: Consider $\mathbb{P} = \{A,B,C,D,E,F\}$, $\mathbb{L}:\ \ell = \{A,B,C,D\}, m = \{A,E\}, n  = \{C,E\} , v = \{D,E\} $, and distance
            \begin{align*}
                \begin{array}{c|ccccc}
                   &A&B&C&D&E \\ 
                    A & 0 & 3 & 1 & 2 & 4\\
                    B &  3 & 0 & 2  & 1 & 4\\
                    C &  1 & 2 & 0 & 3 & 4\\
                    D & 2 &1 & 3 & 0 & 4\\
                    E & 4 & 4& 4 & 4 & 0\\
                \end{array}
            \end{align*}
            \bigbreak \noindent 
            \begin{figure}[ht]
                \centering
                \incfig{ic}
                \label{fig:ic}
            \end{figure}
            \bigbreak \noindent 
            The seven axioms hold, $\mathbb{D} = \{0,1,2,3,4\}, \omega = 4$, and all betweenness occurs for points on $\ell$
            \begin{align*}
                A-C-B \quad A-D-B \quad C-A-D \quad C-B-D
            \end{align*}
        \item \textbf{Segments and rays}: Let $A\ne B$ be points in $ \mathbb{P}$ with $AB < \omega $. Then, there is a unique line through $A,B$, call it $ \overleftrightarrow{AB}$ 
            \begin{itemize}
                \item \textbf{The segment} $\overline\{AB\} = \{A,B\} \cup \{X: A-X-B\}$
                \item \textbf{The ray} $\overrightarrow\{AB\} = \{A,B\} \cup \{X: A-X-B\} \cup \{X: A-B-X\}$
            \end{itemize}
            \textbf{Note:} $\{X: A-X-B\} \cup \{X: A-B-X\} = \varnothing$
            \bigbreak \noindent 
            \textbf{Notation}: $\overline{AB}, \overrightarrow{AB}, \overleftrightarrow{AB}$ denote sets of points, with $\{A,B\} \subseteq \overline{AB} \subseteq \overrightarrow{AB} \subseteq \overleftrightarrow{AB}$
        \item \textbf{Segments and rays on $\mathbb{S}$}
            \bigbreak \noindent 
            \fig{.5}{./figures/24.png}
            \bigbreak \noindent 
            Ray $\overrightarrow{AB}$ goes from $A$, through $B$, around to $A^{*}$. Since $A-B-A^{*}$, $\overrightarrow{AB}$ includes $A^{*} $
            \bigbreak \noindent 
            We have 
            \begin{itemize}
                \item \textbf{Segment} $\overline{AB} = \{A,B\} \cup \{X: A-X-B\}$ as usual
                \item \textbf{Ray} $\overrightarrow{AB} = \{A,B\} \cup \{X: A-X-B\} \cup \{X: B-X-A^{*}\} \cup \{A^{*}\}$, where $A^{*}$ is the antipode of $A$
            \end{itemize}

        \item \textbf{Proving results about general (abstract) planes $\mathbb{P}$}: We only use the undefined terms point, line, distance, the definitions, the assumed axioms, previously proved results, arithmetic of $\mathbb{R}$, and logic.
            \bigbreak \noindent 
            Sketches from $\mathbb{E}$, while sometimes useful, are not valid for general proofs. General planes include many examples besides $\mathbb{E}$, and Euclidean pictures may not apply to them, and may be misleading.
            \bigbreak \noindent 
            We assume plane $\mathbb{P}$, in which we have points, lines, and the first seven axioms satisfied.
            \bigbreak \noindent 
            Recall, for points $A\ne B$, $AB < \omega$,
            \begin{itemize}
                \item \textbf{Betweenness}: $A-B-C$ if $A,B,C$ are different, collinear, and $AB + BC = AC $
                \item \textbf{Segment} $\overline{AB} = \{A,B\} \cup \{X: A-X-B\}$
                \item \textbf{Ray} $\overrightarrow{AB} = \{A,B\} \cup \{X: A-X-B\} \cup \{X: A-B-X\}  $
            \end{itemize}
        \item \textbf{Proposition: Segments and lines}:
            \bigbreak \noindent 
            \textbf{Proposition.}
            \begin{enumerate}[label=(\alph*)]
                \item $\overline{AB}$ lies in one line, the line $\overleftrightarrow{AB} $
                \item $\overline{AB} = \overline{BA} $
                \item If $x\in \overline{AB}$, with $X \ne B$, then $AX < AB $
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof}} a.) Since $\overline{AB}$ exists, we have $AB < \omega$. Thus, by incidence axioms three and four, there is exactly one line containing points $A$, and $B$. Namely, $\overleftrightarrow{AB} $. If $X$ is any other point in $\overline{AB}$, then $A-X-B$ by definition of $\overline{AB}$. Thus, $X$ is collinear with $A,B$ by definition of betweenness, and hence, $x \in \overleftrightarrow{AB}$
            \bigbreak \noindent 
            b.) We have
            \begin{align*}
                \overline{AB} &= \{A,B\} \cup \{X: A-X-B\} \tag{1}\\
                \overline{BA} &= \{B,A\} \cup \{X: B-X-A\} \tag{2}\\
            \end{align*}
            But, since ordering in sets doesn't matter, $\{B,A\} = \{A,B\}$, and we have seen previously that $B-X-A = A-X-B$. Thus, (2) is precisely (1). That is, $\{B,A\} \cup \{X: B-X-A\} = \{A,B\} \cup \{X: A-X-B\}$, and therefore $\overline{AB} = \overline{BA} $
            \bigbreak \noindent 
            c.) We have
            \begin{align*}
                \overline{AB} = \{A,B\} \cup \{X: A-X-B\}
            \end{align*}
            Let $x\in \overline{AB} $, with $X\ne B$. Then, we have $A-X-B$, and $AX + XB = AB$. This implies that $AB$ greater than both $AX, XB$, which means $AB > AX$.
            \bigbreak \noindent 
            \textbf{Note}: Ray $\overrightarrow{AB}$ is also contained in exactly one line, the line $\overleftrightarrow{AB}$
            \bigbreak \noindent 
            Also, $\overrightarrow{AB} = \overrightarrow{BA}$ mostly does not hold. We have
            \begin{align*}
                \overrightarrow{AB} &= \{A,B\} \cup \{X: A-X-B\} \cup \{X: A-B-X\} \\
                \overrightarrow{BA} &= \{A,B\} \cup \{X: A-X-B\} \cup \{X: B-A-X\} \\
            \end{align*}
            Since $\{X: A-B-X\} \ne \{X: B-A-X\}$, it  is not generally the case that $\overrightarrow{AB} = \overrightarrow{BA} $ (In general). The scenario where $\overrightarrow{AB} = \overrightarrow{BA} $ is when $\overline{AB}, \overline{BA}$ are exactly the line where they are contained. This fact is true in the IO example, since $\overline{AB} = \overline{BA } = \overline{CD} = \overline{DC} = \{A,B,C,D\} = \ell  $
        \item \textbf{Proposition}
            \bigbreak \noindent 
            \textbf{Proposition}: Let $A,B,C,D$ be collinear points with $0 < AB < \omega$, $0< CD<\omega$, and $\overline{AB} = \overline{CD}$, then
            \begin{enumerate}[label=(\alph*)]
                \item Either $\{A,B\} = \{C,D\}$ or $\{A,B\} \cap \{C,D\} = \varnothing$
                \item $AB = CD$
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof (a)}} Part a says that $\{A,B\}$ and $\{C,D\}$ can have two (all) elements in common, or no elements in common. Thus, we show that it cannot be the case that they have one element in common
            \bigbreak \noindent 
            Suppose for the sake of contradiction that $\{A,B\}$ and $\{C,D\}$ have exactly one element in common. Assume it is $A=C$. Then, $A \ne B$, $B\ne C$, and $B \ne D$. 
            \bigbreak \noindent 
            By definition of a segment, $D \in \overline{CD} = \{AB\}$, which implies $A\text{-}D\text{-}B$ since $D\ne A$ and $D \ne B$. Also, $B \in  \overline{AB} = \overline{CD}$ implies $C\text{-}B\text{-} D$ (since $B \ne C$ and $B \ne D$). But, since $A = C$, we have $C\text{-}B\text{-}D  = A\text{-}B\text{-}D$ which cannot happen by the UMT since we know we have $A\text{-}D\text{-}B $. Thus, our assumption that $A = C$ must be false. A similar argument for the other equality pairs shows that the two sets must not contain exactly one common element.
            \bigbreak \noindent 
            Therefore, $\{A,B\} = \{C,D\}$ or $\{A,B\} \cap \{C,D\} = \varnothing$
            \bigbreak \noindent 
            \textbf{\textit{Proof (b)}} If $\{A,B\} = \{C,D\} $ then $AB = CD$ by substitution. So, we may assume that $\{A,B\} \cap \{C,D\} = \varnothing$. 
            \bigbreak \noindent 
            We have $C,D \in \overline{CD} = \overline{AB}$, and $C,D \ne A \text{ or } B$, which implies $A\text{-}C\text{-} B$ and $A\text{-}D\text{-}B$. Similarly, $A,B \in \overline{AB} = \overline{CD} $ yields $C\text{-}A\text{-}D$ and $C\text{-}B\text{-}D$. Hence, we have $AC + AD = CD$ and $CB +BD = CD$. Adding these two equations and making suitable substitutions  yields $2CD = 2AB$, hence, $CD = AB$
            \endpf
        \item \textbf{Proposition}
            \bigbreak \noindent 
            \textbf{Proposition}. If $A\text{-}B\text{-}C$ and $A\text{-}C\text{-}D$, then $A,B,C,D$ are distinct and collinear 
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Be the definition of betweenness, $A,C,D$ are distinct and collinear, and $AC + CD = AD$. Since $CD > 0$, $AC < AD$. But, since $AD \leq \omega$, it must be that $AC < \omega$. Thus, $A,C$ are together in a unique line  (the line $\overleftrightarrow{AC} $)
            \bigbreak \noindent 
            Also, $A,B,C$ are distinct and collinear. Thus, $B,D$ are both collinear with $A$ and $C$ which implies all four points must be in $\overleftrightarrow{AC}$, and hence they are all collinear.
            \bigbreak \noindent 
            The only way two of $A,B,C,D$ could be equal is if $B =D$. But then, substituting $B$ for $D$ in $A\text{-}C\text{-}D$, we get $A\text{-}C\text{-}B$. This contradicts $A\text{-}B\text{-}C$ and the UMT. Thus, all four points are different. \endpf


    \end{itemize}

    \pagebreak 
    \subsection{Three axioms for the line}
    \begin{itemize}
        \item \textbf{Definition:} Define $A\text{-}B\text{-}C\text{-}D$ to mean the following betweenness relations are all satisfied
            \begin{align*}
                A\text{-}B\text{-}C \quad A\text{-}B\text{-}D \quad A\text{-}C\text{-}D \quad B\text{-}C\text{-}D 
            \end{align*}
            \bigbreak \noindent 
            Also, for collinear points $A,B,C,D$
            \begin{align*}
                A\text{-}B\text{-}C\text{-}D \implies AB + BC + CD = AD
            \end{align*}
        \item \textbf{Proposition.} If $A\text{-}B\text{-}C\text{-}D$, then $A,B,C,D$ are distinct and collinear, and $D\text{-}C\text{-}B\text{-}A $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} $A\text{-}B\text{-}C\text{-}D$ implies $ A\text{-}B\text{-}C$, $ A\text{-}B\text{-}D, A\text{-}C\text{-}D, B\text{-}C\text{-}D$. Since $ A\text{-}B\text{-}C$ and $ A\text{-}C\text{-}D$ are true, then $A,B,C,D$ are distinct and collinear, if we switch the order on the four betweenness relations (first point and last for each of them), we get precisely 
            \begin{align*}
                D\text{-}C\text{-}B\text{-}A
            \end{align*}
            \endpf
        \item \textbf{Betweenness of points axiom (Ax. BP)}: If $A,B,C$ are distinct, collinear points, and if $AB + BC \leq \omega$, then there exists a betweenness relation among $A,B,C$
            \bigbreak \noindent 
            What this is really saying is that if \textbf{any} of $AB + BC$, $BA + AC$, $AC + CB$ is $ \leq \omega$, then there is a betweenness relation.
            \bigbreak \noindent 
            \textbf{Note:} If Ax.BP is true for a plane $\mathbb{P}$, and if $AB + BC \leq \omega$ for distinct collinear $A,B,C$, then there is a betweenness relation, but not necessarily $ A\text{-}B\text{-}C $
            \bigbreak \noindent 
            When $\omega = \infty$, then for any distinct collinear $A,B,C$, $AB +BC  < \infty = \omega $, so there will be a betweenness relation
        \item \textbf{What would make Ax.BP false?} Three collinear points $A,B,C$ so that at least one of $AB + BC \leq \omega, AC + CB \leq \omega, BA + AC \leq \omega$, and no betweenness relation for $A,B,C$ exists
            \bigbreak \noindent 
            \textbf{Note:} If there are no lines with three points, then the axiom is vacuously true.
        \item \textbf{Planes with first 8 axioms}: Consider a general plane $\mathbb{P}$ with points, lines, distance, and all 8 axioms true. We can establish some important properties of all these planes
        \item \textbf{Triangle inequality for the line}: If $A,B,C$ are any three distinct, collinear points, then 
            \begin{align*}
                AB + BC \leq AC 
            \end{align*}
            \bigbreak \noindent 
            \textbf{Note:} Don't worry about why the word triangle is in the name. Also, the triangle inequality is not necessarily true without Ax.BP
        \item \textbf{Rule of insertion}: 
            \begin{itemize}
                \item If $ A\text{-}B\text{-}C$ and $ A\text{-}X\text{-}B$, then $ A\text{-}X\text{-}B\text{-}C $
                \item If $ A\text{-}B\text{-}C$ and $ B\text{-}X\text{-}C$, then $ A\text{-}B\text{-}X\text{-}C $
            \end{itemize}
            \bigbreak \noindent 
            \textbf{\textit{Proof (a).}} Since $ A\text{-}B\text{-}C$, and $ A\text{-}X\text{-}B$, then we know that $A,X,B,C$ are distinct, collinear. 
            \bigbreak \noindent 
            By the definition of betweenness, we have
            \begin{align*}
                AB  + BC &= AC \\
                AX + XB &= AB
            \end{align*}
            Thus,
            \begin{align*}
                AX + XB + BC &= AC
            \end{align*}
            By the triangle inequality, we have $XB + BC \leq XC$. Thus,
            \begin{align*}
                AC & =AX + XB +  BC \leq AX + XC
            \end{align*}
            But the triangle inequality also implies that 
            \begin{align*}
                AX + XC \leq AC
            \end{align*}
            Thus, since $AX + XC \leq AC \leq AX + XC$. Thus, it must be that $AC = AX + XC$. Hence, $ A\text{-}X\text{-}C $. Next, plugging $AC = AX + XC$ into $AC = AX + XB + BC$ yields
            \begin{align*}
                AX + XC &= AX + XB + BC \\
                \implies XB + BC &= XC
            \end{align*}
            Thus, $ X\text{-}B\text{-}C $.
            \bigbreak \noindent 
            \textbf{\textit{Proof (b)}} If $ A\text{-}B\text{-}C$ and $ B\text{-}X\text{-}C$, then $ C\text{-}B\text{-}A$ and $ C\text{-}X\text{-}B $, so by part (a), we have
            \begin{align*}
                C\text{-}X\text{-}B\text{-}A
            \end{align*}
            Which means $ A\text{-}B\text{-}X\text{-}C$ \endpf
        \item \textbf{What does the betweenness of points axiom get us?} The triangle inequality and the insertion theorem 
        \item \textbf{Quadrichotomy Axiom for Points (Ax.QP)}: If $A,B,C,X$ are distinct, collinear points, and if $ A\text{-}B\text{-}C$. Then, at least one of the following must hold
            \begin{align*}
                X\text{-}A\text{-}B, \quad A\text{-}X\text{-}B, \quad B\text{-}X\text{-}C, \quad \text{or } \quad B\text{-}C\text{-}X
            \end{align*}
            \bigbreak \noindent 
            Thus, Ax.QP says that whenever $ A\text{-}B\text{-}C$ (say on line $\ell$), then any other point $X$ on line $\ell$ is in either $ \overrightarrow{BA} $ or $ \overrightarrow{BC} $. That is,
            \begin{align*}
                \ell = \overrightarrow{BA} \cup \overrightarrow{BC}
            \end{align*}
            \bigbreak \noindent 
            Ax.QP is true for
            \begin{itemize}
                \item $\mathbb{E}$
                \item $\mathbb{M}$
                \item $\mathbb{G}$
                \item $\mathbb{H}$
                \item $\mathbb{S}$
                \item $\mathbb{R}^{3}$
                \item $\hat{\mathbb{E}}$ (bumpy plane)
            \end{itemize}
            It is also true vacuously for the white stripes model, the TDM, and the Fano plane
            \bigbreak \noindent 
            Ax.QP is also true for the Inside Out (IO) example. It is vacuously two for the 2-point lines, but we can also check that it is satisfied for $\ell = \{A,B,C,D\} $
            \bigbreak \noindent 
            \textbf{Note:} If the first 8 axioms are true for a plane $\mathbb{P}$, and if $\omega = \infty$, then the statement of Ax.QP can be proved to hold true in $\mathbb{P}$. A key reason for this is that because $\omega = \infty$, any three collinear points must have a betweenness relation.
        \item \textbf{When is Ax.QP false?}: In a plane with at least four collinear points $A,B,C,X$ with $ A\text{-}B\text{-}C$, and none of 
            \bigbreak \noindent 
            \begin{align*}
                    X\text{-}A\text{-}B, \quad A\text{-}X\text{-}B, \quad B\text{-}X\text{-}C, \quad \text{or } \quad B\text{-}C\text{-}X
            \end{align*}
            Are true
    \end{itemize}


    \pagebreak 
    \unsect{Numerical analysis with Julia}
    \subsection{Numerical algorithms, roundoff errors, and nonlinear equations in one variable}
    \begin{itemize}
        \item \textbf{Scientific computing}: Scientific computing is a discipline concerned with the development and study of \textbf{numerical algorithms} for solving mathematical problems that arise in various disciplines in science and engineering.
            \bigbreak \noindent 
            Typically, the starting point is a given \textbf{mathematical model} which has been formulated in an attempt to explain and understand an observed phenomenon in biology, chemistry, physics, economics, or any other scientific or engineering discipline. We will concentrate on those mathematical models which are continuous (or piecewise continuous) and are difficult or impossible to solve analytically; this is usually the case in practice
            \bigbreak \noindent 
            In order to solve such a model approximately on a computer, the continuous or piecewise continuous problem is approximated by a discrete one. Functions are approximated by finite arrays of values. Algorithms are then sought which approximately solve the mathematical problem efficiently, accurately, and reliably. This is the heart of scientific computing. \textbf{Numerical analysis} may be viewed as the theory behind such algorithms
            \bigbreak \noindent 
            \fig{.5}{./figures/22.png}
        \item \textbf{Relative and absolute errors}: There are in general two basic types of measured error. Given a scalar quantity $u$ and its approximation $v$:
            \begin{itemize}
                \item \textbf{Absolute error}: The \textit{absolute error} in $v$ is 
                    \begin{align*}
                        \left\lvert u - v \right\rvert
                    \end{align*}
                \item \textbf{Relative error}: The \textit{relative error}, assuming $u\ne 0$ is 
                    \begin{align*}
                        \frac{\left\lvert u-v \right\rvert}{\left\lvert u \right\rvert}
                    \end{align*}
            \end{itemize}
            \textbf{Note:} If we take the absolute error, $\left\lvert u-v \right\rvert $. Then it is clear it will be some percentage of $u$. In other words, some scaled version of $u$. Thus, we have $\left\lvert u-v \right\rvert  = p\left\lvert u \right\rvert$.
            \bigbreak \noindent 
            The relative error is usually a more meaningful measure. This is especially true for errors in floating point representation. For example, we record absolute and relative errors for various hypothetical calculations in the following table
            \begin{center}
                \begin{tabular}{|c|c|c|c|}
                    \hline
                    $u$ & $v$ & Absolute error & Relative error \\ \hline
                    1 & 0.99 & 0.01 & 0.01 \\ \hline
                    1 & 1.01 & 0.01 & 0.01 \\ \hline
                    -1.5 & -1.2 & 0.3 & 0.2 \\ \hline
                    100 & 99.99 & 0.01 & 0.0001 \\ \hline
                    100 & 99 & 1 & 0.01 \\ \hline
                \end{tabular}
            \end{center}
            \bigbreak \noindent 
            We expect the approximation in the last row of the above table to be similar in quality to the one in the first row. This expectation is borne out by the value of the relative error but is not reflected by the value of the absolute error
            \bigbreak \noindent 
            When the approximated value is small in magnitude, things are a little more delicate, and here is where relative errors may not be so meaningful. But let us not worry about this at this early point.
        \item \textbf{The sterling approximation}: The quantity
            \begin{align*}
                v = S_{n} = \sqrt{2\pi n}\left(\frac{n}{e}\right)^{n}
            \end{align*}
            Is called sterling's approximation and is used to approximate $u = n!$ for large $n$
        \item \textbf{Error types}: Knowing how errors are typically measured, we now move to discuss their source. There are several types of error that may limit the accuracy of a numerical calculation.
            \begin{enumerate}
                \item \textbf{Errors in the problem to be solved}: These may be approximation errors in the mathematical model
                    \bigbreak \noindent 
                    Another typical source of error in the problem is error in the input data. This may arise, for instance, from physical measurements, which are never infinitely accurate. Thus, it may be that after a careful numerical simulation of a given mathematical problem, the resulting solution would not quite match observations on the phenomenon being examined.
                    \bigbreak \noindent 
                    At the level of numerical algorithms, which is the focus of our interest here, there is really nothing we can do about the above-described errors. Nevertheless, they should be taken into consideration, for instance, when determining the accuracy (tolerance with respect to the next two types of error mentioned below) to which the numerical problem should be solved.
                \item  \textbf{Approximation errors}: Such errors arise when an approximate formula is used in place of the actual function to be evaluated.
                    \bigbreak \noindent 
                    We will often encounter two types of approximation errors:
                    \begin{enumerate}
                        \item \textbf{Discretization errors} arise from discretizations of continuous processes, such as interpolation, differentiation, and integration.
                        \item \textbf{Convergence errors} arise in iterative methods. For instance, nonlinear problems must generally be solved approximately by an iterative process. Such a process would converge to the exact solution in infinitely many iterations, but we cut it off after a finite (hopefully small!) number of such iterations. Iterative methods in fact often arise in linear algebra.
                    \end{enumerate}
                \item \textbf{Roundoff errorss:} Any computation with real numbers involves roundoff error. Even when no approximation error is produced (as in the direct evaluation of a straight line, or the solution by Gaussian elimination of a linear system of equations), roundoff errors are present. These arise because of the finite precision representation of real numbers on any computer, which affects both data representation and computer arithmetic.
            \end{enumerate}
        \item \textbf{Digits of accuracy}: If $p$ is the relative error when $v$ approximates $u$, then the digits of accuracy in the approximation $v$ can be found with
            \begin{align*}
                \log_{10}{\left(\frac{1}{p}\right)} = -\log_{10}{(p)}
            \end{align*}
        \item \textbf{Catastrophic cancellation}: A numerical phenomenon that occurs when subtracting two nearly equal numbers in floating-point arithmetic. The result of this subtraction can lose significant digits, leading to a dramatic loss of precision in the computed result.
            \bigbreak \noindent 
            In floating-point representation, numbers are stored with a finite number of significant digits (or bits). When two numbers are nearly equal, their leading digits cancel each other out during subtraction. The result is dominated by the remaining, less significant digits, which are more prone to rounding errors.
            \bigbreak \noindent 
            Suppose we want to compute $x-y$, where $x= 1.0000001$, and $y=1.0000000$. The true result is 
            \begin{align*}
                x - y = 0.0000001
            \end{align*}
            \bigbreak \noindent 
            However, if $x$ and $y$ are represented with only 7 significant digits in a floating-point system, $x=1.000000$, and $y=1.000000$. Then, their subtraction gives
            \begin{align*}
                x-y = 0.000000
            \end{align*}
            The true value is completely lost because the subtraction eliminates all significant digits.
        \item \textbf{Numerical noise}: Numerical noise refers to small errors or inaccuracies that arise in numerical computations due to the limitations of floating-point arithmetic. These errors are often very small, but they can accumulate or become significant in certain situations, especially when the computations involve many steps or operations sensitive to precision.
            \bigbreak \noindent 
            Computers represent real numbers in a finite number of bits (e.g., 64 bits for double-precision floats).
            \bigbreak \noindent 
            This representation cannot store every real number exactly, so numbers are rounded to the nearest representable value. These small rounding errors introduce "noise" into computations.
        \item \textbf{Machine epsilon}: The machine epsilon is the smallest positive number  $\varepsilon$ such that 
            \begin{align*}
                1+ \varepsilon > 1
            \end{align*}
            in a given floating-point system. It represents the upper bound on the relative error due to rounding in floating-point arithmetic.
            \begin{itemize}
                \item \textbf{Single Precision (32-bit):} 
                    \[
                        \varepsilon_{\text{machine}} \approx 2^{-23} \approx 1.19 \times 10^{-7}
                    \]
                \item \textbf{Double Precision (64-bit):} 
                    \[
                        \varepsilon_{\text{machine}} \approx 2^{-52} \approx 2.22 \times 10^{-16}
                    \]
            \end{itemize}


        \item \textbf{Approximation Error (approximating the derivative)}:
            Consider the formula for the derivative of a differentiable function $f \colon \mathbb{R} \to \mathbb{R}$ at $x_0$:
            $$ f'(x_0) = \lim_{h \to 0} \frac{f(x_0 + h) - f(x_0)}{h}.$$
            It is therefore reasonable to approximate $f'(x_0)$ using
            $$\frac{f(x_0 + h) - f(x_0)}{h}$$
            for some small positive $h$. The error in this approximation is 
            $$\left|f'(x_0) - \frac{f(x_0 + h) - f(x_0)}{h}\right|$$
            and is called a \textbf{discretization error}.
            \bigbreak \noindent 
            For example, consider $f(x) = \sin{x}$ at $x_{0} = 1$. Note that $f^{\prime}(x) = \cos{x} $. We have
            \begin{align*}
                f^{\prime}(x_{0}) = \cos{1} =  0.5403023058681398\ldots
            \end{align*}
            Let's now approximate this with
            \begin{align*}
                f^{\prime}(x_{0}) \approx \frac{f(x_{0} + h) - f(x_{0})}{h}
            \end{align*}
            For $h=10^{-1}, 10^{-2},...,10^{-16} $. The following Julia code
            \bigbreak \noindent 
            \begin{jlcode}
using Printf

function deriv_approx(f, x0, fp)
    @printf("%6s %24s %12s %10s %8s\n", "h", "fpapprox", "abserr", "relerr", "digits")

    for k in 1:16
        h = 10.0^(-k)
        fpapprox = (f(x0+h) - f(x0))/h
        abserr = abs(fp - fpapprox)
        relerr = abserr/abs(fp)
        digits = -log10(relerr)
        @printf("%6.0e %24.16e %12.4e %10.2e %8.1f\n", h, fpapprox, abserr, relerr, digits)
    end
    
    return nothing
end

deriv_approx(f, 1.0, cos(1.0))
            \end{jlcode}
            \bigbreak \noindent 
            Yields the following output
            \begin{center}
                \begin{tabular}{c|c|c|c|c}
                    h                 &fpapprox       &abserr     &relerr   &digits \\
                    \hline
                    1e-01   &4.9736375253538911e-01   &4.2939e-02   &7.95e-02      &1.1\\
                    1e-02   &5.3608598101186888e-01   &4.2163e-03   &7.80e-03      &2.1\\
                    1e-03   &5.3988148036032690e-01   &4.2083e-04   &7.79e-04      &3.1\\
                    1e-04   &5.4026023141862112e-01   &4.2074e-05   &7.79e-05      &4.1\\
                    1e-05   &5.4029809850586474e-01   &4.2074e-06   &7.79e-06      &5.1\\
                    1e-06   &5.4030188512133037e-01   &4.2075e-07   &7.79e-07      &6.1\\
                    1e-07   &5.4030226404044868e-01   &4.1828e-08   &7.74e-08      &7.1\\
                    1e-08   &5.4030230289825454e-01   &2.9699e-09   &5.50e-09      &8.3\\
                    1e-09   &5.4030235840940577e-01   &5.2541e-08   &9.72e-08      &7.0\\
                    1e-10   &5.4030224738710331e-01   &5.8481e-08   &1.08e-07      &7.0\\
                    1e-11   &5.4030113716407868e-01   &1.1687e-06   &2.16e-06      &5.7\\
                    1e-12   &5.4034554608506369e-01   &4.3240e-05   &8.00e-05      &4.1\\
                    1e-13   &5.3956838996782608e-01   &7.3392e-04   &1.36e-03      &2.9\\
                    1e-14   &5.4400928206632670e-01   &3.7070e-03   &6.86e-03      &2.2\\
                    1e-15   &5.5511151231257827e-01   &1.4809e-02   &2.74e-02      &1.6\\
                    1e-16   &0.0000000000000000e+00   &5.4030e-01   &1.00e+00     &-0.0
                \end{tabular}
            \end{center}
            \bigbreak \noindent 
            Notice that when $h$ is decreased by a factor of ten, the absolute error decreases by a factor of ten.
            \bigbreak \noindent 
            Further, notice that when $h = 10^{-k}$, for $k\in\{9,10,11,...,16\} $, the absolute error gets worse instead of better. Also, when $h=10^{-16}$, we notice that the approximation reads zero. This is a result of round-off errors and the limitations of floating-point arithmetic in computers.
            \begin{itemize}
                \item \textbf{Catastrophic Cancellation:} The approximation formula involves subtracting two very close values $f(x_{0} + h)$ and $f(x_{0}) $, for very small $h$
                    \bigbreak \noindent 
                    When $h$ becomes very small, the values of  $f(x_{0} + h)$ and $ f(x_{0})$ are nearly identical. In floating-point arithmetic, this subtraction loses precision because the significant digits cancel out, leaving only the less accurate lower-order bits
                \item \textbf{Floating-Point Precision:} Floating-point numbers have limited precision. For typical 64-bit double-precision floating-point numbers, the relative precision is about $10^{-16}$ (The choice of $h$ going up to $10^{-16} $ was no coincidence)
                    \bigbreak \noindent 
                    When $h$ is smaller than $10^{-8}$, the differences $f(x_{0} + h) - f(x_{0})$ approach the limits of floating-point precision. Consequently, the computation becomes dominated by numerical noise, which introduces errors.
 
            \end{itemize}
            \bigbreak \noindent 
            Observe the plot of $h$ versus the absolute error in this approximation
            \bigbreak \noindent 
            \fig{.7}{./figures/savefig1.png}
        \item \textbf{Taylor series}: Assume that $f$ is a function that is $(k+1)$-differentiable on an interval containing $x_0$ and $x_0 + h$. Then
            $$
            f(x_0 + h) = f(x_0) + h f'(x_0) + \frac{h^2}{2} f''(x_0) + \cdots + \frac{h^k}{k!} f^{(k)}(x_0) + \frac{h^{k+1}}{(k+1)!} f^{(k+1)}(\xi),
            $$
            for some $\xi \in (x_0, x_0 + h)$.
        \item \textbf{Proof that the discretization error decreases at the same rate as}:
            Solving for $f'(x_0)$ in the Taylor series expansion, we get
            $$
            f'(x_0) = \frac{f(x_0+h)-f(x_0)}{h} - \left(\frac{h}{2} f''(x_0) + \frac{h^2}{6} f'''(x_0)  + \cdots + \frac{h^{k-1}}{k!} f^{(k)}(\xi)\right).
            $$
            Therefore,
            $$
            \left|f'(x_0) - \frac{f(x_0+h)-f(x_0)}{h}\right| = \left|\frac{h}{2} f''(x_0) + \frac{h^2}{6} f'''(x_0) + \cdots + \frac{h^{k-1}}{k!} f^{(k)}(\xi)\right|.
            $$
            If $f''(x_0) \neq 0$ and $h$ is small, then the right-hand-side is dominated by $\frac{h}{2} f''(x_0)$. Thus,
            $$
            \left|f'(x_0) - \frac{f(x_0+h)-f(x_0)}{h}\right| \approx \frac{h}{2}\left| f''(x_0)\right| = \mathcal{O}(h). \quad \blacksquare
            $$
            \bigbreak \noindent 
            Recall that $f(x) = \sin{x}$. Thus, $f^{\prime\prime}(x) = -\sin{x}$. Therefore,
            \begin{align*}
                \frac{\abs{f^{\prime\prime}(x_{0})}}{2} = \frac{-\sin{1}}{2} = 0.42073549240394825\ldots                
            \end{align*}
        \item \textbf{Roundoff error}: Numbers are stored in the computer using a finite precision representation. Roughly 16 digits of precision are possible using the 64-bit floating point format.
            \bigbreak \noindent 
            Whenever an arithmetic operation takes place, the result must be rounded to roughly 16 digits of precision. Such an error is called roundoff error.
        \item \textbf{Accuracy}: As we have seen above, it is easy to write mathematically correct code that produces very inaccurate results.
            \bigbreak \noindent 
            Accuracy is affected by the following two conditions:
            \begin{enumerate}
                \item \textbf{Problem conditioning}: Some problems are highly sensitive to small changes in the input: we call such problems ill-conditioned. A problem that is not sensitive to small changes in the input is called well-conditioned. For example, computing $\tan(x)$ for $x$ near $\frac{\pi}{2} $ is an ill-conditioned problem (Example 1.5 in Ascher-Greif).
                \item \textbf{Algorithm stability}: An algorithm is called stable if it is guaranteed to produce an exact answer to a slightly perturbed problem. (Example 1.6 in Ascher-Greif gives an example of an unstable algorithm).
                    \bigbreak \noindent 
                    A "slightly perturbed problem" means a problem that has been altered by a small amount. For example, this could be small changes in the input data due to measurement errors or rounding errors.
                    \bigbreak \noindent 
                    The algorithm is said to be stable if it provides the exact solution to this slightly perturbed problem. In other words, the output corresponds to what would happen if you solved the slightly modified problem exactly, rather than the original unmodified problem.
                    \bigbreak \noindent 
                    A stable algorithm ensures that the effects of small input errors or numerical approximations (like rounding) do not grow uncontrollably during computations.

            \end{enumerate}
        \item \textbf{Unstable algorithm example}: Let 
            $$ y_n = \int_0^1 \frac{x^n}{x + 10} dx. $$
            Then 
            $$
        y_n + 10y_{n-1} = \int_0^1 \frac{x^n + 10x^{n-1}}{x + 10} dx = \int_0^1 x^{n-1} dx = \frac{1}{n}x^n \Big\rvert_0^1 = \frac1n
        $$
        and
        $$
    y_0 = \int_0^1 \frac{1}{x + 10} dx = \ln|x+10| \Big\rvert_0^1 = \ln(11) - \ln(10).
    $$
    Then use these formulas to numerically compute $y_{30}$.
    \bigbreak \noindent 
    First, let's look at the functions $\frac{x^{n}}{x+10}$ as $n$ grows. Using the Julia code
    \bigbreak \noindent 
    \begin{jlcode}
        plot()
        for n in 1:10
            plot!(x -> x^n/(x+10), 0, 1, label="n = $n")
        end
        plot!()
    \end{jlcode}
    We get the graphs
    \bigbreak \noindent 
    \fig{.5}{./figures/savefig2.png}
    \bigbreak \noindent 
    So it appears the area under the curve is approaching zero. First, let's look at the integral result and error from a known stable algorithm (for $n=30$)
    \bigbreak \noindent 
    \begin{jlcode}
        using QuadGK

        n = 30
        integral, error = quadgk(x -> x^n/(x + 10), 0, 1)

        #(0.002940928704861327, 8.45119305817703e-12)
    \end{jlcode}
    \bigbreak \noindent 
    The Julia code that uses the derived algorithm gives
    \bigbreak \noindent 
    \begin{jlcode}
        y0 = log(11) - log(10)

        yvals = zeros(30)
        yvals[1] = 1 - 10*y0
        for n = 2:30
            yvals[n] = 1/n - 10*yvals[n-1]
        end
        yvals

        # Out
        30-element Vector{Float64}:
       0.04689820195675232
       0.031017980432476833
       0.023153529008564988
       0.01846470991435012
       0.015352900856498819
       0.013137658101678468
       0.011480561840358172
       0.010194381596418278
       0.009167295146928323
       0.00832704853071678
       0.007638605601923115
       0.0069472773141021765
       0.007450303782055162
       ⋮
     916.9927348292546
   -9169.877348292546
   91698.82110197308
 -916988.1655651854
       9.169881699130116e6
      -9.169881694963449e7
       9.169881695363449e8
      -9.169881695324987e9
       9.169881695328691e10
      -9.169881695328334e11
       9.16988169532837e12
      -9.169881695328366e13
    \end{jlcode}
    \bigbreak \noindent 
    Thus, This algorithm is \textit{very} \textbf{unstable}. The reason is the computation of $y_{0}$ using the log function. The log function introduces some roundoff error. Continuously using the results of the previous introduces more and more roundoff error.
\item \textbf{Efficiency}:
    The efficiency of a code is affected by many factors:
    \begin{enumerate}
        \item the rate of convergence of the method
        \item the number of arithmetic operations performed
        \item how the data in memory is accessed
    \end{enumerate}
\item \textbf{Robustness (Reliability)}: We want to ensure that our code works under \textit{all possible inputs}, and generates the clear warnings when it is not possible to produce an accurate result for some input.
    \end{itemize}

    \pagebreak 
    \subsection{Roundoff errors}
    \begin{itemize}
        \item \textbf{Real numbers stored on a computer}: Real numbers are stored on a computer following the IEEE floating-point standard:
            \begin{enumerate}
                \item \textbf{half precision:} using 16 bits (Julia type: `Float16`)
                \item \textbf{single precision:} using 32 bits (Julia type: `Float32`)
                \item \textbf{double precision:} using 64 bits (Julia type: `Float64`)
            \end{enumerate}
            \bigbreak \noindent 
            Julia also has an \textit{arbitrary precision} floating-point data type called `BigFloat`. It is excellent if you need more precision, but it is also much slower.
            \bigbreak \noindent 
            Julia has the type \textit{AbstractFloat}, which is a subtype of the class Real, and is an abstract supertype for all floating point numbers.
            \bigbreak \noindent 
            \begin{jlcode}
            AbstractFloat <: Real

            > subtypes(AbstractFloat)
             5-element Vector{Any}:
             BigFloat
             Core.BFloat16
             Float16
             Float32
             Float64           
         \end{jlcode}
     \item \textbf{Description of the IEEE Float64}: Suppose $x$ is a floating-point number stored in the following 64-bits:
         $$
         \begin{array}{|c|c|c|c|c|c|c|}
             \hline
             1 & 2 & \cdots & 12 & 13 & \cdots & 64 \\
             \hline
             s & e_{10} & \cdots & e_0 & f_1 & \cdots & f_{52} \\
             \hline
         \end{array}
         $$
         Where
         \begin{itemize}
             \item 1 bit $s$ represents the \textbf{sign}
             \item 11 bits $e_{10} \cdots e_{0}$ represent the \textbf{exponent}
             \item 52 bits $f_1 \cdots f_{52}$ represent the \textbf{fraction} (a.k.a. the mantissa or significand)
         \end{itemize}
         Then
         $$ x = (-1)^s [1.f_1 \cdots f_{52}]_2 \times 2^{(e-1023)}.$$
         \bigbreak \noindent 
         \textbf{Notes:}
         \begin{itemize}
             \item $x$ is \textbf{normalized} to have its first digit nonzero.
             \item $e = [e_{10} \cdots e_{0}]_2 = e_{10} 2^{10} + \cdots + e_1 2^1 + e_0 2^0 \in \left[0, 2^{11}-1\right] = [0, 2047]$
             \item $e = 0$ and $e = 2047$ are reserved for special floating-point values, so 
         \end{itemize}
         $$e \in [1, 2046]$$
     The "$-1023$" in the exponent is called the \textbf{bias}:  $e-1023 \in [-1022,1023]$
     \bigbreak \noindent 
     Also, 
     \begin{align*}
         [1.f_1 \cdots f_{52}]_2 = 1 + \frac{f_1}{2^1} + \frac{f_2}{2^2} + \cdots + \frac{f_{52}}{2^{52}}
     \end{align*}
     \bigbreak \noindent 
     For example, suppose
     \begin{align*}
         x & = -[1.101101]_2 \times 2^{(1026-1023)} \\
           & = -[1.101101]_2 \times 2^{3} \\
           & = -[1101.101]_2 \\
           & = -\left(1 \cdot 8 + 1 \cdot 4 + 0 \cdot 2 + 1 \cdot 1 + 1 \cdot \frac{1}{2} + 0 \cdot \frac{1}{4} + 1 \cdot \frac{1}{8}\right)  \\
           & = -13.625
     \end{align*}
     \bigbreak \noindent 
     Even if a number can be represented exactly in base-10 with a finite number of digits, it may require an infinite number of digits in base-2.
     $$
     0.1 = \left[0.000110011001\ldots\right]_2 = \left[1.\overline{1001}\right]_2 \times 2^{-4}
     $$
     Therefore, $0.1$ cannot be represented exactly as a floating-point number.
    \item \textbf{16-bit and 32-bit IEEE representation}
        \begin{itemize}
            \item \textbf{16-bit (half-precision)}: The IEEE 754 half-precision floating-point format consists of:
                \begin{itemize}
                    \item 1 bit for the sign (\(s\))
                    \item 5 bits for the exponent (\(e_4, e_3, e_2, e_1, e_0\))
                    \item 10 bits for the fraction/mantissa (\(f_1, f_2, \ldots, f_{10}\))
                \end{itemize}

                \[
                    \begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
                        \hline
                        1 & 2 & 3 & 4 & 5 & 6 & \cdots & 16 \\
                        \hline
                        s & e_4 & e_3 & e_2 & e_1 & e_0 & f_1 & \cdots & f_{10} \\
                        \hline
                    \end{array}
                \]
            \item \textbf{32-bit (Single precision)}: The IEEE 754 single-precision floating-point format consists of:
                \begin{itemize}
                    \item 1 bit for the sign (\(s\))
                    \item 8 bits for the exponent (\(e_7, e_6, e_5, e_4, e_3, e_2, e_1, e_0\))
                    \item 23 bits for the fraction/mantissa (\(f_1, f_2, \ldots, f_{23}\))
                \end{itemize}
                \[
                    \begin{array}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
                        \hline
                        1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & \cdots & 32 \\
                        \hline
                        s & e_7 & e_6 & e_5 & e_4 & e_3 & e_2 & e_1 & e_0 & f_1 & \cdots & f_{23} \\
                        \hline
                    \end{array}
                \]
        \end{itemize}
    \item \textbf{Bias calculation}: The bias used above is calculated as 
        \begin{align*}
            \text{Bias} = 2^{(E-1)} -1
        \end{align*}
        where $E$ is the number of bits allocated to the exponent field.
        \bigbreak \noindent 
        \begin{itemize}
            \item \textbf{16-bit half precision}: Exponent is allowed 5 bits, thus
                \begin{align*}
                    \text{Bias} = 2^{5-1} - 1 = 15
                \end{align*}
            \item \textbf{32-bit single precision}: Exponent is allowed 8 bits, thus
                \begin{align*}
                    \text{Bias} = 2^{7} - 1 = 127
                \end{align*}
            \item \textbf{64-bit double precision}: Exponent is allowed 11 bits, thus
                \begin{align*}
                    \text{Bias} = 2^{10} - 1 = 1023
                \end{align*}
        \end{itemize}
    \item \textbf{Convert real to binary representation}: So we now know how to convert a binary representation of a float to its decimal representation. 
        \bigbreak \noindent 
        Consider the base ten real $-13.625$. To convert a base ten real into its binary representation, we first
        \bigbreak \noindent 
        \textbf{Convert the integer part to binary}: Following the standard algorithm to convert 13 to binary
        \begin{align*}
            13 &= 2(6) + 1:\ 1_{2} \\
            6 &= 2(3) + 0:\ 0_{2} \\
            3 &= 2(1) + 1:\ 1_{2} \\
            1 &= 2(0) + 1:\ 1_{2}
        \end{align*}
        $13_{10}$ is therefore $1101_{2}$
        \bigbreak \noindent 
        \textbf{Convert the fractional part}: Convert the fractional part (0.625) by repeatedly multiplying by 2 and recording the whole number parts. Stop when the fractional part becomes 0. We build the resulting representation in the opposite way of the integer algorithm (top down)
        \begin{align*}
            0.625 \cdot 2 &= 1.25:\ 1_{2} \\
            0.25 \cdot 2 &= 0.5:\ 0_{2} \\
            0.5 \cdot 2 &= 1:\ 1_{2}
        \end{align*}
        The result is therefore $101_{2} $
        \bigbreak \noindent 
        \textbf{Combine the integer and fractional parts}: We have
        \begin{align*}
            13.625_{10} = 1101.101_{2}
        \end{align*}
        \bigbreak \noindent 
        \textbf{Normalize the Binary Number}: Normalize the binary number to the form 
        \begin{align*}
            1.\text{mantissa} \cdot 2^{\text{exponent}}
        \end{align*}
        For $1101.101_{2}$, shift the decimal point left by three places to get $1.101101_{2}$. The exponent is therefore three because
        \begin{align*}
            1101.101 = 1.101101 \cdot 2^{3}
        \end{align*}
        \bigbreak \noindent 
        \textbf{Determine the Sign Bit}: The sign bit is:
        \begin{itemize}
            \item 0 for positive numbers.
            \item 1 for negative numbers.
        \end{itemize}
        Since $-13.625$ is negative, the sign bit is 1
        \bigbreak \noindent 
        \textbf{Encode the Exponent}: The exponent is stored in "biased" form, for 64-bit double precision the bias is $1023$. We add the bias to the actual exponent to get the biased to get the biases exponent
        \begin{align*}
            3+1023 = 1026
        \end{align*}
        Then, convert the biased exponent to binary
        \begin{align*}
            1026_{10} = 10000000010_{2} 
        \end{align*}
        \bigbreak \noindent 
        \textbf{Encode the Mantissa}: The mantissa is the fractional part of the normalized binary number ( 1.mantissa), excluding the leading 1.
        \bigbreak \noindent 
        From $1.101101_{2}$, the mantissa is 101101. We pad with zeros to make it the required 52 bits
        \bigbreak \noindent 
        \textbf{Combine the parts}: The IEEE 754 representation is formed by combining
        \begin{itemize}
            \item \textbf{Sign bit (1 bit):} 1
            \item \textbf{Exponent (11 bits):} 10000000010
            \item \textbf{Mantissa (52 bits):} 10110100000000000000000...$0_{52}$
        \end{itemize}
    \item \textbf{Finding decimal value}: In a binary string of all ones, we have a mathematical formula to compute its value... Specifically
        \begin{align*}
            1 + 2 + 4 + 8 +... + 2^{n} = 2^{n+1}-1
        \end{align*}
        For example (unsigned), $1111 = 2^{3+1}-1 = 15$. But what about for binary decimals numbers, where we instead divide by two to find its value. Consider the binary string
        \begin{align*}
            0.11111_{2} = \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \frac{1}{16} + ...
        \end{align*}
        Notice this a geometric series
        \begin{align*}
            S = \sum_{k=1}^{n}\frac{1}{2^{k}}
        \end{align*}
        The sum of the geometric series is given by
        \begin{align*}
            S = \frac{a(1-r^{n})}{1-r}
        \end{align*}
        Where $a$ is the first term, $r$ is the common ratio, and $n$ is the number of terms. Therefore, for $a=\frac{1}{2}, r =\frac{1}{2}$, we have
        \begin{align*}
            S &= \frac{1}{2} \cdot \frac{1-\left(\frac{1}{2}\right)^{n}}{1-\left(\frac{1}{2}\right)} \\
            &= 1-\frac{1}{2^{n}}
        \end{align*}
        Thus, consider $0.1111$, where $n=4$. Note that $n$ is not $3$, like in the formula described for integers, this is because the sum starts at $n=1$, instead of $n=0$ like the integer formula.  Thus,
        \begin{align*}
            0.1111 = 0 + 1-\frac{1}{2^{n}} = 1-\frac{1}{2^{4}} = 0.9375
        \end{align*}
        And 
        \begin{align*}
            1.1111 = 1 + 1-\frac{1}{2^{n}} = 1-\frac{1}{2^{4}} = 1 + 0.9375 = 1.9375
        \end{align*}
    \item \textbf{More on normalized float}: To be normalized in the context of IEEE 754 floating-point numbers means that the number is represented in a standardized form where:
        \begin{itemize}
            \item The leading digit of the significand (mantissa) is always 1 (except for special cases like subnormal numbers).
            \item This representation ensures there is only one unique way to represent each number.
        \end{itemize}
        \bigbreak \noindent 
        This is akin to scientific notation, where we always write numbers like 
        \( 3.25 \times 10^2 \) instead of \( 32.5 \times 10^1 \) or \( 0.325 \times 10^3 \). 
        In IEEE 754, normalized numbers always take the form:

        \[
            1.\text{fraction} \times 2^{(\text{exponent} - \text{bias})}
        \]
    \item \textbf{Exponent of all ones}: All ones in the exponent is reserved for  infinity and NaN. Thus, the largest exponent to work with in calculations is $11111111110 = 2046$
    \item \textbf{Limits of floating point numbers}: The largest Float64 is $(2-2^{-52}) \times 2^{1023} \approx 1.97769 \times 10^{308} \approx  2\times 10^{308}$
        \bigbreak \noindent 
        The largest float is when the sign bit is zero, all exponent bits are one, and all fraction bits are one. The exponent is then $2^{10 + 1}- 1 - 2047$, However, this value is reserved for infinity (and NaN). The largest finite exponent is 2046. The exponent bias is 1023, so the largest actual exponent $2046 - 1023 = 1023$. is The fractional part is $1.111...1_{52} = 1 + 1-\frac{1}{2^{52}} = 2-\frac{1}{2^{52} } = 2$. Thus, we get
        \begin{align*}
            (-1)^{0} \cdot 2 \cdot 2^{1023} = 2^{1024} \approx 2\times 10^{308}
        \end{align*}
        \bigbreak \noindent 
        Thus, the largest possible float64 is
        \begin{align*}
            0\ 11111111110\ 111...1_{64}
        \end{align*}
        \bigbreak \noindent 
        The smallest positive possible normalized float64 is $2^{-1022} \approx 2\times 10^{-308} $, and it occurs when the sign bit is zero, the exponent is $00000000001$ (all zeros reserved), and the fractional part is $1.000000...0_{52} = 1.0_{10}$. Thus, we get
        \begin{align*}
            (-1)^{0} \cdot  1.0 \cdot 2^{1-1023} = 2^{-1022} \approx 2.225 \times 10^{-308} \approx 2 \times 10^{-308}
        \end{align*}
        \bigbreak \noindent 
        The smallest negative possible normalized float64 is then when the sign bit is one, we have
        \begin{align*}
            (-1)^{1} \cdot 1.0 \cdot 2^{-1022} \approx -2.225 \times 10^{-308} \approx -2 \times 10^{-308}
        \end{align*}
    \item \textbf{Finding these values in julia}: In julia, we have the functions
        \bigbreak \noindent 
        \begin{jlcode}
        floatmax(T = Float64)
        floatmin(T = Float64)
        typemax(T)
        \end{jlcode}
    \item \textbf{Float overflow and underflow}: Floating-point overflow occurs when a calculation produces a number larger than the maximum representable value in the floating-point system. In IEEE 754 double precision (Float64), the largest finite number is $\approx 1.79769 \times 10^{308} \approx 2\times 10^{308}$
        \bigbreak \noindent 
        If an operation results in a number greater than this limit, IEEE 754 rules dictate that the result is represented as positive infinity
        \bigbreak \noindent 
        If the result is negative, it becomes negative infinity
    \item \textbf{De-normalized (subnormal) floating-point numbers}: The IEEE floating-point standard also allows de-normalized numbers that are smaller than $\pm 2^{-1022}$. De-normalized floats are represented by $e=0$. Also note that subnormal floats have mantissa non-zero. Subnormal is therefore represented as
        \begin{align*}
            (-1)^{s} \cdot [0.f_{1}f_{2}...]_{2} \cdot 2^{-1022}
        \end{align*}
        Note that the exponent is $-1022$ instead of $-1023$. This is due to the IEE convention for subnormal numbers to insure there is no gap between the largest subnormal number and the smallest normal number
        \bigbreak \noindent 
        The smallest positive subnormal float that is not zero is therefore
        \begin{align*}
            0 \ 00000000000 \ 000...01
        \end{align*}
        And is equal to 
        \begin{align*}
            (-1)^{0} \frac{1}{2^{52}} \cdot 2^{-1022} \approx  4.94 \times 10^{-324} \approx 5 \times 10^{-324}
        \end{align*}
    \item \textbf{Other special floats}:
        \begin{itemize}
            \item \textbf{0.0 and -0.0}:
                \begin{align*}
                    e_{10}...e_{0} = 0... 0 \text{ and } f_{1}...f_{52} = 0...0
                \end{align*}
                \bigbreak \noindent 
                If a very small negative number is rounded to zero, then it becomes $-0.0$. If a very small positive number rounds to zero, it becomes $0.0$
            \item \textbf{Inf and -Inf}:
                \begin{align*}
                    e_{10}...e_{0} = 1... 1 \text{ and } f_{1}...f_{52} = 0...0
                \end{align*}
            \item \textbf{Nan}:
                \begin{align*}
                    e_{10}...e_{0} = 1... 1 \text{ and } f_{1}...f_{52} \ne 0
                \end{align*}
        \end{itemize}
        \bigbreak \noindent 
        \textbf{Note:} $0.0, -0.0, \infty, -\infty, NaN$ are neither normal or subnormal
        \bigbreak \noindent 
        Also, from Julia
        \begin{itemize}
            \item Finite numbers are ordered in the usual manner.
            \item Positive zero is equal but not greater than negative zero.
            \item Inf is equal to itself and greater than everything else except NaN.
            \item -Inf is equal to itself and less then everything else except NaN.
            \item NaN is not equal to, not less than, and not greater than anything, including itself.
        \end{itemize}
    \item \textbf{Summary (Float64)}
        \begin{itemize}
            \item \textbf{0.0 and -0.0}:
                \begin{align*}
                    0 \ 00000000000 \ 000...0
                    1 \ 00000000000 \ 000...0
                \end{align*}
            \item \textbf{Smallest positive normal}
                \begin{align*}
                    0 \ 00000000001 \ 000...00
                \end{align*}
                And has value
                \begin{align*}
                    (-1)^{0}[1.000...0]_{2} \cdot 2^{1-1023}  = 1.0 \cdot 2^{-1022} \approx 2.225 \cdot 10^{-308}
                \end{align*}
            \item \textbf{Largest positive normal}: Occurs when
                \begin{align*}
                    0 \ 11111111110 \ 111...11
                \end{align*}
                And has value
                \begin{align*}
                    &(-1)^{0}[1.111...11]_{2} \cdot 2^{2^{10+1} -1 - 1-1023} \\
                    &=1 + 1- \frac{1}{2^{52}} \cdot 2^{2046 -1023} = 2 - \frac{1}{2^{52}} \cdot 2^{1023} \approx 1.797 \times 10^{308}
                \end{align*}
            \item \textbf{Smallest positive subnormal}
                \begin{align*}
                   0 \ 00000000000 \ 000...01 
                \end{align*}
                And has value
                \begin{align*}
                    (-1)^{0} \cdot \frac{1}{2^{52}} \cdot 2^{-1022} \approx 4.94 \times 10^{-324}
                \end{align*}
            \item \textbf{Largest positive subnormal}
                \begin{align*}
                    0 \ 00000000000 \ 111..11
                \end{align*}
                \begin{align*}
                    (-1)^{0} \cdot 1-\frac{1}{2^{52}} \cdot 2^{-1022} \approx 2.225 \times 10^{-308}
                \end{align*}
            \item \textbf{$\infty$ and $-\infty$}
                \begin{align*}
                    0 \ 11111111111 \ 000...00 \\
                    1 \ 11111111111 \ 000...00 \\
                \end{align*}
            \item \textbf{NaN}: Any sign bit, exponent all ones, any nonzero combination of fractional bits.
        \end{itemize}
        Therefore, we can also derive the largest and smallest negative normals and subnormals
            \item \textbf{Largest negative normal}
                \begin{align*}
                    1 \ 00000000001 \ 000...00
                \end{align*}
                And has value
                \begin{align*}
                    (-1)^{1}[1.000...0]_{2} \cdot 2^{1-1023}  = (-1) 1.0 \cdot 2^{-1022} \approx -2.225 \cdot 10^{-308}
                \end{align*}
            \item \textbf{Smallest negative normal}: Occurs when
                \begin{align*}
                    1 \ 11111111110 \ 111...11
                \end{align*}
                And has value
                \begin{align*}
                    &(-1)^{1}[1.111...11]_{2} \cdot 2^{2^{10+1} -1 - 1-1023} \\
                    &=(-1) 1 + 1- \frac{1}{2^{52}} \cdot 2^{2046 -1023} = (-1) 2 - \frac{1}{2^{52}} \cdot 2^{1023} \approx -1.797 \times 10^{308}
                \end{align*}
            \item \textbf{Largest negative subnormal}
                \begin{align*}
                   1 \ 00000000000 \ 000...01 
                \end{align*}
                And has value
                \begin{align*}
                    (-1)^{1} \cdot \frac{1}{2^{52}} \cdot 2^{-1022} \approx -4.94 \times 10^{-324}
                \end{align*}
            \item \textbf{Smallest negative subnormal}
                \begin{align*}
                    1 \ 00000000000 \ 111..11
                \end{align*}
                \begin{align*}
                    (-1)^{1} \cdot 1-\frac{1}{2^{52}} \cdot 2^{-1022} \approx -2.225 \times 10^{-308}
                \end{align*}
                \bigbreak \noindent 
                \textbf{Notes:} Float underflow takes you to -inf, float overflow takes you to +inf. A negative number rounded to zero will be -0.0, a positive number rounded to zero will be 0.0
                \bigbreak \noindent 
                Behold
                \bigbreak \noindent 
                \begin{figure}[ht]
                    \centering
                    \incfig{beholdmane}
                    \label{fig:beholdmane}
                \end{figure}
            \item \textbf{nextfloat and prevfloat in Julia}: In Julia, we can find the next float and the previous float with
                \bigbreak \noindent 
                \begin{jlcode}
                nextfloat(f)
                prevfloat(f)
                \end{jlcode}
            \item \textbf{Bounding of significand in a normalized number}: The significand is always in the range
                \begin{align*}
                    1 \leq 1.b_{1}b_{2}b_{3}...b_{t-1} < 2
                \end{align*}
                since the leading bit is always 1 in a normalized number.
                \bigbreak \noindent 
                This means that $x$ satisfies
                \begin{align*}
                    2^{e} \leq \left\lvert x \right\rvert < 2^{e+1}
                \end{align*}
                We sometimes take $\left\lvert x \right\rvert \approx 2^{e} $


            \item \textbf{Machine epsilon}: In the IEEE 754 floating-point standard, machine epsilon (denoted as $\epsilon_{\text{mach}}$) is the smallest positive number that, when added to 1, results in a different representable floating-point number. It represents the upper bound on relative error due to rounding in floating-point arithmetic. That is
                \begin{align*}
                    1 + \epsilon \ne 1
                \end{align*}
                \bigbreak \noindent 
                For a floating-point system with $t$ bits in the significand (mantissa) (including the implicit leading 1), the machine epsilon is:
                \begin{align*}
                    e_{\text{mach}} = 2^{-(t-1)}
                \end{align*}
                For the IEEE 754 double precision (64-bit) format, the mantissa has $52$ fractional bits and one implicit leading bit. Thus, the machine epsilon is
                \begin{align*}
                    2^{-(53-1)} = 2^{-52} \approx 2.2204 \times 10^{-16}
                \end{align*}
                \bigbreak \noindent 
                In Julia, we can find the machine epsilon with
                \bigbreak \noindent 
                \begin{jlcode}
                eps(Float64)
                \end{jlcode}
                \bigbreak \noindent 
                Any rounding error in IEEE floating-point arithmetic is bounded above by $\epsilon_{\text{mach}} $
            \item \textbf{Understanding machine epsilon}:
                In an IEEE 754 floating-point number with $t$ bits in the significand (including the implicit 1), the machine epsilon is defined as
                \begin{align*}
                    \epsilon_{\text{mach}} = 2^{-(t-1)} = \frac{1}{2^{t-1}}
                \end{align*}
                A floating-point number is stored in normalized form
                \begin{align*}
                    x = 1.b_{1}b_{2}b_{3}...b_{t-1} \times 2^{e}
                \end{align*}
                The gap between two consecutive representable floating-point numbers is determined by the last bit of the significand
                \begin{align*}
                    \text{Unit gap } = 2^{e-(t-1)}
                \end{align*}
                \bigbreak \noindent 
                This is because the smallest possible difference in the mantissa is $2^{-t(t-1)} $, which gets scaled by $2^{e} $
                \bigbreak \noindent 
                When rounding to the nearest floating-point number, the maximum error occurs when $x$ falls exactly between two consecutive representable numbers.
                \bigbreak \noindent 
                Since the gap between two consecutive numbers is
                \begin{align*}
                    2^{e-(t-1)}
                \end{align*}
                the maximum absolute rounding error is
                \begin{align*}
                    \frac{1}{2} \times 2^{e-(t-1)}
                \end{align*}
                because the number is rounded to the nearest representable value.
                \bigbreak \noindent 
                The relative error is given by
                \begin{align*}
                    \frac{\text{max absolute rounding error}}{\left\lvert x \right\rvert}
                \end{align*}
                Since $\left\lvert x \right\rvert \approx  2^{e}$ in normalized form
                \begin{align*}
                    \frac{\frac{1}{2}2^{e-(t-1)}}{e} = \frac{1}{2} \times 2^{-(t-1)}
                \end{align*}
                Since $\epsilon_{\text{mach}} =2^{-(t-1)}$, we conclude
                \begin{align*}
                    \text{Relative rounding error} \leq \frac{1}{2}\epsilon_{\text{mach}}
                \end{align*}







            \item \textbf{Unit roundoff $\eta$}: We define the unit roundoff $\eta = \frac{\epsilon}{2.0}$, and it is the largest possible relative error due to roundoff
                \begin{align*}
                    \eta = 2^{-53} \approx 1.1 \times 10^{-16}
                \end{align*}
                \bigbreak \noindent 
                The unit roundoff represents the maximum rounding error in a floating-point system when using round-to-nearest mode
                \bigbreak \noindent 
                (the default in IEEE 754). This is because rounding introduces an error at most half the distance between two consecutive representable floating-point numbers.
            \item \textbf{Roundoff error example}: Suppose we are using a base-10 floating-point system with 4 significant digits, using `RoundNearest`:
                \begin{align*}
                    \left( 1.112 \times 10^1 \right) \times \left( 1.112 \times 10^2 \right)
                    & = 1.236544 \times 10^3 \\
                    & \rightarrow 1.237 \times 10^3 = 1237
                \end{align*}
                The absolute error is $1237 - 1236.544 = 0.456$.
                \bigbreak \noindent 
                The relative error is 
                \begin{align*}
                    \frac{0.456}{1236.544} \approx 0.0004 = 0.04 \%
                \end{align*}
                The default rounding mode is `RoundNearest` (round to the nearest floating-point number). This implies that
                $$ \frac{|x - \mathrm{fl}(x)|}{|x|} \leq \eta.$$
                If `RoundToZero` is used (a.k.a. \textbf{chopping}), then
                $$ \frac{|x - \mathrm{fl}(x)|}{|x|} \leq 2 \eta.$$
                `RoundNearest` is used since it produces smaller roundoff errors.
            \item \textbf{Roundoff error accumulation}: When performing arithmetic operations on floats, extra \textbf{guard digits} are used to ensure \textbf{exact rounding}. This guarantees that the relative error of a floating-point operation (\textbf{flop}) is small. More precisely, for floating-point numbers \(x\) and \(y\), we have
                \begin{align*}
                    \mathrm{fl}(x \pm y) &= (x \pm y)(1 + \varepsilon_1) \\
                    \mathrm{fl}(x \times y) &= (x \times y)(1 + \varepsilon_2) \\
                    \mathrm{fl}(x \div y) &= (x \div y)(1 + \varepsilon_3) \\
                \end{align*}
                where \( |\varepsilon_i| \leq \eta \), for \( i = 1,2,3 \), where \( \eta \) is the unit roundoff.
                \bigbreak \noindent 
                Although the relative error of each flop is small, it is possible to have the roundoff error accumulate and create significant error in the final result. If \( E_n \) is the error after \( n \) flops, then:
                \begin{itemize}
                    \item \textbf{Linear roundoff error accumulation} is when \( E_n \approx c_0 n E_0 \)
                    \item \textbf{Exponential roundoff error accumulation} is when \( E_n \approx c_1^n E_0 \), for some \( c_1 > 1 \)
                \end{itemize}
                In general, linear roundoff error accumulation is unavoidable. On the other hand, exponential roundoff error accumulation is not acceptable and is an indication of an \textbf{unstable algorithm}. (See Example 1.6 in Ascher-Greif for an example of exponential roundoff error accumulation, and see Exercise 5 in Section 1.4 for a numerically stable method to accomplish the same task.)
            \item \textbf{General advice}: 
                \begin{enumerate}
                    \item Adding \( x + y \) when \( |x| \gg |y| \) can cause the information in \( y \) to be "lost" in the summation.
                    \item Dividing by very small numbers or multiplying by very large numbers can \textbf{magnify error}.
                    \item Subtracting numbers that are almost equal produces \textbf{cancellation error}.
                    \item An \textbf{overflow} occurs when the result is too large in magnitude to be representable as a float. The result will become either \texttt{Inf} or \texttt{-Inf}. Overflows should be avoided.
                    \item An \textbf{underflow} occurs when the result is too small in magnitude to be representable as a float. The result will become either \texttt{0.0} or \texttt{-0.0}.
                \end{enumerate}
        \item \textbf{Information lose example}: This example shows that the summation order can make a difference. Consider the sum
            \begin{align*}
                s =\sum_{n=1}^{1,000,000} \frac{1}{n}
            \end{align*}
            Let's do this sum in two different ways. First, from largest to smallest, then from smallest to largest.
            \bigbreak \noindent 
            \textbf{Largest to smallest}
            \bigbreak \noindent 
            \begin{pythoncode}
                sum = 0
                for i in 1:1000000
                    sum+=1/i
                end
                # 14.392726722864989
            \end{pythoncode}
            \bigbreak \noindent 
            \textbf{Smallest to largest}
            \bigbreak \noindent 
            \begin{pythoncode}
            sum = 0
            for i in 1000000:-1:1
                sum += 1/i
            end
            # 14.392726722865772
            \end{pythoncode}
            \bigbreak \noindent 
            We can do the computation with a BigFloat to see which one is more precise
            \bigbreak \noindent 
            \begin{jlcode}
            bfsum::BigFloat = 0
            for i in 1:1000000
                sum+=BigFloat(1)/i
            end
            # 14.39272672286572363138112749318858767664480001374431165341843304581295850751194
            \end{jlcode}
            \bigbreak \noindent 
            So we see the smallest to largest sum is slightly more accurate. Why is this? When summing a sequence of numbers, the order in which the numbers are added affects how rounding errors accumulate. Adding smaller numbers to a large sum can cause the smaller values to be "swallowed" due to the limitations of floating-point precision.
            \bigbreak \noindent 
            When summing from large terms to small terms, the large values dominate early in the computation. Because floating-point numbers have limited precision, adding much smaller numbers later may result in those numbers being effectively ignored (i.e., they contribute little due to rounding errors).
            \bigbreak \noindent 
            When summing from small terms to large terms, the intermediate sum stays small for longer, allowing more precise accumulation of the smaller values before reaching the larger ones. This reduces the impact of rounding errors.
        \item \textbf{Cancellation error example}: We consider 
            \begin{align*}
                \ln{\left(x - \sqrt{x^{2} -1}\right)} = -\ln{\left(x + \sqrt{x^{2} - 1}\right)}
            \end{align*}
            First, we show that these expressions are actually equivalent
            \begin{align*}
                x-\sqrt{x^{2} -1} &= x-\sqrt{x^{2} -1} \left(\frac{x+\sqrt{x^{2}-1}}{x+\sqrt{x^{2} - 1}}\right) \\
                                  &= \frac{x^{2} - \sqrt{x^{2}-1} + \sqrt{x^{2} - 1} - \left(\sqrt{x^{2} - 1}\right)^{2}}{x+\sqrt{x^{2}-1}} \\
                                  &= \frac{1}{x+\sqrt{x^{2}-1}} = \left(x+\sqrt{x^{2}-1}\right)^{-1}
            \end{align*}
            Thus, 
            \begin{align*}
                \ln{\left(x-\sqrt{x^{2}-1}\right)} &= \ln{\left(\left(x+\sqrt{x^{2}-1}\right)^{-1}\right)}  \\
                                                   &= - \ln{\left(x+\sqrt{x^{2}-1}\right)}
            \end{align*}
            \bigbreak \noindent 
            Let's see which one is more accurate in numerical computations.
            \bigbreak \noindent 
            \begin{jlcode}
            x = 1e6
            fl = log(x-sqrt(x^2 -1))
            fr = -log(x+sqrt(x^2 -1))
            fl,fr

            # (-14.50865012405984, -14.508657738523969)
            \end{jlcode}
            \bigbreak \noindent 
            If we examine the quantities $x$, and $\sqrt{x^{2}-1}$, we see that the are very close to each other
            \bigbreak \noindent 
            \begin{jlcode}
            x, sqrt(x^2-1)
            # (1.0e6, 999999.9999995)
            \end{jlcode}
            \bigbreak \noindent 
            The first expression $\ln{\left(x- \sqrt{x^{2}-1}\right)} $ gives cancellation error, which happens when two nearly equal floating-point numbers are subtracted, leading to significant loss of precision.
            \bigbreak \noindent 
            When two very close numbers are subtracted, the leading digits cancel out, leaving only a small result with much fewer significant digits. This makes the result inaccurate.
        \item \textbf{Example: Avoiding overflow}: 
            Overflow is possible when squaring a large number. This needs to be avoided when computing the Euclidean norm (a.k.a. the $2$-norm) of a vector $x$:
            $$
            \|x\|_2 = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}.
            $$
            \bigbreak \noindent 
            If some $x_i$ is very large, it is possible that $x_i^2$ will overflow, causing the final result to be \textbf{Inf}. We can avoid this as follows.
            \bigbreak \noindent 
            Let 
            $$\bar{x} = \max_{i=1:n} |x_i|.$$
            Then
            $$
            \|x\|_2 = \bar{x} \sqrt{\left(\frac{x_1}{\bar{x}}\right)^2 + \left(\frac{x_2}{\bar{x}}\right)^2 + \cdots + \left(\frac{x_n}{\bar{x}}\right)^2}.
            $$
            Since $|x_i/\bar{x}| \leq 1$ for all $i$, no overflow will occur. Underflow may occur, but this is harmless.











    \end{itemize}

    \pagebreak 
    \subsection{Non linear equations in one variable}
    \begin{itemize}
        \item \textbf{Julia \LaTeX \ strings}: In a Julia REPL or jupyter notebooks, we can include the LatexStrings package. This package allows us to create strings that contain \LaTeX \ and format them. We do this by creating a string like
            \begin{center}
                L"string contents"
            \end{center}
            For example
            \begin{center}
                L"\int f(x)\ dx"
            \end{center}
            \bigbreak \noindent 
            \begin{jlcode}
            using LatexStrings
            \end{jlcode}
        \item \textbf{Intro}: In many applications, one needs the solution to a \textbf{nonlinear equation} for which there is no closed formula.
            \bigbreak \noindent 
            Suppose you do not have a cube-root function, but only the operations $+$, $-$, $\times$, $\div$
            \bigbreak \noindent 
             Polynomials with degree at least five have no general algebraic solution
             \bigbreak \noindent 
             Some nonlinear equations may not be solved analytically, for example
             \begin{align*}
                 10\cosh{\left(\frac{x}{4}\right)} = x \quad \text{ and } 2\cosh{\left(\frac{x}{4}\right)} = x
             \end{align*}
             Recall the hyperbolic sine, cosine, and tangent functions are defined as
             \begin{align*}
                 \sinh{\left(t\right)} &= \frac{e^{t} - e^{-t}}{2} \\
                 \cosh{\left(t\right)} &= \frac{e^{t} + e^{-t}}{2} \\
                 \tanh{\left(t\right)} &= \frac{e^{t} - e^{-t}}{e^{t} + e^{-t}} \\
             \end{align*}
             Also, $\tanh{(t)} = \frac{\sinh{(t)}}{\cosh{(t)}},\ \frac{d}{dt}\sinh{(t)} = \cosh{(t)}$ , and $\frac{d}{dt}\cosh{(t)} = \sinh{(t)} $
        \item \textbf{Problem statement: roots}: 
            Given $f \in C[a,b]$ (i.e., a \textit{continuous} function $f \colon [a,b] \to \mathbb{R}$) and we want to find $x^* \in [a, b]$ such that
            $$
            f(x^*) = 0.
            $$
        The solution $x^*$ is called a \textbf{root} or \textbf{zero} of the function $f$. There could be exactly one root, many roots, or no roots at all.
    \item \textbf{The Julia Roots package}: In Julia, the package \textit{Roots} gives us functions like \texttt{find\_zero} to find or approximate the roots of an equation
        \bigbreak \noindent 
        \begin{jlcode}
        using Pkg
        Pkg.add("Roots")
        using Roots
        \end{jlcode}
        \bigbreak \noindent 
        Consider the functions
        \bigbreak \noindent 
        \begin{jlcode}
            f(x) = 10cosh(x/4) - x
            g(x) = 2cosh(x/4) - x
        \end{jlcode}
        \bigbreak \noindent 
        We can first plot the functions to get an tight interval that contains a root
        \bigbreak \noindent 
        \begin{jlcode}
            plot(axes_style=:zerolines, xlims=[-2,12], xlabel=L"x", ylabel=L"y")
            plot!(f, -2, 12, label=L"y = 10\cosh(x/4) - x")
            plot!(g, -2, 12, label=L"y = 2\cosh(x/4) - x")
        \end{jlcode}
        Using the function \texttt{find\_zero}, passing in a function and an interval, we can find approximate or exact roots 
        \bigbreak \noindent 
        \begin{jlcode}
        x1 = find_zero(g, (2,3))
        # 2.357551053877402

        g(x1) # 0.0
    \end{jlcode}
\item \textbf{Iterative methods}: Often there is no closed formula for a root $x^*$ of the function $f$. Instead of using a formula to compute a root $x^*$, we will start with an \textbf{initial guess} $x_0$ and generate a \textbf{sequence of iterates}
    \bigbreak \noindent 
    $$ x_1, x_2, x_3, \ldots, x_k, \ldots $$
    that we hope \textbf{converges} to $x^*$; i.e.,
    $$\lim_{k \to \infty} x_k = x^*$$
    \textbf{Note:} Different initial guesses $x_0$ may generate sequences of iterates that converge to different roots. We will see how to deal with this issue.
\item \textbf{Iterative methods: When to stop}: Since the sequence of iterates is infinite, we must decide when we are close enough to a root $x^{*}$ . However, we do not know , so how can we decide when we are close enough?
    \bigbreak \noindent 
    Stop options are to stop when
    \begin{enumerate}
        \item The function value is small:
            $$\left|f(x_k)\right| < \mathtt{ftol}.$$
             A problem with this test is that $\left|f(x_k)\right|$ may be very small although $x_k$ is still very far from a root.
         \item Consecutive iterates are very close to each other:
             $$\left|x_k - x_{k-1}\right| < \mathtt{atol}.$$
             A problem with this test is that \textit{atol} must take into account the magnitude of the iterates.
         \item  Consecutive iterates are \textbf{relatively} close to each other:
              $$\left|x_k - x_{k-1}\right| < \mathtt{rtol} \left|x_k\right|.$$
               Usually this is more robust than the above absolute test.
    \end{enumerate}
    Often a combination of the above conditions is used. For example, items 2 and 3 can be combined:
    $$\left|x_k - x_{k-1}\right| < \mathtt{tol}(1 + \left|x_k\right|).$$
\item \textbf{Intermediate value theorem}:     If $f \in C[a,b]$ and $f(a) \leq s \leq f(b)$, then there exists a real number $c \in [a,b]$ such that $f(c) = s$.
\item \textbf{Bisection method}: Suppose $f \in C[a,b]$ and that $f(a)$ and $f(b)$ have opposite signs; i.e.,
    $$
    f(a) \cdot f(b) < 0.
    $$
    \bigbreak \noindent 
    Recall the IVT from calculus
    \bigbreak \noindent 
    If $f \in C[a,b]$ and $f(a) \leq s \leq f(b)$, then there exists a real number $c \in [a,b]$ such that $f(c) = s$.
    \bigbreak \noindent 
    Since $f$ changes sign over $[a,b]$, the Intermediate Value Theorem implies that there is some $x^* \in [a,b]$ such that $f(x^*) = 0$.
    The \textbf{bisection method} searches for a root of $f$ in $[a,b]$ as follows.
    \begin{enumerate}
        \item Let $p = \frac{a+b}{2}$ be the \textbf{midpoint} of $[a,b]$.
        \item If $f(a) \cdot f(p) < 0$, then there is a root in $[a,p]$.
        \item If $f(a) \cdot f(p) = 0$, then $p$ is a root.
        \item If $f(a) \cdot f(p) > 0$, then there is a root in $[p,b]$.
    \end{enumerate}
    Each time we apply the above, we get a subinterval that contains a root that is \textbf{half the size} of the interval $[a,b]$.
    \bigbreak \noindent 
    Consider the Julia code for the bisection method 
    \bigbreak \noindent 
    \begin{jlcode}
function bisect(f, a, b; maxiters=1000, tol=1e-6)
    fa, fb = f(a), f(b)
    
    if fa * fb > 0
        error("f(a) and f(b) must have opposite signs")  # Ensure root exists
    end
    
    for i in 1:maxiters
        p = (a + b) / 2
        fp = f(p)

        if abs(fp) < tol || abs(b - a) < tol  # Stop if function value is small or interval is tiny
            return p
        elseif fa * fp < 0
            b, fb = p, fp
        else
            a, fa = p, fp
        end
    end
    
    return (a + b) / 2  # Return best approximation if maxiters is reached
end

f(x) = 2cosh(x/4) - x
a, b = 5.0, 10.0

p = bisect(f, a, b, tol=1e-6)
p, f(p)
    \end{jlcode}
    \bigbreak \noindent 
    The example
    \bigbreak \noindent 
    \begin{jlcode}
        f(x) = 2cosh(x/4) - x
        a, b = 5.0, 10.0

        p = bisect(f, a, b, tol=0.0)
        p, f(p)

        # (8.507199570713027, 1.7763568394002505e-15)
    \end{jlcode}
    \bigbreak \noindent 
    Shows that we get a pretty good approximation

\item \textbf{Analyzing the bisection method}:
    Initially, we know a root $x^*$ is somewhere in the interval $[a,b]$. If we let $x_k$ be the midpoint of the $k$th subinterval, then
    $$\left|x^* - x_0\right| \leq \frac{b-a}{2}.$$
    In the next iteration, 
    $$\left|x^* - x_1\right| \leq \frac{b-a}{4},$$
    and in the following iteration,
    $$\left|x^* - x_2\right| \leq \frac{b-a}{8},$$
    and so on, each time reducing our error bound by a factor of $2$.
    In general,
    $$\left|x^* - x_k\right| \leq \frac{b-a}{2} \cdot 2^{-k}, 
    \qquad \text{for $k = 0,1,2,\ldots$}.$$
    Suppose we want to compute $x_k$ such that 
    $$\left|x^* - x_k\right| \leq \mathtt{atol}.$$
    Then we just need to find the smallest positive integer $k$ such that
    $$\frac{b-a}{2} \cdot 2^{-k} \leq \mathtt{atol}.$$
    That is,
    $$\frac{b-a}{2\mathtt{atol}} \leq 2^k,$$
    which gives us
    $$\log_2\left(\frac{b-a}{2\mathtt{atol}}\right) \leq k,$$
    so we just need the first integer $k$ that is larger than $\log_2\left(\frac{b-a}{2\mathtt{atol}}\right)$. Therefore, 
    $$k = \left\lceil \log_2\left(\frac{b-a}{2\mathtt{atol}}\right) \right\rceil.$$
\item \textbf{Pros and cons of the bisection method}:
\item \textbf{Pros:}
    \begin{enumerate}
        \item \textbf{Simple:} The bisection method only requires function values, is easy to understand and implement, and it is easy to analyze.
        \item \textbf{Robust:} The bisection method is guaranteed to work, provided that $f$ is continuous and changes sign on the interval $[a,b]$.
    \end{enumerate}
\textbf{Cons:}
\begin{enumerate}
    \item \textbf{Slow to converge:} The bisection method often requires many function evaluations.
    \item \textbf{Does not generalize:} The bisection method only applies to solving equations involving one variable; it does not generalize to solving equations involving multiple variables.
\end{enumerate}
\item \textbf{Fixed point iteration}:
    Another simple approach to solving 
    $$f(x) = 0$$
    is to re-write it as
    $$x = g(x)$$
    for some continuous function $g$. We call a point $x$ a \textbf{fixed-point} of $g$ if $x = g(x)$.
    \bigbreak \noindent 
    For example, If we let 
    $$g(x) = x - f(x),$$ 
    then
    $$x = g(x) \quad \Rightarrow \quad x = x - f(x) \quad \Rightarrow \quad f(x) = 0.$$
    Let's plot these functions using $f(x) = x^2 - 2.$
    \bigbreak \noindent 
    \begin{jlcode}
f(x) = x^2 - 2
g(x) = x-f(x)
a, b = -3.0, 3.0

plot(axes_style=:zerolines, aspect_ratio=:equal, legend=:topleft, ylims=[-3,3])
plot!(f, a, b, label=L"y = f(x)", c=1)
plot!(g, a, b, label=L"y = g(x)", c=2)
plot!(x -> x, a, b, label=L"y = x", c=3)
plot!([-sqrt(2), -sqrt(2)], [0, -sqrt(2)], linestyles=:dash, color=:black, label=:none)
plot!([sqrt(2), sqrt(2)], [0, sqrt(2)], linestyles=:dash, color=:black, label=:none)
xlabel!(L"x"); ylabel!(L"y")
    \end{jlcode}
    \bigbreak \noindent 
    \fig{.5}{./figures/savefig40.png}
    \bigbreak \noindent 
    We see that $f(x) = 0$ precisely  when $g(x) = x$ (notice when the orange curve intersects the line $y=x$, it traces back up to the root of the blue curve)
\item \textbf{Fixed point iteration: Choices of $g$}:
    There are many possible choices for $g$:
    \begin{itemize}
        \item $g(x) = x - f(x)$
        \item $g(x) = x + cf(x)$, for some nonzero constant $c$
        \item $g(x) = x - f(x)\big/f'(x)$
    \end{itemize}
Some choices for $g$ will be better than others.
\item \textbf{Iterations with fixed point iteration}:
    Given some initial guess $x_0$, we can use the function $g$ to generate a sequence of iterates as follows:
    $$x_{k+1} = g(x_{k}), \qquad k = 0, 1, 2, \ldots.$$
    If the sequence $\{x_k\}$ converges to some point $x^*$, then we must have $x^* = g(x^*)$, so $f(x^*) = 0$.
    \bigbreak \noindent 
    Consider the Julia function that runs the above algorithm for $f(x) = x^{2} - 2$, and $g(x) = x-f(x) $
    \bigbreak \noindent 
    \begin{jlcode}
function fixedPointPlot(g, a, b, x0; num=5, usequiver=true)

    plt = plot(g, a, b, label=L"y = g(x)", color=:blue)
    plot!(x -> x, a, b, label=L"y = x", color=:green)
    
    x = x0
    for i = 1:num
        if usequiver
            quiver!([x, x], [x, g(x)],
                quiver=([0, g(x)-x], [g(x)-x, 0]))
        else
            plot!([x, x], [x, g(x)], color=i, label=:none)
            plot!([x, g(x)], [g(x), g(x)], color=i, label=:none)
        end
        x = g(x)
    end
    
    scatter!([x0], [x0], label=:none, color=:lime)
    scatter!([x], [x], label=:none, color=:red)
    
    xlabel!(L"x")
    ylabel!(L"y")
    plot!(legend=:outertopright)
    title!("Fixed-point iteration")
    
    return plt
end

g1(x) = x - f(x)
fixedPointPlot(g1, -2, 3, x0, num=5)
    \end{jlcode}
    \bigbreak \noindent 
    \fig{.5}{./figures/savefig41.png}
    \bigbreak \noindent 
    We can examine $k,$ and $x_{k}$
    \bigbreak \noindent 
    \begin{jlcode}
using Printf
x0 = 1.0; x = x0
@printf("%4s %12s\n", "k", "xk")
for k = 1:20
    x = g1(x)
    @printf("%4d %12.4e\n", k, x)
end 
    \end{jlcode}
    \bigbreak \noindent 
    Which gives the table
    \bigbreak \noindent 
    \begin{center}
        \begin{tabular}{c c}
            \hline
            $k$ & $x_k$ \\
            \hline
            1  & 2.0000e+00 \\
            2  & 0.0000e+00 \\
            3  & 2.0000e+00 \\
            4  & 0.0000e+00 \\
            5  & 2.0000e+00 \\
            6  & 0.0000e+00 \\
            7  & 2.0000e+00 \\
            8  & 0.0000e+00 \\
            9  & 2.0000e+00 \\
            10 & 0.0000e+00 \\
            11 & 2.0000e+00 \\
            12 & 0.0000e+00 \\
            13 & 2.0000e+00 \\
            14 & 0.0000e+00 \\
            15 & 2.0000e+00 \\
            16 & 0.0000e+00 \\
            17 & 2.0000e+00 \\
            18 & 0.0000e+00 \\
            19 & 2.0000e+00 \\
            20 & 0.0000e+00 \\
            \hline
        \end{tabular}
    \end{center}
    \bigbreak \noindent 
    It does not seem to be converging to anything. Now let's try $g(x) = x - f(x)\big/f'(x)$.
    \bigbreak \noindent 
    \begin{jlcode}
    fixedPointPlot(x -> x-f(x)/2x, 1.0, 1.5, 1.1, usequiver=true)
    \end{jlcode}
    \bigbreak \noindent 
    Gives the plot
    \bigbreak \noindent 
    \fig{.5}{./figures/savefig42.png}
    \bigbreak \noindent 
    We can also examine the absolute errors
    \bigbreak \noindent 
    \begin{jlcode}
x = 1.0; xs = sqrt(2)

@printf("%4s %12s\n", "k", "error")
for k = 1:5
    x = (x->x-f(x)/2x)(x)
    @printf("%4d %12.4e\n", k, x - xs)
end
    \end{jlcode}
    \bigbreak \noindent 
    \begin{center}
        \begin{tabular}{cc}
            k        &error \\
            1   &8.5786e-02
            2   &2.4531e-03
            3   &2.1239e-06
            4   &1.5947e-12
            5   &0.0000e+00
        \end{tabular}
    \end{center}
    \bigbreak \noindent 
    It converges very rapidly! We will see later why this is happening.
\item \textbf{Mean value theorem}: If $f \in C[a,b]$ and $f$ is differentiable on the open interval $(a,b)$, then there exists a number $c \in (a,b)$ such that 
$$f'(c) = \frac{f(b)-f(a)}{b-a}$$
\bigbreak \noindent 
Which means there exists some point $c$ in which the tangent line at $c$ is equal to the secant line drawn connecting points $a$ and $b$
\item \textbf{Existence and uniqueness of a fixed point}: A fixed point may not exist in $[a,b]$, and if it does, it may not be unique.
    \bigbreak \noindent 
    \textbf{Fixed point theorem}:
    Let $g \in C[a,b]$ such that one of the two following conditions hold:
    \begin{enumerate}
        \item $g(a) \geq a$ and $g(b) \leq b$;
        \item $g(a) \leq a$ and $g(b) \geq b$.
    \end{enumerate}
    Then $\exists x^* \in [a,b]$ such that $g(x^*) = x^*$.
    In addition, if $g$ is differentiable on the open interval $(a,b)$ and 
    $$\left|g'(x)\right| \leq \rho, \quad \forall x \in (a,b),$$
    for some $\rho < 1$, then $x^*$ is the \textit{unique} fixed point in $[a,b]$.
    \bigbreak \noindent 
    \textbf{\textit{Proof.}}  Suppose $g(a) \geq a$ and $g(b) \leq b$. If $g(a) = a$ or $g(b) = b$, then we are done. Otherwise we have $g(a) > a$ and $g(b) < b$.
    Let
    $$\phi(x) = g(x) - x.$$
    Then $\phi(a) > 0$ and $\phi(b) < 0$. Thus, since $\phi$ is continuous, the **Intermediate Value Theorem** tells us that there is an $x^* \in [a,b]$ such that $\phi(x^*) = 0$. Thus $x^* = g(x^*)$.
    \bigbreak \noindent 
    The other case of $g(a) \leq a$ and $g(b) \geq b$ can be proven similarly.
    \bigbreak \noindent 
    Now suppose $g$ is differentiable and there is a $\rho < 1$ such that $\left|g'(x)\right| \leq \rho$ for all $x \in (a,b)$. Suppose, **for the sake of contradiciton**, that $x^*$ is not the only fixed point of $g$ in $[a,b]$. Then, there is a $y^* \in [a,b]$ such that $g(y^*) = y^*$ and $y^* \neq x^*$. 
    \bigbreak \noindent 
    By the \textbf{Mean Value Theorem}, there is a $\xi$ strictly between $x^*$ and $y^*$ such that
    $$  g'(\xi) = \frac{g(x^*) - g(y^*)}{x^* - y^*} = \frac{x^* - y^*}{x^* - y^*} = 1.$$
    Note that $\xi \in (a,b)$. This contradicts our assumption that $\left|g'(x)\right| \leq \rho < 1$, for all $x \in (a,b)$. Therefore, the fixed point of $g$ in $[a,b]$ must be unique. $\blacksquare$
\item \textbf{Convergence}: We have seen that the fixed point iteration does not always converge. 
    \bigbreak \noindent 
    \textbf{Theorem: (Convergence of the Fixed Point Iteration)}:
    Let $g \in C[a,b]$. If 
    \begin{itemize}
        \item$a \leq g(x) \leq b$, for all $x \in [a,b]$, and
        \item there is a $\rho < 1$ such that $\left|g'(x)\right| \leq \rho$ for all $x \in (a,b),$
    \end{itemize}
    then the iteration 
    $$x_{k+1} = g(x_{k}), \qquad k = 0, 1, 2, \ldots$$
    converges to the unique fixed point $x^* \in [a,b]$ starting from any $x_0 \in [a,b]$.
    \bigbreak \noindent 
    \textbf{\textit{Proof.}} First of all, since $g(x) \in [a,b]$ for all $x \in [a,b]$, and since $x_0 \in [a,b]$, we have $x_k \in [a,b]$, for all $k = 0, 1, 2, \ldots$. Moreover, by the \textbf{Fixed Point Theorem}, our assumptions imply that there is a unique fixed point $x^* \in [a,b]$. 
    \bigbreak \noindent 
    Let $k \in \{1,2,\ldots\}$. If $x_{k-1} = x^*$, then we have already converged to the fixed point. Otherwise, suppose that $x_{k-1} \neq x^*$. By the \textbf{Taylor Series Theorem} (could also use the \textbf{Mean Value Theorem} like above), there exists a $\xi$ strictly between $x_{k-1}$ and $x^*$ such that 
    $$ g(x_{k-1}) = g(x^* + (x_{k-1} - x^*)) = g(x^*) + g'(\xi) (x_{k-1} - x^*).$$
    Note that $\xi \in (a,b)$. Thus,
    $$ \left|x_k - x^*\right| = \left|g(x_{k-1}) - g(x^*)\right| = \left|g'(\xi)(x_{k-1} - x^*)\right| = \left|g'(\xi)\right|\left|x_{k-1} - x^*\right| \leq \rho \left|x_{k-1} - x^*\right|. $$
    So $\left|x_k - x^*\right| \leq \rho \left|x_{k-1} - x^*\right|$ for $k = 1, 2, \ldots$, which implies that
    $$ 0 \le \left|x_k - x^*\right| \leq \rho \left|x_{k-1} - x^*\right| \leq \rho^2 \left|x_{k-2} - x^*\right| \leq \cdots \leq \rho^k \left|x_{0} - x^*\right|.$$
    Since $\rho < 1$, the right-hand-side converges to $0$ as $k \to \infty$. Therefore,
    $$ \lim_{k \to \infty} \left|x_k - x^*\right| = 0,$$
    so $x_k$ converges to $x^*$. $\blacksquare$
\item \textbf{Contraction factor}: We call $\rho$ the \textit{contraction factor}, the smaller $\rho$ is, the faster the convergence
\item \textbf{Convergence example}:
    The first $g$ we considered was
    $$g(x) = x - x^2 + 2$$
    which has the fixed points $x_1^* = -\sqrt{2}$ and $x_2^* = \sqrt{2}$. Note that
    $$g'(x) = 1 - 2x$$
    and that 
    $$\begin{align}
        g'(x_1^*) & = 1 + 2\sqrt{2} = 3.8284271247461903\ldots, \\
        g'(x_2^*) & = 1 - 2\sqrt{2} = -1.8284271247461903\ldots. \\
    \end{align}
    $$
    So, $\left|g'(x_i^*)\right| > 1$ for $i=1,2$, which explains why the fixed point iteration would not converge to either fixed point.
    \bigbreak \noindent 
    The second $g$ we considered was
    $$g(x) = x - \frac{x^2 - 2}{2x} = \frac{x}{2} + \frac{1}{x},$$
    which has the fixed points $x_1^* = -\sqrt{2}$ and $x_2^* = \sqrt{2}$. Now the derivative is
    $$g'(x) = \frac{1}{2} - \frac{1}{x^2},$$
    and so
    $$g'(x_i^*) = 0, \quad i=1,2.$$
    Thus, for $i=1,2$, we have $\left|g'(x_i^*)\right| < \rho$, for any $\rho \in (0,1)$. This explains why the fixed point iteration converged rapidly to $x_2^*$ from $x_0 = 1.1$; we also expect rapid convergence to $x_1^*$ from suitable $x_0$.
\item \textbf{Newton's method}:
    Let 
    \[
        f \in C^2[a,b].
    \]
    That is, \( f \) is a \textbf{twice-continuously differentiable} function over \([a,b]\), which means that the \textbf{first} and \textbf{second} derivatives of \( f \) \textbf{exist} and are \textbf{continuous} on the open interval \( (a,b) \). \textbf{Newton's method} is defined as:
    \[
        x_{k+1} = x_k - \frac{f(x_k)}{f'(x_k)}, \quad k = 0, 1, 2, \ldots.
    \]
    This is the fixed point iteration using the function \( g(x) = x - f(x)\big/ f'(x) \).
\item \textbf{Formulating Newton's method}:
    Suppose that $f(x^*) = 0$ and that we are at the iterate $x_k$. By the \textbf{Taylor Series Theorem}, we have
    $$
    f(x^*) = f(x_k) + f'(x_k)(x^* - x_k) + \frac{f''(\xi)}{2}(x^* - x_k)^2,
    $$
    for some point $\xi$ between $x^*$ and $x_k$. If $x_k$ is already fairly close to $x^*$, then $(x^* - x_k)^2$ will be very small, so we have
    $$0 \approx f(x_k) + f'(x_k)(x^* - x_k).$$
    Solving for $x^*$, we obtain
    $$x^* \approx x_k - \frac{f(x_k)}{f'(x_k)}.$$
    Therefore, it makes sense to define our next iterate $x_{k+1}$ using this approximation.
\item \textbf{Another formulation for Newton's method}:
    Another way to obtain Newton's method is as follows. Consider the \textbf{first-order (linear) approximation} of $f$ around the point $x_k$:
    $$f(x) \approx f(x_k) + f'(x_k)(x - x_k), \quad \text{for all $x \approx x_k$}.$$
    Suppose that $x_k$ is close to $x^*$, and that $f(x^*) = 0$. Then
    $$f(x^*) \approx f(x_k) + f'(x_k)(x^* - x_k),$$
    which implies that
    $$x^* \approx x_k - \frac{f(x_k)}{f'(x_k)}.$$
    Therefore, our next iterate should be 
    $$x_{k+1} = x_k - \frac{f(x_k)}{f'(x_k)}.$$
\item \textbf{Newton's method example: The Babylonian method for computing $\sqrt{a}$}:
    Let $f(x) = x^2 - a$. Newton's method gives us the iteration:
$$ x_{k+1} = x_k - \frac{x_k^2 - a}{2x_k} = \frac{1}{2}\left(x_k + \frac{a}{x_k}\right).$$
\item \textbf{Speed of convergence}:
    If \( x_k \to x^* \), we can measure the speed of the convergence as follows.
    \begin{itemize}
        \item  \textbf{Linear convergence} means there is a constant \( 0 < \rho < 1 \) such that
        \[
            \left|x_{k+1}-x^*\right| \leq \rho \left|x_k - x^*\right|, \quad \text{for all } k \text{ sufficiently large};
        \]
        that is,
        \[
            \lim_{k \to \infty} \frac{\left|x_{k+1}-x^*\right|}{\left|x_k - x^*\right|} = \rho < 1.
        \]

        \item \textbf{Superlinear convergence} means there is a sequence \( \rho_k \to 0 \) such that
        \[
            \left|x_{k+1}-x^*\right| \leq \rho_k \left|x_k - x^*\right|, \quad \text{for all } k \text{ sufficiently large};
        \]
        that is,
        \[
            \lim_{k \to \infty} \frac{\left|x_{k+1}-x^*\right|}{\left|x_k - x^*\right|} = 0.
        \]

        \item  \textbf{Quadratic convergence} means there is a constant \( M \) such that
        \[
            \left|x_{k+1}-x^*\right| \leq M \left|x_k - x^*\right|^2, \quad \text{for all } k \text{ sufficiently large};
        \]
        that is,
        \[
            \lim_{k \to \infty} \frac{\left|x_{k+1}-x^*\right|}{\left|x_k - x^*\right|^2} = M < \infty.
        \]
    \end{itemize}
Note that \textbf{quadratic convergence} is an example of \textbf{superlinear convergence} with \( \rho_k = M \left|x_k - x^*\right| \).
\item \textbf{Quadratic convergence of Newton's method}
    \bigbreak \noindent 
    \textbf{Theorem}: Let $f \in C^2[a,b]$. If $f$ has a root $x^* \in (a,b)$ such that $f'(x^*) \neq 0$, then there is a $\delta > 0$ such that Newton's method \textbf{converges quadratically} to $x^*$ from any $x_0 \in [x^*-\delta, x^*+\delta]$.
    \bigbreak \noindent 
    \textbf{\textit{Proof.}} 
    Since
    \begin{itemize}
        \item $f \in C^2[a,b]$ 
        \item $x^* \in (a,b)$
        \item $f'(x^*) \neq 0$
    \end{itemize}
    there are positive constants $\delta_1$, $\varepsilon$, and $M$ such that
    \begin{itemize}
        \item $\left|f'(x)\right| \geq \varepsilon$ 
        \item $\left|f''(x)\right| \leq M$
    \end{itemize}
    for all $x \in [x^*-\delta_1, x^*+\delta_1] \subset (a,b)$.
    \bigbreak \noindent 
    Suppose $x_k \in [x^*-\delta_1, x^*+\delta_1]$. Then, there is a $\xi_k$ between $x^*$ and $x_k$ such that
    $$f(x^*) = f(x_k) + f'(x_k) (x^* - x_k) + \frac{f''(\xi_k)}{2} (x^* - x_k)^2.$$
    Using the fact that $f(x^*) = 0$, we have
    $$0 = f(x_k) + f'(x_k) (x^* - x_k) + \frac{f''(\xi_k)}{2} (x^* - x_k)^2.$$
    Also, $x_{k+1}$ satisfies
    $$0 = f(x_k) + f'(x_k) (x_{k+1} - x_k).$$
    Subtracting these equations, we obtain
    $$0 = f'(x_k) (x^* - x_{k+1}) + \frac{f''(\xi_k)}{2} (x^* - x_k)^2.$$
    \bigbreak \noindent 
    Since $f'(x_k) \ne 0$, we have 
    $$x^* - x_{k+1} = -\frac{f''(\xi_k)}{2f'(x_k)} (x^* - x_k)^2.$$
    Thus,
    $$\left|x^* - x_{k+1}\right| = \left|\frac{f''(\xi_k)}{2f'(x_k)}\right| \left|x^* - x_k\right|^2 \leq \frac{M}{2\varepsilon} \left|x^* - x_k\right|^2,$$
    so if $x_k \to x^*$, then the \textbf{convergence will be quadratic}.
    \bigbreak \noindent 
    We just need to find $\delta > 0$ so that if $x_0 \in [x^* - \delta, x^* + \delta]$, then $x_k \to x^*$.
    Let
    $$\delta = \min\left\{\frac{\varepsilon}{M}, \delta_1\right\}.$$
    Suppose that $x_k \in [x^* - \delta, x^* + \delta]$. Then
    \begin{align*}
        \left|x^* - x_{k+1}\right| 
&\leq \frac{M}{2\varepsilon} \left|x^* - x_k\right|^2 \\
&\leq \frac{M}{2\varepsilon} \delta \left|x^* - x_k\right| \\
&\leq \frac{1}{2} \left|x^* - x_k\right| \\
&< \delta,
    \end{align*}
    so $x_{k+1} \in [x^* - \delta, x^* + \delta]$ as well. Thus, if $x_0 \in [x^* - \delta, x^* + \delta]$, we have $x_k \in [x^* - \delta, x^* + \delta]$ for $k = 0, 1, 2, \ldots$.
    \bigbreak \noindent 
    Moreover,
    $$0 \leq \left|x^* - x_k\right| \leq \frac12 \left|x^* - x_{k-1}\right| \leq \frac14 \left|x^* - x_{k-2}\right| \leq \cdots \leq \frac{1}{2^k} \left|x^* - x_{0}\right|.$$
    Since $\frac{1}{2^k} \left|x^* - x_{0}\right| \to 0$ as $k \to \infty$, we conclude that $x_k \to x^*$. Thus, if $x_0 \in [x^* - \delta, x^* + \delta]$ then $x_k$ converges to $x^*$ quadratically. $\blacksquare$
\item \textbf{Pros and cons of Newton's method}:
    \bigbreak \noindent 
    \textbf{Pros:}
    \begin{itemize}
        \item \textbf{Fast to converge:} Newton's method enjoys quadratic convergence near the root when $f'(x^*) \neq 0$.
        \item \textbf{Generalizes to multiple variables:} Let $\mathbf{F} \colon \mathbb{R}^n \to \mathbb{R}^n$. Newton's method for solving 
        $$\mathbf{F}(\mathbf{x}) = \mathbf{0}$$ 
        (i.e., $n$ nonlinear equations with $n$ unknowns) is
        $$ \mathbf{x}_{k+1} = \mathbf{x}_k - \mathbf{J}(\mathbf{x}_k)^{-1} \mathbf{F}(\mathbf{x}_k),$$
        where $\mathbf{J}(\mathbf{x})$ is the $n \times n$ **Jacobian** of $\mathbf{F}$:
        $$
        \mathbf{J}(\mathbf{x}) = 
        \begin{bmatrix}
            \frac{\partial F_1}{\partial x_1}& \cdots &
            \frac{\partial F_1}{\partial x_n}\\
            \vdots & \ddots & \vdots \\
            \frac{\partial F_n}{\partial x_1}& \cdots &
            \frac{\partial F_n}{\partial x_n}\\
        \end{bmatrix}$$
    \end{itemize}
    \bigbreak \noindent 
    \textbf{Cons}
    \begin{itemize}
        \item \textbf{Requires the derivative:} We must give Newton's method both the function $f$ and its derivative $f'$. This may not always be possible or easy.
        \item \textbf{Need to start close to $x^*$:} Newton's method is a \textbf{local method}. When $x_0$ is far from $x^*$, Newton's method may not converge to $x^*$, or may require many iterations before quadratic convergence begins.
    \end{itemize}
\item \textbf{Secant method}:
    Sometimes it is not possible to evaluate the derivative $f'$:
    \begin{itemize}
        \item $f'$ is unknown or difficult to obtain
        \item evaluating $f'$ takes too much time
    \end{itemize}
    Instead, we can use the \textbf{secant approximation} of the derivative. When $x_k \approx x_{k-1}$, we have
    $$ f'(x_k) \approx \frac{f(x_k) - f(x_{k-1})}{x_k - x_{k-1}}.$$
    Plugging this approximation into the formula for Newton's method, we get:
    $$x_{k+1} = x_k - \frac{f(x_k)(x_k - x_{k-1})}{f(x_k) - f(x_{k-1})}$$
    \bigbreak \noindent 
    The secant method is an example of a \textit{Quasi-Newton method} method since we are replacing $f'$ with an approximation of $f'$.
    \bigbreak \noindent 
    When $f'(x^*) \neq 0$, the secant method will converge \textbf{superlinearly}, so it may not be as fast as Newton's method.
\item \textbf{The case of a multiple root}:
    When $f'(x^*) = 0$, we are no longer guaranteed to obtain superlinear convergence of the secant method, nor quadratic convergence of Newton's method. In this case, both methods will be merely **linearly convergent**.

\item \textbf{Minimizing a function in one variable}:
    We can use the root-finding methods described above to find the \textbf{minimum} or \textbf{maximum} value of a function $\phi \in C^2[a,b]$.
    Recall that $x^* \in (a,b)$ is a \textbf{critical point} of $\phi$ if 
    $$\phi'(x^*) = 0.$$
    We can find $x^*$ by applying Newton's method to this nonlinear equation to obtain:
    $$x_{k+1} = x_k - \frac{\phi'(x_k)}{\phi''(x_k)}.$$
\item \textbf{Another interpretation}:
    We can also obtain this by considering the \textbf{second-order (quadratic) approximation} of $\phi$ around the point $x_k$:
    $$\phi(x) \approx \phi(x_k) + \phi'(x_k)(x-x_k) + \frac{\phi''(x_k)}{2}(x-x_k)^2, \quad \text{for all $x \approx x_k$}.$$
    If $x_k$ is close to $x^*$, we expect the minimum/maximum of $\phi$ to be near the minimum/maximum of the **quadratic approximation** of $\phi$:
    $$q(x) = \phi(x_k) + \phi'(x_k)(x-x_k) + \frac{\phi''(x_k)}{2}(x-x_k)^2.$$
    We should choose $x_{k+1}$ to be the critical point of $q$, so we want to find $x_{k+1}$ such that $q'(x_{k+1}) = 0$. Note that
    $$q'(x) = \phi'(x_k) + \phi''(x_k)(x-x_k).$$
    Thus $q'(x_{k+1}) = 0$ gives us
    $$x_{k+1} = x_k - \frac{\phi'(x_k)}{\phi''(x_k)}.$$










    \end{itemize}















    
\end{document}
