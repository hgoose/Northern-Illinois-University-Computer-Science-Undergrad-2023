\documentclass{report}

\input{~/dev/latex/template/preamble.tex}
\input{~/dev/latex/template/macros.tex}

\title{\Huge{}}
\author{\huge{Nathan Warner}}
\date{\huge{}}
\fancyhf{}
\rhead{}
\fancyhead[R]{\itshape Warner} % Left header: Section name
\fancyhead[L]{\itshape\leftmark}  % Right header: Page number
\cfoot{\thepage}
\renewcommand{\headrulewidth}{0pt} % Optional: Removes the header line
%\pagestyle{fancy}
%\fancyhf{}
%\lhead{Warner \thepage}
%\rhead{}
% \lhead{\leftmark}
%\cfoot{\thepage}
%\setborder
% \usepackage[default]{sourcecodepro}
% \usepackage[T1]{fontenc}

% Change the title
\hypersetup{
    pdftitle={Math 3}
}

\begin{document}
    % \maketitle
        \begin{titlepage}
       \begin{center}
           \vspace*{1cm}
    
           \textbf{Undergraduate Topics in Mathematics (4)} \\
           Proof writing, The theory of sets, Axiomatic geometry, Numerical analysis
    
           \vspace{0.5cm}
            
                
           \vspace{1.5cm}
    
           \textbf{Nathan Warner}
    
           \vfill
                
                
           \vspace{0.8cm}
         
           \includegraphics[width=0.4\textwidth]{~/niu/seal.png}
                
           Computer Science \\
           Northern Illinois University\\
           United States\\
           
                
       \end{center}
    \end{titlepage}
    \tableofcontents
    \pagebreak 
    \unsect{Proofs}
    \bigbreak \noindent 
    \subsection{Intro to proof writing, intuitive proofs}
    \begin{itemize}
        \item \textbf{Intro to definitions, propositions and proofs: the chessboard problem}: Suppose you have a chessboard (8$\times$8 grid of squares) and a bunch of dominoes (2$\times$1 block of squares), so each domino can perfectly cover two squares of the chessboard.
            \bigbreak \noindent 
            Note that with 32 dominoes you can cover all 64 squares of the chessboard. There are many different ways you can place the dominoes to do this, but one way is to cover the first column by 4 dominoes end-to-end, cover the second column by 4 dominoes, and so on
            \bigbreak \noindent 
            Math runs on definitions, so let’s give a name to this idea of covering all the squares. Moreover, let’s not define it just for 8 $\times$ 8 boards — let’s allow the definition to apply to boards of other dimensions
            \bigbreak \noindent 
            \textbf{Definition.} A perfect cover of an $m\times n$ board with 2 $\times$ 1 dominoes is an arrangement of those dominoes on the chessboard with no squares left uncovered, and no dominoes stacked or left hanging off the end.
            \bigbreak \noindent 
            As we demonstrated above, there exist perfect covers of the 8 $\times$ 8 chessboard. This is a book about proofs, so let’s write this out as a proposition (something which is true and requires proof) and then let’s write out a formal proof of this fact.
            \bigbreak \noindent 
            \textbf{Proposition.} There exists a perfect cover of an 8 $\times$ 8 chessboard.
            \bigbreak \noindent 
            This proposition is asserting that “there exists” a perfect cover. To say “there exists” something means that there is at least one example of it. Therefore, any proposition like this can be proven by simply presenting an example which satisfies the statement.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Observe that the following is a perfect cover.
            \bigbreak \noindent 
            \fig{.7}{./figures/1.png}
            \bigbreak \noindent 
            We have shown by example that a perfect cover exists, completing the proof. $\blacksquare$
            \bigbreak \noindent 
            We typically put a small box at the end of a proof, indicating that we have completed our argument. This practice was brought into mathematics by Paul Halmos, and it is sometimes called the Halmos tombstone
            \bigbreak \noindent 
            One apocryphal story is that Halmos regarded proofs as living until proven. Once proven, they have been defeated — killed. And so he wrote a little tombstone to conclude his proof
            \bigbreak \noindent 
            What if I cross out the bottom-left and top-left squares, can we still perfectly cover the 62 remaining squares?
            \bigbreak \noindent 
            As you can probably already see, the answer is yes. For example, the first column can now be covered by 3 dominoes and the other columns can be covered by 4 dominoes each.
            \bigbreak \noindent 
            What if I cross out just one square, like the top-left square? Can this be perfectly covered? 
            \bigbreak \noindent 
            The answer is no
            \bigbreak \noindent 
            \textbf{Proposition.} If one crosses out the top-left square of an 8 $\times$ 8 chessboard, the remaining squares can not be perfectly covered by dominoes.
            \bigbreak \noindent 
            \textbf{Proof Idea}. The idea behind this proof is that one domino, wherever it is placed, covers two squares. And two dominoes must cover four squares. And three cover six. In general, the number of squares covered — 2, 4, 6, 8, 10, etc. — is always an even number. This insight is the key, because the number of squares left on this chessboard is 63— an odd number
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Since each domino covers 2 squares and the dominoes are non-overlapping, if one places our k dominoes on the board, then they will cover $2k$ squares, which is always an even number. Therefore, a perfect cover can only cover an even number of squares. Notice, though, that the board has 63 remaining squares, which is an odd number. Thus, it can not be perfectly covered.
            \bigbreak \noindent 
            What if I take an 8$\times$8 chessboard and cross out the top-left and the bottom-right squares? Then can it be covered by dominoes?
            \bigbreak \noindent 
            \textbf{Proposition.} If one crosses out the top-left and bottom-right squares of an 8 $\times$ 8 chessboard, the remaining squares can not be perfectly covered by dominoes.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Observe that the chessboard has 62 remaining squares, and since every domino covers two squares, if a perfect cover did exist it would require
            \begin{align*}
                \frac{62}{2} = 31 \text{ dominoes}
            .\end{align*}
            \bigbreak \noindent 
            Also observe that every domino on the chessboard covers exactly one white square and exactly one black square
            \bigbreak \noindent 
            Thus, whenever you place 31 non-overlapping dominoes on a chessboard, they will collectively cover 31 white squares and 31 black squares.
            \bigbreak \noindent 
            Next observe that since both of the crossed-out squares are white squares, the remaining squares consist of 30 white squares and 32 black squares. Therefore, it is impossible to have 31 dominoes cover these 62 squares. $\blacksquare$
        \item \textbf{Naming Results}: So far, all of our results have been called “propositions.” Here’s the run-down on the naming of results:
            \begin{itemize}
                \item A theorem is an important result that has been proved.
                \item A proposition is a result that is less important than a theorem. It has also been proved.
                \item A lemma is typically a small result that is proved before a proposition or a theorem, and is used to prove the following proposition or theorem.
                \item A corollary is a result that is proved after a proposition or a theorem, and which follows quickly from the proposition or theorem. It is often a special case of the proposition or theorem.
            \end{itemize}
            All of the above are results that have been proved — a conjecture, though, has not.
            \begin{itemize}
                \item A conjecture is a statement that someone guesses to be true, although they are not yet able to prove or disprove it.
            \end{itemize}
        \item \textbf{Conjectures and counterexamples}: As an example of a conjecture, suppose you were investigating how many regions are formed if one places $n$ dots randomly on a circle and then connects them with lines.
            \bigbreak \noindent 
            \fig{.7}{./figures/2.png}
            \bigbreak \noindent 
            At this point, if you were to conjecture how many regions there will be for the $n = 6$ case, your guess would probably be 32 regions — the number of regions certainly seems to be doubling at every step. In fact, if it kept doubling, then with a little more thought you might even conjecture a general answer: that n randomly placed dots form $2^{n-1}$ regions;
            \bigbreak \noindent 
            Surprisingly, this conjecture would be incorrect. One way to disprove a conjecture is to find a counterexample to it. And as it turns out, the $n = 6$ case is such a counterexample
            \bigbreak \noindent 
            \fig{.8}{./figures/3.png}
            \bigbreak \noindent 
            This counterexample also underscores the reason why we prove things in math. Sometimes math is surprising. We need proofs to ensure that we aren’t just guessing at what seems reasonable. Proofs ensure we are always on solid ground. Further, proofs help us understand why something is true — and that understanding is what makes math so fun
            \bigbreak \noindent 
            Lastly, we study proofs because they are what mathematicians do
        \item \textbf{The pingeonhole principle}
            \bigbreak \noindent 
            \textbf{Principle}. The principle has a simple form and a general form. Assume $k$ and $n$ are positive integers
            \bigbreak \noindent 
            \textbf{Simple form:} If $n + 1$ objects are placed into $n$ boxes, then at least one box has at least two objects in it.
            \bigbreak \noindent 
        \textbf{General form:} If $kn + 1$ objects are placed into $n$ boxes, then at least one box has at least $k + 1$ objects in it.
            \bigbreak \noindent 
            \textbf{Birthday example}: If there are 330 million people in the united states, how many U.S. residents are guaranteed to have the same birthday according to the pigeonhole principle?
            \bigbreak \noindent 
            To determine this, let’s see what would happen if each date of the year had exactly the same number of people born on it
            \begin{align*}
                \frac{330\times10^{6}}{366} = 901,639.344
            .\end{align*}
            \bigbreak \noindent 
            Since 901,639.344 people are born on an average day of the year, we should be able round up and say that at least one day of the year has had at least 901,640 people born on it. That is, with the pigeonhole principle we should be able to prove that there are at least 901,640 people in the USA with the same birthday
            \bigbreak \noindent 
            \textbf{Solution.} Imagine you have one box for each of the 366 dates of the (leap) year, and each person in the U.S. is considered an object. Put each person in the box corresponding to their birthday. By the general form of the pigeonhole principle (with $n = 366$ and $k = 901, 639$ and thus $k + 1 = 901, 640$), any group of
            \begin{align*}
                (901, 639)(366) + 1
            .\end{align*}
            \bigbreak \noindent 
            people is guaranteed to contain 901,640 people which have the same birthday.
        \item \textbf{Another pingeonhole example}:
            \bigbreak \noindent 
            \textbf{Proposition.} Given any five numbers from the set $\{1, 2, 3, 4, 5, 6, 7, 8\}$, two of the chosen numbers will add up to 9.
            \bigbreak \noindent 
            We may think to start by listing the pairs that sum to 9. We have
            \begin{align*}
                1 &+ 8 \\ 
                2 &+ 7 \\
                3 &+ 6 \\
                4 &+ 5 
            .\end{align*}
            And of course $8+1,7+2,..$ etc. We see we have four sums, we choose these sums as our boxes. If each of the four sums is a box, and each number is an object, then we are placing five objects into four boxes 
            \bigbreak \noindent 
            \textbf{Proof.} Let one box correspond to the numbers 1 and 8, a second box correspond to 2 and 7, another to 3 and 6, and a final box to 4 and 5. Notice that each of these pairs adds up to 9.
            \bigbreak \noindent 
            Given any five numbers from $\{1, 2, 3, 4, 5, 6, 7, 8\}$, place each of these five numbers in the box to which it corresponds; for example, if your first number is a 6, then place it in the box labeled “3 and 6.” Notice that we just placed five numbers into four boxes. Thus, by the simple form of the pigeonhole principle, there must be some box which contains two numbers in it. These two numbers add up to 9, as desired
        \item \textbf{Another pingeonhole example}:
            \bigbreak \noindent 
            \textbf{Proposition.} Given any collection of 10 points from inside the following square (of side-length 3), there must be at least two of these points which are of distance at most $\sqrt{2}$
            \bigbreak \noindent 
            \fig{1}{./figures/4.png}
            \bigbreak \noindent 
            \textbf{Proof.} Divide the $3\times 3$ square into nine $1\times 1$ boxes. Placing 10 arbitrary points amongst the boxes gaurantees that at least one box will have at least two points. We observe that the farthest these two points can be from each other is when they sit in two corners such that a diagonal line through the box hits both points. The length of this line is given by
            \begin{align*}
                \sqrt{1^{2} + 1^{2}} = \sqrt{2}
            .\end{align*}
            Thus, we observe that the maximum distance of these two points is $\sqrt{2}$ $\blacksquare$
        \item \textbf{Another pingeonhole example}:
            \bigbreak \noindent 
            \textbf{Proposition.} Given any 101 integers from $\{1, 2, 3, . . . , 200\}$, at least one of these numbers will divide another
            \bigbreak \noindent 
            \textbf{Solution.} As we ponder about how to construct 100 boxes from the properties of the set, we may wonder how the even and odd members partition this set. Call $S = \{1,2,3,...,200\} $, $E=\{2,4,6,...,200\} $, and $O = \{1,3,5,...,199\} $. Note that $E \cup O = S$. We notice that these two sets are arithmetic sequences, each with difference two. If $a_{n} = a_{1} +  (n-1)d$, then 
            \begin{align*}
                n &= \frac{a_{n} - a_{1}}{2} + 1 \\
                \implies n&= 100
            .\end{align*}
            \bigbreak \noindent 
            Let's make the odd numbers are boxes. We note that any even number $\ell$ can be written as $\ell = 2^{k}m$, where $m$ is odd, and $k$ is the highest power of two that divides $\ell$. Thus, in box $m$, we place any number of the form $2^{k}m$
            \bigbreak \noindent 
            \fig{.5}{./figures/5.png}
            \bigbreak \noindent 
            For any pair of numbers in the same box, the smaller divides the larger. Picking 101 numbers from the set $S$, and only 100 boxes... by the pigeonhole principle we must have atleast two numbers in the same box, and thus the smaller divides the larger. $\blacksquare$.
            \bigbreak \noindent 
            \textbf{Formal proof.} 
            \textbf{Proof.} For each number $n$ from the set $\{1, 2, 3, \dots, 200\}$, factor out as many 2's as possible, and then write it as $n = 2^k \cdot m$, where $m$ is an odd number. So, for example, $56 = 2^3 \cdot 7$, and $25 = 2^0 \cdot 25$. Now, create a box for each odd number from 1 to 199; there are 100 such boxes.
            \bigbreak \noindent 
            Remember that we are given 101 integers and we want to find a pair for which one divides the other. Place each of these 101 integers into boxes based on this rule:
            \bigbreak \noindent 
            \begin{quote}
                If the integer is $n$, then place it in Box $m$ if $n = 2^k \cdot m$ for some $k$.
            \end{quote}
            \bigbreak \noindent 
            For example, $72 = 2^3 \cdot 9$ would go into Box 9, because that's the largest odd number inside it.
            \bigbreak \noindent 
            Since 101 integers are placed in 100 boxes, by the pigeonhole principle (Principle 1.5) some box must have at least 2 integers placed into it; suppose it is Box $m$. And suppose these two numbers are $n_1 = 2^k \cdot m$ and $n_2 = 2^\ell \cdot m$, and let’s assume the second one is the larger one, meaning $\ell > k$. Then we have now found two integers where one divides the other; in particular $n_1$ divides $n_2$, because:
            \[
                \frac{n_2}{n_1} = \frac{2^\ell \cdot m}{2^k \cdot m} = 2^{\ell - k}.
            \]
            This completes the proof.$\blacksquare$
        \item \textbf{Another pigeonhole example}
            \bigbreak \noindent 
            \textbf{Proposition}. Suppose $G$ is a graph with $n \geq 2$ vertices. Then $G$ contains two vertices which have the same degree.
            \bigbreak \noindent 
            We start by observing that the minimum degree is zero, and the maxmium is $n-1$. It could happen that a vertex is connected to no other vertices, and a vertex could be connected to all other vertices. If a vertex is connected to all other vertices, than it has degree $n-1$, because it has an edge going to all vertices but itself. Thus, we have our boxes. But you may notice that we have $n$ boxes for $n$ vertices. This may seem like a problem, but after some thought you may see that it is not possible for the zero box and the $n-1$ box to both be used for a specific graph $G$. Thus, we have only $n-1$ boxes for $n$ vertices.
            \bigbreak \noindent 
            The rest of the proof is left as an exercise for the reader.
        \item \textbf{Classic Geometry Theorem}. Given any two points on the sphere, there is a great circle that passes through those two points. 
            \bigbreak \noindent 
            Given a sphere, there are infinitely many ways to cut it in half, and each of these paths of the knife is called a great circle
            \bigbreak \noindent 
            \fig{.5}{./figures/6.png}
        \item \textbf{Final pigeonhole example}
            \bigbreak \noindent 
            \textbf{Proposition}. If you draw five points on the surface of an orange in marker, then there is always a way to cut the orange in half so that four points (or some part of the point) all lie on one of the halves.
            \bigbreak \noindent 
            \textbf{\textit{Proof}}. Consider an orange with five points drawn on it. Pick any two of these points, and call them $p$ and $q$. By the Classic Geometry Theorem, there exists a great circle passing through these points; angle your knife to cut along this great circle. Because the points are drawn in marker, they are wide enough so that part of these two points appear on both halves.
            \bigbreak \noindent 
            Now consider the remaining three points and the two halves that you just cut the orange into. Consider these three points to be objects and the halves to be boxes; by the simple form of the pigeonhole principle, at least two of these three points are on the same orange half. These two, as well a portion of $p$ and of $q$, give four points or partial points, as desired $\quad \blacksquare $



    \end{itemize}

    \pagebreak 
    \subsection{Direct proofs}
    \begin{itemize}
        \item \textbf{Fact about integers}: The sum of integers is an integer, the difference of integers is an integer, and the product of integers is an integer. Also, every integer is either even or odd.
            \bigbreak \noindent 
            We are calling these facts because, while they are true and one could prove them, we will not be proving them here
        \item \textbf{Even and odd integers}: An integer $n$ is \textit{even} if $n=2k$ for some integer $k $
            \bigbreak \noindent 
            An integer $n$ is \textit{odd} if $n=2k+1$ for some integer $k$
        \item \textbf{Sum of two even integers}
            \bigbreak \noindent 
            \textbf{Proposition.} The sum of two even integers is even
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $n$ and $m$ are even integers, then $n = 2a$, and $m = 2b$ for some integers $a$ and $b$. Furthermore,
            \begin{align*}
                n + m &= 2a + 2b = 2(a+b)
            .\end{align*}
            \bigbreak \noindent 
            Since the sum of two integers is itself an integer, then we have two times an integer, which satisfies the definition of an even number. Hence, the sum $n + m$ is even, where $n$ and $m$ are even. $\int$
        \item \textbf{More on propositions}: We can rewrite our propositions to take the form
            \begin{quote}
               if \textit{statement} is true, then \textit{other statement} is also true 
            \end{quote}
            For example, 
            \begin{quote}
               if $m$ and $n$ are even, then $m+n$ is also even
            \end{quote}
            \bigbreak \noindent 
            Another way to summarize such statements is this:
            \begin{quote}
               \textit{some statement} is true implies \textit{some other statement} is true. 
            \end{quote}
            Which allows us to use the implies symbol $\implies$. For example, 
            \begin{quote}
               $m$ and $n$ being even $\implies$ $m+n$ is even 
            \end{quote}
            We have the general form $P \implies Q$, where $P$  and $Q$ are statements
            \bigbreak \noindent 
             However, when writing formally, like when writing up the final draft of your homework, these symbols are rarely used. You should write out solutions with words, complete sentences, and proper grammar. Pick up any of your math textbooks, or look online at math research articles, and you will find that such practices are standard.
        \item \textbf{The structure of direct proofs}: A direct proof is a way to prove a “$P \Rightarrow Q$” proposition by starting with $P$ and working your way to $Q$. The “working your way to $Q$” stage often involves applying definitions, previous results, algebra, logic, and techniques. Here is the general structure of a direct proof:
            \bigbreak \noindent 
            \begin{mdframed}
                \textbf{Proposition}. $P\implies Q$
                \bigbreak \noindent 
                \textbf{\textit{Proof.}} Assume $P$
                \bigbreak \noindent 
                \hspace{1cm}\textit{Explain what $P $ means by applying definitions and/or other results}
                \begin{align*}
                    &\vdots \quad \text{Apply algebra,} \\
                    &\vdots \quad \text{logic techniques}
                .\end{align*}
                \bigbreak \noindent 
                \hspace{1cm} \textit{Hey look, that's what $Q$ means}
                \bigbreak \noindent 
                Therefore $Q$ \hspace{10cm} $\blacksquare $
            \end{mdframed}
        \item \textbf{Proof by cases}: A related proof strategy is proof by cases. This is a “divide and conquer” strategy where one breaks up their work into two or more cases 
            \bigbreak \noindent 
            The below example of proof by cases will also give us more practice with direct proofs involving definitions. Indeed, when you break up a problem in two parts, those two parts still need to be proven, and a direct proof is often the way to tackle each of those parts
            \bigbreak \noindent 
            \textbf{Proposition.} If $n$ is an integer, then $n^{2} + n + 6$ is even.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $n$ is an integer, then either $n$ is even or it is odd.
            \begin{tcolorbox}[penv]
                \textit{Case I}. Assume $n$ is even, then $n=2m$ for some integer $m$. Thus, we have
                \begin{align*}
                    n^{2} + n + 6 &= (2m)^{2} + 2m + 6 \\
                      &=4m^{2} + 2m + 6 \\
                      &= 2 (2m^{2} + m + 3)
              .\end{align*}
              \bigbreak \noindent 
              Observe that $2m^{2} + m + 3 \in \mathbb{Z}$. Thus, we have two times an integer, which satisfies the definition of an even number.
              \bigbreak \noindent 
              \textit{Case 2.} Assume $n$ is odd, then $n=2m+1$ for some integer $m$. Thus,
              \begin{align*}
                  n^{2} + n + 6 &= (2m+1)^{2} + 2m + 1 + 6 \\
                                &=4m^{2} + 4m + 1 + 2m + 7 \\
                                &= 4m^{2} + 6m + 8 \\
                                &= 2(2m^{2} + 3m + 4)
              .\end{align*}
              \bigbreak \noindent 
              Since $m$ is an integer, $2m^{2} + 3m +4$ is an integer, and we again have two times an integer, which is an even integer.
              \bigbreak \noindent 
              We have shown that $n^{2} + n  + 6 $ is even whether $n$ is even or odd. Combined, this shows that $n^{2} + n + 6$ is even for all integers $n$ $\quad \blacksquare$
                
            \end{tcolorbox}
        \item \textbf{Proof by exhaustion (brute force proof)}: A proof by cases cuts up the possibilities into more manageable chunks. If the theorem refers to a collection of elements and your proof is simply checking each element individually, then it is called a \textit{proof by exhaustion} or a \textit{brute force proof}
        \item \textbf{Divisibility}: An integer \(a\) is said to divide an integer \(b\) if \(b = ak\) for some integer \(k\). When \(a\) does divide \(b\), we write \(a \mid b\), and when \(a\) does not divide \(b\), we write \(a \nmid b\).
            \bigbreak \noindent 
            \textbf{Note:} A common mistake is to see something like “$2 \mid 8$” and think that this equals 4. The expression “$a \mid  b$” is either true or false
            \bigbreak \noindent 
            \textbf{Remark.} $a\mid 0$ for any integer $a$, because $0 = a \cdot 0$ for every such $a$
            \bigbreak \noindent 
            $0\nmid b$ for any nonzero integer $b$, because for any such $b$, we have $b\ne 0 \cdot k $ for any integer $k$
        \item \textbf{The transitive property of divisibility}:
            \bigbreak \noindent 
            \textbf{Proposition}. Let $a,b$, and $c$ be integers, if $a\mid b$ and $b \mid c$, then $a\mid c$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $a,b$, and $c$ are integers. Further assume that $a\mid b$, and $b\mid c$
            \penv {
                By the definition of divisibility, $a\mid b$ and $b \mid c$ implies $b = ak$ for some integer $k$, and $c = bs$ for some integer $s$
                \bigbreak \noindent 
                If $a\mid c$, we require that $c = ar$ for some integer $r$
                \bigbreak \noindent 
                \begin{align*}
                    b &= ak  \\
                    \implies c &= (ak)s \\
                    \implies c&= a(ks)
                .\end{align*}
                \bigbreak \noindent 
            }
            Since $k$ and $s$ are integers, then their product $ks$ is itself an integer. Let $r = ks$. Then $c  = ar$, which is precisely the definition of divisiblity, and we conclude that $a\mid c$. $\quad \blacksquare$
        \item \textbf{The division algorithm}:
            \bigbreak \noindent 
            \textbf{Theorem.} For all integers $a$ and $m $ with $m>0 $, there exist unique integers $q $ and $r $ such that
            \begin{align*}
                a = mq + r
            .\end{align*}
            Where $0 \leq r < m$. We call $q$ the \textit{quotient} and $r$ the \textit{remainder}
        \item \textbf{Common divisor, greatest common divisor}:
            Let $a$ and $b$ be integers. If $c \mid a$ and $c \mid b$, then $c$ is said to be a common divisor of $a$ and $b$.
            \bigbreak \noindent 
            The greatest common divisor of $a$ and $b$ is the largest integer $d$ such that $d \mid a$ and $d \mid b$. This number is denoted $\text{gcd}(a, b)$.
            \bigbreak \noindent 
            Note that there is one pair of integers that does not have a greatest common divisor; if $a = 0$ and $b = 0$, then every positive integer $d$ is a common divisor of $a$ and $b$. This means that no divisor is the greatest divisor, since you can always find a bigger one. Thus, in this one case, $gcd(a, b)$ does not exist
        \item \textbf{Bezout's identity}: If $a$ and $b$ are positive integers, then there exist integers $k$ and $\ell$ such that
            \begin{align*}
                \gcd{(a, b)} = ak + b\ell
            .\end{align*}
            \bigbreak \noindent 
            As an example, suppose $a=12$ and $b=20$, then $\gcd{(12,20)} =4$, and we have
            \begin{align*}
                4 &= 12k + 20 \ell  \\
                \implies \ell &= \frac{1}{5}-\frac{3}{5}k
            .\end{align*}
            Let $k=2$, then we see $\ell = -1$. We see that there are infinitely many solutions, $k=2, \ell = -1$ is just one of them. Nevertheless, this theorem simply says that at least one solution must exist. 
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $a$ and $b$ are fixed positive integers, notice that the expression $ax + by$ can take many values for integers $x$ and $y$. Let $d$ be the \textit{smallest positive integer} that $ax + by$ can be equal. Let $k$ and $\ell$ be the $x$ and $y$ that obtain this $d$. That is, 
            \begin{align*}
                d = ak + b\ell
            .\end{align*}
            \penv{
               We now must show that $d$ is a common divisor of $a$ and $b$, and then that it is the \textit{greatest common divisor}
               \bigbreak \noindent 
               \textit{Part 1 (common divisor)}. $d$ is a common divisor of $a$ and $b$ if $d\mid a$ and $d\mid b$. To see that $d \mid a$, we examine the division algorithm. We know that there exsits unique integers $q $ and $r $ such that
               \begin{align*}
                   a = dq + r
               .\end{align*}
               With $0 \leq r < d$. We have
               \begin{align*}
                   r &= a-dq \\
                     &=a-(ak + b\ell)q \\
                     &=a-akq -b\ell q \\
                     &= a(1-kq) + b(-\ell q)
               .\end{align*}
               Observe that $1-kq$, and $-\ell q$ are both integers, Since $r$ is written in the form $ax + by$, $0 \leq r < d$, and $d$ is the smallest positive integer that this form can produce (with the given $a,b$), it must be that $r=0$. Thus,
               \begin{align*}
                   a = dq + 0 = dq
               .\end{align*}
               And we see that $d\mid a$. A similar argument will show that $d\mid b$ as well. This proves that $d$ is a common divisor of $a$ and $b$.
               \bigbreak \noindent 
           }
           \penv{
               \textit{Part 2 (gcd)}. Assume that $d^{\prime}$ is some other common divisor of $a$ and $b$. We must show that $d^{\prime} \leq d$. If $d^{\prime}$ is a common divisor of $a$ and $b$, then $d^{\prime} \mid a$ and $d^{\prime} \mid b$, which implies $a = d^{\prime}n$, and $b = d^{\prime} m$, for some integers $n$ and $m$. If $d = ak + b\ell$, then
               \begin{align*}
                   d &= d^{\prime}nk + d^{\prime}m\ell \\
                   &=d^{\prime}(nk + m\ell) \\
                   \implies d^{\prime} &=\frac{d}{nk + m\ell}
               .\end{align*}
               Since $n,k,m,\ell \in \mathbb{Z}$, it follows that $nk +m\ell \in \mathbb{Z}$. Thus, $d^{\prime} \leq d$.
           }
           \bigbreak \noindent 
           Therefore, we have shown that $d$ is not only a common divisor of $a$ and $b$, but that it is also the largest, and hence the $gcd$. Thus,
           \begin{align*}
               \gcd{(a,b)} = d = ak + b \ell
           .\end{align*}
           $\blacksquare$
           \bigbreak \noindent 
           A corollary from this result is that $\gcd{(ma, mb)} = m \gcd{(a,b)}$. If $\gcd{(a,b)} = ak + b\ell$, we have
           \begin{align*}
               \gcd{(ma,mb)} &= mak + mb\ell  \\
                             &=m(ak + b\ell) \\
                             &=m\gcd{(a,b)}
           .\end{align*}
       \item \textbf{Modulo and congruence}: 
           For integers \(a\), \(r\), and \(m\), we say that \(a\) is congruent to \(r\) modulo \(m\) and we write \(a \equiv r \pmod{m}\) if \(m \mid (a - r)\).
           \bigbreak \noindent 
           For example, $18 \equiv  4 \pmod{7}$ because $18 = 7(2) +4 $, we see that $7 \mid (18-4)$
           \bigbreak \noindent 
           If \(a\) divided by \(m\) leaves a remainder of \(r\), then \(a \equiv r \pmod{m}\). However, this is not the only way to have \(a \equiv r \pmod{m}\) — it is not required that \(r\) be the remainder when \(a\) is divided by \(m\); all that is required is that \(a\) and \(r\) have the same remainder when divided by \(m\). For example:
           \begin{align*}
               18 =11 \pmod{7}
           .\end{align*}
        \item \textbf{Properties of modular congruence}: Assume that $a, b, c, d$
            and $m$ are integers, $a \equiv b \pmod{m}$ and $c \equiv d\pmod{m}$. Then
            \begin{enumerate}[label=(\roman*)]
                \item $a + c  \equiv b + d \pmod{m} $ 
                \item $a - c  \equiv b - d \pmod{m} $ 
                \item $a \cdot  c  \equiv b \cdot  d \pmod{m} $ 
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{\textit{Proof of property $i$}}. Assume that $a \equiv b \pmod{m}$, and $c \equiv d \pmod{m}$, we must show that $a + c \equiv b + d \pmod{m}$
            \penv{
                If $a\equiv b \pmod{m}$, then $m \mid a-b$, which implies $a-b = mk$ for some $k\in \mathbb{Z}$. Similarly, $c \equiv d \pmod{m} \implies m \mid c-d \implies c-d = m\ell$, for some $\ell \in \mathbb{Z}$. Adding these two equations yields
                \begin{align*}
                    (a-b) + (c-d) &= mk + m\ell \\
                    \implies (a+c) - (b + d) &= m(k+\ell)
                .\end{align*}
        }
        Since $k+\ell \in \mathbb{Z}$, then by the definition of divisibility
        \begin{align*}
            m \mid (a+c) - (b+d)
        .\end{align*}
        Which then by the definition of congruence
        \begin{align*}
            a+c \equiv b+d \pmod{m}
        .\end{align*}
        $\blacksquare$
        \bigbreak \noindent 
        \textbf{\textit{Proof of property $iii$}}. Assume $a \equiv b \pmod{m}$, and $c \equiv d \pmod{m}$
        \penv{
            From above we know it follows that $a - b = mk $, and $c-d = m\ell$, for $k,\ell \in \mathbb{Z}$. If $ ac \equiv bd \pmod{m}$, it must be that $ac -bd = ms$, for some $s\in \mathbb{Z}$. Let's see if we can derive $ac-bd$ in terms of what we know, namely $a-b$ and $c-d$. Amazingly,
            \begin{align*}
                ac -bd &= (a-b)c + (c-d)b \\
                &= mkc + m\ell b \\
                &= m(kc +\ell b)
            .\end{align*}
        }
        It then follows that
        \begin{align*}
            m \mid ac-bd
        .\end{align*}
        Thus,
        \begin{align*}
            ac \equiv bd \pmod{m}
        .\end{align*}
        $\blacksquare$
    \item \textbf{Prime and composite integers}: An integer $p \geq 2$ is prime if its only positive divisors are 1 and $p$. An integer $n \geq 2$ is composite if it is not prime. Equivalently, $n$ is composite if it can be written as $n = st$, where $s$ and $t$ are integers and $1 < s, t < n$.
        \bigbreak \noindent 
        \textbf{Note:} To be clear, “$1 < s, t < n$” means that both $s$ and $t$ are between 1 and $n$.
    \item \textbf{Properties of primes and divisibility}:
        \bigbreak \noindent 
        \textbf{Lemma}. Let \( a, b \) and \( c \) be integers, and let \( p \) be a prime:
        \begin{enumerate}[label=(\roman*)]
            \item If \( p \nmid a \), then \( \gcd(p, a) = 1 \).
            \item If \( a \mid bc \) and \( \gcd(a, b) = 1 \), then \( a \mid c \).
            \item If \( p \mid bc \), then \( p \mid b \) or \( p \mid c \) (or both).
        \end{enumerate}
        \bigbreak \noindent 
        \textbf{\textit{Proof of property $i$}}. Assume that $p$ does not divide $a$, then $p$ cannot possibly be a common divisor of $a$ and $p$, because it is not a divisor of $a$. 
        \bigbreak \noindent 
        Since $p \in \mathbb{P}\footnote{Where $\mathbb{P}$ is the family of primes}$, then the only divisors of $p$ are one and itself. Thus, the only option left is one. Hence, the greatest common divisor is one. $\blacksquare$
        \pagebreak \bigbreak \noindent 
        \textbf{\textit{Proof of property $ii$}}. Assume $a\mid bc$, and $\gcd{(a,b)} = 1$. Then, $bc = ar$ for some integer $r$, and by Bezout's identity, there exist some integers $k, \ell$ such that
        \begin{align*}
            \gcd{(a,b)} &= ak + b\ell \\
            \implies 1&= ak + b\ell 
        .\end{align*}
        If $a\mid c$, we require $c = as$, for some integer $s$. If we multiply the above expression by c, we get
        \begin{align*}
            c &= cak + cb\ell
        .\end{align*}
        Since we assumed $a\mid bc$, then it must be that $bc = ar$, for $r\in \mathbb{Z}$. Thus, we have
        \begin{align*}
            c &= cak + ar\ell \\
              &= a(ck + r\ell)
        .\end{align*}
        Since $c,k,r,\ell \in \mathbb{Z}$, the expression $ck+r\ell$ is also an integer, and by the definition of divisibility, it must be that $a\mid c$  $\quad \blacksquare $
        \bigbreak \noindent 
        \textbf{\textit{Proof of property $iii$}}. Assume that $p \mid bc$. Then there are two cases, either $p\mid b$, or $p\nmid b$.
        \bigbreak \noindent 
        \textit{Case I}. If $p\mid b$, then the statement is true and we are done
        \bigbreak \noindent 
        \textit{Case II}. If $p\nmid b$, then by property $i$, it must be that $\gcd{(p,b)} = 1$. By property $ii$, if $p \mid bc$, and $\gcd{(p,b)} = 1$, then it must be that $p \mid c$. $\quad \blacksquare$.
    \item \textbf{More on properties of congruence}: We return to congruence to examine the statement
        \begin{align*}
            ak \equiv bk \pmod{m} \stackrel{?}{\implies} a\equiv b \pmod{m}
        .\end{align*}
        \bigbreak \noindent 
        \textbf{Proposition (\textit{modular cancellation law})}. Let $a,b,k,m$ be integers. If $ak \equiv bk \pmod{m}$, and $\gcd{(m,k)} = 1$, then $a \equiv b \pmod{m}$
        \bigbreak \noindent 
        \textbf{\textit{Proof}}. Assume $ak \equiv bk\pmod{m}$, and $\gcd{(m,k)} =1$, then $m \mid ak-bk$, and $ak-bk = m\ell$, for some integer $\ell$. 
        \bigbreak \noindent 
        \penv{
            If $a\equiv b\pmod{m}$, then $m\mid a-b$, and $a-b = mr$, for some integer $r$. Since $ak \equiv bk\pmod{m}$, then it must be that
            \begin{align*}
                ak-bk &= m\ell \\
                \implies k(a-b) &= m\ell \\
                \implies a-b &= \frac{m\ell}{k}
            .\end{align*}
            Thus, we require $\frac{\ell}{k}$ to be an integer, it then follows that the proposition holds true.
            \bigbreak \noindent 
            We know that if $a\mid bc$, and $\gcd{(a,b)} = 1$, then $a\mid c$. Thus, since $k\mid m\ell$, and $\gcd{(m,k)} = 1$, it must be that $k\mid \ell$. Hence, $ \frac{\ell}{k} \in \mathbb{Z}$, and 
            \begin{align*}
                a-b = m\left(\frac{\ell}{k}\right)
            .\end{align*}
            And by the definition of divisibility, $m\mid a-b$, which implies $a \equiv b \pmod{m}$ $\quad \blacksquare$.
        }
    \item \textbf{Fermat's little theorem}: If $a$ is an integer and $p$ is a prime which does not divide $a$, then
        \begin{align*}
            a^{p-1} \equiv 1 \pmod{p}
        .\end{align*}
        \bigbreak \noindent 
        \textbf{\textit{Proof.}} 
        Assume that $a$ is an integer and $p$ is a prime which does not divide $a$. We begin by proving that when taken modulo $p$,
        \[
            \{a, 2a, 3a, \dots, (p-1)a\} \equiv \{1, 2, 3, \dots, p-1\}.
        \]
        To do this, observe that the set on the right has every residue modulo $p$ except $0$, and each such residue appears exactly once. Therefore, since both sets have $p-1$ elements listed, in order to prove that the left set is the same as the right set, it suffices to prove this:
        \begin{enumerate}
            \item No element in the left set is congruent to $0$, and
            \item Each element in the left set appears exactly once.
        \end{enumerate}
        In doing so, we will twice use the modular cancellation law (Proposition 2.18) to cancel out an $a$, and so we note at the start that by Lemma 2.17 part (i) we have $\gcd(p, a) = 1$.
        \bigbreak \noindent 
        \textbf{Step 1.} First we show that none of the terms in $\{a, 2a, 3a, \dots, (p-1)a\}$, when considered modulo $p$, are congruent to $0$. To do this, we will consider an arbitrary term $ia$, where $i$ is anything in $\{1, 2, 3, \dots, p-1\}$. Indeed, if we did have some
        \[
            ia \equiv 0 \pmod{p},
        \]
        which is equivalent to
        \[
            ia \equiv 0a \pmod{p},
        \]
        then by the modular cancellation law (Proposition 2.18) we would have
        \[
            i \equiv 0 \pmod{p}.
        \]
        That is, in order to have $ia \equiv 0 \pmod{p}$, that would have to have $i \equiv 0 \pmod{p}$. Therefore we are done with Step 1, since no $i$ from $\{1, 2, 3, \dots, p-1\}$ is congruent to $0$ modulo $p$.
        \bigbreak \noindent 
        \textbf{Step 2.} Next we show that every term in $\{a, 2a, 3a, \dots, (p-1)a\}$, when considered modulo $p$, does not appear more than once in that set. Indeed, if we did have
        \[
            ia \equiv ja \pmod{p},
        \]
        for $i$ and $j$ from $\{1, 2, 3, \dots, p-1\}$, then by the modular cancellation law (Proposition 2.18) we have
        \[
            i \equiv j \pmod{p}.
        \]
        And since $i$ and $j$ are both from the set $\{1, 2, 3, \dots, p-1\}$, this means that $i = j$. In other words, each term in $\{a, 2a, 3a, \dots, (p-1)a\}$ is not congruent to any other term from that set — it is only congruent to itself. This completes Step 2.
        \bigbreak \noindent 
        We have succeeded in proving that when taken modulo $p$,
        \[
            \{a, 2a, 3a, \dots, (p-1)a\} \equiv \{1, 2, 3, \dots, p-1\},
        \]
        even though the numbers in these sets may be in a different order. But since the order does not matter when multiplying numbers, we see that
        \[
            a \cdot 2a \cdot 3a \cdot 4a \cdot \dots \cdot (p-1)a \equiv 1 \cdot 2 \cdot 3 \cdot 4 \cdot \dots \cdot (p-1) \pmod{p}.
        \]
        Then, since $\gcd(2, p) = 1$ by Lemma 2.17 part (i), by the modular cancellation law (Proposition 2.18) we may cancel a $2$ from both sides:
        \[
            a \cdot 3a \cdot 4a \cdot \dots \cdot (p-1)a \equiv 1 \cdot 3 \cdot 4 \cdot \dots \cdot (p-1) \pmod{p}.
        \]
        Then, since $\gcd(3, p) = 1$ by Lemma 2.17 part (i), by the modular cancellation law (Proposition 2.18) we may cancel a $3$ from both sides:
        \[
            a \cdot a \cdot 4a \cdot \dots \cdot (p-1)a \equiv 1 \cdot 4 \cdot \dots \cdot (p-1) \pmod{p}.
        \]
        Continuing to do this for the $4, 5, \dots, (p-1)$ on each side (each of which has a greatest common divisor of $1$ with $p$, by Lemma 2.17 part (i)), by the modular cancellation law (Proposition 2.18) we obtain
        \[
            \underbrace{a \cdot a \cdot a \cdot \dots \cdot a}_{p-1 \text{ copies}} \equiv 1 \pmod{p},
        \]
        which is equivalent to what we sought to prove:
        \[
            a^{p-1} \equiv 1 \pmod{p}.
        \]
    \item \textbf{Bonus proof}:
        \bigbreak \noindent 
        \textbf{Proposition.} If $x$ and $y$ are positive integers, and $x \geq y$, then $\sqrt{x} \geq \sqrt{y} $
        \bigbreak \noindent 
        \textbf{\textit{Proof.}} Assume $x$ and $y$ are positive integers, and $x \geq y$. Then
        \begin{align*}
            x &\geq y \\
            \implies x -y & \geq 0  \\
        .\end{align*}
        Since $x,y \geq 0$, $\sqrt{x^{2}} = \abs{x} = x$, and $\sqrt{y^{2}} = \abs{y} = y $. Thus,
        \begin{align*}
            x-y &\geq 0 \\
            \implies \sqrt{x^{2}} - \sqrt{y^{2}} &\geq 0  \\
            \implies (\sqrt{x} - \sqrt{y})(\sqrt{x} + \sqrt{y}) &\geq 0 \\
            \implies \sqrt{x} - \sqrt{y} &\geq 0  \quad \quad \blacksquare
        .\end{align*}
    \item \textbf{The AM-GM inequality}:
        \bigbreak \noindent 
        \textbf{Theorem (\textit{AM-GM inequality})}. If $x,y \geq 0 \in \mathbb{Z}$, then $\sqrt{xy} \leq \frac{x+y}{2} $
        \bigbreak \noindent 
        \textbf{\textit{Proof.}} Assume $x,y \geq 0 \in \mathbb{Z}$. Consider
        \begin{align*}
            0 \leq (x-y)^{2}
        .\end{align*}
        Which we know to be true, squaring an integer is always positive, and we know $x-y$ to be an integer. It then follows that
        \begin{align*}
            0 \leq x^{2} -2xy + y^{2}
        .\end{align*}
        If we add $4xy$ to both sides, we get
        \begin{align*}
            4xy &\leq x^{2} + 2xy + y^{2} \\
            \implies 4xy &\leq (x + y)^{2} \\
        .\end{align*}
        Now let's take the square root of both sides
        \begin{align*}
            2\sqrt{xy} \leq \abs{x+y}
        .\end{align*}
        Since $x,y \geq 0$, $\abs{x+y} = x+y$. Thus,
        \begin{align*}
            2\sqrt{xy} \leq x + y \\
            \therefore \sqrt{xy} \leq \frac{x+y}{2}
        .\end{align*}
        \bigbreak \noindent 
        \textbf{Note:} Some of the steps taken in this proof may seem a bit random, but if we start at the proposition $\sqrt{xy} \leq \frac{x+y}{2}$ and work backwards algebraically, we see
        \begin{align*}
            \sqrt{xy} &\leq \frac{x+y}{2} \\
            2\sqrt{xy} &\leq x+y \\
            4xy &\leq (x+y)^{2} \\
            4xy &\leq x^{2} + 2xy + y^{2} \\
            0 &\leq x^{2} + 2xy + y^{2} - 4xy \\
            0 &\leq x^{2} - 2xy + y^{2} \\
            0 &\leq (x-y)^{2}
        .\end{align*}
        \bigbreak \noindent 
        We see that we have derived a starting point, and were just working backwards in the proof.
            
    \end{itemize}

    \pagebreak 
    \subsection{Sets}
    \begin{itemize}
        \item \textbf{Vacuous truth}: a vacuous truth is a conditional or universal statement (a universal statement that can be converted to a conditional statement) that is true because the antecedent cannot be satisfied.[1] It is sometimes said that a statement is vacuously true because it does not really say anything. For example, the statement "all cell phones in the room are turned off" will be true when no cell phones are present in the room. In this case, the statement "all cell phones in the room are turned on" would also be vacuously true, as would the conjunction of the two: "all cell phones in the room are turned on and turned off", which would otherwise be incoherent and false.
        \item \textbf{Review: Proper subset}: If $A = B$, then $A \subseteq B$. In the case that $A \subseteq B$ and $A \ne B$, we say that $A$ is a proper subset of $B$. the correct notation for this is “$A \subset B$.”
        \item \textbf{Proving $A \subseteq B $}
            \bigbreak \noindent 
            \textbf{Definition}. Suppose $A$ and $B$ are sets. If every element in $A$ is also an element of $B$, then $A$ is a subset of $B $, which is denoted $A \subseteq B$
            \bigbreak \noindent 
            \textbf{Note:} For every set $B$, it is true that $\varnothing \subseteq B $. 
            To see it, first note that, because there are no elements in $\varnothing$, it would be true to say  
            "for any $x \in \varnothing$, $x$ is a purple elephant that speaks German.'' It’s vacuously\footnote{A statement is vacuously true if it asserts something about all elements of the empty set.} true!  
            You certainly can’t disprove it, right? You can’t present to me any element in $\varnothing$ that is not a purple elephant that speaks German.
            \bigbreak \noindent 
            By this reasoning, I could switch out "is a purple elephant that speaks German" for any other statement, and it would still be true! And this includes the subset criteria: if $x \in \varnothing$, then $x \in B$, which by definition means that $\varnothing \subseteq B$.  
            Again, you certainly can not present to me any $x \in \varnothing$ which is not also an element of $B$, can you?
            \bigbreak \noindent 
            in order to prove that $A \subseteq B$, what we would have to show is this:
            \begin{align*}
                \text{If } x\in A, \text{ then } x\in B 
            .\end{align*}
            In other words, for any arbitrary element in $A$, that same element is also in $B$
            \bigbreak \noindent 
            \textbf{Proposition.} It is the case that 
            \begin{align*}
                \{n \in \mathbb{Z}:\ 12 \mid n\} \subseteq \{n\in\mathbb{Z}:\ 3\mid n\}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Let $A = \{n\in\mathbb{Z}:\ 12\mid n\} $, and $B =\{n\in\mathbb{Z}:\ 3\mid n\} $. Assume $a\in A$
            \penv{
                Since $a\in A$, then $12 \mid a$, which implies $a = 12k$, for some $k\in \mathbb{Z}$. If $a\in B$, then $3\mid a \implies a = 3\ell$
                \bigbreak \noindent 
                Since $a =12k$, and $a=3\ell$, then $12k=3\ell \implies \ell = 4k$. Thus, we have
                \begin{align*}
                    a = 3(4k)
                .\end{align*}
                Which by the definition of divisiblity, and since $4k \in \mathbb{Z}$, we have $3\mid a$. 
                \bigbreak \noindent 
                Therefore, $a \in B \quad \blacksquare$
            }
        \item \textbf{Proving $A = B$}:
            Recall that, for sets $A$ and $B$, to say that ``$A = B$'' is to say that these two sets contain \textit{exactly} the same elements. Said differently, it means these two things:
            \begin{enumerate}
                \item Every element in $A$ is also in $B$ (which means $A \subseteq B$), and
                \item Every element in $B$ is also in $A$ (which means $B \subseteq A$).
            \end{enumerate}
            Indeed, a slick way to prove that $A = B$ is to prove both $A \subseteq B$ and $B \subseteq A$, both of which can be done using the approach discussed above.
        \item \textbf{Review of set operations}:
            \begin{itemize}
                \item The \textit{union} of sets $A$ and $B$ is the set $A \cup B = \{x : x \in A \text{ or } x \in B\}$.
                \item The \textit{intersection} of sets $A$ and $B$ is the set $A \cap B = \{x : x \in A \text{ and } x \in B\}$.
                \item Likewise, if $A_1, A_2, A_3, \dots, A_n$ are all sets, then the union of all of them is the set
                    \[
                        A_1 \cup A_2 \cup \cdots \cup A_n = \{x : x \in A_i \text{ for some } i\}.
                    \]
                    This set is also denoted
                    \[
                        \bigcup_{i=1}^n A_i.
                    \]
                \item Likewise, if $A_1, A_2, A_3, \dots, A_n$ are all sets, then the intersection of all of them is the set
                    \[
                        A_1 \cap A_2 \cap \cdots \cap A_n = \{x : x \in A_i \text{ for all } i\}.
                    \]
                    This set is also denoted
                    \[
                        \bigcap_{i=1}^n A_i.
                    \]
            \end{itemize}
            \bigbreak \noindent 
            Assume $A$ and $B$ are sets and ``$x \notin B$'' means that $x$ is not an element of $B$.
            \begin{itemize}
                \item The \textit{subtraction} of $B$ from $A$ is $A \setminus B = \{x : x \in A \text{ and } x \notin B\}$.
                \item If $A \subseteq U$, then $U$ is called a \textit{universal set} of $A$. The \textit{complement} of $A$ in $U$ is $A^c = U \setminus A$.
            \end{itemize}
            \bigbreak \noindent 
            Furthermore, 
            \begin{itemize}
                \item The \textit{power set} of a set $A$ is $\mathcal{P}(A) = \{X : X \subseteq A\}$.
                \item The \textit{cardinality} of a set $A$ is the number of elements in the set, and it is denoted $|A|$.
            \end{itemize}
            \bigbreak \noindent 
            Assume $A$ and $B$ are sets, The Cartesian product of A and B is 
            \begin{align*}
                A \times B = \{(a, b):\  a \in A and b \in B\}.
            .\end{align*}
            \pagebreak \bigbreak \noindent 
        \item \textbf{More on power sets}: 
            \bigbreak \noindent 
            \textbf{Proposition.} Suppose $A$ and $B $ are sets. If $\mathcal{P}(A)\subseteq \mathcal{P}(B)$, then $A\subseteq B$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} Assume $A$ and $B$ are sets, and $\mathcal{P}(A) \subseteq \mathcal{P}(B)$.
            \bigbreak \noindent 
            \penv{
                Choose $x\in \mathcal{P}(A)$, which means $x \subseteq A$. Since $\mathcal{P}(A) \subseteq \mathcal{P}(B)$, it follows that $x \in \mathcal{P}(B)$, which means $x \subseteq B$. Let $x=A$, since $A\in\mathcal{P}(A)$. Since $x \subseteq B$, then $A \subseteq B $
            }
            \bigbreak \noindent 
            Therefore, $A\subseteq B \quad \blacksquare$
        \item \textbf{De Morgan's law}:
            \bigbreak \noindent 
            \textbf{Theorem}. Suppose $A$ and $B$ are subsets of a universal set $U$. Then,
            \begin{align*}
                (A \cup B)^{C} &= A^{C} \cap B^{C} \tag{1}
            .\end{align*}
            And
            \begin{align*}
                (A \cap B)^{C} &= A^{C} \cup B^{C} \tag{2}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof (1)}}. Assume $A$ and $B$ are subsets of a universal set $U$, since $(A \cup B)^{C}$, and $A^{C} \cap B^{C} $ are sets, we show equality by showing $(A\cup B)^{C} \subseteq A^{C}\cap B^{C}$, and $A^{C} \cap B^{C} \subseteq (A\cup B)^{C}$. It then follows that $(A \cup B)^{C} = A^{C} \cap B^{C} $
            \penv{
                Choose $x\in (A\cup B)^{C} $, by the definition of the complement, we have $x\not\in(A\cup B)$, which by the definition of the union means $x$ cannot be in $A$, and it cannot be in $B$. In other words, $x\not\in A$ and $x\not\in B \implies x \in A^{C}$ and $x\in B^{C} $. Therefore,
                \begin{align*}
                    x\in A^{C} \cap B^{C}
                .\end{align*}
                Which by the definition of the subset, means $(A\cup B)^{C} \subseteq A^{C} \cap B^{C}$
                \bigbreak \noindent
                Next, let $x\in A^{C} \cap B^{C}$, then $x \in A^{C}$ and $x\in B^{C}$, which means $x\not\in A$ and $x\not\in B$, which implies $x\not\in (A\cup B) \implies x\in (A\cup B)^{C}$.
                \bigbreak \noindent 
                Therefore, since $x\in A^{C} \cap B^{C} \implies x\in (A\cup B)^{C}$, by the definition of a subset, we have $A^{C} \cap B^{C} \subseteq (A\cup B)^{C} $
            }
            Since both $(A\cup B)^{C} \subseteq A^{C} \cap B^{C}$, and $A^{C} \cap B^{C} \subseteq (A \cup B)^{C}$, it must be the case that $(A\cup B)^{C} = A^{C} \cap B^{C} \quad \blacksquare$
            \bigbreak \noindent 
            It should be addressed that this proof can be done by simply manipulating the set builder notation. We have
            \begin{align*}
                A^{C} \cap B^{C} &= \{x \in \mathbb{R}:\ x \in A^{C} \text{ and } x\in B^{C}\} \\
                                 &=\{x\in\mathbb{R}:\ x\not\in A \text{ and } x\not\in B\} \\
                                 &=\{x\in\mathbb{R}:\ x\not\in (A\cup B)\}  \\
                                 &=\{x\in\mathbb{R}:\ x\in (A\cup B)^{C}\}
            .\end{align*}
            $\blacksquare$
        \item \textbf{Proving $a\in A$}: Consider the set $\{x\in S:\ P(x)\}$, where $P(x)$ is some condition on $x$
            \bigbreak \noindent 
            Given a set of this form, if you are presented with a specific $a$ and you wish to prove that $a \in A$, then you must show that
            \begin{enumerate}
                \item $a\in S$
                \item $P(a)$ is true
            \end{enumerate}
            \bigbreak \noindent 
            For example, Let $A = \{(x,y) \in \mathbb{Z} \times \mathbb{N}:\ x\equiv y\pmod{5}\} $, then $(17,2) \in A$
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} First, note that $(17,2) \in\mathbb{Z} \times \mathbb{N}$ because $17\in \mathbb{Z}$, and $2 \in \mathbb{N} $, Next, observe that
            \begin{align*}
                17 \equiv 2 \pmod{5}
            .\end{align*}
            Because $5\mid (17-2)$
        \item \textbf{Indexed Families of Sets}: Consider a set $\mathcal{F}$, If every element of $\mathcal{F} $ is itself a set, then $\mathcal{F}$ is called a \textit{family of sets}. Then, one can ask questions about such a family, — like, what is the union of all of the sets in $\mathcal{F}$. That is,
            \begin{align*}
                \bigcup_{S \in \mathcal{F}} S &= \{x:\ x\in S \text{ for some } S \in \mathcal{F}\}
            .\end{align*}
            Likewise, 
            \begin{align*}
                \bigcap_{S\in \mathcal{F}} S &= \{x:\ x\in S \text{ for every } S \in \mathcal{F}\}
            .\end{align*}
        \item \textbf{Bonus example I}.
            \bigbreak \noindent 
            \textbf{Proposition}. It is the case that 
            \begin{align*}
                \{n \in \mathbb{Z}:\ 12\mid n\} = \{n\in\mathbb{Z}:\ 3\mid n\} \cap \{n\in \mathbb{Z}:\ 4\mid n\}
            .\end{align*}
            \textbf{\textit{Proof.}} Let $A = \{n \in \mathbb{Z}:\ 12\mid n\}$, $B =\{n\in\mathbb{Z}:\ 3\mid n\}$, and $C= \{n\in \mathbb{Z}:\ 4\mid n\}$
            \penv{
                \textit{Part i.)} Choose $x\in A$, we then have $ 12\mid x$, and $x = 12k$, for some $k\in \mathbb{Z}$. Thus,
                \begin{align*}
                    x = 12k = 3(4k) = 4(3k)
                .\end{align*}
                Which by the definition of divisibility implies both $3\mid x $ and $4\mid x$, since both $4k$ and $3k \in \mathbb{Z}$. Hence, $x\in B \cap C$
                \bigbreak \noindent 
                \textit{Part ii.)} Choose $x\in B\cap C$, then both $x = 3r$ and $x=4s$, for $r,s\in\mathbb{Z} $. We have
                \begin{align*}
                    3r = 4s
                .\end{align*}
                Which implies $3\mid 4s$, since $r \in \mathbb{Z}$. Because $3\in \mathbb{P}$, we know that either $3\mid 4$ or $3\mid s$. Since it is clear that $3\nmid 4$, it must be the case that $3\mid s$, and thus $s = 3\ell$ for an integer $\ell$. It then follows that
                \begin{align*}
                    x=4s = 4(3\ell) = 12\ell
                .\end{align*}
                Which by the definition of divisibility implies $12\mid x$, and thus $x\in A$
            }
            Since choosing an $x\in A \implies x\in B\cap C$, it must be that $A\subseteq B\cap C$, and choosing an $x\in B\cap C \implies x\in A$, it must also be that $B\cap C \subseteq A$. With these two facts, we can assert that $A = B \cap C \quad \blacksquare$
        \item \textbf{The Cardinality of the Power Set}: Suppose $A$ is a set with $n$ elements. How many subsets of $A$ are there? Said differently, what is $\abs{P(A)}$?
            \bigbreak \noindent 
            We could check the first few cases by hand
            \begin{center}
                \begin{tabular}{c|c|c}
                    $A$& $\abs{A} = n$ & $\abs{\mathcal{P}(A)}$ \\
                    \hline
                    $\{1\}$ & $1$ & 2 \\
                    $\{1,2\}$ & 2 & 4 \\
                    $\{1,2,3\}$ & 3 & 8 \\
                    $\{1,2,3,4\}$ & 4 & 16
                \end{tabular}
            \end{center}
            \bigbreak \noindent 
            It sure looks like if $|A| = n$, then $|P(A)| = 2^n$.  Why would this be true? There is actually a pretty slick way to see it. Every subset  of $\{1, 2, 3\}$ can be thought of by asking whether or not each element is included in the  subset. For example, $\{1, 3\}$ can be thought of as $\langle \text{yes, no, yes} \rangle$, since 1 was included,  2 was not, and 3 was.
            \bigbreak \noindent 
            Suppose you’re trying to generate a subset of $\{1, 2, 3\}$. You could think about  doing so by asking three yes/no questions, the answers to which uniquely determine  your set. With 2 options for the first element, 2 for the second, and 2 for the third, in  total there are $2 \times 2 \times 2 = 8$ ways to answer the three questions, and hence 8 subsets!
            \bigbreak \noindent 
            With $n$ straight yes/no questions, there are $2 \times 2 \times \cdots \times 2 = 2^n$ ways to answer  the questions, each corresponding uniquely to a subset of $A$. Thus, if $|A| = n$, then  $|P(A)| = 2^n$.
        \item \textbf{A consequence of the above fact}:
            \bigbreak \noindent 
            \textbf{Proposition}. Given any $A \subseteq \{1, 2, 3, \ldots, 100\}$ for which $|A| = 10$, there  exist two different subsets $X \subseteq A$ and $Y \subseteq A$ for which the sum of the elements  in $X$ is equal to the sum of the elements in $Y$.
            \bigbreak \noindent 
            For example, consider the set $\{6, 23, 30, 39, 44, 46, 62, 73, 90, 91\}$, If we let 
            \begin{align*}
                X = \{6, 23, 46, 73, 90\} \text{ and } Y = \{30, 44, 73, 91\}
            .\end{align*}
            then the elements in both sets sum to $238$:
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We prove this fact using the pigeonhole principle. Consider the smallest and largest possible subset sums. If $A = \varnothing \subseteq \{1,2,3,...,100\} $, then the sum is $0$. If $A = \{91,92,93,94,95,96,97,98,99,100\} $, then the subset sum is $955$. Thus, there are no more than $956$ possible subset sums for the set $A \subseteq \{1,2,3,...,100\} $, for which $\abs{A} = 10$.
            \bigbreak \noindent 
            Consider $956$ boxes, each representing a unique subset sum. Since we have $2^{\abs{A}} = 2^{10} = 1024$ subsets and only $956$ boxes to place each subset in, there must be a box containing two subsets $A$, which means they must have the same sum $\quad \blacksquare$.
        \item \textbf{The symmetric difference of sets}. The \textit{symmetric difference} of two sets $A$ and $B$, denoted $A \Delta B $, or $A \ominus B$, is the set which contains the elements which are either in set $A$ or in set $B$ but not in both 

    \end{itemize}

    \pagebreak 
    \subsection{Induction}
    \begin{itemize}
        \item \textbf{Dominoes}: Consider a line of dominoes, perfectly arranged, just waiting to be knocked over. Dominoes stacked up like this have the following properties:
            \begin{enumerate}
                \item If you give the first domino a push, it will fall (in particular, it will fall into the second domino, knocking it over).
                \item Moreover, every domino, when it’s knocked over, falls into the next one and knocks it over.
            \end{enumerate}
            Given these two properties, it must be the case that if you knock over the first domino, then every domino will eventually fall. The first premise gets the process going, as it implies that the first domino will fall. And then the second premise keeps it going: Applying the second premise means that the falling first domino will cause the second domino to fall. Applying the second premise again means that the second falling domino will cause the third domino to fall. Applying the second premise again means that the third falling domino will cause the fourth domino to fall. And so on.
        \item \textbf{Sum of the first $n$  odd numbers}: Take a look at the following
            \begin{align*}
                1 = 1 &= 1^{2} \\
                1 + 3 = 4 &= 2^{2}\\
                1 + 3 + 5 = 9 &= 3^{2}\\
                1 + 3 + 5 + 7 = 16 &= 4^{2}\\
                1 + 3 + 5 + 7 + 9 = 25 &= 5^{2}\\
                1 + 3 + 5 + 7 + 9 + 11 = 36 &= 6^{2}\\
                1 + 3 + 5 + 7 + 9 + 11 + 13 = 49 &= 7^{2}
            .\end{align*}
            \bigbreak \noindent 
            It sure looks like the sum of the first $n$ odd numbers is $n^{2}$. But how can we prove that it’s true for every one of the infinitely many $n$? The trick is to use the domino idea. Imagine one domino for each of the above statements.
            \bigbreak \noindent 
            \fig{.7}{./figures/7.png}
            \bigbreak \noindent 
            Suppose we do the following:
            \begin{itemize}
                \item Show that the first domino is true (this is trivial, since obviously $1=1^{2} $).
                \item Show that any domino, if true, implies that the following domino is true too
            \end{itemize}
            Given these two, we may conclude that all the dominoes are true. It’s exactly the same as noting that all the dominoes from earlier will fall. This is a slick way to prove infinitely many statements all at once, and it is called the \textit{principle of mathematical induction}, or, when among friends, it is simply called \textit{induction}.
        \item \textbf{Induction}: Consider a sequence of mathematical statements, $S_{1}, S_{2}, S_{3}, . . . .$
            \begin{itemize}
                \item Suppose $S_{1}$ is true, and
                \item Suppose, for each $k \in \mathbb{N}$, if $S_{k}$ is true then $S_{k+1}$ is true.
            \end{itemize}
            Then, $S_{n} $ is true for every $n\in \mathbb{N}$.
        \item \textbf{Induction framework}:
            \bigbreak \noindent 
            \textbf{Proposition}. $S_{1}, S_{2}, S_{3},... $ are all true
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} \textit{General setup or assumptions if needed}
            \penv{
                \textit{Base case.} $\left\langle\left\langle \text{Demonstration that $S_{1}$ is true} \right\rangle\right\rangle$
                \bigbreak \noindent 
                \textit{Inductive hypothesis}. Assume that $S_{k}$ is true
                \bigbreak \noindent 
                \textit{Induction step}. $\left\langle \left\langle \text{Proof that $S_{k}$ implies $S_{k+1} $} \right\rangle \right\rangle $
            }
            \textit{Conclusion}. Therefore, by induction, all the $S_{n}$ are true. \hspace{5cm} $\blacksquare $
        \item \textbf{Induction example 1}: Let’s simply sum the first $n$ natural numbers: $1 + 2 + 3 + 4 + · · · + n$. These sums are called the triangular numbers since they can be pictured as the number of balls in the following triangles.
            \bigbreak \noindent 
            \fig{.6}{./figures/8.png}
            \bigbreak \noindent 
            \textbf{Proposition.} For any $n\in \mathbb{N}$, $\sum_{i=1}^{n} i = 1 + 2 + 3 + \ldots + n = \frac{n(n+1)}{2} $
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by induction
            \penv{
                \underline{Base case:} The base case is when $n=1$, and
                \begin{align*}
                    1 = \frac{1(1+1)}{2} = 1
                .\end{align*}
                \bigbreak \noindent 
                \underline{Inductive hypothesis}: Let $k\in \mathbb{N}$, assume 
                \begin{align*}
                    1 + 2 + 3 + ... + k = \frac{k(k+1)}{2}
                .\end{align*}
                \bigbreak \noindent 
                \underline{Inductive step}: We aim to show that the result holds for $k+1$. Thus,
                \begin{align*}
                    1+ 2 + 3 + ... + k+k+1 = \frac{(k+1)((k+1)+1)}{2} 
                .\end{align*}
                We have
                \begin{align*}
                    1 + 2 + 3 + ... + k + k+1 &= \frac{(k+1)(k+2)}{2}  \\
                    \implies \frac{k(k+1)}{2} + k+1 &= \frac{(k+1)(k+2)}{2} \\
                    \implies \frac{k^{2} + k + 2k + 1}{2} &= \frac{k^{2} + 2k + k + 2}{2}
                .\end{align*}
            }
            Therefore, by induction, $1+2+3+...+n = \frac{n(n+1)}{2} $ for all $n\in \mathbb{N} \quad \blacksquare$
        \item \textbf{Induction example 2}: 
            \bigbreak \noindent 
            \textbf{Proposition}. Let $S_{n}$ be the sum of the first $n$ natural numbers. Then, for any $n \in \mathbb{N}$,
            \begin{align*}
                S_{n} + S_{n+1} = (n+1)^{2}
            .\end{align*}
            \bigbreak \noindent 
            We will prove this proposition twice. The first proof is a direct proof, the second will be by induction.
            \bigbreak \noindent 
            \textbf{\textit{Direct proof.}} We have
            \begin{align*}
                S_{n} + S_{n+1} &= \frac{n(n+1)}{2} + \frac{(n+1)((n+1)+1)}{2} \\
                                &= \frac{n^{2} + n}{2} + \frac{n^{2} + 2n + n + 2}{2} \\
                                &= \frac{n^{2} + n + n^{2} + 3n + 2}{2} \\
                                &= \frac{2n^{2} + 4n + 2}{2} \\
                                &= \frac{2(n^{2} + 2n + 1)}{2} \\
                                &= n^{2} + 2n + 1 \\
                                &= (n+1)^{2} \quad \blacksquare
            .\end{align*}
            \pagebreak \bigbreak \noindent 
            \textbf{\textit{Proof by induction}}. We proceed by induction
            \penv{
                \underline{Base case}: The base case is when $n=1$, and 
                \begin{align*}
                    S_{1} + S_{2} = 1 + 3 = 4 = (1+1)^{2}
                .\end{align*}
                as desired
                \bigbreak \noindent 
                \underline{Inductive hypothesis}. Let $k\in\mathbb{N}$, and assume that 
                \begin{align*}
                    S_{k} + S_{k+1} = ( k+1)^{2}
                .\end{align*}
                \bigbreak \noindent 
                \underline{Inductive step}. We aim to prove that the result holds for $k+1$. That is, 
                \begin{align*}
                    S_{k+1} + S_{k+2} = (k+2)^{2}
                .\end{align*}
                For this, we use the fact that $S_{k+1} $ is the sum of the first $k+1$ natural numbers, thus we can write it as $S_{k} + (k+1)$. Likewise, $S_{k+2} = S_{k+1} + (k+2)$. Thus,
                \begin{align*}
                    S_{k+1} + S_{k+2} &= S_{k} + (k+1) + S_{k+1} + (k+2) \\
                                      &= S_{k} + S_{k+1} + 2k+3 \\
                                      &=(k+1)^{2} + 2k + 3\\
                                      &= k^{2} + 2k + 1 + 2k + 3 \\
                                      &= k^{2} + 4k + 4 \\
                                      &= (k+2)^{2}
                .\end{align*}
            }
            \underline{Conclusion.} Therefore, by induction, the proposition holds for all $n\in \mathbb{N} \quad \blacksquare$
        \item \textbf{A quick note about induction}: For some proof techniques, adding a sentence at the end of your proof is nice but not required. For induction, though, it really is required. You can prove that the first domino will fall, and you can prove that each domino — if fallen— will knock over the next domino, but why does this mean they all fall? Because induction says so! Until you say “by induction. . . ” your work will not officially prove the result
        \item \textbf{Induction example 3.}
            \bigbreak \noindent 
            \textbf{Proposition.} For every $n \in N$, the product of the first $n$ odd natural numbers equals $\frac{(2n)!}{2^{n}n!} $. That is, 
            \begin{align*}
                1 \cdot  3 \cdot 5 \cdot ... \cdot (2n-1) = \frac{(2n)!}{2^{n}n!}
            .\end{align*}
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by induction.
            \bigbreak \noindent 
            \underline{Base case:} The base case occurs when $n=1$, 
            \begin{align*}
                1 = \frac{(2(1))!}{2^{1}1!} = 1
            .\end{align*}
            As desired
            \bigbreak \noindent 
            \underline{Inductive hypothesis}. Let $k\in \mathbb{N}$, assume
            \begin{align*}
                1 \cdot 3 \cdot 5 \cdot ... \cdot (2k-1) = \frac{(2k)!}{2^{k}k!}
            .\end{align*}
            \bigbreak \noindent 
            \underline{Inductive step}. We aim to prove that the result holds for $k+1$. Thus, we wish to show
            \begin{align*}
                1 \cdot 3 \cdot 5 \cdot ... \cdot (2k-1) \cdot (2(k+1)-1) &= \frac{(2(k+1))!}{2^{k+1}(k+1)!}\\
                                                                          &=\frac{(2k+2)!}{2^{k+1}(k+1)!}
            .\end{align*}
            By the inductive hypothesis, we have
            \begin{align*}
                1 \cdot 3 \cdot 5 \cdot ... \cdot (2k-1) \cdot (2k+1) &= \frac{(2k)!}{2^{k}k!}(2k+1) \\
                                                                      &= \frac{(2k)!(2k+1)}{2^{k}k!} \\
                                                                      &= \frac{(2k+1)!}{2^{k}k!} \\
                                                                      &=\frac{(2k+1)!}{2^{k}k!} \cdot \frac{(2k+2)}{(2k+2)} \\
                                                                      &= \frac{(2k+2)!}{2^{k}k!(2k+2)} \\
                                                                      &= \frac{(2k+2)!}{2^{k}k! \cdot 2(k+1)} \\
                                                                      &= \frac{(2k+2)!}{2^{k+1}(k+1)!}
            .\end{align*}
            Therefore, by induction, the proposition holds for all $n\in \mathbb{N} \quad \blacksquare$
        \item \textbf{Induction example 4}. 
            \bigbreak \noindent 
            \textbf{Proposition.} For every $n \in \mathbb{N}$, if any one square is removed from a $2^n \times 2^n$ chessboard, the result can be perfectly covered with $\text{L}$-shaped tiles.
            \bigbreak \noindent 
            The tiles cover three squares and look like this:
            \bigbreak \noindent 
            \fig{1}{./figures/9.png}
            \bigbreak \noindent 
            Since the proposition refers to something being true “for every \( n \in \mathbb{N} \),” that’s a pretty good indication that induction is the way to proceed. The base case (when \( n = 1 \)) will be fine. For the inductive hypothesis, we will be assuming that any \( 2^k \times 2^k \) board, with one square removed, can be perfectly covered by L-shaped tiles.
            \bigbreak \noindent 
            In the induction step we are going to consider a $2^{k+1} \times 2^{k+1}$ board — a board that is twice as big in each dimension— with one square missing.
            \pagebreak \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by induction
            \bigbreak \noindent 
            \penv{
                \underline{Base Case}. The base case is when $n = 1$, and among the four possible squares that one can remove from a $2 \times 2$ chessboard, each leaves a chessboard which can be perfectly covered by a single $L$-shaped tile:
                \bigbreak \noindent 
                \fig{.9}{./figures/10.png}
                \bigbreak \noindent 
                \underline{Inductive Hypothesis}. Let $k \in \mathbf{N}$, and assume that if any one square is removed from a $2^{k} \times 2^{k}$ chessboard, the result can be perfectly covered with $L$–shaped tiles.
                \bigbreak \noindent 
                \underline{Induction Step.} Consider a $2^{k+1} \times 2^{k+1}$ chessboard with any one square removed.  Cut this chessboard in half vertically and horizontally to form four $2^k \times 2^k$ chessboards.  One of these four will have a square removed, and hence, by the induction hypothesis, can be perfectly covered.
                \bigbreak \noindent 
                Next, place a single $L$-shaped tile so that it covers one square from each of the other three $2^{k} × 2^{k}$ chessboards, as shown in the picture below.
                \bigbreak \noindent 
                \fig{.7}{./figures/11.png}
                \bigbreak \noindent 
                Each of these other three $2^k \times 2^k$ chessboards can be perfectly covered by the  inductive hypothesis, and hence the entire $2^{k+1} \times 2^{k+1}$ chessboard can be perfectly covered.
                \bigbreak \noindent 
            }
            \textbf{Conclusion.} By induction, for every $n \in \mathbb{N}$, if any one square is removed from a  $2^n \times 2^n$ chessboard, the result can be perfectly covered with L-shaped tiles.
        \item \textbf{Another note about induction}: So far, in all of our examples we proved that a statement holds from all $n \in \mathbb{N}$.  
            The base case was $n = 1$ and in the inductive hypothesis we assumed that the result holds for some $k \in \mathbb{N}$.  
            \bigbreak \noindent 
            There are times where one instead wants to prove that a statement holds for only the natural numbers past some point.  
            For example, it is possible to prove the $p$-test by induction, a result that you might remember from your calculus class:
            \[
                \sum_{i=1}^\infty \frac{1}{i^n} \text{ converges for all integers } n \geq 2.
            \]
            To prove this result, the base case would be $n = 2$ and in the inductive hypothesis we would assume that the result holds for some $k \in \{2, 3, 4, 5, \ldots\}$.  
            \bigbreak \noindent 
            At other times, you may want to prove that a result holds for more than just the natural numbers.  
            For example, a result from combinatorics is that
            \[
                \sum_{i=1}^n \binom{n}{i} = 2^n \text{ holds for all integers } n \geq 0.
            \]
            Here, the base case is $n = 0$, and the inductive hypothesis is the assumption that this holds for some $k \in \{0, 1, 2, 3, \ldots\}$.
        \item \textbf{Strong induction idea}: The idea behind strong induction is that at the point when the 100th domino is the  next to get knocked down, you know for sure that all of the first 99 dominoes have  fallen, not just the 99th. Likewise, when you are proving some sequence of statements  $S_1, S_2, S_3, S_4, \ldots$, instead of just assuming that $S_k$ is true in order to prove $S_{k+1}$,  why not just assume that $S_1, S_2, \ldots, S_k$ are all true in order to prove $S_{k+1}$ — because  by the time you are proving $S_{k+1}$, you have shown them all to be true!
        \item \textbf{Strong induction}: Consider a sequence of mathematical statements, $S_{1}, S_{2}, S_{3}, ...$
            \begin{itemize}
                \item Suppose $S_1$ is true, and  
                \item Suppose, for any $k \in \mathbb{N}$, if $S_1, S_2, \ldots, S_k$ are all true, then $S_{k+1}$ is true.
            \end{itemize}
            Then $S_n$ is true for every $n \in \mathbb{N}$.
            \bigbreak \noindent 
            \textbf{Note:} In regular induction, you essentially use $S_1$ to prove $S_2$, and then $S_2$ to prove $S_3$,  and then $S_3$ to prove $S_4$, and so on. With strong induction, you use $S_1$ to prove $S_2$,  and then $S_1$ and $S_2$ to prove $S_3$, and then $S_1, S_2$, and $S_3$ to prove $S_4$, and so on.
        \item \textbf{Fundemental theorem of arithmetic}: If $n$ is an integer and $n \geq 2$,  then $n$ is either prime or composite. An integer $p$ is prime if $p \geq 2$ and its only  positive divisors are $1$ and $p$. A positive integer $n \geq 2$ that is not prime is called  composite, and is therefore one that can be written as $n = st$, where $s$ and $t$ are  integers smaller than $n$ but larger than $1$. And with that, it is time for a really big  and important result.
            \bigbreak \noindent 
            \textbf{Theorem 4.8 (Fundamental Theorem of Arithmetic).}  Every integer $n \geq 2$ is either prime or a product of primes.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by strong induction
            \pagebreak \bigbreak \noindent 
            \penv{
                \underline{Base case.} The base case occurs when $n=2$. Observe that $2\in \mathbb{P} $
                \bigbreak \noindent 
                \underline{Inductive hypothesis}. Let $k\in \mathbb{N}$ such that $k \geq 2$. Assume that the integers $2,3,4,...,k$ are either prime or a product of primes.
                \bigbreak \noindent 
                \underline{Induction step}. Next, we consider $k+1$. We aim to show that $k+1$ is either prime or a product of primes. Since $k+1$ is larger than one, it is either prime or composite. Consider these two cases separately. Case 1 is that $k+1$ is prime. In this case, our goal is achieved.
                \bigbreak \noindent 
                Case 2 is that $k+1$ is composite; that is, $k+1$ has positive factors other than one and itself. Say, $k+1 = st$, where $s,t$ are positive integers greater than zero, and  
                \begin{align*}
                    1 < s < k+1 \quad 1<t<k+1
                .\end{align*}
                By the inductive hypothesis, both $s$ and $t$ can be written as a product of primes, say
                \begin{align*}
                    s &= p_{1} \cdot p_{2} \cdot ... \cdot p_{m} \\
                    t &= q_{1} \cdot q_{2} \cdot  ... \cdot q_{\ell}
                .\end{align*}
                Where each $p_{i}, q_{j} \in \mathbb{P}$, then 
                \begin{align*}
                    k + 1 = st = (p_{1} \cdot p_{2} \cdot ... \cdot p_{m})(q_{1} \cdot q_{2} \cdot  ... \cdot q_{\ell})
                .\end{align*}
                \bigbreak \noindent 
                Is written as a product of primes
                \bigbreak \noindent 
                Note that if $s$ or $t$ where prime, then $m$ or $\ell$ would be one. Say $s$ was prime, then $s = p_{1} $
                \bigbreak \noindent 
                \textbf{Conclusion}. By strong induction, every positive integer larger than 2 can be written as a product of primes.
            }
        \item \textbf{Chocolate bar example}:
            \bigbreak \noindent 
            \textbf{Proposition.} Suppose you have a chocolate bar that is an $m \times n$ grid of squares. The entire bar, or any smaller rectangular piece of that bar, can be broken along the vertical or horizontal lines separating the squares. 
             
            The number of breaks to break up that chocolate bar into individual squares is precisely $mn - 1$.
            \bigbreak \noindent 
            \textbf{\textit{Proof.}} We proceed by strong induction
            \penv{
                \underline{Base case}: The base case occurs when $n=1$, which is an $1\times 1$ chocolate bar. Since the number of breaks needed to break the bar into individual squares is clearly zero, we have
                \begin{align*}
                    0 = 1(1) -1 = 0
                .\end{align*}
                As desired
                \bigbreak \noindent 
                \underline{Inductive hypothesis}: Let $k\in\mathbb{N}$, assume that all bars with at most $k$ squares satisfy the proposition.
                \bigbreak \noindent 
                \underline{Induction step}: Consider now any bar with $k+1$ squares, suppose this bar has dimensions $m\times n $. Consider an arbitrary first break, and suppose the two smaller bars have $a$ squares and $b$ squares, respectively. Note that we must have $a + b = mn$, because the number of squares in the smaller bars must add up to the number of squares in the original $m \times n$ bar.
                \bigbreak \noindent 
                By the inductive hypothesis, the bar with $a$ squares will require $a − 1$ breaks to completely break it up, and the bar with $b$ breaks will require $b−1$ breaks. Therefore, to break up the $m \times n$ bar, we must make a first break, followed by $(a − 1) + (b − 1)$ additional breaks. The total number of breaks is then
                \begin{align*}
                    1 + (a-1) + (b-1) &= a+b-1 \\
                                      &=mn - 1
                .\end{align*}
                And $mn − 1$ is indeed one less than the number of squares in the $m \times n$ bar.
                \bigbreak \noindent 
            }
            \underline{Conclusion}. By strong induction, a chocolate bar of any size requires one break less than its number of squares to break it up into individual squares $\quad \blacksquare $
            \bigbreak \noindent 
            \textbf{Note:} What if the pieces were in the shape of a triangle? If it had $T$ squares would it still require $T - 1$ breaks?
            \bigbreak \noindent 
            What about other shapes? What if there are pieces missing in the middle? Interestingly, the answer is $T - 1$ no matter the bar’s shape, and even if pieces are missing! As long as each of your “breaks” divides one chunk into two, that’s the answer.
            \bigbreak \noindent 
            Here is some intuition for that: No matter the shape, the bar starts out as a  
            single “chunk” of chocolate, and after your sequence of breaks the bar is broken into  
            $T$ chunks of chocolate — the $T$ individual squares. How many breaks does it take to  
            move from 1 chunk to $T$ chunks? Notice that every break increases the number of  
            chunks by 1. So after 1 break, there will be 2 chunks. After 2 breaks, there will be 3  
            chunks. And so on. Thus, after $T - 1$ breaks there will be $T$ chunks, which is why  
            $T - 1$ breaks is guaranteed to be the answer, no matter which shape you started with.

        \item \textbf{Multiple base cases}: When proving the $(k + 1)$st case within the induction step, strong induction allows  you to apply not just the $k$th step, but any of the steps $1, 2, 3, \ldots, k$. In the previous  two examples, you had no idea which earlier steps you will need, so it was vital that  you assumed them all. At times, though, you really only need, say, the previous two  steps. The $k$th step is perhaps not enough, but the $(k - 1)$st step and the $k$th step is  guaranteed to be enough.
            \bigbreak \noindent 
            If you rely on the two previous steps, then that is analogous to saying that it takes the previous two dominoes to knock over the next one. Thus, if you knock over dominoes 1 and 2, then they will collectively knock over the third. Then, since the second and third have fallen, those two will collectively knock over the fourth. Then the third and fourth will knock over the fifth. And so on. Thus, the induction relies on two base cases, because without knocking over the first two the third won’t fall and the process won’t begin
            \bigbreak \noindent 
            \textbf{Example:} 
            \bigbreak \noindent 
            \textbf{Proposition.} Every $n \in N$ with $n \geq 11$ can be written as $2a + 5b$ for some natural numbers $a$ and $b$.
            \bigbreak \noindent 
            \textbf{Base Cases.} In the induction step, we will need two cases prior, so we show two base  
            cases here: $n = 11$ and $n = 12$. Both of these can be written as asserted:
            \[
                11 = 2 \cdot 3 + 5 \cdot 1 \\
                12 = 2 \cdot 1 + 5 \cdot 2.
            \]
            \textbf{Inductive Hypothesis.} Assume that for some integer $k \geq 12$, the results hold for  
            \[
                n = 11, 12, 13, \ldots, k.
            \]
            \textbf{Induction Step.} We aim to prove the result for $k + 1$. By the inductive hypothesis,  
            \[
                k - 1 = 2a + 5b
            \]
            for some $a, b \in \mathbb{N}$. Adding 2 to both sides,
            \[
                k + 1 = 2(a + 1) + 5b.
            \]
            Observe that $(a + 1) \in \mathbb{N}$ and $b \in \mathbb{N}$, proving that this is indeed a representation of  
            $(k + 1)$ in the desired form.
            \bigbreak \noindent 
            \textbf{Conclusion.} Therefore, by strong induction, every integer $n \geq 11$ can be written as  
            the proposition asserts. \(\blacksquare\)
            \pagebreak 
        \item \textbf{False proofs with induction}: 
            \bigbreak \noindent 
            \textbf{Proposition}. Everyone on Earth has the same name
            \bigbreak \noindent 
            \textit{Fake Proof.} We will consider groups of $n$ people at a time, and by induction we will  
            ``prove'' that for every $n \in \mathbb{N}$, every group of $n$ people must have everyone with the  
            same name.
            \penv{
                \textbf{Base Case.} If $n = 1$, then of course everyone in the group has the same name, since  
                there’s only one person in the group!
                \bigbreak \noindent 
                \textbf{Inductive Hypothesis.} Let $k \in \mathbb{N}$, and assume that any group of $k$ people all have  
                the same name.
                \bigbreak \noindent 
                \textbf{Induction Step.} Consider a group of $k + 1$ people.
                \bigbreak \noindent 
                \fig{.7}{./figures/12.png}
                \bigbreak \noindent 
                But notice that we can look at the first $k$ of these people and then the last $k$ of these people, and to each of these groups we can apply the inductive hypothesis:
                \bigbreak \noindent 
                \fig{.7}{./figures/13.png}
                \bigbreak \noindent 
                And the only way that this can all happen, is if all $k + 1$ people have the same name.
            }
            Conclusion. This “proves” by induction that for every $n \in N$, every group of $n$ people must have the same name. So if you let $n$ be equal to the number of people on Earth, this “proves” that everyone has the same name.
            \bigbreak \noindent 
            For $k+1$ people, the proof assumes that you can take the first $k$ people and the last  
            $k$ people, and both of these subsets must have the same name because the induction  
            hypothesis applies to them individually.  
            \bigbreak \noindent 
            However, this reasoning fails when $k+1 = 2$. For $k+1 = 2$, the first subset has one  
            person, and the second subset also has one person. These subsets do not overlap, so  
            there is no logical connection ensuring that these two people share the same name.
            \bigbreak \noindent 
            The induction relies on overlapping subsets of $k$ people to conclude that all $k+1$ people  must have the same name. However, this overlap only works if $k+1 > 2$, meaning the proof  doesn't actually establish the result for $k+1 = 2$, which breaks the induction chain.  Without the foundation for $n = 2$, the argument fails for all larger $n$.
        \item \textbf{Induction bonus example 1}.
            \bigbreak \noindent 
            \textbf{Lemma 4.13}. For every $n\in \mathbb{N}_{0} $,
            \begin{align*}
                1 + 2 + 4 + 8 + ... + 2^{n} = 2^{n+1}-1
            .\end{align*}
            For example, 
            \begin{align*}
                1 &= 2^{1}-1 \\
                1 + 2 &= 2^{2}-1 \\
                1 + 2 + 4 &= 2^{3}-1 \\
                1 + 2 + 4 + 8 &= 2^{4}-1
            .\end{align*}
            \penv{
                \underline{Base case}. The base case occurs when $n=1$, we have
                \begin{align*}
                    1 = 2^{1}-1 = 1
                .\end{align*}
                As desired
                \bigbreak \noindent 
                \underline{Inductive hypothesis}. Let $k\in \mathbb{N}_{0}$, assume that
                \begin{align*}
                    1 + 2 + 4 +... + 2^{k} = 2^{k+1}-1
                .\end{align*}
                \bigbreak \noindent 
                \underline{Induction step}. We wish to show that the result holds for $k+1$. That is, 
                \begin{align*}
                    1 + 2 + 4+ ... + 2^{k} + 2^{k+1} = 2^{(k+1)+1}-1 = 2^{k+2} -1
                .\end{align*}
                By the inductive hypothesis, we have
                \begin{align*}
                    1 + 2 + 4 + ... + 2^{k} + 2^{k+1} &= 2^{k+1}-1 + 2^{k+1} \\
                                                      &=2(2^{k+1})-1 \\
                                                      &=2^{k+2} -1
                .\end{align*}
                As desired

            }
            \bigbreak \noindent 
            Therefore, by induction, the proposition holds for all $n\in \mathbb{N}_{0} $
            \bigbreak \noindent 
        \item \textbf{Induction bonus example 2}. \textbf{Proof.} We proceed by strong induction.
            \textbf{Base Case.} Our base case is when \( n = 1 \). Note that 1 can be written as \( 2^0 \), and this is the only way to write 1 as a sum of distinct powers of 2, because all other powers of 2 are larger than 1.
            \bigbreak \noindent 
            \textbf{Inductive Hypothesis.} Let \( k \in \mathbb{N} \), and assume that each of the integers \( 1, 2, 3, \dots, k \) can be expressed as a sum of distinct powers of 2 in precisely one way.
            \bigbreak \noindent 
            \textbf{Induction Step.} We now aim to show that \( k+1 \) can be expressed as a sum of distinct powers of 2 in precisely one way.
            \bigbreak \noindent 
            Let \( 2^m \) be the largest power of 2 such that \( 2^m \leq k+1 \). We now consider two cases: the first is if \( 2^m = k+1 \), and the second is if \( 2^m < k+1 \).
            \bigbreak \noindent 
            \textbf{Case 1:} \( 2^m = k+1 \). If this occurs, then \( 2^m \) itself is a way to express \( k+1 \) as a (one-term) sum of distinct powers of 2. Moreover, there is no other way to express \( k+1 \) as a sum of distinct powers of 2, because by Lemma 4.13 all smaller powers of 2 sum to \( 2^m - 1 = k \). Thus, even by including all smaller powers of 2, we are unable to reach \( k+1 \). So, in Case 1, there is precisely one such expression for \( k+1 \).
            \bigbreak \noindent 
            \textbf{Case 2:} \( 2^m < k+1 \). In order to apply the inductive hypothesis, we will consider \( (k+1) - 2^m \). First, note that \( (k+1) - 2^m \) is less than \( 2^m \), because otherwise \( k+1 \) would have two copies of \( 2^m \) within it, implying that \( 2^m + 2^m \leq k+1 \). However, since \( 2^m + 2^m = 2 \cdot 2^m = 2^{m+1} \), this would mean \( 2^{m+1} \leq k+1 \). This can't be, since \( 2^m \) was chosen to be the largest power of 2 that is at most \( k+1 \). Thus, it must be the case that \( (k+1) - 2^m < 2^m \).
            \bigbreak \noindent 
            Next, by the inductive hypothesis, \( (k+1) - 2^m \) can be expressed as a sum of distinct powers of 2 in precisely one way, and since \( (k+1) - 2^m < 2^m \), this unique expression for \( (k+1) - 2^m \) will not contain a \( 2^m \). Thus, by adding a \( 2^m \) to it, we obtain an expression for \( k+1 \) as a sum of powers of 2. And this expression is unique because \( (k+1) - 2^m \) is unique according to the inductive hypothesis, and the \( 2^m \) portion is unique because, again by Lemma 4.13, even if you summed all of the smaller powers of 2, you will not reach \( 2^m \).
            \bigbreak \noindent 
            \textbf{Conclusion.} By strong induction, every \( n \in \mathbb{N} \) can be expressed as a sum of distinct powers of 2 in precisely one way. \(\Box\)
        \item \textbf{Induction bonus example 3.}
            \bigbreak \noindent 
            \textbf{Theorem 4.15 (\textit{The binomial theorem})}. For $x,y \in \mathbb{R}$, and $n\in \mathbb{N}_{0} $
            \begin{align*}
                (x+y)^{n} = \sum_{m=0}^{n}\binom{n}{m} x^{n-m}y^{m}
            .\end{align*}
            Here, when $n \geq m$, the binomial coefficient $\binom{n}{m}$ is defined to be 
            \[
                \binom{n}{m} = \frac{n!}{m!(n-m)!},
            \]
            which one can show is always an integer. The binomial coefficients can also be defined combinatorially: $\binom{n}{m}$ is equal to the number of ways to choose $m$ elements from an $n$-element set; in fact, $\binom{n}{m}$ is read "n choose m." For example, 
            \[
                \binom{4}{2} = 6
            \]
            because there are six subsets of the set $\{1, 2, 3, 4\}$ containing two elements:
            \[
                \{1, 2\}, \{1, 3\}, \{1, 4\}, \{2, 3\}, \{2, 4\}, \{3, 4\}.
            \]
            Binomial coefficients can be computed iteratively using \textit{Pascal's rule}, which says that
            \[
                \binom{n}{r} = \binom{n-1}{r-1} + \binom{n-1}{r},
            \]
            as well as the fact that
            \[
                \binom{n}{0} = 1 \quad \text{and} \quad \binom{n}{n} = 1 \quad \text{for all } n \in \mathbb{N}_0.
            \]
            A beautiful way to combine these facts is called \textit{Pascal's triangle}:
            \bigbreak \noindent 
            \fig{.6}{./figures/15.png}
            \bigbreak \noindent 
            Indeed, we can even prove the binomial theorem by induction, by making use of Pascal’s rule. Here is a sketch of that proof:
            \bigbreak \noindent 
            \textbf{\textit{Proof sketch}}. The base case is when $n = 0$, and indeed $(x + y)^0 = 1$. The next couple cases are more interesting, and you can check that $(x + y)^1 = x + y$ and $(x + y)^2 = x^2 + 2xy + y^2$ do indeed match the theorem. The inductive hypothesis will be
            \[
                (x + y)^k = x^k + \binom{k}{1}x^{k-1}y + \binom{k}{2}x^{k-2}y^2 + \cdots + \binom{k}{k-1}xy^{k-1} + y^k.
            \]
            For the induction step, we perform easy algebra, then apply the inductive hypothesis, then perform hard algebra, then apply Pascal's rule:
            \[
                (x + y)^{k+1} = (x + y)(x + y)^k
            \]
            \[
                = (x + y) \left[ x^k + \binom{k}{1}x^{k-1}y + \binom{k}{2}x^{k-2}y^2 + \cdots + \binom{k}{k-1}xy^{k-1} + y^k \right]
            \]
            \[
                = x^{k+1} + \left[\binom{k}{0}\right]x^k y + \left[\binom{k}{1}\right]x^{k-1}y^2 + \cdots + \left[\binom{k}{k}\right]xy^k + y^{k+1}
            \]
            \[
                = x^{k+1} + \binom{k+1}{1}x^k y + \binom{k+1}{2}x^{k-1}y^2 + \cdots + \binom{k+1}{k}xy^k + y^{k+1}.
            \]
            And that—a few boring algebraic details omitted—is the proof.
            \bigbreak \noindent 
            The binomial theorem tells us that in order to expand $(x + y)^5$ you can just look at the 5th row of Pascal’s triangle (where the top element counts as the $0$th row, so the 5th row is $1 \ 5 \ 10 \ 10 \ 5 \ 1$):
            \[
                (x + y)^5 = 1x^5 + 5x^4y + 10x^3y^2 + 10x^2y^3 + 5xy^4 + 1y^5.
            \]
            Moreover, by plugging in special values for $x$ and $y$, all sorts of neat identities pop out. There are loads of examples of this, but here are just three:
            \begin{itemize}
                \item By plugging in $x = 1$, $y = 1$, we prove $\sum_{k=0}^n \binom{n}{k} = 2^n$.
                \item By plugging in $x = 2$, $y = 1$, we prove $3^n = \sum_{k=0}^n \binom{n}{k}2^k$.
                \item By plugging in $x = -1$, $y = 1$, we prove $0 = \sum_{k=0}^n (-1)^k \binom{n}{k}$.
            \end{itemize}
        % \item \textbf{Fermat's little theorem with 4.15}:
        %     \bigbreak \noindent 
        %     \textbf{Theorem}. If $a$ is a natural number and $p$ is a prime which does not divide $a$, then
        %     \begin{align*}
        %         a^{p} \equiv a \pmod{p}
        %     .\end{align*}
        %     \textbf{Note: } Written just slightly differently by multiplying each side of the congruence by a, which can also be undone by using the cancellation law



    \end{itemize}

    \pagebreak 
    \subsection{Logic}
    \begin{itemize}
        \item \textbf{Statements}: A statement is a sentence or mathematical expression that is either true or false. If the logic is valid and the statements are true, then it is called sound
            \bigbreak \noindent 
            Every theorem/proposition/lemma/corollary is a (true) statement; Every conjecture is a statement (of unknown truth value); and Every incorrect calculation is a (false) statement.
        \item \textbf{Open sentence}: 
            A related notion is that of an \textit{open sentence}, which refers to sentences or mathematical expressions that:
            \begin{enumerate}
                \item do not have a truth value,
                \item depend on some unknown, like a variable $x$ or an arbitrary function $f$, and
                \item when the unknown is specified, the open sentence becomes a statement (and thus has a truth value).
            \end{enumerate}
            Their truth value depends on the specific value of $x$ or $f$ that is chosen.
            \bigbreak \noindent 
            Typically, we use capital letters for statements, like $P$, $Q$ and $R $. Open sentences are often written the same, or perhaps like $P(x)$, $Q(x)$ or $R(x)$ when one wishes to emphasize the variabl

        \item \textbf{And, or, not}: Let $P$ and $Q$ be statements or open sentences.
            \begin{enumerate}
                \item $P \land Q$ means "P and Q".
                \item $P \lor Q$ means "P or Q (or both)".
                \item $\sim P$ means "not P".
            \end{enumerate}
        \item \textbf{Implies, iff}:
            Let $P$ and $Q$ be statements or open sentences.
            \begin{enumerate}
                \item $P \implies Q$ means "P implies Q".
                \item $P \iff Q$ means "P if and only if Q".
            \end{enumerate}
            \bigbreak \noindent 
            Let’s now discuss a subtle aspect of implications: Translating them to and from English. Language can be complicated,\footnote{Language nuances can make logical translation challenging.} and we in fact have many different ways in English to say “$P$ implies $Q$.” Here are some examples:
            \begin{itemize}
                \item If $P$, then $Q$
                \item $Q$ if $P$
                \item $P$ only if $Q$
                \item $Q$ whenever $P$
                \item $Q$, provided that $P$
                \item Whenever $P$, then also $Q$
                \item $P$ is a sufficient condition for $Q$
                \item For $Q$, it is sufficient that $P$
                \item For $P$, it is necessary that $Q$
            \end{itemize}
            For example, “If it is raining, then the grass is wet” has the same meaning as “The grass is wet if it is raining.” These also mean the same as “The grass is wet whenever it is raining” or “For the grass to be wet, it is sufficient that it is raining.”
            \bigbreak \noindent 
            Next, here are some ways to say “$P$ if and only if $Q$”:
            \begin{itemize}
                \item $P$ is a necessary and sufficient condition for $Q$.
                \item For $P$, it is necessary and sufficient that $Q$.
                \item $P$ is equivalent to $Q$.
                \item If $P$, then $Q$, and conversely.
                \item $P$ implies $Q$ and $Q$ implies $P$.
                \item Shorthand: $P$ iff $Q$.
                \item Symbolically: $(P \implies Q) \land (Q \implies P)$.
            \end{itemize}




    \end{itemize}


    \pagebreak 
    \unsect{Combinatorics}
    \bigbreak \noindent 
    \subsection{Introduction}
    \begin{itemize}
        \item \textbf{What is combinatorics?}: Combinatorics is a collection of techniques and a language for the study of finite or countably infinite discrete structures. Given a set of elements and possibly some structure on that set, typical questions are
            \begin{itemize}
                \item Does a specific arrangement of the elements exists?
                \item How many such arrangemets are there?
                \item What properties do these arrangements have?
                \item Which one of the arrangemetns is maximal, minimal, or optimal according to some criterion?
            \end{itemize}
        \item \textbf{Counting the number of subsets for a set}: Let $[n] = \{1,2,...,n\} $, and let $f(n)$ be the number of subsets of $[n]$. Then $f(n) = 2^{n}$. For any particular subset of $[n]$, each element is either in that subset or not. Thus, to construct a subset, we have to make one of two choices for each element of $[n]$. Furthermore, these choices are independent of each other. Hence, the total number of choices, and consequently the total number of subsets is 
            \begin{align*}
                \underbrace{2\times2\times...\times2}_{n} = 2^{n}
            .\end{align*}
        \item \textbf{Number of subsets without consecutive integers}: For a sequence $[n] = \{1,...,n\}$ we can count the number of subsets given by $f(n)$, that do not contain consecutive integers with the recurrence relation
            \begin{align*}
                f(n) = f(n-1) + f(n-2)
            .\end{align*}
            We consider two cases
            \begin{enumerate}
                \item $n$ in not included in the subsets
                \item $n$ is included in the subsets. In this case, we build the subsets considering the subsequence $[n-2]  = \{1,...,n-2\}$. Note that if we include $n$, we must exclude $n-1$, because $n-1$ and $n$ are consecutive, this will become cleare in the upcoming example.
            \end{enumerate}
            \bigbreak \noindent 
            Consider the sequence $[n] = \{1,2,3,4\}$. By the relation above, 
            \begin{align*}
                f(4) &= f(3) + f(2) 
            .\end{align*}
            Before we are able to compute this, we must define our base cases. 
            \begin{align*}
                f(n) &= \begin{cases}
                    3 & \text{if } n = 2 \\
                    2 & \text{if } n =1
                \end{cases}
            .\end{align*}
            If $n=2$, we have $\{1,2\}$, and the allowed subsets are $\varnothing, \{1\}, \{2\} $. If we have $n=1$, the subsets are $\{\varnothing, \{1\}\} $. Thus
            \begin{align*}
                f(4) &= f(3) + f(2) = f(2) + f(1) + f(2)  \\
                     &= 3 + 2 + 3 = 8               
            .\end{align*}
            Let's explicitly break up the given sequence so we can see whats going on. In the first case, $n$ is excluded, thus the sequence becomes $\{1,2,3\}$. If $n$ is included, the sequence becomes $\{1,2\}$, where we build the subsets of $\{1,2\}$, and then add 4 to each one. Thus,
            \begin{align*}
                \{1,2,3\} + \{1,2\} &= \{1,2,3\}  + \varnothing + \{1\} + \{2\} \\
                                    &= \{1,2,3\} + \{4\} + \{1,4\} + \{2,4\}
            .\end{align*}
            Since the sequence $\{1,2,3\}$ in not a base case, we must split this one up aswell, we have
            \begin{align*}
                \{1,2,3\} &= \{1,2\} + \{1\}  + \{4\} + \{1,4\} + \{2,4\} \\
                          &=  \varnothing + \{1\} + \{2\} + \varnothing + \{1\} + \{4\} + \{1,4\} + \{2,4\} \\
                          &= \varnothing + \{1\} + \{2\} + \{3\} + \{1,3\} + \{4\} + \{1,4\} + \{2,4\} 
            .\end{align*}
            Thus, we conclude all "good" subsets of $[n]$ either have $n$ or don't have $n$. The ones that don't have $n$ are exactly the "good" subsets of $[n-1]$. The "good" subsets of $[n]$ that include $n$ are exactly the "good" subsets of $[n-2]$ together with $n$. Thus $f(n) = f(n-1) + f(n-2) $ $\blacksquare$
            
    \end{itemize}

    \pagebreak 
    \subsection{Induction and recurrence relations}
    \begin{itemize}
        \item \textbf{Principal of Mathematical Induction}: Given an infinite sequence of propositions
            \begin{align*}
                P_{1}, P_{2}, P_{3},...P_{n},...,
            .\end{align*}
            In order to prove that all of them are true, it is enough to show two things
            \begin{enumerate}
                \item \textbf{The base case:} $P_{1}$ is true
                \item \textbf{The inductive step}: For all positive integers $k$, if $P_{k}$ is true, then so is $P_{k+1}$
            \end{enumerate}
            \bigbreak \noindent 
            \textbf{Example}: Show that 
            \begin{align*}
                1 + 2 + 3 + ... + n = \frac{n(n+1)}{2}
            .\end{align*}
            \textbf{Base case}:
            \begin{align*}
                1 &= \frac{1(1+1)}{2} = \frac{2}{2} = 1
            .\end{align*}
            \bigbreak \noindent 
            \textbf{Inductive step}: $P_{k}$ is given by
            \begin{align*}
                1 + 2 + 3 + ... + k = \frac{k(k+1)}{2}
            .\end{align*}
            \bigbreak \noindent 
            $P_{k+1}$ is given by
            \begin{align*}
                1 + 2 + 3 + ... + k + k+1 = \frac{k+1(k+2)}{2}
            .\end{align*}
            If $1+2+3+...+k  = \frac{k(k+1)}{2}$, then
            \begin{align*}
                1 + 2 + 3 + ... + k + k+1 &= \frac{k+1(k+2)}{2} \\
                \frac{k(k+1)}{2} + k + 1 &= \frac{k+1(k+2)}{2} \\
                \frac{k(k+1) + 2k + 2}{2} &= \frac{k^{2} + 3k + 2}{2} \\
                \frac{k^{2} + 3k  + 2}{2} &= \frac{k^{2} + 3k + 2}{2}
            .\end{align*}
            Thus, we have showed that $P_{k} \implies P_{k+1}$ $\blacksquare$.
            \bigbreak \noindent 
            \textbf{Note}: Our aim is not to directly prove $P_{k+1}$, but to prove that $P_{k}$ implies $P_{k+1}$. In the inductive step we assume $P_{k}$ to be true, then show under this assumption, $P_{k+1}$ is also true.
        \item \textbf{Understanding gauss's formula for the sum of the first $n$ natural numbers}: Suppose we want to find the sum $1+2+3+...+(n-1)+n$. We could have discovered the formula that we proved above by first writing the sum twice
            \begin{align*}
                &1 + 2  + 3 + ... + (n-1) + n \\
                &n + (n-1) + (n-2) + ... + 2 + 1
            .\end{align*}
            The sum of the two numbres in each column is $n+1$, and there are $n$ columns, so the total sum is $n(n+1)$, it then follows that the actual sum is $\frac{1}{2}n(n+1)$
        \item \textbf{Trianglular numbers}: The sequence of integers
            \begin{align*}
                &1
                &3 = 1+2 \\
                &6 = 1 + 2  + 3 \\
                &10 = 1 + 2 + 3 + 4 \\
                &15  = 1 + 2 + 3 + 4 + 5  \\
                &...
            .\end{align*}
            Are called \textit{triangular numbers}. If you were to make a triangle of dots out of the sum, where the highest number is the base, the second highest is the layer ontop of the base, etc, you would form a triangle.
        \item \textbf{Strong induction}: Given an infinite sequence of propositions
            \begin{align*}
                P_{1}, P_{2}, P_{3}, ..., P_{n}
            .\end{align*}
            In order to demonstrate that all of them are true, it is enough to know two things.
            \begin{enumerate}
                \item \textbf{The base case}: $P_{1}$ is true
                \item \textbf{The inductive step}: For all integers $k \geq 1$, if $P_{1}, P_{2}, P_{3},...,P_{k}$ are true, then so is $P_{k+1}$
            \end{enumerate}
        \item \textbf{Pingala-fibonacci numbers}: Define a sequence of positive integers as follows: $F_{0} = 0, F_{1} = 1$, and for $n=2,3,... $ we have
            \begin{align*}
                F_{n} = F_{n-2} + F_{n-1}
            .\end{align*}
            This sequence is also known as \textit{the fibonacci sequence}.
        \item \textbf{Lucas numbers}: Change the initial values on the fibonacci sequence. Let $L_{0} = 2, L_{1} = 1$, and $L_{n} = L_{n-2} + L_{n-1}$. Then, we get the \textit{Lucas numbers}
            \begin{align*}
                2,1,3,4,7,11,18,29,47,...
            .\end{align*}
        \begin{align*}
            \mathcal{L}
        .\end{align*}

    \end{itemize}















    
\end{document}
